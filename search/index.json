[{"content":"開頭 這陣子公司有個新需求，說要做一個短連結的功能，希望可以讓會員分享彼此之間的投資組合，例如我可以分享我的投資組合給別人，別人點進來後就可以看到我底下有什麼股票，然後後台要有地方紀錄每個用戶分享碼的訪問次數，然後還有QrCoed的功能，我當時心裡想\n「喔喔喔，那大概就是寫個Get API，最後Reponse用Http Code 303做重定向，location指定到用戶的投資組合前端頁面就可以了」\n於是我寫了一個大概這樣子的code出去\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  @GetMapping(\u0026#34;/portfolio/{uid}\u0026#34;) public ResponseEntity\u0026lt;Void\u0026gt; redirect(@PathVariable(\u0026#34;uid\u0026#34;) String uid) throws URISyntaxException { String baseUrl = \u0026#34;http://yahoofinancial/user/portfolio/\u0026#34;; //去檢查redis中有沒有這個uid的值  Integer integer = redisTool.getkeyValue(uid, Integer.class); if(integer!=null){ //如果有的話就+1  redisTool.setkeyValue(uid, integer + 1); return ResponseEntity.status(HttpStatus.TEMPORARY_REDIRECT).location(new URI(baseUrl+uid)).build(); } //沒有的話就去查看看有沒有這個人  if(integer==null){ //先去檢查資料庫真的有這個user  User user =userService.findByUid(uid); //如果有的話就+1  if(user!=null){ //為這個值+1，並放回redis中  redisTool.setkeyValue(uid, integer + 1); return ResponseEntity.status(HttpStatus.TEMPORARY_REDIRECT).location(new URI(baseUrl+uid)).build(); } //沒有就返回首頁給他  else{ return ResponseEntity.status(HttpStatus.TEMPORARY_REDIRECT).location(new URI(baseUrl)).build(); } } return ResponseEntity.status(HttpStatus.TEMPORARY_REDIRECT).location(new URI(baseUrl)).build(); }   然後在配置檔裡把這個API設成白名單，不需要登入就可以使用，接著跟前端配合，於是用戶按下了「分享我的投資組合」後，在前端頁面就會產生這樣的畫面\n然後QA過了沒問題，接著這東西就上生產了\n大佬反應 接著上生產的隔天，我就在大群裡被Tag了\n「Hoxton，你寫這什麼洨？」\n開玩笑的，大佬們不會這樣講，大意大概就是說，我這個縮網址的功能，根本沒有縮到什麼東西，還是很長，而且也沒有一個機制去處理用戶一直去洗分享碼，衝高分享次數的機制，並且邀請碼是用uid的方式去傳遞，很容易就會被用戶猜到，讓他們亂打，再加上我在第一步就去掃資料庫，並將Api設成白名單，換言之只要有人夠閒，他就可以用程式一直對我們伺服器發送I/O，一直打，打到我們崩潰。\n於是大佬提供了幾個要求，要我去處理\n 短網址太長，想辦法縮短 Api 不要直接用uid 要加密 不要讓用戶一直刷分享碼，衝高分享數  改進方式 短網址縮短 首先要解決的就是短網址太長這件事情，我原先是想說可以把api的prefix拆掉，但想想這方法真的有點太白癡了，我問了一下我的好同事，他建議我可以讓前端出一個頁面\nhttp://financa/sharecode/XXXXX\n短連結就是產生這個網址，當用戶訪問這個頁面時，會去打我的API，打完後再由前端轉頁面到他們投資組合的前端頁面，換言之，就是讓\napi/finance/profolio/share/{PathVariable}\n這個API不要再做轉網址的事情，轉網址的操作讓前端去處理，後端只需要專心去紀錄訪問量就好。\nUid加密 這個我其實一開始不太理解為啥要特地加密，原則上來說一個uid就是對應到一個base62，那這樣還有什麼意義嗎？後來發現針對uid加密實在是好處多多\n 可以在decrypt的時候就做參數檢查，不合規的直接reject掉，不需要經資料庫 因為1對1的關係，不需要再把加密後的base62存到資料庫中，如此一來也少了很多入庫檢索的操作，降低I/O開銷  由於這個加密的加入，可以說是從源頭上避免了很多惡意打API的操作\n阻擋有人一直刷分享數 這邊我的想法是，因為我們的前端會把用戶的ip request也帶進來，所以我把ip 跟 share code 放到redis中成為一個鍵，並把存續期間設成一小時，意即這個ip一小時只能增加這個share code一次分享數，如此一來，只要是同一個ip一小時內的訪問我就不紀錄+1，避免了重複刷的可能性\n更新完後的code長這樣\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  public ResponseEntity redirect(String shortUrl, Request request, User user){ String ip = request.getIp(); //這邊解密失敗就直接throw錯誤出去  String uid =DESEncrypt.decrypt(shortUrl, ENCRYPT_KEY); //這邊在用用戶的ip做判斷短連結的訪問次數  //我設置1小時作為單次訪問的區間  //意即相同的Ip 一小時內訪問只記錄一次  if(ip !=null){ String redisKey = String.format(SHARE_CODE_CACHE,uid,ip); Date date = redisTool.get(redisKey, Date.class); //如果redis中沒有date值，代表這個Ip過去一小時內沒有訪問過，將這個Ip加入到redis中，設置一小時到期時間(60*60)  //並將這個uid的訪問次數+1  if(date!=null){ //設置Ip key 的緩存，ttl為1小時，避免重複刷訪問次數  //key的value設置成new Date() 其實沒啥特別意義，但懶得改了，只要放個值進去都ok  redisTool.set(redisKey,new Date(),60*60); //判斷uid是否在redis中有紀錄訪問次數+1，如果有的話就加，沒的話就創建  ClcikStatisticDO clcikStatisticDO = redisTool.getObject(SHARE_CODE_CLICK, uid, ClcikStatistic.class); if (clcikStatisticDO != null) { clcikStatisticDO.setClickTime(clcikStatisticDO.getClickTime() + 1); clcikStatisticDO.setLastClickTime(new Date()); redisTool.put(SHARE_CODE_CLICK, uid, clcikStatisticDO); log.info(\u0026#34;Ip :{} 在 {}訪問了 會員 {} 的投資頁面，訪問數+1\u0026#34; ,ip,DateUtils.format(new Date(), \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;),clcikStatisticDO.getUsername()); } else { User user = userService.findById(uid); //找不到uid 那就直接回傳  if(User==null){ return builder.success().build(); } ClcikStatistic clcikStatistic = new ClcikStatistic(); clcikStatistic.setUsername(user.getUsername()); clcikStatistic.setShareCode(uid); clcikStatistic.setClickTime(1); clcikStatistic.setCreateTime(new Date()); clcikStatistic.setLastClickTime(new Date()); redisTool.put(SHARE_CODE_CLICK, uid, clcikStatistic); log.info(\u0026#34;Ip :{} 在 {}訪問了 會員 {} 的投資頁面，訪問數+1\u0026#34; ,ip,DateUtils.format(new Date(), \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;),user.getUsername()); } } } log.info(\u0026#34;Ip:{} 於 {} 訪問 {}\u0026#34;,ip,DateUtils.format(new Date(), \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;),uid); return ResponseEntity.ok().build(); }   ","date":"2024-06-21T14:08:42+08:00","image":"https://i.imgur.com/F9zafh3.png","permalink":"https://hoxtonhsu.com/p/%E7%9F%AD%E9%80%A3%E7%B5%90%E9%96%8B%E7%99%BC%E5%88%86%E4%BA%AB/","title":"短連結開發分享"},{"content":"這陣子工作上的時候又遇到一個要從兩個List中找出相同Id，然後 Assign 給對方的那種，正當我準備再寫個Double-ForEach來解決這個問題時，腦中突然被這種很醜的寫法給噁心到了，頓時間在想\n「肯定有更好的方式吧」\n於是就想到了HashMap，我知道取出Map的時間複雜度為O(1)，但這是保證都是O(1)嗎？還是說只有用index查找，例如get(1)這種才快呢？老實說我不是很清楚，另外我如果要用HashMap，我勢必要先把List的內容put到Map中，那這樣跟我直接用Double-ForEach查找來講，是不是會更慢呢？於是今天打算來研究一下，我的想法很簡單，創造10,000,000個UID，並分別放到List跟Map，最後取出最後新增的UID，來比較兩者之間的速度\n程式碼如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public static void main(String[] args) { System.out.println(\u0026#34;開始執行\u0026#34;); HashMap\u0026lt;String, String\u0026gt; stringStringHashMap = new HashMap\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; uuidList = new ArrayList\u0026lt;\u0026gt;(); String theLastUid=\u0026#34;\u0026#34;; long inputStartTime = System.currentTimeMillis(); for(int i =0;i\u0026lt;10_000_000;i++){ String uid = new UID().toString(); stringStringHashMap.put(uid,uid); uuidList.add(uid); theLastUid=uid; } long inputEndTime = System.currentTimeMillis(); System.out.println(\u0026#34;資料塞完耗時\u0026#34; +(inputEndTime - inputStartTime)); System.out.println(\u0026#34;=======\u0026#34;); long mapStartTime = System.currentTimeMillis(); String mapString = stringStringHashMap.get(theLastUid); long mapEndTime = System.currentTimeMillis(); System.out.println(\u0026#34;Map耗時 :\u0026#34;+(mapEndTime - mapStartTime)); System.out.println(\u0026#34;Map撈出來的\u0026#34; + mapString); System.out.println(\u0026#34;=======\u0026#34;); long listStartTime = System.currentTimeMillis(); String finalTheLastUid = theLastUid; String listString = uuidList.stream().filter(s -\u0026gt; s.equals(finalTheLastUid)).findFirst().orElse(null); long listEndTime = System.currentTimeMillis(); System.out.println(\u0026#34;List耗時 :\u0026#34;+(listEndTime - listStartTime)); System.out.println(\u0026#34;List撈出來的 = \u0026#34; + listString); }   最後輸出的結果\n1 2 3 4 5 6 7 8  開始執行 資料塞完耗時2228 ======= Map耗時 :0 Map撈出來的-122815f4:190363175b6:1717 ======= List耗時 :103 List撈出來的 = -122815f4:190363175b6:1717   沒想到Map查詢的速度居然是List的無限倍！那接下來我要驗證看看，Map雖然比較快，但是在塞資料這件事情上面，會不會Map消耗的時間比List還多，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public static void main(String[] args) { System.out.println(\u0026#34;開始執行\u0026#34;); HashMap\u0026lt;String, String\u0026gt; stringStringHashMap = new HashMap\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; uuidList = new ArrayList\u0026lt;\u0026gt;(); String theLastUid=\u0026#34;\u0026#34;; long inputStartTime = System.currentTimeMillis(); for(int i =0;i\u0026lt;10_000_000;i++){ String uid = new UID().toString(); stringStringHashMap.put(uid,uid); } long inputEndTime = System.currentTimeMillis(); System.out.println(\u0026#34;Map資料塞完耗時\u0026#34; +(inputEndTime - inputStartTime)); System.out.println(\u0026#34;=======\u0026#34;); long inputStartTime2 = System.currentTimeMillis(); for(int i =0;i\u0026lt;10_000_000;i++){ String uid = new UID().toString(); uuidList.add(uid); theLastUid=uid; } long inputEndTime2 = System.currentTimeMillis(); System.out.println(\u0026#34;List資料塞完耗時\u0026#34; +(inputEndTime2 - inputStartTime2)); }   1 2 3 4  開始執行 Map資料塞完耗時2288 ======= List資料塞完耗時1656   可以看到我的想法確實沒錯，塞到hashMap確實比單純塞到List耗時還要長，因為還要處理哈希碰撞的問題，但相對來說，Map跟List塞進去的性能差異並沒有到搜尋的差異那麼大，而且這只是在只需要搜尋一次的場景，如果單一方法有需要搜尋兩次的話，那麼設定成Map確實是個不錯的解法。\n","date":"2024-06-20T22:48:07+08:00","image":"https://i.imgur.com/fioKvTX.png","permalink":"https://hoxtonhsu.com/p/%E4%BD%BF%E7%94%A8map%E4%BE%86%E6%89%BE%E7%9C%9F%E7%9A%84%E6%AF%94list%E9%82%84%E5%BF%AB%E5%97%8E/","title":"使用Map來找真的比List還快嗎"},{"content":"GitHub網址在 ：https://github.com/Hoxton019030/591_rent_google_apps_script_fullauto\n靈感來自於：超簡單一鍵推播 591 租屋資訊完全免 Coding－透過 Google Sheet 與 LINE Notify\n你厭倦了一直F5刷新網頁查看有沒有新的資料嗎？你厭倦了每次好的物件都被別人搶走嗎？別擔心，591自動化他來了\n使用了Google Apps Script作為自動化的設置，並即時傳送Line通知到你的手機，讓你永遠可以領先別人一步！\n使用教學  首先訪問這個Google Sheet頁面  https://docs.google.com/spreadsheets/d/1Pngp5EAy1oElm5phF2S-I02llRuTgc8ULklcdBci2h4/edit?usp=sharing\n並選擇建立副本\n訪問你剛剛的副本，並選擇Apps Script  到591中選擇自己想要的租屋條件，把網址複製下來  把網址貼上到Apps Script中  接著申請Line Token 把Line Token塞進去，請記得這個Token不要外流，如果用不到也請記得刪掉  點擊 Line Notify\n選擇登入\n選擇個人頁面\n選擇發行權杖，然後命名一下，最後選擇你要推送到哪個聊天室，建議可以選擇「透過1對1聊天接收LINE NOTIFY的通知」\n複製權杖\n點擊觸發條件  結果展示  ","date":"2024-05-28T01:42:08+08:00","image":"https://i.imgur.com/dYtFfAi.png","permalink":"https://hoxtonhsu.com/p/591%E7%B5%90%E5%90%88google-apps-script-%E8%87%AA%E5%8B%95%E5%82%B3%E9%80%81line/","title":"591結合Google Apps Script 自動傳送Line"},{"content":"最近找房子真的找得好累，偶然間在網路上看到超簡單一鍵推播 591 租屋資訊完全免 Coding－透過 Google Sheet 與 LINE Notify，想要拿來用卻發現好像\n已經失效了，想要維護一下發現自己完全不懂這些東西，於是秉持著能坐就不躺，能躺就不坐的懶人心態，決定要來研究一下怎麼利用GAS跟Line Notify來達到只要有更新資料，就會發送Line通知給我的功能。\n快速上手 名詞定義   SpreadSheet：試算表，其實就是你看得的這整個Google Excel，對應到下面的Hoxton App Script Practice\n  Sheet：工作簿，工作表，就類似分頁的東西啦\n  夢開始的地方 反正先隨便創個試算表吧\n接著在Google Sheet的活頁簿中，選擇Apps Script\n在這邊，就會看到一個類似javascript的東西，但是是.gs結尾的，接下來會給幾段Code，讓你感受一下gs這個東西是怎麼運作的\n打印出目前操作的SpreadSheet名稱 1 2 3 4 5 6 7 8 9 10 11  function myFunction() { // 獲取當前活動的電子表格  var spreadSheet = SpreadsheetApp.getActiveSpreadsheet(); // 獲取當前活動的電子表格名稱  var spreadSheetName = spreadSheet.getName(); // 輸出電子表格的名稱  console.log(spreadSheetName); }   打印出底下分頁的名稱 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  function myFunction() { // 獲取當前活動的電子表格  var spreadSheet = SpreadsheetApp.getActiveSpreadsheet(); // 獲取當前活動的工作表  var sheet = spreadSheet.getActiveSheet(); // 獲取所有工作表  var sheets = spreadSheet.getSheets(); // 輸出所有工作表的名稱  for (var i = 0; i \u0026lt; sheets.length; i++) { console.log(sheets[i].getName()); } }   把Sheet的A1欄位改成Hello World 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  function myFunction() { // 獲取當前活動的電子表格  var spreadSheet = SpreadsheetApp.getActiveSpreadsheet(); // 獲取當前活動的電子表格名稱  var spreadSheetName = spreadSheet.getName(); // 輸出電子表格的名稱  console.log(spreadSheetName); // 獲取當前活動的工作表  var sheet = spreadSheet.getSheetByName(\u0026#34;我是第一個Sheet\u0026#34;); // 在 A1 單元格中設置值為 \u0026#34;Hello World\u0026#34;  sheet.getRange(\u0026#34;A1\u0026#34;).setValue(\u0026#34;Hello World\u0026#34;); }   設置自動執行的排程器 選擇Trigger\n按照下圖的順序去執行\n這樣就可以了，接下來我們寫一段Code，把A1欄位的值改成當前時間\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  function myFunction() { // 獲取當前活動的電子表格  var spreadSheet = SpreadsheetApp.getActiveSpreadsheet(); // 獲取當前活動的工作表  var sheet = spreadSheet.getSheetByName(\u0026#34;我是第一個Sheet\u0026#34;); // 獲取當前日期  var now = new Date(); // 定義日期格式  var formattedDate = Utilities.formatDate(now, Session.getScriptTimeZone(), \u0026#34;yyyy MM dd HH:mm:ss\u0026#34;); // 在 A1 單元格中設置格式化後的日期  sheet.getRange(\u0026#34;A1\u0026#34;).setValue(formattedDate); }   結合Line Notify 每分鐘跟我說現在幾時幾分 首先到\nhttps://notify-bot.line.me/zh_TW/\n網站申請一個個人Token\n然後會給你一個Token，複製下來\n把以下的Code貼到你的程式中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  function myFunction() { // 發送消息  sendLineNotify(new Date()) } function sendLineNotify(message){ var token =\u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34; var options = { \u0026#34;method\u0026#34; : \u0026#34;post\u0026#34;, \u0026#34;payload\u0026#34; : {\u0026#34;message\u0026#34; : message}, \u0026#34;headers\u0026#34; : {\u0026#34;Authorization\u0026#34; : \u0026#34;Bearer \u0026#34; + token} }; UrlFetchApp.fetch(\u0026#34;https://notify-api.line.me/api/notify\u0026#34;, options); }   接著按執行，就會發通知給你囉^_^ 有沒有很簡單呀\n","date":"2024-05-22T23:49:06+08:00","image":"https://i.imgur.com/V6lmUtX.png","permalink":"https://hoxtonhsu.com/p/%E7%82%BA%E4%BA%86%E7%A7%9F%E6%88%BF%E5%AD%90%E8%80%8C%E5%AD%B8%E7%9A%84gasgoogle-apps-script/","title":"為了租房子而學的GAS(Google Apps Script)"},{"content":"Amazon Web Server 介紹 Amazon EC2 架伺服器的，動態擴充的VPS\nAmazon RDS 放資料庫的\nAmazon S3 CDN的功能，可以放圖片等等的靜態資源\nIAM Identify And Access Management, Global Service\nRoot Account是你創辦帳戶時就創建，而Users則是這個組織或是群組裡面的用戶\nIMA 在進行IMA的設定時，右上角的區域會被鎖定成「Global」，因為IAM的設定是全局生效的\n進行練習時，首先先創立一個User，因為我們所創建的Aws帳號都是Root User\n創建使用者\n指定使用者的類型，密碼型態\n創建好之後，可以使用這邊的Url登入Account Id在這邊查看\n登入畫面\n創建群組，創建完之後記得要勾喔，我這邊忘了截圖。創建完、加完後，這個群組的User就有Admin的權限了\nIMA Policy 使用JSON來做User的Group的設定，定義了各種Permissions，範例如下\n Version: Policy Language的版本，通常都是2012-10-12 Id：一個識別碼，可填可不填 Statement：必填的，可以是一個或是多個 Sid：每個Statement的Id，選填的 Effect：Allow 或是 Deny Principal: 這個帳戶遵循的是哪個policy Action：Effect所Allow或Deny的 Resource：Action所使用的resouces Condition：Effect生效的條件 選填  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  { \u0026#34;Version\u0026#34;:\u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;:\u0026#34;S3-Account-Permissions\u0026#34; \u0026#34;Statement\u0026#34;:[ { \u0026#34;Sid\u0026#34;:\u0026#34;1\u0026#34;, \u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;:{ \u0026#34;AWS\u0026#34;:[\u0026#34;arn:aws:iam:123456789012:root\u0026#34;] }, \u0026#34;Action\u0026#34;:\u0026#34;ec2:Describe*\u0026#34;, \u0026#34;Resource\u0026#34;:\u0026#34;*\u0026#34; },{ \u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;:\u0026#34;elasticloadbalncing:Describe*\u0026#34;, \u0026#34;Resouce\u0026#34;:\u0026#34;*\u0026#34; }.{ \u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;:[ \u0026#34;cloudwatch:ListMetrics\u0026#34;, \u0026#34;coludwatch:GetMetricStatistics\u0026#34;, \u0026#34;cloudwatch:Describe*\u0026#34; ], \u0026#34;Resouce\u0026#34;:\u0026#34;*\u0026#34; } ] }   Policy的詳細設定 可以點擊右邊的Policies查看\n點擊右邊的Json就會顯示出他的Json長什麼樣子\n1 2 3 4 5 6 7 8 9 10  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }   Json與Action的對應，可以使用WildCard來匹配\n當然你也是可以自己Custome自己的Police啦\nAws Command Line Interface 安裝 到官網下載對應的版本\nhttps://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html 安裝好後在Terminal中輸入，就可以看到對應的資料了\n1  aws --version   創建AccessKey 跟所有的Access Key一樣，這些Key也只會在這邊顯示這一次，之後就不會再顯示了\n輸入來設定\n1  aws configure   列出IAM User List 1  aws   Cloud Shell 其實就是一個雲端Termianl，跟Digital Ocean的那個差不多\nIAM Role 有些 AWS 服務需要代表你執行操作，為此，我們將使用 IAM 角色分配權限給 AWS 服務\nSome AWS service will need to perform actions on your behalf. To do so, you assign permissions to AWS services with IAM Roles.\n完成！\n為Aws設置帳單提醒 記得先用Root帳號，把IAM user and role access to Billing Information\n選擇Billing And Cost Management\n就能看到這樣的畫面\n選擇Bill 可以看到目前的帳單狀況\n在最下面有個charge By service，可以查看哪些服務各自花了什麼內容\n實際進入帳單警告(Alert)的部分則是從這邊\n選擇右邊橘色的ceate a budget\n選擇Zero Spend Budget，這樣如果只要有被收到費，就會立刻寄信給我們，要我們處理\n還有這種如果月帳單超過10塊，就發通知給我們的\nEC2(Elastic Compute Cloud) 彈性雲端運算 是個IAAS(Infrastructure as a Service)\nEC2有什麼功能呢\n 租用虛擬機Elastic Compute Cloud(EC2) 儲存資料 Elastic Block Store(EBS) 負載均衡Elastic Load Balance(ELB) Scaling the service using an Auto-Scaling Group(ASG)  一些EC2的類型，當然不只有以下這五種，還有很多，只是列出五種作參考\n創建EC2 選擇創建Key Pair\n還有網路的部分，要把下面的Allow Http traffic from the Internet，這樣才可以部屬Web服務\n接下來拉到最底下，有個User Data，但我覺得命名的不是很好，這邊其實就是指定EC2初次啟動時的執行腳本是什麼，我們可以複製以下的內容到EC2當中\n1 2 3 4 5 6 7 8  #!/bin/bash # Use this for your user data (script from top to bottom) # install httpd (Linux 2 version) yum update -y yum install -y httpd systemctl start httpd systemctl enable httpd echo \u0026#34;\u0026lt;h1\u0026gt;Hello World from $(hostname -f)\u0026lt;/h1\u0026gt;\u0026#34; \u0026gt; /var/www/html/index.html   選好了之後就可以按創建了，創建完之後點選我們剛剛創建的instance，就可以看到詳細的內容\n開啟的Port，一些security的內容\n你也可以通過訪問你創建的Public Ip 來看到你剛剛User Data 的內容\n七種不同的EC2 Instance https://aws.amazon.com/tw/ec2/instance-types/\nInstance的命名邏輯  m5.2xlarge\n m: instance class\n5: generation 世代\n2xlarge: size within the instance class ，通常代表了多大的記憶體、硬碟空間、CPU\n  General Purpose\n通常用來做Web Server或是Code Repository\n  Compute Optimized\n資料處理、高計算、機器學習、遊戲伺服器的Instance\n  Memory Optimized\n可以很快地把東西放到Memory中，適合用來作為資料庫儲存的Instance，或是放一些對Real-Time即時性較高的資料\n  Storage Optimzed\n對於高讀寫很有一套，適合用在高頻交易(OLTP)系統、關聯、非關聯式資料庫\n  Security Groups 一個類似防火牆的東西，把EC2 繞起來\n相同Security Group的Instance可以相互通訊\n所謂的Inbound Rules跟Outbound rules就是傳入規則與傳出規則\n可以按右上角的Edit Inbound Rules 編輯一下規則，向我這邊就把Http的規則加進來\n常見的Port  22: SSH連線 21: FTP連線 22：透過SSH來使用FTP上傳檔案 80：HTTP 443：HTTPS 3389：RDP 登入Windows Instance  如何SSH進去我的EC2 Instance 首先電腦裡面要有你RSD的密鑰檔，並確保你的Security允許SSH連線\n然後結合你的Public Ip\n語法 ec2-user是創建instance時就會幫我們創建的一個user\n1  ssh -i Aws-2024-05-11.pem ec2-user@43.206.215.70   這樣就行囉，如果不行的話可能要用chmod調一下權限\nEBS EBS Volume 類似資料庫的東西，可以儲存資料的東西\n參考網址 【Udemy付费课程】Ultimate AWS Certified Solutions Architect Associate AWS认证课程\n【AWS】云计算课程全集（更新中\n[AWS][教學] AWS基本使用#01. AWS免費方案介紹\n","date":"2024-05-11T14:25:03+08:00","image":"https://i.imgur.com/lluhyyC.png","permalink":"https://hoxtonhsu.com/p/aws%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"AWS學習筆記"},{"content":"安裝 Mac Homebrew 1  brew install nginx   啟動與停止 啟動 1  brew services start nginx   或\n1  ngnix   成功後訪問\nhttp://localhost:8080/\n就可以看到以下畫面\n可以輸入\n1  ps -ef |grep nginx   1 2 3 4 5 6 7  ps -ef | grep nginx 是一个用于在 macOS 或类 Unix 系统中查找正在运行的 nginx 进程的命令。它的作用如下： ps: 这个命令用于显示当前运行的进程列表。 -ef: 这是 ps 命令的选项，其中 -e 用于显示所有进程，-f 用于显示全面的进程信息。 |: 这是管道符，它将 ps -ef 命令的输出发送到下一个命令。 grep nginx: 这个命令用于过滤包含关键字 \u0026#34;nginx\u0026#34; 的行，只显示与 nginx 相关的进程。 因此，ps -ef | grep nginx 的作用是显示所有包含 \u0026#34;nginx\u0026#34; 关键字的进程，帮助你找出当前正在运行的 nginx 进程。   看到nginx的執行狀況\n停止 1  nginx -s signal   優雅停止 1  nginx -s quit   立刻停止 1  nginx -s stop   重載配置文件 1  nginx -s reload   重新打開日誌文件 1  nginx -s reopen   Ngnix介紹 做負載均衡、反向代理、虛擬主機的一個中間件\n可以輸入以下指令查看進程\n1  ps -ef |grep nginx   1 2 3 4 5 6 7  ps -ef | grep nginx 是一个用于在 macOS 或类 Unix 系统中查找正在运行的 nginx 进程的命令。它的作用如下： ps: 这个命令用于显示当前运行的进程列表。 -ef: 这是 ps 命令的选项，其中 -e 用于显示所有进程，-f 用于显示全面的进程信息。 |: 这是管道符，它将 ps -ef 命令的输出发送到下一个命令。 grep nginx: 这个命令用于过滤包含关键字 \u0026#34;nginx\u0026#34; 的行，只显示与 nginx 相关的进程。 因此，ps -ef | grep nginx 的作用是显示所有包含 \u0026#34;nginx\u0026#34; 关键字的进程，帮助你找出当前正在运行的 nginx 进程。   Master Process \u0026amp; Worker Process Master 負責讀取以及驗證文件、管理woker process，只有一個\nWorker 負責處理實際請求，可以有很多個\n如何更改Ngnix的啟動畫面，配置index.html等靜態資源 輸入，找到配置檔的位置\n1  nigix -t   接著輸入打開編輯\n1  code /opt/homebrew/etc/nginx/nginx.conf   這邊就是檔案配置的位置\n![image-20240510151026498](/Users/hoxtonashes/Library/Application Support/typora-user-images/image-20240510151026498.png)\n接著找看看Nginx的安裝目錄\n1  cd /opt/homebrew/Cellar/nginx/1.25.5   修改這個檔案\n1  code /opt/homebrew/Cellar/nginx/1.25.5/html/index.html   就可以了，如果要佈置自己的網頁也是放到一個的目錄底下即可\n調整Worker數量 1  code /opt/homebrew/etc/nginx/nginx.conf   重新加載\n1  nginx -s reload   1  ps -ef |grep nginx   Worker 數量跟cpu 核心數量一致會比較好，或是設置成auto\nNginx配置文件介紹 https://www.bilibili.com/video/BV1mz4y1n7PQ?p=5\u0026amp;spm_id_from=pageDriver\u0026amp;vd_source=422eafa6570139128e44a83238959fa0\n底下的每個Server塊就是一個虛擬主機\n我們可以先將整個配置文件清空，從頭寫一遍配置文件來學習\n此時想啟動也啟動不了，會跟我們說少了event區塊\n補上後就可以成功啟動\n1 2 3  events{ }   但啟動後會發現，我們的nginx沒有監聽任何port號\n因此我們需要再配置http 模塊\n1 2 3 4 5 6 7 8 9  events{} http{ # 定義的是虛擬服務器，可以配置很多server server { listen 8087; server_name localhost; } }   此時如果我們有在html/資料夾底下配置index.html 就會顯示那個html的內容，如果沒有就不顯示，顯示403這樣\n也可以配置寫死的返回值 8089\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  events{} http{ # 定義的是虛擬服務器，可以配置很多server server { listen 8087; server_name localhost; } server { listen 8089; server_name localhost; return 200 \u0026#34;Hoxton Hello\u0026#34;; } }   配置重定向 可以用\n1 2 3 4 5 6 7  server { listen 8087; server_name localhost; location /temp{ return 307 index.html; } }   的方式\n或是用rewrite\n1 2 3 4 5  server { listen 8087; server_name localhost; rewrite /temp index.html }   何謂正向代理，何謂反向代理 正向代理 正向代理就是類似VPN，透過一個代理節點去幫我訪問網站，例如中國的翻牆\n反向代理 對外指暴露一個端口，但背後可能有好幾個端口，代理的是服務端\n使用Java來配置網址，理解反向代理 先配置3個不同的port (8081,8082,8083)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package org.hoxton; import com.sun.net.httpserver.HttpExchange; import com.sun.net.httpserver.HttpHandler; import com.sun.net.httpserver.HttpServer; import java.io.IOException; import java.io.OutputStream; public class Main { public static void main(String[] args) throws Exception { int port = 8081; HttpServer server = HttpServer.create(new java.net.InetSocketAddress(port), 0); server.createContext(\u0026#34;/\u0026#34;, new MyHandler()); server.setExecutor(null); // 使用默认的执行器  server.start(); System.out.println(\u0026#34;Server is listening on port \u0026#34; + port); } static class MyHandler implements HttpHandler { @Override public void handle(HttpExchange exchange) throws IOException { String response = \u0026#34;Hello, World!\u0026#34;; exchange.sendResponseHeaders(200, response.getBytes().length); OutputStream os = exchange.getResponseBody(); os.write(response.getBytes()); os.close(); } } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package org.hoxton; import com.sun.net.httpserver.HttpExchange; import com.sun.net.httpserver.HttpHandler; import com.sun.net.httpserver.HttpServer; import java.io.IOException; import java.io.OutputStream; public class Main2 { public static void main(String[] args) throws Exception { int port = 8082; HttpServer server = HttpServer.create(new java.net.InetSocketAddress(port), 0); server.createContext(\u0026#34;/\u0026#34;, new MyHandler()); server.setExecutor(null); // 使用默认的执行器  server.start(); System.out.println(\u0026#34;Server is listening on port \u0026#34; + port); } static class MyHandler implements HttpHandler { @Override public void handle(HttpExchange exchange) throws IOException { String response = \u0026#34;Hello, World!\u0026#34;; exchange.sendResponseHeaders(200, response.getBytes().length); OutputStream os = exchange.getResponseBody(); os.write(response.getBytes()); os.close(); } } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package org.hoxton; import com.sun.net.httpserver.HttpExchange; import com.sun.net.httpserver.HttpHandler; import com.sun.net.httpserver.HttpServer; import java.io.IOException; import java.io.OutputStream; public class Main3 { public static void main(String[] args) throws Exception { int port = 8083; HttpServer server = HttpServer.create(new java.net.InetSocketAddress(port), 0); server.createContext(\u0026#34;/\u0026#34;, new MyHandler()); server.setExecutor(null); // 使用默认的执行器  server.start(); System.out.println(\u0026#34;Server is listening on port \u0026#34; + port); } static class MyHandler implements HttpHandler { @Override public void handle(HttpExchange exchange) throws IOException { String response = \u0026#34;Hello, World!\u0026#34;; exchange.sendResponseHeaders(200, response.getBytes().length); OutputStream os = exchange.getResponseBody(); os.write(response.getBytes()); os.close(); } } }   修改配置檔案，配置如下，把8081 8082 8083 設置一下，如此一來，訪問\nhttp://localhost:8080/app\n時，就會代理到這三個port號(預設是輪詢)，見下方Gif\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; upstream backend_hoxton{ server 127.0.0.1:8081; server 127.0.0.1:8082; server 127.0.0.1:8083; } #gzip on; server { listen 8080; server_name localhost; } }   也可以設置權重(weight) 來調整\n1 2 3 4 5  upstream backend_hoxton{ server 127.0.0.1:8081 weight =3; server 127.0.0.1:8082; server 127.0.0.1:8083; }   也可以使用ip_hash，這樣相同的請求就會被轉到一樣的port號了，這動作也就是讓nginx把流量導到指定的服務集群\n1 2 3 4 5 6  upstream backend_hoxton{ ip_hash; server 127.0.0.1:8081 weight =3; server 127.0.0.1:8082; server 127.0.0.1:8083; }   配置Path要注意的內容，避免不當訪問 但這個方法非常不安全！等於說我們可以讓用戶用這樣的方式訪問我們服務器的內容。\n比如說我們可能只想暴露http://localhost:8080/app/index.html這個文件，但如果寫成\n1 2 3  location /app｛ proxy_pass http://backend_ hoxton ｝   用戶可以訪問\nhttp://localhost:8080/apple/index.html\nhttp://localhost:8080/app/screctKey\n等等的內容，所以我們最好用全限定的方式，限定訪問的資源，也可以使用正則表達式來限定，這邊還有很多的內容，比如說前綴配對還有什麼東西之類的，就不展開了。\n1 2 3  location /app｛ proxy_pass http://backend_ hoxton ｝   虛擬主機 目的是在一台主機上面配置多個站點，\n常用命令 查看版本 1  nginx -v\t  查看運行狀態 1  service nginx status   查看Nginx配置 1  nginx -V   查看Nginx配置文件 1  nigix -t   參考網址 https://www.bilibili.com/video/BV1mz4y1n7PQ?p=3\u0026amp;vd_source=422eafa6570139128e44a83238959fa0\nhttps://www.bilibili.com/video/BV1TZ421b7SD/?spm_id_from=333.337.search-card.all.click\u0026amp;vd_source=422eafa6570139128e44a83238959fa0\n","date":"2024-05-08T17:43:33+08:00","image":"https://i.imgur.com/h4PsSxV.jpeg","permalink":"https://hoxtonhsu.com/p/nginx/","title":"Nginx"},{"content":"​\n延續上一篇\n本文會用到的連結\nHow to Integrate Elastic Search With Spring Boot CRUD Project| Spring Boot | Elasticsearch| EnggAdda\n這東西的坑真的很多\nspringBoot Elastic Search 還有相關的套件版本必須一致\n版本設置與Maven Elastic Search \u0026amp; Kibana 版本 我個人使用的設置如下\nElastic Search: 8.13.2\nKibana:8.13.2\nMaven 1 2 3 4 5 6 7 8 9 10 11  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.elasticsearch.client\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;elasticsearch-rest-high-level-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.4.0\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;log4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt;   SprignBoot版本 SpringBoot:3.2.5\nSpringBoot與Elastic連線設定 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  import org.apache.http.HttpHost; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class ElasticSearchConfig { private String host =\u0026#34;localhost\u0026#34;; private Integer port=9200; /** * 如果@Bean没有指定bean的名称，那么这个bean的名称就是方法名 */ @Bean public RestHighLevelClient restHighLevelClient() { return new RestHighLevelClient( RestClient.builder( new HttpHost(host, port, \u0026#34;http\u0026#34;) ) ); } }   基本操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  import jakarta.annotation.Resource; import lombok.extern.slf4j.Slf4j; import org.elasticsearch.action.search.SearchRequest; import org.elasticsearch.action.search.SearchResponse; import org.elasticsearch.client.RequestOptions; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.index.query.BoolQueryBuilder; import org.elasticsearch.index.query.QueryBuilders; import org.elasticsearch.search.SearchHit; import org.springframework.stereotype.Service; @Service @Slf4j public class ElasticSearchService { @Resource private RestHighLevelClient client; public void test() throws IOException { BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); SearchRequest indices = new SearchRequest().indices(\u0026#34;news_headlines\u0026#34;); SearchResponse search = client.search(indices, RequestOptions.DEFAULT); SearchHit[] hits = search.getHits().getHits(); for (SearchHit hit : hits) { log.info(hit.getSourceAsString()); } } }   ","date":"2024-04-29T18:00:50+08:00","image":"https://i.imgur.com/PKZTCYE.png","permalink":"https://hoxtonhsu.com/p/springboot%E6%95%B4%E5%90%88elasticsearch/","title":"SpringBoot整合ElasticSearch"},{"content":"在新的公司裡面，對於commit 還有分支其實是沒啥規範的，如果我資策會剛畢業，應該會覺得這家公司沒有規範，但我現在會覺得不規範可能也是好事，畢竟我實際去工作時，真的會去翻commit 的次數少之又少。\n但時間久了發現這樣也有些問題，比如說我會有很多commit 是\n1 2 3 4 5 6 7  log log log log 看看問題 看看變數是啥 log log   這種基本上沒啥用的資訊，我看了也會有點不好意思，再加上之前有同事問我這段code改了什麼，結果我只有寫一個「錯誤修正」就commit出去了，當下還是有點難堪的。\n後來曾經有段時間想要認真把commit 內容寫一下，但有時候又沒什麼好靈感，不知道寫什麼，心裡就想著\n「ChatGPT這麼屌，怎麼不讓他來幫我寫 commit 」\n無獨有偶，網路上就有一位大神寫了個lib，可以用來產生git commit 的內容\n用 ChatGPT 自動幫開發者產生 Commit Message\n安裝 安裝方式在GIthub的README中有連結\n1 2  brew tap appleboy/tap brew install codegpt   安裝好後可以輸入\n1  codegpt version   來查看版本\n設定 Codegpt 安裝完後需要設定一些參數，比如說openAI的token，這部分就需要花新台幣購買，我是買5鎂的token來用，目前用了快一個月，大概消耗0.2鎂而已，相當划算\nhttps://platform.openai.com/settings/organization/general\n設定api key 1 2  codegpt config set openai.provider \u0026#34;openai\u0026#34; codegpt config set openai.api_key \u0026#34;sk-xxxxxxx\u0026#34;   然後還有一些設定，可以在\n1  vim $HOME/.config/codegpt/.codegpt.yaml   中設定，比如說\n設定commit 語言 1  codegpt config set output.lang \u0026#34;zh-tw\u0026#34;   設定git_diff的行數 1  codegpt commit --preview --diff_unified 1   這參數會決定codegpt會幫你產生的comit訊息的準確度，像藍色的部分就是抓5行的code，所以可能會包括你沒寫的內容，而選擇1的話就是紅色的部分，會產生較為精準的commit (參照before \u0026amp; after)\n使用 使用\n1  codegpt commit   自動產生commit訊息\n或是輸入\n1  codegpt commit --preview   來預覽\n當然也可以透過git hook來使用\n使用GitHook來調用codegpt(不推薦) 輸入安裝\n1  codegpt hook install   輸入解除安裝\n1  codegpt hook uninstall   這個指令會在你專案的 .git/hooks底下產生一個 prepare-commit-msg\n內容如下\n1  codegpt commit --file $1 --preview   如此一來，我們每次輸入\ngit commit 時，就會自動呼叫codegpt幫我們產生commit 了\n但這其實有個問題，prepare-commit-msg這個hook，會在所有執行git commit的操作後執行，當然也包刮pull跟merge，像這些時候我們是不需要調用codegpt 的功能的，但我研究了一下git hook發現沒有這個功能，經過了幾天的研究，發現要滿足我的需求只能透過bash alias，詳見下篇\n 當我需要時才調用codegpt commit，我也要保留 git commit 的功能 merge跟pull時都不要調用codegpt 我要能夠編輯codegpt 的commit內容，不能直接幫我儲存  將codegpt 做成alias 來調用codegpt(推薦) 編輯 bashrc\n1  vim ~/.bash_profile   將這段複製上去\n1  alias auto-commit=\u0026#39;codegpt commit \u0026amp;\u0026amp; git commit --amend\u0026#39;   然後儲存，回到terminal中重新刷新\n1  source ~/.bash_profile   如此一來當\n1  git add .   後，就能夠輸入\n1  auto-commit   來執行codegpt了喔\n","date":"2024-04-26T18:20:02+08:00","image":"https://i.imgur.com/o0SuW5w.png","permalink":"https://hoxtonhsu.com/p/%E6%87%89%E7%94%A8codegpt%E5%BF%AB%E9%80%9F%E7%94%A2%E7%94%9Fcommit/","title":"應用codegpt快速產生commit"},{"content":"大概在4/3的時候跑去打了上顎的兩顆骨釘，在打之前有看了很多水管仔跟BiliBili的影片，感覺骨釘好像也沒有想像中的可怕，畢竟會打麻藥，打了麻之後應該是不會痛到哪裡去吧，天真的我當時就是這麼認為。\n4/3打骨釘當天還是有點緊張，坐上手術椅當下還是有點小緊張，後來打了麻藥，醫生就把骨釘插進了我的上顎骨中，為什麼說插入呢，因為當時其實沒有什麼旋轉的感覺，感覺我的骨頭就像一塊豆腐一樣，咻咻咻的就被插進來了\u0026gt; ///// \u0026lt;\n大概整個過程不到1分鐘吧，上顎的兩顆骨釘就已經打完了，我當下還有點失望，想說打骨釘應該要是個驚心動魄，吚咿歐歐的過程。在診所的鏡子照了一下之後感覺也是蠻特別的，自己的身上莫名其妙就被穿孔了，突然想到之前在網路上看的那些有穿孔癖好的人，自己還是無法理解在身上鑽個洞的痛苦。\n回去之後就開始很正常的工作，直到兩三個小時過後，我突然感覺到左右兩邊頭骨開始有種疼痛感蔓延上來，直至我的太陽穴。五個小時後，我感覺我的頭像是有兩個電鑽在鑽我的左右太陽穴一樣，並且伴隨著不適的上顎疼痛，那感覺就很像是你在大力咬一點，你的上顎骨就會像車禍現場一樣四分五裂。那時候我大概每隔兩個小時就吃兩顆止痛藥，不然痛到根本睡不著，在我昏迷的時候一直想著那些在網路上說打骨釘不痛的，我希望你們不得好死^_^，根本痛死，幹你媽的。\nbtw 骨釘痛了一天其實就差不多，真的不適的是後續骨釘一直摩擦到我的口腔黏膜，導致我的黏膜破了一個0.5公分的超大傷口，抹藥的當下真得哭出來，比骨釘還慘\n","date":"2024-04-16T15:05:38+08:00","image":"https://i.imgur.com/BV6bKbq.png","permalink":"https://hoxtonhsu.com/p/%E7%89%99%E5%A5%97%E7%B4%80%E9%8C%84%E4%BA%8C/","title":"牙套紀錄\u003c二\u003e"},{"content":"說明 1 2 3 4 5 6 7 8  INSERT INTO global_zz.gl_language_dic (config_key, language, config_value, module, id) VALUES (\u0026#39;ADJUST_TYPE_101\u0026#39;, \u0026#39;en\u0026#39;, \u0026#39;Salary bonus\u0026#39;, \u0026#39;activity-dic\u0026#39;, generated); INSERT INTO global_zz.gl_language_dic (config_key, language, config_value, module, id) VALUES (\u0026#39;ADJUST_TYPE_102\u0026#39;, \u0026#39;en\u0026#39;, \u0026#39;Event bonus\u0026#39;, \u0026#39;activity-dic\u0026#39;, generated); INSERT INTO global_zz.gl_language_dic (config_key, language, config_value, module, id) VALUES (\u0026#39;ADJUST_TYPE_103\u0026#39;, \u0026#39;en\u0026#39;, \u0026#39;Recharge bonus\u0026#39;, \u0026#39;activity-dic\u0026#39;, generated); INSERT INTO global_zz.gl_language_dic (config_key, language, config_value, module, id) VALUES (\u0026#39;ADJUST_TYPE_104\u0026#39;, \u0026#39;en\u0026#39;, \u0026#39;Test account bonus\u0026#39;, \u0026#39;activity-dic\u0026#39;, generated); INSERT INTO global_zz.gl_language_dic (config_key, language, config_value, module, id) VALUES (\u0026#39;ADJUST_TYPE_105\u0026#39;, \u0026#39;en\u0026#39;, \u0026#39;Compensation bonus\u0026#39;, \u0026#39;activity-dic\u0026#39;, generated); INSERT INTO global_zz.gl_language_dic (config_key, language, config_value, module, id) VALUES (\u0026#39;ADJUST_TYPE_106\u0026#39;, \u0026#39;en\u0026#39;, \u0026#39;Other bonus\u0026#39;, \u0026#39;activity-dic\u0026#39;, generated); INSERT INTO global_zz.gl_language_dic (config_key, language, config_value, module, id) VALUES (\u0026#39;ADJUST_TYPE_201\u0026#39;, \u0026#39;en\u0026#39;, \u0026#39;Decrease bonus\u0026#39;, \u0026#39;activity-dic\u0026#39;, generated);   Explain是MySQL中用來診測執行效能的一個滿好用的工具的，用法大概就是在SQL語句前加上Explain就可以，例如\n1  explain select * from user   這樣子，就會跳出許多的欄位\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE url null ALL null null null null 200 100 null    接下來會說明各個欄位代表的意思\nId: 代表SQL的執行順序\nSelect_type：有四種可能\n Simple：簡單查詢 Primary：代表是複雜查詢中，最外層的那個Select Subquery：代表的是複雜查詢中裡面的那個Select Derived：派生查詢，代表from後面跟著的查詢語句  Table：查了哪些表\nPartitions：不太重要\nType：最為重要的屬性，代表Sql使用什麼樣的方式去查詢資料庫數據，由好到差分別是\nSystem\u0026gt;const\u0026gt;eq_ref\u0026gt;ref\u0026gt;range\u0026gt;index\u0026gt;all\n如果是Null代表不需要訪問表，可以從索引鍵中找出來\n\u0026hellip;\n我的天，我寫到一半發現我的參考資料寫的已經致臻完美了，看參考資料就可以了\n參考資料 https://blog.csdn.net/bugNoneNull/article/details/107489256\n","date":"2024-04-06T03:03:13+08:00","image":"https://i.imgur.com/cNCBPDA.png","permalink":"https://hoxtonhsu.com/p/mysql%E4%B8%AD%E7%9A%84explain%E4%B9%8B%E8%AA%AA%E6%98%8E/","title":"MySql中的explain之說明"},{"content":"在2024/3/19號之前如果你問我，我買過最貴的東西是啥，我會跟你說是我那臺垃圾Macbook，但在2024/3/20過後，我買過最貴的東西是牙齒矯正，花了我17萬^_^。\n拔完了四顆小臼齒，過了兩個禮拜上了上排矯正器，剛上去的感想，大概就是感覺有很多根手指從各個方向一直按著你的牙齒，除此之外沒太大的感覺，原本以為會痛到睡不著的，但實際上不去咬、碰、敲他，是不會自發行疼痛的，但確實不太能咬東西，我看網路上很多人說酸軟，我感覺倒比較像是牙齦發炎的感覺，咬東西就會很痛，所以這幾天我大部分都是靠著麥當勞的玉米濃湯過生活，今天有順便叫了顆蘋果派，壓成一塊一塊的，送到最後一顆牙齒那邊咬，目前感覺沒太大問題= =\n然後我矯正是在恆美做的，那時候在網路上看，2016年是12萬，但我做要17萬，ㄏ，謝謝你 蔡英文\n1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890\n","date":"2024-03-22T05:27:09+08:00","image":"https://i.imgur.com/Em59IXr.png","permalink":"https://hoxtonhsu.com/p/%E7%89%99%E5%A5%97%E7%B4%80%E9%8C%84%E4%B8%80/","title":"牙套紀錄\u003c一\u003e"},{"content":"每次他媽用MyBatis，都他媽出一些白癡問題，真的不懂他媽一堆公司抱著MyBatis這垃圾到底是要欉三小\nMyBatis相關Dependency 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/com.baomidou/mybatis-plus --\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/tk.mybatis/mapper-spring-boot-starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;tk.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mapper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   Properties的配置 然後記得在properties中配置xml的位置\n1  mybatis.mapper-locations=classpath:mapper/*.xml   Mapper的寫法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package com.hoxton.urlshorter.mapper; import com.hoxton.urlshorter.entity.Url; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; import org.springframework.stereotype.Repository; import tk.mybatis.mapper.common.BaseMapper; @Mapper @Repository public interface ShorterMapper extends BaseMapper\u0026lt;Url\u0026gt; { String findByShortURL(@Param(\u0026#34;url\u0026#34;) String shortURL); }   ","date":"2024-03-13T00:34:02+08:00","image":"https://i.imgur.com/TcbKVGe.jpeg","permalink":"https://hoxtonhsu.com/p/mybatis%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E6%AA%94/","title":"MyBatis快速配置檔"},{"content":"前一陣子要安裝Zookeeper時遇到各種困難，其中一個問題就在於當我啟動zkServe.sh時，會跳出一個錯誤訊息並立刻關閉視窗，畫面上看起來像這樣\n這process終止的猝不及防，讓我連讀的機會都沒有就跳掉了，一直想辦法讓他停留在報錯的那一個moment，但調了好幾次的iTerm，都無疾而終，最後只得跟朋友借了另一部電腦來測，才看到錯誤訊息是什麼，那如果我們想要讓Terminal 停在錯誤的那一個瞬間，我們該怎麼做呢？\n或者是說，我們想讓 Terminal 停留在某個moment該怎麼做呢？\n沒錯，聰明的小朋友肯定想到了，那就是Windows系統下的Pause，那Liunx系統呢？雖然沒有Pause指令，但可以用read指令來達到類似的效果，以下就是我在zkServer.sh中加入一段read所達成的效果\n1  read -n 1 -p \u0026#34;時間よ止まれ！\u0026#34;   通常是加在最後一行啦，最後看起來的效果就會像這樣，如果是windows的cmd或是bat，就是改成pause就可以了\n","date":"2024-03-04T14:10:48+08:00","image":"https://i.imgur.com/VlJrNRr.jpeg","permalink":"https://hoxtonhsu.com/p/%E6%88%91%E7%9A%84%E7%B5%82%E7%AB%AF%E6%A9%9F%E7%AB%8B%E5%88%BB%E8%B7%B3%E6%8E%89%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E9%8C%AF%E8%AA%A4%E8%A8%8A%E6%81%AF/","title":"我的終端機立刻跳掉,如何查看錯誤訊息"},{"content":"1 2 3 4 5 6  call %JAVA% \u0026#34;-Dzookeeper.log.dir=%ZOO_LOG_DIR%\u0026#34; \u0026#34;-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%\u0026#34; -cp \u0026#34;%CLASSPATH%\u0026#34; %ZOOMAIN% \u0026#34;%ZOOCFG%\u0026#34; %* 修改为 java \u0026#34;-Dzookeeper.log.dir=%ZOO_LOG_DIR%\u0026#34; \u0026#34;-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%\u0026#34; -cp \u0026#34;%CLASSPATH%\u0026#34; %ZOOMAIN% \u0026#34;%ZOOCFG%\u0026#34; %*   來源\nhttps://blog.csdn.net/qq_34125483/article/details/105285727\n","date":"2024-03-04T13:02:56+08:00","image":"https://i.imgur.com/jSXsDO0.png","permalink":"https://hoxtonhsu.com/p/zookeeper%E4%B8%80%E7%9B%B4%E9%A1%AF%E7%A4%BA-dzookeeper.log.dir..-%E4%B8%8D%E6%98%AF%E5%86%85%E9%83%A8%E6%88%96%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4%E8%A9%B2%E5%A6%82%E4%BD%95%E8%99%95%E7%90%86/","title":"ZooKeeper一直顯示 Dzookeeper.log.dir=..' 不是内部或外部命令該如何處理"},{"content":"第一次認識SDKMAN是那時候在多奇，一個叫Sam的同事，那時候問他怎麼設置環境的，他說他都用SDKMAN，只見他雙手在鍵盤上來來回回，各種JAVA版本就已經安裝好，設置Path也不用到什麼./bash、系統變數裡面去設定，因此自己就默默記下這個好用的工具了，今天終於有機會可以來學習他。\n安裝 在MAC、Linux環境的安裝會比較簡單一點，這邊先介紹Window的安裝\nWindows安裝 這個東西要在一個Linux環境下運行，比如說WLS、cygwin之類的，或者是安裝Git時會自動幫我們安裝的git bash\n這邊就預設各位已經有安裝了，畢竟連Git都沒安裝，想必也不會點進這篇文章的^_^\n在bash中輸入\n1  curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash   有可能會出現\n1 2 3  Please install zip on your system using your favourite package manager. Restart after installing zip.   這時候請到\nhttps://sourceforge.net/projects/gnuwin32/files/zip/3.0/\n這個網站，下載它的zip-3.0-bin.zip\n然後把它丟到你的Git/mingw64/bin 就可以了\n接著再重新安裝一次\n1  curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash   把sdkman加到Path中\n1  source \u0026#34;$HOME/.sdkman/bin/sdkman-init.sh\u0026#34;   這樣就可以了！\n此時我們可以輸入\n1  sdk version   來查看目前sdkman的版本\n切記切記\nSDKMAN只能運行在Linux環境，所以你要用SDKMAN就一定要用Bash\nSDKMAN常用指令 常看幫助 1  sdk help   查看Java有啥 1  sdk ls java   安裝Java 1  sdk install java 17.0.10-zulu   查看Maven有啥 1  sdk ls maven   安裝Maven 1  sdk install maven 3.9.6   切換Java版本 1  sdk use java 14.0.2.j9-adpt   指定預設的JDK版本 1  sdk default java 14.0.2.j9-adpt   查看目前的Java是什麼版本 1  sdk current java   來源 https://www.jianshu.com/p/ddce36a50720\nhttps://blog.miniasp.com/post/2022/09/17/Useful-tool-SDKMAN\n","date":"2024-03-04T12:03:14+08:00","image":"https://i.imgur.com/2sYLJmc.png","permalink":"https://hoxtonhsu.com/p/sdkman%E6%95%99%E5%AD%B8/","title":"SDKMAN教學"},{"content":"Brief 2023算是我正式轉職的第一年吧， 這段期間換了好幾份工作，也學到了很多技術，打算彙整一下這段時間學習到的技術並描繪一下2024的學習路線圖\n2023回顧 研究所相關   作業系統\n  線性代數\n  「看」完了作業系統跟線性代數，但兩個都沒有認真的好好寫過題目，記得在2023年初的時候想說我有一整年的時間可以來讀書，結果發現自己還是抱著三天打魚兩天曬網的方式，年初打戰神、年中打魔物、年末打Steam Deck，一整年下來就只讀了兩科，記得年終的時候有好幾個月都在忙著面試還有加班，有段時間荒廢掉，然後咻一下的發線再過20幾天就要考研究所了，自己卻還在這邊打這篇廢文^_^\n自己預計2024年末要能夠讀完所有的科目，寫完考古題並且拚搏看看，看能不能拼2025年考上\n技術相關 技術相關的部分占了蠻大一部分的，基本上我2023年的生活就是三個重心\n 讀書 學技術 打遊戲  技術的部份盤點了一下，大概學了這些\n  Junit單元測試框架：\n當初忘了在哪邊看到[你就是都不寫測試才會沒時間](https://ithelp.ithome.com.tw/articles/10258902)這篇文章，當時就覺得寫單元測試真的是太酷了！所以在御諾的時候很認真的跟大家說一起來寫單元測試吧！然後就這樣子寫了半年的單元測試還有整合測試，前陣子跟御諾的同事吃飯，我說在御諾10個月，我學到最多的就是怎麼講笑話逗大家開心，除此之外啥都沒學到，但騎車回去的路上想了一下，發現其實自己學最多的是寫Test的部分 如何將Junit的測試粒度控制在最小單元\n  Docker：\n也是當初在御諾的時候看同事在用，覺得很有趣就學下來了，結果發現蠻實用也蠻有趣的，目前最常做的應用就是把WebApp包裝成Image，部屬到我的Digital Ocean上面 Docker學習筆記\n  GitLab CI/CD：\n也是當初在御諾（發現在御諾真的沒啥事情要忙，都在學這些有的沒有的東西= =）看到同事每次上板都要自己手動去Deployment，覺得實在是太累了，所以把這個東西學起來，結果還沒等到我去做CI/CD我就離職了，自己從小就對這種自動化的內容非常有興趣，最早原本是想學Jenkins的，結果Jenkins弄一弄發現也太難了= = 退而求其次跑去學GitLab CI/CD GitLab-CI/CD筆記\n  Store Procedure：\n這個是有一次在御諾，同事需要到客戶那邊Create Table的時候學的，但好像也只用過那次，到後面幾乎都沒啥用到了，更常用的是Java排程或者是其他的定時工具(Xxl-Job 分布式任務調度中心學習筆記)來做，畢竟預存程序這個東西要debug有點困難\n  Zabbix：\n一個主從式的系統監控，也是在御諾那邊學的，記得當時勇哥(御諾的老闆)，希望說不要裝任何東西就能夠監控客戶的電腦，時至今日依然覺得這個想法真的是太Amazing了，後來極力勸說之下，終於同意我去研究Zabbix，後來有為了Zabbix寫了一個LibraryZabbix-Sender，當時很認真的投到Maven Repo中，結果自己太懶就沒動力了。\n  MyBatis：\n當初為了轉職換工作所學習的ORM框架，我從原本排斥到現在覺得這東西真的是太好用了，以前看MyBatis會覺得很麻煩，要自己寫SQL，現在反而是看Hibernate，覺得不能自己寫SQL也太可怕。\n  Mac：\n2023年度最盤的行為大概就是自費買了一台Mac電腦，用到現在依然覺得很難用^_^，所以為了它學了很多東西，寫了很多篇文章，因此歸類在技術類 可參照：如何讓Mac的使用體驗更加絲滑，我的Mac實用插件介紹\n  Maven：\n原本在資策會的時候覺得Maven就只是個管Jar包的，後來工作之後才發現是我格局小了，原來Maven有很多用處，包括現在依然在學習Maven的一些內容，前陣子在開發Side Project要用多模組時也因為不熟Maven 出了一堆問題 Maven詳細研究\n  Selenium：\n當時在多奇當QA當的不是很開心，自己實在對QA的工作沒啥興趣，所以跑去學了一下Selenium，想說工作上可以用到，結果也沒用到，後來被我拿來做104跟CakeResume的爬蟲^_^Selenium學習筆記-以104人力銀行為例\n  Redis：\n加入新公司後學到的，原本就有興趣想要學這個技術，學了之後發現還蠻簡單的，但對於Cache的時機還是不太熟，之後的Side Project我也想要用這門技術試看看Redis學習筆記\n  RabbitMQ：\n其實不能說學，應該說有碰過，大概知道是啥，但距離「學會」還有一段路要走 RabbitMQ學習筆記\n  Vue：\n學沒幾天就跑去打魔物獵人了= =\n  Xxl-job：\n非常好用的一個分布式任務調度，概念就像是SpringBoot中的排程器，但是更猛更強大，讓我再次感嘆祖國的紅太陽的偉大，中國人實在是太牛啦！Xxl-Job 分布式任務調度中心學習筆記\n  Elastic Search：\n也是一個碰過但沒學透的東西，前陣子公司因為ES資料太多然後爆炸了，有機會再繼續研究這塊，感覺是個很棒的技術 ElasticSearch學習筆記\n  Django：\n為了side project跑去學的，結果也沒學完就鴿了 = =\n  2024展望 研究所相關 肯定是要來個大滿貫的吧\n目標是讀完六科，然後在今年年底達到應試水準\n 作業系統 計算機組織 線性代數 離散數學 資料結構 演算法  技術相關   Vue：\n為了做side project，也為了自己，不求能夠達到工作的水準，但至少要能夠做一些基本的開發，有時候想做一些有的沒的的東西\n  微服務相關：\n嘴巴上一直說想學，但一直沒碰= = ，想看一下SpringCloud、AlibabaCloud、Dubbo等等之類跟微服務相關的技術吧，都工作快兩年了，該碰看看了\n  Elastic Search：\n一個很酷的東西，目前還不知道他跟SQL具體差在哪裡，為什麼要用它？對於他的分片、分組機制都沒到很熟。\n  MongoDB：\n也是新公司有用到，但我完全沒碰過的東西= = 完全沒概念是啥\n  Github Action：\n就Github的CICD，我blog目前的發佈就是靠Github Action去啟動的\n  完成Side Project：\n沒啥好說的，就是SideProject開發(1)-台股監控Web這個不知道我多久沒動的Side Project，因為前鎮子遭遇技術上的困難，等我考完試之後再來繼續完成這一部分。\n  Rabbit MQ：\n不熟的一個東西，但也是去學習\n  架看看Jump Server ：\n雖然說跟後端沒啥關係，但覺得這門技術蠻酷的，想學看看\n  學習AWS：(2024/1補充) 很常聽到這個，好像不只是個雲端機的感覺，想了解一下\n  想要做一個結合SpringBoot + Vue + Redis + RabbitMQ + Elastic Search 的專案吧，希望今年年末的時候能夠達成目標！\n","date":"2024-01-11T21:57:14+08:00","image":"https://i.imgur.com/kFNcWip.jpg","permalink":"https://hoxtonhsu.com/p/%E6%8A%80%E8%A1%93%E5%9B%9E%E9%A1%A7%E4%BB%A5%E5%8F%8A2024%E5%AD%B8%E7%BF%92%E7%9B%AE%E6%A8%99/","title":"技術回顧以及2024學習目標"},{"content":"前言 在公司一次版本迭代中，有多了新的table還有新的欄位，因此有舊資料跟新資料之間要過度，原本用來join on的欄位也要跟著換\n原本的如下\n1  on student.id = player.id   我為了要兼容舊資料，沒有動太多心思，就想說用or去處理就好\n1  on student.id = player.id or member.id = player.id   就傻傻的用or去處理了。\n服務器爆炸 這個語法普遍出現在我所有需要做新舊資料兼容的SQL中，當時在寫的時候想說自己真是牛逼，多加了幾個字就解決兼容性的問題，真是個不世出的天才\n沒想到這段Code被發佈到正式環境時，就出現了jdbc連線超時的問題。\n1  druid.pool.DataSourceClosedException   後來大家開始排查問題，想說為什麼jdbc會突然出問題，大概找了一個多小時，公司裡面一個大佬說\n「這個sql有問題，有or導致整張表的查詢時間增加太多，就是這些or語法導致sql在查詢時耗時太久，因為測試環境的資料相對較少，所以這問題測試環境看不出來」\n後來搜尋了一下，發現最主要的問題在於說where搭配or搜尋，會導致索引失效\n原因 參考至SQL中使用or影响性能的解决办法的解決方案，裡面內文有說到，在where中使用or的情形中，可能會導致SQL放棄使用index，轉而去進行逐表Full Scan，如果是不會增長的資料還好，但會員數是會增長的，正式環境可能有上萬筆的會員資料，就等於SQL在執行時會像個白癡一樣傻傻的去找對應的資料，這件事情的複雜度是O(n)，如果真的有需要用到or的需求，也應該用union來替代，用or會導致SQL搜尋直接炸掉。\nMySQL Explain 以下用我自己side Project的table來示範，這張table有兩個index，id跟stock_code\n在MySQL中，我們可以在一個搜尋語句前面加上explain，來查看SQL語句的健檢報告\n1  select * from daily_stock_data;   使用explain就像這樣\n1  explain select * from daily_stock_data;   使用explain時，執行的就不是這個sql所執行的結果，而是這個sql執行下來的一些指標\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE daily_stock_data null ALL null null null null 10428 100 null    我們可以注意possible_keys跟key，而possible_keys代表可能會使用到的index，key就代表實際有使用到的index，在這個搜尋中，我們基本上沒有用到任何的index（也很正常，畢竟我們本來就沒用到任何條件搜尋）\n那我們接下來用stock_code來搜尋看看\n1  explain select stock_code from daily_stock_data where \u0026#39;2330\u0026#39;      id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE daily_stock_data null index null idx_stock_code 403 null 10428 100 Using index    會發現我們的key有值了，就代表這次的搜尋我們有用到index去處理。\n那我們接下來執行一個where搭配or的搜尋\n1  explain select stock_code from daily_stock_data where date = \u0026#39;112/01/04\u0026#39; or stock_code = \u0026#39;2330\u0026#39;;   在這個情況下，index就失效了，如果想要or搜尋能夠為使用索引，最簡單的方式就是將你要作為條件的兩個列都加上index，就能解決這個全表搜尋性能下降的問題\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE daily_stock_data null ALL idx_stock_code null null null 10428 11.91 Using where    關於explain的內容，可以查看什麼？我寫的一條SQL讓公司網站癱瘓了…SQL慢查詢改善來了解更多\n可能導致索引失效的操作  全模糊搜尋跟左模糊搜尋(’％ABC％‘, \u0026lsquo;%ABC\u0026rsquo;) ，右模糊搜尋是不會影響到的(\u0026lsquo;ABC%') is null Where 配上 or in跟 not in ，可以使用between替代 使用select * 也會放棄index搜尋  更詳細的內容可以參考会引起全表扫描的几种SQL 以及sql优化 （转）\n參考資料 SQL中使用or影响性能的解决办法\nSQL中使用or影响性能的解决办法转载\nSQL UNION vs OR 性能原创\n什麼？我寫的一條SQL讓公司網站癱瘓了…SQL慢查詢改善\n会引起全表扫描的几种SQL 以及sql优化 （转）\n","date":"2024-01-03T18:51:54+08:00","image":"https://i.imgur.com/RAhQlP7.png","permalink":"https://hoxtonhsu.com/p/%E5%9C%A8sql%E4%B8%AD%E4%BD%BF%E7%94%A8or%E6%98%AF%E4%B8%80%E4%BB%B6%E9%9D%9E%E5%B8%B8%E5%8D%B1%E9%9A%AA%E7%9A%84%E4%BA%8B%E6%83%85/","title":"在SQL中使用or是一件非常危險的事情"},{"content":"接續懶人求三階矩陣行列式的方法\n將C1 C2 R1 R2 擴展\nC1 R1 刪去不看\n做這樣子的處理，記得最後的結果要轉置，轉置後的答案就是伴隨矩陣了\n有伴隨矩陣，也有A的行列式，那算出反矩陣就是一秒鐘的事情了，啥也不是，散會\n參考資料 https://www.youtube.com/watch?v=TBlukhJNdX4\u0026amp;ab_channel=RussellKirk\n","date":"2024-01-03T01:34:46+08:00","image":"https://i.imgur.com/spFKI2X.png","permalink":"https://hoxtonhsu.com/p/%E5%BF%AB%E9%80%9F%E6%B1%82%E5%87%BA%E4%B8%89%E9%9A%8E%E7%9F%A9%E9%99%A3%E7%9A%84%E4%BC%B4%E9%9A%A8%E7%9F%A9%E9%99%A3%E5%8F%8D%E7%9F%A9%E9%99%A3/","title":"快速求出三階矩陣的伴隨矩陣、反矩陣"},{"content":"看完這篇別忘了看下篇\n快速求出三階矩陣的伴隨矩陣、反矩陣\n之前在學的時候林緯是教這種形式\n但看一看覺得真的是有夠糊，後來有一次看到有更方便的做法\n過程 矩陣如下\n我們把C1 C2 重複一遍寫在右邊\n結果 接著像這樣畫，將紅色的和減去綠色的和，即為所求\n","date":"2024-01-03T01:28:01+08:00","image":"https://i.imgur.com/hS0CXI6.png","permalink":"https://hoxtonhsu.com/p/%E6%87%B6%E4%BA%BA%E6%B1%82%E4%B8%89%E9%9A%8E%E7%9F%A9%E9%99%A3%E8%A1%8C%E5%88%97%E5%BC%8F%E7%9A%84%E6%96%B9%E6%B3%95/","title":"懶人求三階矩陣行列式的方法"},{"content":"參考網址 https://www.bilibili.com/video/BV1Sf4y1v77f?p=1\n專案程式碼 https://github.com/Hoxton019030/Django_pratice\n筆記 使用conda來安裝DJango\n1  pip install django==2.0   輸入\n1  django-admin   可以查看一些指令集\n startproject 啟動django項目 startapp 啟用django應用 check 教驗項目完整性 runserver 進入django環境 並且運行django項目 shell 進入django shell test 跑單元測試 makemigrations 創建模型變更的遷移文件 migrate 執行上一個命令創建的遷移文件 dumpdata 把數據庫導出到文件 loaddate 把文件數據導入到數據庫  如何創建Django項目 1  django-admin startproject django_introduction   認識Django項目結構  manage.py 項目管理文件 settings.py 項目配置文件 urls.py django路由文件 wsgi.py 不知道是啥  此時可以在根目錄底下運行\n1  python manage.py runserver   如果有看到這個畫面就代表成功了！\nDjango應用 Vs Django項目\n一個Django項目就是一個基於Django的web應用\n一個Django應用就是一個可重用的Python軟體包\n一個Django應用可以自己管理模型、視圖、模板、路由、靜態文件\n一個Django項目可以包含一組配置和若干個Django應用\n如何創建Django應用 1  python manage.py startapp blog   就會在創建一個名為blog的應用\nDjango應用目錄介紹  view.py 視圖處理的地方 models.py 定義應用模型的地方 admin.py 定義Admin模塊管理對象的地方 apps.py 聲明應用的地方 test.py 編寫應用測試的地方 urls.py (要自行創建) 管理應用路由的地方  Django視圖 1 2 3 4 5 6 7 8 9  from django.shortcuts import render from django.http import HttpResponse # Create your views here. # request要加 def hello_world(request): # 要把回傳的東西包裝成HttpResponse物件 return HttpResponse(\u0026#34;Hello world!\u0026#34;)   Django 路由 Django目前對我們的實現的視圖一無所知，請求無法到達，所以需要配置路由，將視圖函數與URL進行綁定\n路由配置有分成\n 應用層次的路由 項目層次的路由  首先配置應用層次的路由，首先新增urls.py的檔案\n應用層次的路由配置 blog 中的urls.py這樣寫\n1 2 3 4 5 6 7 8  from django.urls import path, include import blog.views urlpatterns=[ # 如果路由含有hello_world，則轉發到blog.views.hello_world 記得不用帶() path(\u0026#34;hello_world\u0026#34;, blog.views.hello_world) ]   項目層次的路由 在項目的urls.py中，這樣寫\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026#34;\u0026#34;\u0026#34;django_introduction URL Configuration The `urlpatterns` list routes URLs to views. For more information please see: https://docs.djangoproject.com/en/2.0/topics/http/urls/ Examples: Function views 1. Add an import: from my_app import views 2. Add a URL to urlpatterns: path(\u0026#39;\u0026#39;, views.home, name=\u0026#39;home\u0026#39;) Class-based views 1. Add an import: from other_app.views import Home 2. Add a URL to urlpatterns: path(\u0026#39;\u0026#39;, Home.as_view(), name=\u0026#39;home\u0026#39;) Including another URLconf 1. Import the include() function: from django.urls import include, path 2. Add a URL to urlpatterns: path(\u0026#39;blog/\u0026#39;, include(\u0026#39;blog.urls\u0026#39;)) \u0026#34;\u0026#34;\u0026#34; from django.contrib import admin from django.urls import path,include urlpatterns = [ path(\u0026#39;admin/\u0026#39;, admin.site.urls), path(\u0026#39;blog/\u0026#39;,include(\u0026#39;blog.urls\u0026#39;)) # 若url包含blog/，則轉發至blog資料夾底下的urls ]   調整settings.py 最後去調整項目的settings.py，把blog的config添加到項目中\n啟動專案 輸入\n1  python manage.py runserver   接著訪問\nhttp://127.0.0.1:8000/blog/hello_world\n就有hello world了！\nDjango路由圖 ","date":"2023-12-27T02:46:29+08:00","image":"https://i.imgur.com/fIk8FK8.jpg","permalink":"https://hoxtonhsu.com/p/django%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"Django學習筆記"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12 13 14  public static String readFileAsString(File file) { StringBuilder content = new StringBuilder(); try (BufferedReader br = new BufferedReader(new FileReader(file))) { String line; while ((line = br.readLine()) != null) { content.append(line).append(\u0026#34;\\n\u0026#34;); } } catch (IOException e) { e.printStackTrace(); // 可以根據需要進行錯誤處理  } return content.toString(); }   ","date":"2023-12-27T00:34:04+08:00","image":"https://i.imgur.com/RFS2LGT.png","permalink":"https://hoxtonhsu.com/p/java%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95-%E5%B0%87%E6%AA%94%E6%A1%88%E8%AE%80%E6%88%90string/","title":"Java常用方法 將檔案讀成String"},{"content":"`\n在我的構想中，這個專案底下應該要有兩個模塊\n 是web端的模塊，負責到資料庫撈出一些比如說連續漲、連續跌的股票 是資料同步模塊，用來將股票資訊與台股觀測站的資料同步的，比如說歷史股價，本日股價  用意是為了當這個資料同步模塊需要更新時，我的Web還是可以讓別人訪問的\n但不知道為啥，這個multiModule的功能我弄了快兩個禮拜，期間一直出錯，一直出現Class Not Found的錯誤，當我沒有任何module的時候都沒問題，但只要當我new Module時，我的專案就無法啟動，這期間我在網路上有查到很多解法，比如說指定spring maven的main檔案 或者是把m2資料夾全部刪除 或是mvn clear, mvn install都沒有辦法解決這個問題，有想過可能是SpringBoot 3的問題，但試過SpringBoot 2也有類似的情形發生。\n後來弄了老半天，我才發現我搞錯MultiModule的用法＝＝\n如果要建立多模組的專案，底下是不能有src的，一但有src，專案會不清楚我們到底要執行哪個main，大概就這點事情弄了我兩個禮拜的時間^_^，真好玩，嘻嘻\n","date":"2023-12-24T18:47:38+08:00","image":"https://i.imgur.com/LTNMTzI.png","permalink":"https://hoxtonhsu.com/p/sideproject%E9%96%8B%E7%99%BC2-%E5%8F%B0%E8%82%A1%E7%9B%A3%E6%8E%A7web/","title":"SideProject開發(2)-台股監控Web"},{"content":"大概前一陣子再刷BiliBili的時候，看到一個30up的程序員的影片，內容是說\n「如果能給10年前的自己建議，會想說什麼」\n其中有一項就是說「不要只學技術而不產出」不要學了很多技術，比如說redis呀、ElasticSearch等等的，結果卻沒有把它實際應用過。\n雖然本人目前是要考研究所的狀態，但還是想做一些產出型的東西，於是左思右想決定就以台股網站為目標，來做一個SideProject。為什麼會想做這個的原因是因為我覺得目前市面上的股票App都太爛了，不符合我的需求，我希望可以看到每張股票的狀況，而不是只Show給我看什麼本日最多漲跌之類的訊息，並且我希望有Email通知的功能等等的。\n然後在寫的時候就想到一篇很久以前看到的文章，再講一群學生創業，想要做自動飲料機的紀錄，於是想要試看看寫類似的東西（？，這篇文章打的有點草率，因為我目前還在煮飯，等我有空之後再來補後續\n因為自動飲料機而研畢的一年 ","date":"2023-12-13T01:14:25+08:00","image":"https://i.imgur.com/MWeeVVM.jpg","permalink":"https://hoxtonhsu.com/p/sideproject%E9%96%8B%E7%99%BC1-%E5%8F%B0%E8%82%A1%E7%9B%A3%E6%8E%A7web/","title":"SideProject開發(1)-台股監控Web"},{"content":"省流 如果你是用SpringBoot 3 的話，你的Mybatis版本也要更新到3，不然會一直出現\n1  Parameter 1 of constructor in ...required a bean of type ... that could not be found.   這樣的錯誤，把你的pom更新成這樣就可以了\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   故事 這陣子在做SideProject，想練習redis, rebbitMQ, 以及Elastic Search。在引入MyBatis時出現了一個錯誤(圖是網路找的)\n當時百思不得其解，我該加的Annotation加了，my-batis xml也配了，該處理的都處理了，但不知道為什麼就是找不到，期間來回試了多種方法，用ApplicationContext去找bean呀，改成用setter注入呀之類的方式都不行，大概這樣來回折騰了三四個小時。\n後來實在沒辦法，跑去執行以前的專案，發現相同的配置下不知道為什麼跑得起來，但我的就不行，於是就想到了\n「阿幹你媽的，SpringBoot最近好像升級到3.0了」\n（不管是IDEA或是Spring Initializr都沒辦法在下載2.0版本的SpringBoot了)\n然後順著這個線索，到我的POM裡面去看，果然看到了我的MyBatis版本還留在2.0版，接著重新找一個支援3.0的版本\nShift shift -\u0026gt; reload maven project\n這樣就可以運行起來了。順便抱怨一下，3.0好像有更新過了，我記得剛出來的時候還強制要寫dockerfile = =\n最近在創建新專案的時候就沒這個問題了\n","date":"2023-12-04T16:28:43+08:00","image":"https://i.imgur.com/OXooq5i.png","permalink":"https://hoxtonhsu.com/p/%E8%99%95%E7%90%86-mybatis%E5%B0%8E%E8%87%B4%E7%9A%84-parameter-1-of-constructor-in-...required-a-bean-of-type-...-that-could-not-be-found./","title":"處理 Mybatis導致的 Parameter 1 of constructor in ...required a bean of type ... that could not be found."},{"content":"前陣子公司有個需求，是要用Elastic Search撈出四筆約20萬長度左右的List做數據處理，那時候看到同事用了這個CompletableFuture的Lambda，當時看到這個東西的時候\n後來稍微看了一下，我感覺這個應該就是Java8對於Async操作的封裝詳請可以看這邊。\n如果用形象化一點的比喻的話，CompletableFuture就像是世紀帝國的農民、魔獸爭霸的建築工人一樣\n你在遊戲一開始可能會派幾個農民去挖礦、砍樹，當然也會叫幾個農民去蓋建築物，而這些你下達指令，後續就不用在管他的行為其實就很像CompleteFuture的在做的事，而CompleteFuture與一般的Async，最大的差異在於CompleteFuture支援了一系列後續操作，比如說當你第一個Future完成，接著做的.thenApply .whenComplete .thenAccept ，或是Future 拋出例外時做的exceptionally等等，讓非同步的操作與Method chaining兩者結合在一起\n實際演練 推薦的外部連結 https://popcornylu.gitbooks.io/java_multithread/content/async/cfuture.html\nhttps://www.zhihu.com/question/433003386\n","date":"2023-12-03T11:34:45+08:00","image":"https://i.imgur.com/bbIoOnR.png","permalink":"https://hoxtonhsu.com/p/java%E7%95%B0%E6%AD%A5%E5%9F%B7%E8%A1%8C%E5%B0%8F%E7%B2%BE%E9%9D%88-completablefuture%E4%BB%8B%E7%B4%B9/","title":"Java異步執行小精靈 CompletableFuture介紹"},{"content":"前言 唉呀呀，最近實在是太忙了，這陣子一直在忙公司的內容，沒啥時間更新部落格，趁著今天剛洗好澡的時候來更新一下，這次想講的是IntelliJ的一個功能叫做Code Complete，這功能是啥咧？\nIntelliJ裡面你可以透過sout快速產生System.out.println(\u0026quot;\u0026quot;)的模板對吧，這個功能就叫做Code Complete。之所以會介紹這個功能，是因為公司的Code沒有辦法在本地環境運行，只能在伺服器上跑，所以debugger這個功能是完全不行的\n所以當我們要測試一個東西時，最常用的就是log了，我們log everything，List也log，object也log，不能log的就加上＠ToString讓他log出來，因此我產生了很大量需要log的需求，例如\n1  log.info(\u0026#34;Hoxton查看list長度為{}\u0026#34;,list.size())   這樣的code，頻繁的出現在我的測試分支上，一來一往真的是很麻煩，於是我就想到了我可愛的sout，如果能讓log這件事情變得像sout一樣簡單，那麼我的產出一定會崗崗滴（事實證明沒有，我只是用更快的方式出錯而已）\n實現 要實現這個功能，就要使用postfix complete這個功能，畫面如下\n我們新增一個Java模板\n然後照這樣輸入\n1  log.info(\u0026#34;Hoxton log測試$EXPR$:{}\u0026#34;,$EXPR$);   這樣就能夠快速的log出資料囉！\n如果有需要log String的話，需要再新增一個logs，因為log這個postfix如果打印文字會出現格式錯誤的問題QQ，這我還沒想好怎麼修\n如此一來就能夠快速地打印出log囉！\n","date":"2023-11-22T02:05:31+08:00","image":"https://i.imgur.com/oRRgTer.jpg","permalink":"https://hoxtonhsu.com/p/intellij%E5%BF%AB%E9%80%9F%E7%94%A2%E7%94%9Flog%E6%A8%A1%E6%9D%BF/","title":"IntelliJ快速產生log模板"},{"content":"非常痛苦\u0026hellip;為了苟過試用期、不成為團隊的bottleneck，被迫半夜在這邊學這個shit\n本文會用到的連結\nHow to Integrate Elastic Search With Spring Boot CRUD Project| Spring Boot | Elasticsearch| EnggAdda\n這東西的坑真的很多 springBoot Elastic Search 還有相關的套件版本必須一致\n","date":"2023-11-01T02:16:35+08:00","image":"https://i.imgur.com/PKZTCYE.png","permalink":"https://hoxtonhsu.com/p/springboot%E8%88%87elasticsearch%E7%9A%84%E7%B5%90%E5%90%88/","title":"SpringBoot與ElasticSearch的結合"},{"content":"本文會用到的連結\nBeginner\u0026rsquo;s Crash Course to Elastic Stack - Part 1: Intro to Elasticsearch and Kibana\n我的主¡管底下有三個員工，我是其中一位，今天主管說有一個新需求要交代，派給了另外兩個同事，但沒派給我，為了展現本人一心向學的個性(快打考績了，要狗腿一點，並且希望可以苟過適用期)，我便很假掰的問了一下\n「不好意思，請問等等的會議，雖然我沒有被分配到工作，但我也想參加，不知道可以嗎？」\n中午參加會議完後，主管便打電話給我\n「Hoxton，剛剛的會議你有參加齁？現在有多了一個新的需求OOO，再請你處理一下」\nㄏㄏ ，結果新的需求會用到Elastic Search 我完全不懂，死定\n安裝Elastic Search Kibana 本人強烈建議，一率安裝8.1.0的版本！！！\nElastic Search是一個程式，而Kibana則是它的GUI\n相關的安裝可以到Udemy上查看，這也是我最推薦的方式，安裝的部分是免費可以看的\n教學連結Udemy\n到這邊下載對應版本的Elastic Search，再次強調，安裝8.1.0\nhttps://www.elastic.co/downloads/elasticsearch\n2024/4/27補充\n 下載完後，進到根目錄中，本人強烈建議編輯 config/elasticsearch.yml 中的兩個值\n關閉ssl認證\n1 2  xpack.security.http.ssl:enabled:false  關閉帳號密碼認證\n1  xpack.security.enabled:false   關閉這兩個會讓你少很多痛苦，相信我\n解壓鎖完後進入到Elastic Search的根目錄中，輸入以下指令，就可以啟用ElasticSearch了\n1  bin/elasticsearch   在啟動完成後，ElasticSearch會為我們創建一個超級使用者，並會把它的密碼輸出在terminal中\n如果你不幸忘記了密碼，可以輸入以下指令來重置\n1  bin/elasticsearch-reset-password -u elastic   還會產生一組Token用作Kibana的連接，這組Token會存續30分鐘\n當然，如果你不幸又忘記了，可以輸入以下指令來重新獲取\n1  bin/elasticsearch-create-enrollment-token --scope kibana   接著安裝Kibana\n再次再次強調，請安裝8.1.0的版本\n安裝解壓縮完，到Kibana的根目錄下執行\n1  bin/kibana   就可以啟動Kibana，並且訪問對應的頁面\nURL : http://localhost:5601/app/home#/\n接著按照他的要求，把Elastic Search所提供的token填入Kibana中\n然後帳號密碼的部分也是請查看Elastic Search的Terminal\n這樣就完成登入了！真的是操你媽的8.11版本，我搞超久，後來降成8.1.0就沒問題了，我真的是幹你媽的Elastic Search\n如何使用Kibana URL : http://localhost:5601/app/home#/\n進入Kibana後點選這邊\n按下這個賤，就可以送出請求囉！\nElastic Search 介紹 常見的使用場景有：Uber在搜尋駕駛、搜尋附近的餐廳、遊戲的數據搜集、Tinder配對、火星好奇心號的數據收集、Log紀錄、安全性分析等等\n並不是一個Database，他更像是一個搜尋與分析的工具\nIndex Document Field ElasticSearch的Request格式 本章節參考至\nBeginner\u0026rsquo;s Crash Course to Elastic Stack - Part 1: Intro to Elasticsearch and Kibana\n文章內容來自：Part-1-Intro-to-Elasticsearch-and-Kibana\n編輯一下elastic/congig/elasticsearch.yml的檔案，將這cluster跟node命名如下\n查看cluster狀態 1  GET _API/參數   大概是長這樣，比如說以下的格式就是去查cluster的健康狀況\n1  GET _cluster/health   回應的結果就是這樣\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  { \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;status\u0026#34; : \u0026#34;green\u0026#34;, \u0026#34;timed_out\u0026#34; : false, \u0026#34;number_of_nodes\u0026#34; : 1, \u0026#34;number_of_data_nodes\u0026#34; : 1, \u0026#34;active_primary_shards\u0026#34; : 11, \u0026#34;active_shards\u0026#34; : 11, \u0026#34;relocating_shards\u0026#34; : 0, \u0026#34;initializing_shards\u0026#34; : 0, \u0026#34;unassigned_shards\u0026#34; : 0, \u0026#34;delayed_unassigned_shards\u0026#34; : 0, \u0026#34;number_of_pending_tasks\u0026#34; : 0, \u0026#34;number_of_in_flight_fetch\u0026#34; : 0, \u0026#34;task_max_waiting_in_queue_millis\u0026#34; : 0, \u0026#34;active_shards_percent_as_number\u0026#34; : 100.0 }   查看node狀態 再發一個請求，查看node的狀態，確認我們對node的重新命名有生效\n1  GET _nodes/stats   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  { \u0026#34;_nodes\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;nodes\u0026#34; : { \u0026#34;yz_GM-vITti54G1nS6GiEg\u0026#34; : { \u0026#34;timestamp\u0026#34; : 1698688524532, \u0026#34;name\u0026#34; : \u0026#34;curd_node\u0026#34;, \u0026#34;transport_address\u0026#34; : \u0026#34;127.0.0.1:9300\u0026#34;, \u0026#34;host\u0026#34; : \u0026#34;127.0.0.1\u0026#34;, \u0026#34;ip\u0026#34; : \u0026#34;127.0.0.1:9300\u0026#34;, \u0026#34;roles\u0026#34; : [ \u0026#34;data\u0026#34;, \u0026#34;data_cold\u0026#34;, \u0026#34;data_content\u0026#34;, \u0026#34;data_frozen\u0026#34;, \u0026#34;data_hot\u0026#34;, \u0026#34;data_warm\u0026#34;, \u0026#34;ingest\u0026#34;, \u0026#34;master\u0026#34;, \u0026#34;ml\u0026#34;, \u0026#34;remote_cluster_client\u0026#34;, \u0026#34;transform\u0026#34; ...以下略 }   從這個Response我們也可以確定，我們對elasticsearch.yml的修改(更改cluster以及node名稱，確實是有生效的)\n創建index 1  PUT {NameOfTheIndex}   1  PUT favorite_candy   儲存Document到index中(Create) 有兩種方式，一種是透過PUT、另一種是透過POST，兩者的差別如下\n 當使用POST時，elastic search會自動為你的document創建id 使用PUT時，代表你要自己指定document的id是什麼  Post方式 Reqeust\n1 2 3 4  POST favorite_candy/_doc {\u0026#34;first_name\u0026#34;:\u0026#34;Lisa\u0026#34;, \u0026#34;candy\u0026#34;:\u0026#34;Sour Skittles\u0026#34; }   Response\n1 2 3 4 5 6 7 8 9 10 11 12 13  { \u0026#34;_index\u0026#34; : \u0026#34;favorite_candy\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;RXvLgYsBNuMe8RFD4lGF\u0026#34;, \u0026#34;_version\u0026#34; : 1, \u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 2, \u0026#34;successful\u0026#34; : 1, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;_seq_no\u0026#34; : 0, \u0026#34;_primary_term\u0026#34; : 1 }   Put方式 那個1代表我要Assign的Id名稱\n1 2 3 4  PUT favorite_candy/_doc/1 {\u0026#34;first_name\u0026#34;:\u0026#34;Lisa\u0026#34;, \u0026#34;candy\u0026#34;:\u0026#34;Sour Skittles\u0026#34; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;_index\u0026#34; : \u0026#34;favorite_candy\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_version\u0026#34; : 1, \u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 2, \u0026#34;successful\u0026#34; : 1, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;_seq_no\u0026#34; : 1, \u0026#34;_primary_term\u0026#34; : 1 }   我們在試著多塞一些資料進去，因為我們等等要retrive這些資料\n1 2 3 4 5 6 7 8 9  PUT favorite_candy/_doc/2 {\u0026#34;first_name\u0026#34;:\u0026#34;Rachel\u0026#34;, \u0026#34;candy\u0026#34;:\u0026#34;Rolos\u0026#34; } PUT favorite_candy/_doc/3 {\u0026#34;first_name\u0026#34;:\u0026#34;Tom\u0026#34;, \u0026#34;candy\u0026#34;:\u0026#34;Sweet Tarts\u0026#34; }   這邊特別注意一下，像現在的情況，id 1已經有一組資料了，如果重複PUT資料到id 1的情況，返回的結果會是這樣，version會變成2，result會變成update\n也有另一種方式，類似SQL中的 craete if not exist\u0026hellip;的用法，就是這樣\n1 2 3 4  PUT favorite_candy/_create/1 {\u0026#34;first_name\u0026#34;:\u0026#34;Rachel\u0026#34;, \u0026#34;candy\u0026#34;:\u0026#34;Rolos\u0026#34; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  { \u0026#34;error\u0026#34; : { \u0026#34;root_cause\u0026#34; : [ { \u0026#34;type\u0026#34; : \u0026#34;version_conflict_engine_exception\u0026#34;, \u0026#34;reason\u0026#34; : \u0026#34;[1]: version conflict, document already exists (current version [2])\u0026#34;, \u0026#34;index_uuid\u0026#34; : \u0026#34;PscoViAvQF6UvIEvN35Cpg\u0026#34;, \u0026#34;shard\u0026#34; : \u0026#34;0\u0026#34;, \u0026#34;index\u0026#34; : \u0026#34;favorite_candy\u0026#34; } ], \u0026#34;type\u0026#34; : \u0026#34;version_conflict_engine_exception\u0026#34;, \u0026#34;reason\u0026#34; : \u0026#34;[1]: version conflict, document already exists (current version [2])\u0026#34;, \u0026#34;index_uuid\u0026#34; : \u0026#34;PscoViAvQF6UvIEvN35Cpg\u0026#34;, \u0026#34;shard\u0026#34; : \u0026#34;0\u0026#34;, \u0026#34;index\u0026#34; : \u0026#34;favorite_candy\u0026#34; }, \u0026#34;status\u0026#34; : 409 }   這樣子，如果id已經存在，就不會overwrite這個document\n查看Ducument(Retrive) GET {index名稱}/_doc/{id}\n1  GET favorite_candy/_doc/1   更新Document(Update) 1 2 3 4 5 6 7  POST Name-of-the-Index/_update/id-of-the-document-you-want-to-update { \u0026#34;doc\u0026#34;: { \u0026#34;field1\u0026#34;: \u0026#34;value\u0026#34;, \u0026#34;field2\u0026#34;: \u0026#34;value\u0026#34;, } }   1 2 3 4 5 6  POST favorite_candy/_update/1 { \u0026#34;doc\u0026#34;: { \u0026#34;candy\u0026#34;: \u0026#34;M\u0026amp;M\u0026#39;s\u0026#34; } }   刪除Document(Delete) 1  DELETE Name-of-the-Index/_doc/id-of-the-document-you-want-to-delete   1  DELETE favorite_candy/_doc/1   Precision And Recall 使用實際資料來練習Elastic Search Part-2-Understanding-the-relevance-of-your-search-with-Elasticsearch-and-Kibana\n資料下載連結：Kaggle\n資料大概長這樣，就是一個新聞網站的json資料，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  [ { \u0026#34;link\u0026#34;: \u0026#34;https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9\u0026#34;, \u0026#34;headline\u0026#34;: \u0026#34;Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;U.S. NEWS\u0026#34;, \u0026#34;short_description\u0026#34;: \u0026#34;Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\u0026#34;, \u0026#34;authors\u0026#34;: \u0026#34;Carla K. Johnson, AP\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2022-09-23\u0026#34; }, { \u0026#34;link\u0026#34;: \u0026#34;https://www.huffpost.com/entry/american-airlines-passenger-banned-flight-attendant-punch-justice-department_n_632e25d3e4b0e247890329fe\u0026#34;, \u0026#34;headline\u0026#34;: \u0026#34;American Airlines Flyer Charged, Banned For Life After Punching Flight Attendant On Video\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;U.S. NEWS\u0026#34;, \u0026#34;short_description\u0026#34;: \u0026#34;He was subdued by passengers and crew when he fled to the back of the aircraft after the confrontation, according to the U.S. attorney\u0026#39;s office in Los Angeles.\u0026#34;, \u0026#34;authors\u0026#34;: \u0026#34;Mary Papenfuss\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2022-09-23\u0026#34; }, { \u0026#34;link\u0026#34;: \u0026#34;https://www.huffpost.com/entry/funniest-tweets-cats-dogs-september-17-23_n_632de332e4b0695c1d81dc02\u0026#34;, \u0026#34;headline\u0026#34;: \u0026#34;23 Of The Funniest Tweets About Cats And Dogs This Week (Sept. 17-23)\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;COMEDY\u0026#34;, \u0026#34;short_description\u0026#34;: \u0026#34;\\\u0026#34;Until you have a dog you don\u0026#39;t understand what could be eaten.\\\u0026#34;\u0026#34;, \u0026#34;authors\u0026#34;: \u0026#34;Elyse Wanshel\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2022-09-23\u0026#34; } ]   匯入資料 index name : news_headlines\n查看有哪些index 1  GET /_stats/indexing   查看Index底下有哪些Document 1  GET {index}/_search    如果數量太多，會顯示預設的10個，relation也會顯示 gte 代表 great than\n 為了在大型數據集上提高響應速度，Elasticsearch默認限制了總計數為10,000。如果您想要確切的總命中數，請使用以下查詢。\n1 2 3 4  GET news_headlines/_search { \u0026#34;track_total_hits\u0026#34;: true }   兩種不同的搜尋 Query \u0026amp; Aggregation Query用來搜尋一些符合特定指標的Document\nAggregation是將數據總結為指標、統計數據和其他分析的過程，更接近分析數據\n使用Query依照關鍵字來做搜尋 match中搭配filedname即可達到搜尋的效果－\n1 2 3 4 5 6 7 8  GET user/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;abc123\u0026#34; } } }   1 2 3 4 5 6  GET news_headlines/_search { \u0026#34;query\u0026#34;: {\u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: \u0026#34;Khloe Kardashian Kendall Jenner\u0026#34; }} }   值得注意的是，這個不像是SQL的\n1  select * from news_headlines where headline = \u0026#39;Khloe Kardashian Kendall Jenner\u0026#39;   而是像這樣，match query是一種全文檢索(Fulltext query)\n1  select * from news_headlines where headline like \u0026#39;%Khloe%\u0026#39; or headline like \u0026#39;%Kardashian%\u0026#39; or headline like \u0026#39;%Kendall%\u0026#39; or headline like \u0026#39;%Jenner%\u0026#39;   使用operator 提升 Query精準度 如果我們是希望提升精准度，要找出包含 Khloe、Kardashian、Kendall、Jenner的，我們可以在搜尋加上operator\n1 2 3 4 5 6 7 8 9  GET news_headlines/_search { \u0026#34;query\u0026#34;: {\u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Khloe Kardashian Kendall Jenner\u0026#34;, \u0026#34;operator\u0026#34;:\u0026#34;AND\u0026#34; } }} }   使用minium_should_match 1 2 3 4 5 6 7 8 9  GET news_headlines/_search { \u0026#34;query\u0026#34;: {\u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Khloe Kardashian Kendall Jenner\u0026#34;, \u0026#34;minium_should_match\u0026#34;: 3 } }} }   使用Query依照時間來做搜尋 範例：\ngte : greater than\nlte : less than\n1 2 3 4 5 6 7 8 9 10 11  GET enter_name_of_the_index_here/_search { \u0026#34;query\u0026#34;: { \u0026#34;Specify the type of query here\u0026#34;: { \u0026#34;Enter name of the field here\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;Enter lowest value of the range here\u0026#34;, \u0026#34;lte\u0026#34;: \u0026#34;Enter highest value of the range here\u0026#34; } } } }   1 2 3 4 5 6 7 8 9 10 11  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;date\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2015-06-20\u0026#34;, \u0026#34;lte\u0026#34;: \u0026#34;2015-09-22\u0026#34; } } } }   使用Query依照時間來做搜尋並排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;date\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2015-06-20\u0026#34;, \u0026#34;lte\u0026#34;: \u0026#34;2015-09-22\u0026#34; } } }, \u0026#34;sort\u0026#34;: [ { \u0026#34;date\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34; } } ] }   各種不同的Match 語法 Match_Phrase 假設我們要找一首歌「Shape of You」，如果只用以下的搜尋，會出現很多不相關的結果，因為Match Quert會把 Shape 、 of 、 You 當成三個不同的詞彙去找，想要避免這樣，就需要使用\n1 2 3 4 5 6 7 8  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: \u0026#34;shape of you\u0026#34; } } }   1 2 3 4 5 6 7 8  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;headline\u0026#34;: \u0026#34;shape of you\u0026#34; } } }   Multi_Match 在不同的Field中搜尋，效果就有點像SQL的\nSelect * from news_headlines where headline like \u0026lsquo;%Michelle Obama%\u0026rsquo; or short_description like \u0026lsquo;%Michelle Obama%\u0026rsquo; or authors like like \u0026lsquo;%Michelle Obama%\u0026rsquo;\n1 2 3 4 5 6 7 8 9 10 11 12 13  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Michelle Obama\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;headline\u0026#34;, \u0026#34;short_description\u0026#34;, \u0026#34;authors\u0026#34; ] } } }   但這樣其實有一些問題，我們可能最主要是想找Michelle Obama的文章，但只要short_description裡面有提到Michelle Obama就會被包含進來，我們可能更 Focus 在 headline 的權重上面\n加權型Multi_Match 就是在Field後多加一個次方，就能將 headline 有 Michelle Obama 的結果先列出來了(Per Field Boosting)\n1 2 3 4 5 6 7 8 9 10 11 12 13  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Michelle Obama\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;headline^2\u0026#34;, \u0026#34;short_description\u0026#34;, \u0026#34;authors\u0026#34; ] } } }   將Multi-Match跟Match_Pharse結合 集百家之長，結合出來的搜尋\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Michelle Obama\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;headline^2\u0026#34;, \u0026#34;short_description\u0026#34;, \u0026#34;authors\u0026#34; ], \u0026#34;type\u0026#34;:\u0026#34;phrase\u0026#34; } } }   使用Bool Query來進行搜尋 TimeCode標好了 Beginner’s Crash Course to Elastic Stack - Part 3: Full text queries\n文章內容 ：https://github.com/LisaHJung/Part-3-Running-full-text-queries-and-combined-queries-with-Elasticsearch-and-Kibana\n所謂的bool query其實就是將不同條件整合再一起的一種搜尋，相當於SQL不是會有那種 where id = 1 and status=1的那種where and or語句嗎，bool query就是在做這個部分\n常見的bool query有以下幾種\n must：相當於AND 代表一定要有 filter：表示過濾條件，類似where的用法 should：不會影響到搜尋的結果，但會影響到排序，符合的會靠上 Must_not：表示不匹配的，相當於NOT  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  GET name_of_index/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ {One or more queries can be specified here. A document MUST match all of these queries to be considered as a hit.} ], \u0026#34;must_not\u0026#34;: [ {A document must NOT match any of the queries specified here. It it does, it is excluded from the search results.} ], \u0026#34;should\u0026#34;: [ {A document does not have to match any queries specified here. However, it if it does match, this document is given a higher score.} ], \u0026#34;filter\u0026#34;: [ {These filters(queries) place documents in either yes or no category. Ones that fall into the yes category are included in the hits. } ] } } }   這些bool也會跟基本查詢\n  Term\n  Match\n  Range\n  Terms\n  做搭配\n比如說像這樣\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Search\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;Elasticsearch\u0026#34; }} ], \u0026#34;filter\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;status\u0026#34;: \u0026#34;published\u0026#34; }}, { \u0026#34;range\u0026#34;: { \u0026#34;publish_date\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2019-01-01\u0026#34; }}} ], \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;author\u0026#34;: \u0026#34;John\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;author\u0026#34;: \u0026#34;Doe\u0026#34; }} ], \u0026#34;must_not\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Marketing\u0026#34; }} ] } } }   而一般Query是長這樣，可以稍微比較感覺到Query 跟Bool Query的差異\n1 2 3 4 5 6 7 8 9 10 11  { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;date\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2015-06-20\u0026#34;, \u0026#34;lte\u0026#34;: \u0026#34;2015-09-22\u0026#34; } } } }   以下示範一些常見的Bool Query的寫法\nBool Must查詢 1 2 3 4 5 6 7 8 9 10 11 12 13  { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;Hoxton\u0026#34; } } ] } } }   Bool Filter過濾 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;status\u0026#34;: \u0026#34;1\u0026#34; } },{ \u0026#34;range\u0026#34;:{ \u0026#34;loginTime\u0026#34;:{\u0026#34;gte\u0026#34;:\u0026#34;2023-01-01\u0026#34;,\u0026#34;lte\u0026#34;:\u0026#34;2024-12-31\u0026#34;} } } ] } } }   Bool Should 1 2 3 4 5 6 7 8 9 10 11 12  GET /my_index/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Elasticsearch\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;search\u0026#34; }} ] } } }   Bool MustNot 1 2 3 4 5 6 7 8 9 10 11  { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must_not\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Elasticsearch\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;search\u0026#34; }} ] } } }   Bool 多重搜尋(Match) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  { \u0026#34;query\u0026#34;:{ \u0026#34;bool\u0026#34;:{ \u0026#34;must\u0026#34;:[ { \u0026#34;match\u0026#34;:{ \u0026#34;userName\u0026#34;:\u0026#34;Hoxton\u0026#34; } }, { \u0026#34;match\u0026#34;:{ \u0026#34;gender\u0026#34;:1 } } ] } } }   Bool Terms 搜尋 2024/05/25更新\n找出某個Filed中符合條件的document\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;terms\u0026#34;: { \u0026#34;category\u0026#34;: [ \u0026#34;U.S. NEWS\u0026#34;, \u0026#34;COMEDY\u0026#34; ] } } ] } } }   使用Aggregation做搜尋 Kaggle 網址 ：Kaggle E-Commerce Data\n1 2 3 4 5 6 7 8 9 10 11  GET enter_name_of_the_index_here/_search { \u0026#34;aggs\u0026#34;: { \u0026#34;name your aggregation here\u0026#34;: { \u0026#34;specify aggregation type here\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;name the field you want to aggregate here\u0026#34;, \u0026#34;size\u0026#34;: state how many buckets you want returned here } } } }   Aggs: 代表你要送一個Aggregation\nBy_category: 你Aggregation出來的東西要叫什麼\nTerms: 以字段做分析\nFiled：字段具體的key是什麼\nSize：Filed最大上限，假設現在你的原始資料，key其實有1000個，但你只想要看100個，就可以在這邊限制，底下我有附圖片，可以看差距\n1 2 3 4 5 6 7 8 9 10 11  GET news_headlines/_search { \u0026#34;aggs\u0026#34;: { \u0026#34;by_category\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;category\u0026#34;, \u0026#34;size\u0026#34;: 100 } } } }   原始資料\n聚合出來的結果\n Size參數的影響\n 又使用Query 又使用Aggregation做搜尋 搜尋某一類別中最重要的詞語\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  GET enter_name_of_the_index_here/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;Enter the name of the field\u0026#34;: \u0026#34;Enter the value you are looking for\u0026#34; } }, \u0026#34;aggregations\u0026#34;: { \u0026#34;Name your aggregation here\u0026#34;: { \u0026#34;significant_text\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;Enter the name of the field you are searching for\u0026#34; } } } }   以下的搜尋可以這樣讀\n「我想要找到，在ENTERTAINMENT這個目錄中，headline的中，最具重要性詞語有哪些\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;ENTERTAINMENT\u0026#34; } }, \u0026#34;aggregations\u0026#34;: { \u0026#34;popular_in_entertainment\u0026#34;: { \u0026#34;significant_text\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;headline\u0026#34; } } } }   Aggregation 實戰 Kaggle 網址 ：Kaggle E-Commerce Data\nYoutube 網址 ：Beginner’s Crash Course to Elastic Stack - Part 4: Aggregations\n資料的樣子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  [ { \u0026#34;_index\u0026#34;: \u0026#34;ecommerce_data\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;U3hHL48B6YD2b_RB4N-A\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;UnitPrice\u0026#34;: 0.55, \u0026#34;Description\u0026#34;: \u0026#34;AGED GLASS SILVER T-LIGHT HOLDER\u0026#34;, \u0026#34;Quantity\u0026#34;: 144, \u0026#34;Country\u0026#34;: \u0026#34;United Kingdom\u0026#34;, \u0026#34;InvoiceNo\u0026#34;: \u0026#34;543456\u0026#34;, \u0026#34;InvoiceDate\u0026#34;: \u0026#34;2/8/2011 12:41\u0026#34;, \u0026#34;CustomerID\u0026#34;: 15753, \u0026#34;StockCode\u0026#34;: \u0026#34;21326\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;ecommerce_data\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;VHhHL48B6YD2b_RB4N-A\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;UnitPrice\u0026#34;: 1.25, \u0026#34;Description\u0026#34;: \u0026#34;SET OF SALT AND PEPPER TOADSTOOLS\u0026#34;, \u0026#34;Quantity\u0026#34;: 12, \u0026#34;Country\u0026#34;: \u0026#34;United Kingdom\u0026#34;, \u0026#34;InvoiceNo\u0026#34;: \u0026#34;543457\u0026#34;, \u0026#34;InvoiceDate\u0026#34;: \u0026#34;2/8/2011 12:47\u0026#34;, \u0026#34;CustomerID\u0026#34;: 17428, \u0026#34;StockCode\u0026#34;: \u0026#34;22892\u0026#34; } }, ]   三種Aggregation  Metric Aggregation：用來計算數字型的資料，比如說計算最大值、最小值、平均值等等 Bucket Aggregation：想要聚合複數Subset的資料時，使用Bucket Aggregation (一桶一桶的) Combined Aggregation  Metric Aggregation-求總和 1 2 3 4 5 6 7 8 9 10 11  GET ecommerce_data/_search { \u0026#34;size\u0026#34;:0, \u0026#34;aggs\u0026#34;: { \u0026#34;sum_unit_price\u0026#34;: { \u0026#34;sum\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;UnitPrice\u0026#34; } } } }   Size:0 影響的是會不會顯示hint的資料，如果0就只會顯示聚合結果\nMetric Aggregation-求最低 Size:0 影響的是會不會顯示hint的資料，如果0就只會顯示聚合結果\n1 2 3 4 5 6 7 8 9 10 11  GET ecommerce_data/_search { \u0026#34;size\u0026#34;:0, \u0026#34;aggs\u0026#34;: { \u0026#34;sum_unit_price\u0026#34;: { \u0026#34;min\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;UnitPrice\u0026#34; } } } }   Metric Aggregation-求最高 1 2 3 4 5 6 7 8 9 10 11  GET ecommerce_data/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;highest_unit_price\u0026#34;: { \u0026#34;max\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;UnitPrice\u0026#34; } } } }   Size:0 影響的是會不會顯示hint的資料，如果0就只會顯示聚合結果\nMetric Aggregation-求平均 Size:0 影響的是會不會顯示hint的資料，如果0就只會顯示聚合結果\n1 2 3 4 5 6 7 8 9 10 11  GET ecommerce_data/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;average_unit_price\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;UnitPrice\u0026#34; } } } }   Mertic Aggregation - 求所有(總和、最低、最高、平均) Size:0 影響的是會不會顯示hint的資料，如果0就只會顯示聚合結果\n1 2 3 4 5 6 7 8 9 10 11  GET ecommerce_data/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;all_stats_unit_price\u0026#34;: { \u0026#34;stats\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;UnitPrice\u0026#34; } } } }   使用Query條件來限制Aggregation的範圍 限制只統計Country為Germany的平均單位售價\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  GET ecommerce_data/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;Country\u0026#34;: \u0026#34;Germany\u0026#34; } }, \u0026#34;aggs\u0026#34;: { \u0026#34;germany_average_unit_price\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;UnitPrice\u0026#34; } } } }   Cardinality Aggregation 關鍵字：去重複、去重\n離散數學中的Cardinality，指的是一個集合中，不重複元素的個數，例如集合A={1,2,7,7,7}，那麼A的Cardinality就是3，寫作|A|=3。\n在ES中的Cardinality Aggregation也是類似的概念\n統計不重複的 CustomerID\n1 2 3 4 5 6 7 8 9 10 11  GET ecommerce_data/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;number_unique_customers\u0026#34;: { \u0026#34;cardinality\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;CustomerID\u0026#34; } } } }   共有4359個不重複的CustomerId\nBucket Aggregation 四種不同的Bucket Aggregation\n Date Historgram Aggregation：使用時間區間來 Group 資料 Histogram Aggregation Range Aggregation Terms Aggregation   Historgram ：直方圖\n Date Historgram Aggregation 按InvoiceDate，把資料每八個小時分成一桶\n1 2 3 4 5 6 7 8 9 10 11 12  GET ecommerce_data/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;transactions_by_8_hrs\u0026#34;: { \u0026#34;date_histogram\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;InvoiceDate\u0026#34;, \u0026#34;fixed_interval\u0026#34;: \u0026#34;8h\u0026#34; } } } }   精確與召回(Precision And Recall) 幹，這真的好難翻，精確就有點像是AND，召回就有點像是OR，使用召回，有可能會找到不太相干的資料，比如找臘腸，卻找到臘腸狗那樣，搜尋結果較多，但較不準確\nIncrease Recall 1 2 3 4 5 6 7 8 9 10  GET enter_name_of_index_here/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;Specify the field you want to search\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Enter search terms\u0026#34; } } } }   1 2 3 4 5 6 7 8 9 10  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Khloe Kardashian Kendall Jenner\u0026#34; } } } }   Increase Precision 這個搜尋是精確搜尋，會找到更符合預期的結果，語法其實就是多增加一個operator and就可以了啦\n唉，好累，不知道為啥10/31半夜還在這邊卷\n1 2 3 4 5 6 7 8 9 10 11  GET enter_name_of_index_here/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;Specify the field you want to search\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Enter search terms\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;and\u0026#34; } } } }   1 2 3 4 5 6 7 8 9 10 11  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Khloe Kardashian Kendall Jenner\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;and\u0026#34; } } } }   最小匹配搜尋(minimum_should_match) minimum_should_match是用來微調(fined tuning)匹配量的，我們的搜尋最初是包含Khloe Kardashian Kendall Jenner這四個詞的搜尋，但我們可以選擇到底要匹配幾個，比如說可以匹配3個，那就是C4取3，可以看下面的範例\n1 2 3 4 5 6 7 8 9 10 11  GET enter_name_of_index_here/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Enter search term here\u0026#34;, \u0026#34;minimum_should_match\u0026#34;: Enter a number here } } } }   1 2 3 4 5 6 7 8 9 10 11  GET news_headlines/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;headline\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Khloe Kardashian Kendall Jenner\u0026#34;, \u0026#34;minimum_should_match\u0026#34;: 3 } } } }   不同最小匹配量的值所影響到的結果\n","date":"2023-10-29T15:28:49+08:00","image":"https://i.imgur.com/IJFdjpO.png","permalink":"https://hoxtonhsu.com/p/elasticsearch%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"ElasticSearch學習筆記"},{"content":"本文參考至\nJava and Spring Boot Microservices | 10 Hour Full Course\n我使用的Repository如下\nhttps://github.com/Hoxton019030/SpringCloud\n最近公司需要打考績，其中有一項是關於下一季的自評，我想了一下，就寫了下面這些\n 入門ElasticSearch 學習如何進行資料庫的備份 學習如何製作讀寫分離的資料庫 SpringCloud入門 Java鎖的機制  所以這是一篇為了完成考績而寫的文章^_^，這邊先說一下我對微服務的理解。想像以Dcard作舉例，假設他們就用一台Server去處理註冊、登入、發布文章、回應請求，那麼這台Server可能要配置到很頂才能有辦法處理這件事情，因為當訪問量一大時，很容易就會導致其他功能的阻塞，所以我們的想法就是將不同的服務部署在不同的機器上面，讓A Server負責做登入、B Server負責做發布文章的事情\u0026hellip;等等，如此一來我們就可以讓一些請求頻率比較少，但較耗時的工作(註冊、發布文章)，和請求頻率高，但不耗時的工作(瀏覽文章)，獨立開來，並且某一項服務掛掉時，不會影響到其他Server的運行，不需要整個網站關閉起來來做Hotfix。\n學習目標  建立多模塊(Module的專案) 啟用Eureka作為服務發現中心 理解附載均衡(Load Balance) 使用Open Feign將類統整 使用Sleuth做Trace 理解Spring Cloud GateWay Message Queue之實作  建立多模塊(Module的專案) 請參考[Maven詳細研究]\nㄏㄏ ，第一段就直接水過去了，真爽\n啟用Eureka作為服務發現中心 理解Spring Cloud GateWay Gateway = 路由轉發+過濾器\npredicate 當滿足特定條件，再進行路由轉發。有以下這些，Path也是其中一種方式\nPath 路徑必須為\u0026hellip;才做路由轉發\nQuery 請求參數必須包含\u0026hellip;才做路由轉發\nHeader 請求頭中應該包含的內容，如果只有一個值，代表請求頭必須包含的參數名(key),如果有兩個值，則第一個代表是參數名(key)，第二個代表是參數的值(value)\nMethod 用什麼請求方式。比如說Get, Post 之類的\nRemoteAddr 允許訪問的客戶端地址，限制哪些IP可以訪問Gateway，注意不可以寫localhost！\nHost 功能跟Header差不多\nCookie 要求請求必須包含指定的key跟value\nAfter, Before, Between 在指定時間之前、之後、之中才可以訪問\nＷeigh 負載均衡中的權重，對同一組url做load Balance\nFilter 通過了predicate之後就到Filter這層，Filter有以下三種\n 內置Filter，都是Gateway的實現類  內置GlobalFilter，所有的路由都會經過這個 自定義GatewayFilter，在特定路由上生效  常用的Filter ","date":"2023-10-26T21:39:32+08:00","image":"https://i.imgur.com/tNdn4as.png","permalink":"https://hoxtonhsu.com/p/%E5%BE%AE%E6%9C%8D%E5%8B%99%E7%AD%86%E8%A8%98/","title":"微服務筆記"},{"content":"前言 最近工作上接觸到了這個套件，覺得令人歎為觀止，居然用這麼簡單的方式實現了我一直想做但不知道怎麼做的功能。\nXxl-Job說白話一點，就是一個中央定時任務調度平台，如果是單體式服務的話，我們可能是用Quartz或是Spring Schedule來實現，在這種情況管理這些Job(Batch)相對單純，因為所有東西都可以在單體式應用找到。\n但當專案擴展成微服務後，可能有各種不同的定時任務需要去調度，此時就有可能出現相同的任務，由於缺少任務發現中心，而在不同的服務去實現一樣的功能，此外，要配置這些定時任務時就得去各自的模塊去實現，相當的耗時費力。\n因此xxl-job就是來處理這些場景的，他有以下兩個功能\n 任務發現中心，可以將寫好的Job註冊在這邊，方便管理 統一調用、修改、停止、測試定時任務  在我上手之後，第一個感想就是\n「榮恩，這比魔杖還要好用呀！」\n以下附上作者的介紹\nIntroduction XXL-JOB is a distributed task scheduling framework. It\u0026rsquo;s core design goal is to develop quickly and learn simple, lightweight, and easy to expand. Now, it\u0026rsquo;s already open source, and many companies use it in production environments, real \u0026ldquo;out-of-the-box\u0026rdquo;.\nXXL-JOB是一个分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。\nDevelopment 于2015年中，我在github上创建XXL-JOB项目仓库并提交第一个commit，随之进行系统结构设计，UI选型，交互设计……\n于2015-11月，XXL-JOB终于RELEASE了第一个大版本V1.0， 随后我将之发布到OSCHINA，XXL-JOB在OSCHINA上获得了@红薯的热门推荐，同期分别达到了OSCHINA的“热门动弹”排行第一和git.oschina的开源软件月热度排行第一，在此特别感谢红薯，感谢大家的关注和支持。\n于2015-12月，我将XXL-JOB发表到我司内部知识库，并且得到内部同事认可。\n于2016-01月，我司展开XXL-JOB的内部接入和定制工作，在此感谢袁某和尹某两位同事的贡献，同时也感谢内部其他给与关注与支持的同事。\n于2017-05-13，在上海举办的 \u0026ldquo;第62期开源中国源创会\u0026rdquo; 的 \u0026ldquo;放码过来\u0026rdquo; 环节，我登台对XXL-JOB做了演讲，台下五百位在场观众反响热烈（图文回顾 ）。\n于2017-10-22，又拍云 Open Talk 联合 Spring Cloud 中国社区举办的 \u0026ldquo;进击的微服务实战派上海站\u0026quot;，我登台对XXL-JOB做了演讲，现场观众反响热烈并在会后与XXL-JOB用户热烈讨论交流。\n于2017-12-11，XXL-JOB有幸参会《InfoQ ArchSummit全球架构师峰会》，并被拍拍贷架构总监\u0026quot;杨波老师\u0026quot;在专题 \u0026ldquo;微服务原理、基础架构和开源实践\u0026rdquo; 中现场介绍。\n于2017-12-18，XXL-JOB参与\u0026rdquo;2017年度最受欢迎中国开源软件\u0026ldquo;评比，在当时已录入的约九千个国产开源项目中角逐，最终进入了前30强。\n于2018-01-15，XXL-JOB参与\u0026rdquo;2017码云最火开源项目\u0026ldquo;评比，在当时已录入的约六千五百个码云项目中角逐，最终进去了前20强。\n于2018-04-14，iTechPlus在上海举办的 \u0026ldquo;2018互联网开发者大会\u0026quot;，我登台对XXL-JOB做了演讲，现场观众反响热烈并在会后与XXL-JOB用户热烈讨论交流。\n于2018-05-27，在上海举办的 \u0026ldquo;第75期开源中国源创会\u0026rdquo; 的 \u0026ldquo;架构\u0026rdquo; 主题专场，我登台进行“基础架构与中间件图谱”主题演讲，台下上千位在场观众反响热烈（图文回顾 ）。\n于2018-12-05，XXL-JOB参与\u0026rdquo;2018年度最受欢迎中国开源软件\u0026ldquo;评比，在当时已录入的一万多个开源项目中角逐，最终排名第19名。\n于2019-12-10，XXL-JOB参与\u0026rdquo;2019年度最受欢迎中国开源软件\u0026ldquo;评比，在当时已录入的一万多个开源项目中角逐，最终排名\u0026quot;开发框架和基础组件类\u0026quot;第9名。\n于2020-11-16，XXL-JOB参与\u0026rdquo;2020年度最受欢迎中国开源软件\u0026ldquo;评比，在当时已录入的一万多个开源项目中角逐，最终排名\u0026quot;开发框架和基础组件类\u0026quot;第8名。\n于2021-12-06，XXL-JOB参与\u0026rdquo;2021年度OSC中国开源项目评选 \u0026ldquo;评比，在当时已录入的一万多个开源项目中角逐，最终当选\u0026quot;最受欢迎项目\u0026rdquo;。\n啟動專案 先到作者的\nhttps://github.com/xuxueli/xxl-job\n將專案clone下來，clone下來後修改這兩個地方\n 要連接的jdbc資訊（預設是mysql）  Log檔的儲存位置  設定好連線後，再去資料庫中將Table創建出來，語法在此\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123  # # XXL-JOB v2.4.1-SNAPSHOT # Copyright (c) 2015-present, xuxueli. CREATE database if NOT EXISTS `xxl_job` default character set utf8mb4 collate utf8mb4_unicode_ci; use `xxl_job`; SET NAMES utf8mb4; CREATE TABLE `xxl_job_info` ( `id` int(11) NOT NULL AUTO_INCREMENT, `job_group` int(11) NOT NULL COMMENT \u0026#39;执行器主键ID\u0026#39;, `job_desc` varchar(255) NOT NULL, `add_time` datetime DEFAULT NULL, `update_time` datetime DEFAULT NULL, `author` varchar(64) DEFAULT NULL COMMENT \u0026#39;作者\u0026#39;, `alarm_email` varchar(255) DEFAULT NULL COMMENT \u0026#39;报警邮件\u0026#39;, `schedule_type` varchar(50) NOT NULL DEFAULT \u0026#39;NONE\u0026#39; COMMENT \u0026#39;调度类型\u0026#39;, `schedule_conf` varchar(128) DEFAULT NULL COMMENT \u0026#39;调度配置，值含义取决于调度类型\u0026#39;, `misfire_strategy` varchar(50) NOT NULL DEFAULT \u0026#39;DO_NOTHING\u0026#39; COMMENT \u0026#39;调度过期策略\u0026#39;, `executor_route_strategy` varchar(50) DEFAULT NULL COMMENT \u0026#39;执行器路由策略\u0026#39;, `executor_handler` varchar(255) DEFAULT NULL COMMENT \u0026#39;执行器任务handler\u0026#39;, `executor_param` varchar(512) DEFAULT NULL COMMENT \u0026#39;执行器任务参数\u0026#39;, `executor_block_strategy` varchar(50) DEFAULT NULL COMMENT \u0026#39;阻塞处理策略\u0026#39;, `executor_timeout` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;任务执行超时时间，单位秒\u0026#39;, `executor_fail_retry_count` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;失败重试次数\u0026#39;, `glue_type` varchar(50) NOT NULL COMMENT \u0026#39;GLUE类型\u0026#39;, `glue_source` mediumtext COMMENT \u0026#39;GLUE源代码\u0026#39;, `glue_remark` varchar(128) DEFAULT NULL COMMENT \u0026#39;GLUE备注\u0026#39;, `glue_updatetime` datetime DEFAULT NULL COMMENT \u0026#39;GLUE更新时间\u0026#39;, `child_jobid` varchar(255) DEFAULT NULL COMMENT \u0026#39;子任务ID，多个逗号分隔\u0026#39;, `trigger_status` tinyint(4) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;调度状态：0-停止，1-运行\u0026#39;, `trigger_last_time` bigint(13) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;上次调度时间\u0026#39;, `trigger_next_time` bigint(13) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;下次调度时间\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `xxl_job_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `job_group` int(11) NOT NULL COMMENT \u0026#39;执行器主键ID\u0026#39;, `job_id` int(11) NOT NULL COMMENT \u0026#39;任务，主键ID\u0026#39;, `executor_address` varchar(255) DEFAULT NULL COMMENT \u0026#39;执行器地址，本次执行的地址\u0026#39;, `executor_handler` varchar(255) DEFAULT NULL COMMENT \u0026#39;执行器任务handler\u0026#39;, `executor_param` varchar(512) DEFAULT NULL COMMENT \u0026#39;执行器任务参数\u0026#39;, `executor_sharding_param` varchar(20) DEFAULT NULL COMMENT \u0026#39;执行器任务分片参数，格式如 1/2\u0026#39;, `executor_fail_retry_count` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;失败重试次数\u0026#39;, `trigger_time` datetime DEFAULT NULL COMMENT \u0026#39;调度-时间\u0026#39;, `trigger_code` int(11) NOT NULL COMMENT \u0026#39;调度-结果\u0026#39;, `trigger_msg` text COMMENT \u0026#39;调度-日志\u0026#39;, `handle_time` datetime DEFAULT NULL COMMENT \u0026#39;执行-时间\u0026#39;, `handle_code` int(11) NOT NULL COMMENT \u0026#39;执行-状态\u0026#39;, `handle_msg` text COMMENT \u0026#39;执行-日志\u0026#39;, `alarm_status` tinyint(4) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;告警状态：0-默认、1-无需告警、2-告警成功、3-告警失败\u0026#39;, PRIMARY KEY (`id`), KEY `I_trigger_time` (`trigger_time`), KEY `I_handle_code` (`handle_code`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `xxl_job_log_report` ( `id` int(11) NOT NULL AUTO_INCREMENT, `trigger_day` datetime DEFAULT NULL COMMENT \u0026#39;调度-时间\u0026#39;, `running_count` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;运行中-日志数量\u0026#39;, `suc_count` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;执行成功-日志数量\u0026#39;, `fail_count` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;执行失败-日志数量\u0026#39;, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `i_trigger_day` (`trigger_day`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `xxl_job_logglue` ( `id` int(11) NOT NULL AUTO_INCREMENT, `job_id` int(11) NOT NULL COMMENT \u0026#39;任务，主键ID\u0026#39;, `glue_type` varchar(50) DEFAULT NULL COMMENT \u0026#39;GLUE类型\u0026#39;, `glue_source` mediumtext COMMENT \u0026#39;GLUE源代码\u0026#39;, `glue_remark` varchar(128) NOT NULL COMMENT \u0026#39;GLUE备注\u0026#39;, `add_time` datetime DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `xxl_job_registry` ( `id` int(11) NOT NULL AUTO_INCREMENT, `registry_group` varchar(50) NOT NULL, `registry_key` varchar(255) NOT NULL, `registry_value` varchar(255) NOT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `i_g_k_v` (`registry_group`,`registry_key`,`registry_value`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `xxl_job_group` ( `id` int(11) NOT NULL AUTO_INCREMENT, `app_name` varchar(64) NOT NULL COMMENT \u0026#39;执行器AppName\u0026#39;, `title` varchar(12) NOT NULL COMMENT \u0026#39;执行器名称\u0026#39;, `address_type` tinyint(4) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;执行器地址类型：0=自动注册、1=手动录入\u0026#39;, `address_list` text COMMENT \u0026#39;执行器地址列表，多地址逗号分隔\u0026#39;, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `xxl_job_user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL COMMENT \u0026#39;账号\u0026#39;, `password` varchar(50) NOT NULL COMMENT \u0026#39;密码\u0026#39;, `role` tinyint(4) NOT NULL COMMENT \u0026#39;角色：0-普通用户、1-管理员\u0026#39;, `permission` varchar(255) DEFAULT NULL COMMENT \u0026#39;权限：执行器ID列表，多个逗号分割\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `i_username` (`username`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `xxl_job_lock` ( `lock_name` varchar(50) NOT NULL COMMENT \u0026#39;锁名称\u0026#39;, PRIMARY KEY (`lock_name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; INSERT INTO `xxl_job_group`(`id`, `app_name`, `title`, `address_type`, `address_list`, `update_time`) VALUES (1, \u0026#39;xxl-job-executor-sample\u0026#39;, \u0026#39;示例执行器\u0026#39;, 0, NULL, \u0026#39;2018-11-03 22:21:31\u0026#39; ); INSERT INTO `xxl_job_info`(`id`, `job_group`, `job_desc`, `add_time`, `update_time`, `author`, `alarm_email`, `schedule_type`, `schedule_conf`, `misfire_strategy`, `executor_route_strategy`, `executor_handler`, `executor_param`, `executor_block_strategy`, `executor_timeout`, `executor_fail_retry_count`, `glue_type`, `glue_source`, `glue_remark`, `glue_updatetime`, `child_jobid`) VALUES (1, 1, \u0026#39;测试任务1\u0026#39;, \u0026#39;2018-11-03 22:21:31\u0026#39;, \u0026#39;2018-11-03 22:21:31\u0026#39;, \u0026#39;XXL\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;CRON\u0026#39;, \u0026#39;0 0 0 * * ? *\u0026#39;, \u0026#39;DO_NOTHING\u0026#39;, \u0026#39;FIRST\u0026#39;, \u0026#39;demoJobHandler\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;SERIAL_EXECUTION\u0026#39;, 0, 0, \u0026#39;BEAN\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;GLUE代码初始化\u0026#39;, \u0026#39;2018-11-03 22:21:31\u0026#39;, \u0026#39;\u0026#39;); INSERT INTO `xxl_job_user`(`id`, `username`, `password`, `role`, `permission`) VALUES (1, \u0026#39;admin\u0026#39;, \u0026#39;e10adc3949ba59abbe56e057f20f883e\u0026#39;, 1, NULL); INSERT INTO `xxl_job_lock` ( `lock_name`) VALUES ( \u0026#39;schedule_lock\u0026#39;); commit;   創建完後的樣子\n這樣就可以去啟動專案了，啟動完後輸入\nhttp://localhost:8080/xxl-job-admin/\n訪問頁面，帳號密碼預設是\nadmin\n123456\n像這邊會有數字是因為我之前已經啟動過一次了，所以會顯示資料，否則一開始進來的時候是不會有這些東西的\nXxl-job-master的配置檔 在xxl-job-admin/src/main/resources/application.properties底下是整個master的配置檔，在其中我們可以調整一些內容，比如說Job發生錯誤時，應該寄信給哪個mail、log的保存期間等等，其中有一個叫做AccessToken的值。這個值會跟我們之後啟動後的Job有對應關係（簡單來說就是Master跟Slave會比對AccessToken）如果相互匹配就可以執行Job\nSlave的啟動  現在好像為了避免歧視，都不能用Slave這個詞了\n 我們新建一個SpringBoot專案，並在專案中加入xxl-job的dependency\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.xuxueli\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;xxl-job-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   然後編輯一下我們的application.properties\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 這邊會改的原因是因為我的master已經佔掉8080port了 server.port=8081 # 你的xxl-job的master啟動地址是哪一個 xxl.job.admin.adresses=http://localhost:8080/xxl-job-admin # 要跟master的accessToken一致 xxl.job.accessToken=default_token # 隨便要叫啥都可以 xxl.job.executor.appname=xxl-job-executor-sample xxl.job.executor.address=http://127.0.0.1:9999 xxl.job.executor.ip=127.0.0.1 # executor要佔用哪個port xxl.job.executor.port=9999 xxl.job.executor.logpath=/Users/hoxtonashes/Documents/xxl-job-demo/log xxl.job.executor.logretentiondays=30   accessToken的話就是要跟master(上面提到的那個)一致。這邊寫好之後就配一個SpringBean給它\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  @Configuration public class XxlJobConfig { @Value(\u0026#34;${xxl.job.admin.adresses}\u0026#34;) private String adminAddresses; @Value(\u0026#34;${xxl.job.accessToken}\u0026#34;) private String accessToken; @Value(\u0026#34;${xxl.job.executor.appname}\u0026#34;) private String appName; @Value(\u0026#34;${xxl.job.executor.address}\u0026#34;) private String address; @Value(\u0026#34;${xxl.job.executor.ip}\u0026#34;) private String ip; @Value(\u0026#34;${xxl.job.executor.port}\u0026#34;) private int port; @Value(\u0026#34;${xxl.job.executor.logpath}\u0026#34;) private String logPath; @Value(\u0026#34;${xxl.job.executor.logretentiondays}\u0026#34;) private int logRetentionDays; @Bean public XxlJobSpringExecutor xxlJobSpringExecutor() { XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppname(appName); xxlJobSpringExecutor.setAddress(address); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } }   這樣單例池中就有我們的XxlJobSpringExecutor的資訊了。\n接著使用\n1 2 3 4 5 6 7 8 9 10  @Component @Slf4j public class SimpleXxlJob { //等等要被master識別的名稱  @XxlJob(\u0026#34;demoJobHandler\u0026#34;) public ReturnT\u0026lt;String\u0026gt; demoJobHandler(String jobParam) { log.info(\u0026#34;執行定時任務，執行時間:{}\u0026#34;, new Date()); return new ReturnT\u0026lt;\u0026gt;(ReturnT.SUCCESS_CODE, \u0026#34;成功\u0026#34;); } }   來寫一個執行器，寫好之後就把這個Slave啟動起來。\n實際運行 啟動完後就到master的頁面，將這個Job註冊起來，這邊我們是設定成每5秒執行一次\n接下來就可以去執行它了\n這樣就是Xxl-Job的一個簡單介紹\n","date":"2023-10-19T15:32:09+08:00","image":"https://i.imgur.com/dveNGtg.png","permalink":"https://hoxtonhsu.com/p/xxl-job-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8B%99%E8%AA%BF%E5%BA%A6%E4%B8%AD%E5%BF%83%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"Xxl-Job 分布式任務調度中心學習筆記"},{"content":"專案中i18n之實現 i18n全名internationalization，因為中間的字母有18個，於是就用i18n來稱呼它。所謂的i18n就是根據不同的語系會有不同的Message回傳，比如說臺灣人在登入失敗時會出現「登入失敗」，美國人在登入時會出現「Login Fail」，這種因應不同地區的使用者來客製化訊息的工作，就是i18n。\n涉及到的基本知識 ResourceBundle 想要做到i18n，最重要的就是地區（Locale）的資料，地區資料有兩個部分組成，分別是語言編碼ISO 639加上區域編碼ISO3166，比如說\n en_US：英文_美國 en-AU：英文_澳洲 en-HK ：英文_香港  等等的，詳細資訊可以查看http://www.i18nguy.com/unicode/language-identifiers.html\n而在Java中，想要實現這樣的功能就會涉及到ResouceBundle\n這個類可以用來將程式中的文本，與程式碼分離出來，而不是寫死在程式中，具體可以來看下面的Code。\nJava中如何實現i18n 首先先開一個新的Java Maven專案，並在resources的資料夾底下建立兩個檔案\n messages_en_US.properties messages_zh_TW.properties  再來到我們的Main方法中，先創建出一個Locale物件\n1 2 3 4 5  public class Main { public static void main(String[] args) { Locale locale = new Locale(\u0026#34;zh\u0026#34;, \u0026#34;TW\u0026#34;); } }   可以看出是Language跟Country參數\n接著創造ResourceBundle物件，其中messages就是我們properties檔案的base name，讓程式知道哪些properties是i18n的文本\n1 2 3 4 5 6  public class Main { public static void main(String[] args) { Locale locale = new Locale(\u0026#34;zh\u0026#34;, \u0026#34;TW\u0026#34;); ResourceBundle resourceBundle = ResourceBundle.getBundle(\u0026#34;messages\u0026#34;,locale); } }   接著我們可以用getString 的方式來取得properties中的值\n只要改變Locale的參數，我們就可以去調整打印出來的內容，比如說現在將Locale改成en_US\n這樣就是最基礎的，在Java中實現i18n的方法\n在SpringBoot中如何實現i18n（基礎） 首先先創造一個SpringBoot專案，接著到application.yml中配置一些基礎資訊\n1 2 3 4 5  spring:messages:basename:i18n/messagesencoding:UTF-8  其中basename就和上面的Java Basename一樣，都是在指定我們的i18配置檔是放在什麼地方，以這個basename為例，就代表放在resources/i18n底下\n設置好後，就到resources/i18n資料夾中，配置i18n相關的檔案\n [{0}]代表的是格式化訊息的占位符\n 然後配置一個controller，並加入MessageSource的Bean\n MessageSource 是 Spring Framework 提供的一個介面，用於支援應用程式的國際化（Internationalization）和本地化（Localization）。它提供了一種在應用程式中輕鬆管理文本訊息的機制，以便根據使用者的語言和地區首選項來提供相應的文本訊息。\nMessageSource 介面的主要功能包括：\n 文本訊息檢索： MessageSource 允許您在應用程式中定義和存儲文本訊息，通常以鍵值對的形式。這些文本訊息可以是應用程式中的各種提示、標籤、錯誤訊息等。 國際化支援： 您可以配置不同語言和地區的訊息，以便根據使用者的首選語言和地區設定來動態選擇合適的訊息。這使得應用程式能夠以多語言和本地化方式呈現訊息。 參數替換： MessageSource 支援將參數插入訊息中，以便將動態值嵌入到訊息中。這對於包含佔位符的訊息非常有用。 訊息格式化： 您可以定義訊息的格式，以適應不同的訊息類型，如日期、時間、貨幣等。  MessageSource 介面的常見實現是 ResourceBundleMessageSource，它使用 Java 的 ResourceBundle 機制來存儲和檢索訊息。但 Spring 也提供其他實現，如 ReloadableResourceBundleMessageSource，允許在不重啟應用程式的情況下重新加載訊息資源。\n使用 MessageSource 的主要步驟包括：\n 配置 MessageSource Bean，通常在 Spring 配置文件中或 Java 配置類中完成。 在應用程式中使用 MessageSource 的 getMessage 方法來檢索訊息，指定訊息的鍵和可選參數。 根據使用者的語言和地區首選項，MessageSource 會動態地返回適當的訊息。  總之，MessageSource 是 Spring Framework 中的一個重要元件，用於實現國際化和本地化，幫助開發者構建多語言和多地區支援的應用程式，提高使用者體驗。\n\u0026ndash;Generate By ChatGPT\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14  @RestController @RequiredArgsConstructor public class DemoController { private final MessageSource messageSource; @GetMapping(\u0026#34;/\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; demo() { String message = messageSource.getMessage(\u0026#34;error\u0026#34;, new String[]{\u0026#34;發生錯誤\u0026#34;}, Locale.TAIWAN); System.out.println(message); return ResponseEntity.ok().body(\u0026#34;Hello\u0026#34;); } }   可以看出MessageSource，依照我們配置的Locale去i18n底下找到對應的文本，並且打印出來。我們可以修改Locale的值來改變打印出來的文本\n想當然耳，我們不可能是把i18n的配置寫死，所以可以用 LocaleContextHolder.getLocale()來取得目前使用者的語言來動態注入Locale資料\n1 2 3 4 5 6  @GetMapping(\u0026#34;/\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; demo() { String message = messageSource.getMessage(\u0026#34;error\u0026#34;, new String[]{\u0026#34;發生錯誤\u0026#34;}, LocaleContextHolder.getLocale()); System.out.println(message); return ResponseEntity.ok().body(\u0026#34;Hello\u0026#34;); }   這部分動態注入的方式，實際實現可以有很多種方式，比如說Interceptor、Filter作轉換，然後用AOP的方式轉換，都是可以行的方案。\n","date":"2023-10-11T11:58:32+08:00","image":"https://i.imgur.com/Tb5xdM6.png","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E5%9C%A8springboot%E4%B8%AD%E5%AF%A6%E7%8F%BE%E5%9F%BA%E7%A4%8E%E7%9A%84i18n/","title":"如何在SpringBoot中實現基礎的I18n"},{"content":"使用網站 https://www.geogebra.org/m/JP2XZpzV\n何謂特徵根、特徵向量 Eigen是德文的一個詞彙，意即「自己的」，而中文翻譯成特徵根、特徵向量確實有點摸不著頭腦。所謂特徵根以及特徵向量，代表的是一個向量，經過線性轉換(Linear Transformation)後，向量的方向不會改變，可以看這張圖\n這張圖相當於是說，將向量(0.71,0.71)與矩陣 $$ \\begin{bmatrix} -3\u0026amp;0\\\\\n0\u0026amp;1 \\\\\n\\end{bmatrix} $$\n相乘後，該向量會指向什麼哪裏、長度多少\n下圖中黑色的部分是線性轉換之前的向量，而紅色則是線性變換之後的位置\n那什麼是特徵向量呢，所謂的特徵向量，就是指那些經過線性變換後，向量方向不變（只有長度、正負號）改變的向量，就叫特徵向量，舉個最簡單的例子，假設現在有個線性變換是這樣\n$$ \\begin{bmatrix} 2\u0026amp;0\\\\\n0\u0026amp;2 \\\\\n\\end{bmatrix} $$\n也就說把每個單位向量都拉伸兩倍，那麼它實際看起來就會像是這個樣子\n我們會發現它的每一個向量，經過線性變換後，都和它原先的向量只差一倍，那這個一倍的值就是它的特徵根(EigenValue)。\n以畫面來表示特徵根、特徵向量 比如說現在有一個線性變化如下\n$$ \\begin{bmatrix} 1\u0026amp;2\\\\\n2\u0026amp;1 \\\\\n\\end{bmatrix} $$\n(1,0)轉換的結果就像紅色的那樣\n我們觀察上圖可以發現，是不是在某些時候，紅色跟黑色的線是共線的情形\n（▲長度相差3倍）\n（▲長度相差-1倍）\n像這樣的情況\n(0.71,0.71)、(-0.7,0.71)就是特徵向量(不只一組)，而3、-1就是特徵值\n","date":"2023-10-10T18:00:19+08:00","image":"https://i.imgur.com/Rv7zjbh.jpg","permalink":"https://hoxtonhsu.com/p/%E8%A6%96%E8%A6%BA%E5%8C%96%E7%9A%84%E7%90%86%E8%A7%A3%E7%89%B9%E5%BE%B5%E5%90%91%E9%87%8Feigenvector%E7%89%B9%E5%BE%B5%E6%A0%B9eigenvalue/","title":"視覺化的理解特徵向量(Eigenvector)、特徵根(Eigenvalue)"},{"content":"在SpringBoot中要實現非同步有很多種方式，比如說你自己手寫一個ThreadPool、或是藉由外部的RabbitMQ都可以實現非同步的方法。\n那這邊我選擇實做的方法是使用SpringBoot提供的@Async，什麼是非同步呢？\n舉個例子假設我在做櫃檯，現在有10個客人要辦帳戶，每個客人過來我這邊，都要寫10分鐘的表格，寫完後我在幫他們登記，花兩分鐘。如果一個客人一個客人這樣過來，我需要花120分鐘才可以消化掉。但如果我可以先把表格發給全部10個人填，這樣我只要花10+10*2=30分鐘就可以。\n這就是非同步操作，簡而言之就是避免無意義的等待。\n由於網路上寫的教學實在都太複雜了，我想寫一篇最最最基本的那一種，不需要配什麼config，連什麼資料庫，一切都是最基本的樣子\nGithub連結 https://github.com/Hoxton019030/SpringBootAsync\n如何創建一個非同步方法 非常簡單！只要在方法上加上@Async的註解就可以囉！就像這樣\n1 2 3 4 5 6 7 8 9  @Async public void testAsync() { try { Thread.sleep(3000); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(\u0026#34;非同步測試執行，執行緒為：\u0026#34; + Thread.currentThread().getName()); }   實際感受何謂非同步執行 我們可以寫一個controller來呼叫我們剛剛寫好的testAsync()\n1 2 3 4 5 6 7  @GetMapping(\u0026#34;/\u0026#34;) public String testAsync() { System.out.println(\u0026#34;開始測試，執行緒為 - \u0026#34; + Thread.currentThread().getName()); asyncTask.testAsync(); //這東西會印出非同步測試執行，執行緒為：Async-Service-1  System.out.println(\u0026#34;測試結束，執行緒為 - \u0026#34; + Thread.currentThread().getName()); return \u0026#34;非同步測試\u0026#34;; }   專案執行完後，可以輸入\nhttp://localhost:8080/\n訪問endPoint，可以看到\u0026quot;非同步測試執行，執行緒為：這句話打印出來的時間點，遠小於測試結束，執行緒為 - 這句話，這就是非同步執行帶來的好處。\n繼續感受非同步執行 之前在資策會的專案中，有一個功能是要寄出Email的，當時量沒那麼大，所以沒感覺，實際工作之後發現寄Email這件事情要花很多時間在等待上面，這就是一個很適合用非同步去處理的事情。在這邊我一樣使用Thread.sleep()去模擬寄信這件事情\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Async public void sendEmail(int mailNumber) { for (int i = 1; i \u0026lt; mailNumber + 1; i++) { try { Thread.sleep(1000); System.out.println(\u0026#34;寄出第\u0026#34; + i + \u0026#34;封信，所使用的執行緒是\u0026#34; + Thread.currentThread().getName()); } catch (InterruptedException e) { System.out.println(\u0026#34;寄出第\u0026#34; + i + \u0026#34;封信時發生錯誤！\u0026#34;); throw new RuntimeException(e); } } }   1 2 3 4 5 6 7 8  @GetMapping(\u0026#34;/email\u0026#34;) public String sendEmail() { System.out.println(\u0026#34;開始測試，執行緒為 - \u0026#34; + Thread.currentThread().getName()); asyncTask.sendEmail(10); System.out.println(\u0026#34;測試結束，執行緒為 - \u0026#34; + Thread.currentThread().getName()); return \u0026#34;非同步寄出Email\u0026#34;; }   可以在專案中輸入\nhttp://localhost:8080/email\n來感受到非同步的感覺\n非同步Executor 有時候，有時候，我們在寫的時候不能知道這東西未來會希望變成一個非同步方法，或是說希望可以用非同步的方式在程式內部實現一些功能，像這種時候我們可以結合Java的functional Interface來實現非同步的操作\n首先先寫一個方法介面\n1 2 3 4 5 6 7 8 9  /** * 其實就是方法介面啦\u0026gt;/////\u0026lt; */ @FunctionalInterface public interface ExecuteInterface { void execute(); }   接著完成AsyncTask的方法\n1 2 3 4  @Async public void asyncExecutor(ExecuteInterface executeInterface) { executeInterface.execute(); }   這樣就完成了喔！有沒有，很快吧!\n當我們要在專案中非同步執行某些事情時，就可以使用這個asyncExecutor來做事了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  @GetMapping(\u0026#34;/executor\u0026#34;) public String executeAsyncTask(){ asyncTask.asyncExecutor(() -\u0026gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(\u0026#34;我在做非同步工作耶！\u0026#34;); }); return \u0026#34;非同步執行器\u0026#34;; }   ","date":"2023-10-08T19:25:56+08:00","image":"https://i.imgur.com/LTjIYLa.png","permalink":"https://hoxtonhsu.com/p/%E7%B0%A1%E5%96%AE%E7%9A%84%E8%81%8A%E8%81%8Aspringboot%E4%B8%AD%E7%9A%84%E9%9D%9E%E5%90%8C%E6%AD%A5%E6%93%8D%E4%BD%9Casync/","title":"簡單的聊聊SpringBoot中的非同步操作@Async"},{"content":"專案網址 http://hoxtonhsu.com/vue-project/\n前言 前陣子同事跟我說，交大有一組丁組，可以用推甄的方式來面試研究所，其中一項就是要看對於程式的熱誠，於是打算把自己心裡想很久，但一直懶得做的那些project Idea拿出來做一做，希望明年可以推甄上，推甄不上就只能當考研戰士了\n語法介紹 v-on 可以配合click做點擊事件\n1 2 3 4 5 6 7 8  \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;p\u0026gt; {{title}} {{author}} {{age}}\u0026lt;/p\u0026gt; \u0026lt;button v-on:click=\u0026#34;age++\u0026#34;\u0026gt;Increase Age\u0026lt;/button\u0026gt; \u0026lt;!-- v-on:click=裡面，是可以直接寫javascript的 --\u0026gt; \u0026lt;button v-on:click=\u0026#34;age--\u0026#34;\u0026gt;Decrease Age\u0026lt;/button\u0026gt; \u0026lt;!-- @click跟v-on是一樣的意思，因為v-on太常出現，就用@來代替了 --\u0026gt; \u0026lt;div @click=\u0026#34;changeTitle(\u0026#39;最後帝國\u0026#39;)\u0026#34;\u0026gt;Change Book\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  console.log(\u0026#39;Hello vue\u0026#39;) const app =Vue.createApp({ data(){ return{ title: \u0026#39;The Final Empire\u0026#39;, author: \u0026#39;Brandon Sanderson\u0026#39;, age: \u0026#39;45\u0026#39; } }, methods:{ changeTitle(title){ this.title = title } } }) app.mount(\u0026#39;#app\u0026#39;)   v-if 如果表達式中的值True，則會顯示html，若為False則不顯示(這邊是整個dom直接拿掉，所以是一個頻繁、大量的情形，不要用v-if，會導致性能下降)\n1 2 3 4 5 6 7 8  \u0026lt;div v-if=\u0026#34;showBooks\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;book in books\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{{ book.title }}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt; {{ book.author}}\u0026lt;/p\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;   當然有if也會有else，當v-if沒顯示時，就會顯示else的內容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;div v-if=\u0026#34;showBooks\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;book in books\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{{ book.title }}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt; {{ book.author}}\u0026lt;/p\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div v-else\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;h3\u0026gt; 大哥沒有沒有書 \u0026lt;/h3\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;   與v-if很類似的，是另一個叫做v-show的東西\nv-show v-show是透過css在控制dom的顯示與否，看起來功能跟if有八成像，但由於是css控制的，所以性能上會比v-if好很多\n1 2 3  \u0026lt;div v-show=\u0026#34;showBooks\u0026#34;\u0026gt; 現在展示的書 \u0026lt;/div\u0026gt;   v-for 用來for-each一個list\nv-bind 屬性綁定！\nv-bind:屬性名\n也可以簡化成:\nDynamic class 可以動態的將class 賦予給tag\n1 2 3 4 5 6 7 8  \u0026lt;div v-if=\u0026#34;showBooks\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;book in books\u0026#34; v-bind:class=\u0026#34;{ fav:book.isFav}\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{{ book.title }}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt; {{ book.author}}\u0026lt;/p\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;   computed 用來過濾資料的功能，類似pipLine\nVue Cli 記得要安裝node.js\n1  node -v   接著安裝Vue Cli\n1  npm intsall -g @vue/cli   安裝完之後就可以輸入\n1  vue create project-name   來創建vue專案囉！\n專案目錄 創建好的專案目錄就像這樣子，稍微看起來有點複雜，但其實很簡單的\n public  ​\t底下就是放html的東西\t  Source\n底下放的是js檔案跟vue檔案\n其中js檔案跟我們初始學得不太一樣，他長得是這個樣子\n1 2 3 4 5  import { createApp } from \u0026#39;vue\u0026#39; import App from \u0026#39;./App.vue\u0026#39; createApp(App).mount(\u0026#39;#app\u0026#39;)     ​\t但其實概念是差不多的，比較特別的是vue檔案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  \u0026lt;template\u0026gt; \u0026lt;img alt=\u0026#34;Vue logo\u0026#34; src=\u0026#34;./assets/logo.png\u0026#34;\u0026gt; \u0026lt;HelloWorld msg=\u0026#34;Welcome to Your Vue.js App\u0026#34;/\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; import HelloWorld from \u0026#39;./components/HelloWorld.vue\u0026#39; export default { name: \u0026#39;App\u0026#39;, components: { HelloWorld } } \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; #app { font-family: Avenir, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px; } \u0026lt;/style\u0026gt;   每一個vue檔案都是由\n template script style  這三個部分組成的\nTmplate Refs 控制dom的一些東西，比如說改變它的class，修改它的文字等等\u0026hellip;\nMulitple Component 有時候有一些重複性很高的dom，或是一些有的沒有的東西，反正就是重複性很高的東西，應該要可以重複利用，而Vue借鑒(抄襲)了react的概念，也是用component的方式去實作這個概念\nProps 傳基本資料的一個東西，例如String, Boolean\nSlot ","date":"2023-10-01T03:02:32+08:00","image":"https://i.imgur.com/Yq1lyHE.jpg","permalink":"https://hoxtonhsu.com/p/vue%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"Vue學習筆記"},{"content":"不知道到底從玩幾次了= = 每次都玩一玩，然後過一段時間又忘記怎麼開始\n教學 面板查看 stats 查看各種數值的地方\nTerminal 輸入\nhelp 查看幫助\nls 展示所有當前目錄所有檔案\nscan 展現所有可用的網路節點\nscan-analyze 展示所有可用的網路節點，更詳細的數據\nscan-analyze 2 了解距離兩個node的網路節點資訊\nconnnect [hostname] 連結到網路節點\nanalyze 掃描網路節點，會展示一些有用資料比如說最低hacking skill的要求\n在遊戲的初級，可以透過NUKE.exe來取得root access權限\nrun NUKE.exe 取得root access ，這樣就可以在該server運行script了\nhack 輸入hack，駭進網路\n你現在正試圖入侵伺服器。進行入侵需要時間，成功的機會只有一定的百分比。這個時間和成功機會由各種因素決定，包括你的駭客技能和伺服器的安全級別。\n如果你成功入侵伺服器，你將竊取伺服器總金額的一定百分比。這個百分比受你的駭客技能和伺服器的安全級別影響。\n伺服器上的金額並不是無限的。因此，如果你不斷入侵一個伺服器並耗盡它的資金，那麼你將在駭客活動中遇到遞減的回報。你將需要使用以下命令：\n[n00dles ~/]\u0026gt; grow\n這個命令會誘使公司向他們的伺服器添加資金，\n[n00dles ~/]\u0026gt; weaken\n這個命令會增加入侵、誘使公司添加資金的速度。\n","date":"2023-09-25T18:00:16+08:00","image":"https://i.imgur.com/B1MjQbp.jpg","permalink":"https://hoxtonhsu.com/p/bitburner%E7%AD%86%E8%A8%98/","title":"BitBurner筆記"},{"content":"前言 新的工作充滿著各種類型的微服務架構，讓我頓時間有點分不清南北，於是就利用這段剛入職，還很閒的時候帶薪學習吧！\n為什麼要用網關？ 微服務的架構中，每個業務都需要授權、限流、處理跨域請求，如果每個功能都各自為棧，自己的輪子自己造，會非常厲害！但有些東西是可以抽出來，放到一個統一的地方去維護。另外來說，微服務中，如果每個微服務都分配一個域名，這樣子會非常難以維護客戶端的Code，因為涉及到數百個域名，另一方面是連接數量的瓶頸，想像一下如果你打開一個網站，結果發現光開啟網站就涉及了數百個RPC(Remote Procude Call)，這樣會非常低效，各何況Address存在集群(Cluster)的情況下，那麼複雜度會成幾何增長。\n沒有使用網關的調用 使用網關的調用 不用直接去請求微服務，可以透過Gateway來訪問\n何謂默認網關 所謂的默認網關就只是讓設備可以透過網路，和一端設備溝通的東西。\n那麼相同網域的電腦如果要相互溝通，則只需要透過switch就可以，因為他們的數據不需要通過Gateway傳出去\n那麼接下來就有一個問題了，我要跟A電腦溝通，但我如何知道A電腦和我是否處在同一個網域中呢？\nIP地址與子網遮罩 一個Ip位址包含兩個部分\n Network Address Host Address  而區分哪個部分屬於網際網路與本地主機的方式，則是透過子網遮罩\n所謂子網路遮罩，是這段看起來有點像ip位址的東西，熟悉2進制的朋友應該有感覺，255這個數字就是28-1，我們把子網路遮罩的255.255.255.0換作是二進制來，就會變成\n11111111.11111111.11111111.00000000\n這樣子的東西，而透過子網路遮罩來辨別Ip地址哪一個部分是網際網路的方法是\n「當子網遮罩的二進制數字為1時，就代表這部分是來自網際網路IP的網路位」\n因此，若前面這幾個數字一樣，就代表這些是來自同一個網域的通訊，不需要透過Gateway，反之，若有不同，則代表是來自不同網域的請求，需要走Gateway\n參考網址 目前B站唯一把Gateway网关讲透的视频教程！一天即可掌握Gateway！\n","date":"2023-09-14T11:16:37+08:00","image":"https://i.imgur.com/VwMgRtW.png","permalink":"https://hoxtonhsu.com/p/%E5%88%9D%E6%8E%A2%E5%BE%AE%E6%9C%8D%E5%8B%99-%E4%BD%95%E8%AC%82%E7%B6%B2%E9%97%9Cgateway/","title":"初探微服務 何謂網關(Gateway)"},{"content":"參考網址 https://www.cupoy.com/collection/000001699E6396C0000000046375706F795F72656C656173654355?layoutType=content\nLinear Algebra Lecture 1：What are we going to learn? 何謂線性系統(Linear System) 所謂系統，也可稱作一個function，通常會有一個input，一個output，而一**b **\n Perservering Multiplication  若x經過線性系統計算後得到y，那麼kx經過線性系統計算後應該也要得到ky\nPersevering Addition  x1計算後得y1，x2計算後得y2，那麼(x1+x2)的計算結果為(y1+y2)\nAsk 矩陣的轉置是線性的嗎？\nYes\nAsk 微分是線性的嗎？\nYes\nAsk積分是線性的嗎\nYes，積分也是線性的^_^\n線性系統的應用   電路學(ㄏ 沒修過)\n  信號與系統(ㄏ 也沒學過)\n   傅立葉轉換(Fourier Transform) 搜尋引擎的Page Rank 演算法  Linear Algebra Lecture 2: System of Linear Equations  A System of Linear equations(多元一次聯立方程式)   ​\t定義域： y=x2，x∈R\n​\t對應域：不思考function的實際內容，大概猜一下可能的解範圍，故對應域為R\n​\t值域：考慮一下function的實際內容，可以得知值域為x\u0026gt;=0\n   ​\tOne-to-One： Domain跟range一樣大\n​\tOnto：Co-domain= range\nLinear Algebra Lecture 3: Vector   Vector\n一組數字的集合 ex: $$ \\begin{bmatrix} 1 \\\\\n2 \\\\\n3 \\end{bmatrix} $$\n  Vector Set：一群向量組合在一起，且可以包含無限組的的向量，即稱為向量集合\n  ​\t Matrix：多組向量組合成Ｍatrix  ​\t![image-20230909023009609](/Users/hoxtonashes/Library/Application Support/typora-user-images/image-20230909023009609.png)\nLinear Algebra Lecture 4：Matrix 什麼是Martix，很多組的Vector放在一起就是Martin\n  Zero Matrix\n  Linear Algebra Lecture 5：Matrix-vector ProductLinear Algebra Lecture 5：Matrix-vector Product 何謂向量內積 內積的值是一個純量，不是一個向量。D\n以Row、Column觀點來看矩陣乘法 現有一方程 $$ \\begin{align*} x_1 + 4x_2 \u0026amp;= b_1 \\\\\n-3x_1 - 2x_2 \u0026amp;= b_2 \\end{align*} $$\n對其輸入，[-2,0.5]，得到的結果是 $$ \\begin{bmatrix} 0 \\\\\n7\n\\end{bmatrix} $$\n以Row觀點來理解這件事情\n那麼0相當於是輸入向量與Row1進行內積，得出的結果。而7相當於是輸入向量與Row2得出來的結果\n以Column觀點來看這件事情\n那麼相當於是將 $$ \\begin{bmatrix} 1 \\\\\n3\n\\end{bmatrix} $$ 這個向量拉長-2倍變成 $$ \\begin{bmatrix} -2 \\\\\n-6\n\\end{bmatrix} $$\n然後再將 $$ \\begin{bmatrix} 4 \\\\\n2\n\\end{bmatrix} $$ 這個向量拉長0.5倍變成 $$ \\begin{bmatrix} 2 \\\\\n1 \\end{bmatrix} $$\n兩個向量在相加，變成 $$ \\begin{bmatrix} 0 \\\\\n7\n\\end{bmatrix} $$\nLinear Algebra Lecture 6： Having Solution or Not   一線性系統有解稱之為consistent，無解稱 之為inconsistent\n  現一線性系統Ax=B，若這個系統有解，則代表這個系統是consistent，也代表B是可以通過A的線性組合而來\n      任兩條非平行的向量，都可以組合出平面空間中的所有向量\n  但任三條非平行的向量，不可以組合出立體空間中的所有向量，有可能第三條向量，落在前兩條向量張成的向量空間中\n  Span 假設現在你有一堆向量集合，u1,u2,u3\u0026hellip;然後去窮舉這些向量能做的線性組合，這個得出的集合就叫做Span\n生成集(generating set) Linear Algebra Lecture 7：How many solutions? King Crimson\nLinear Algebra Lecture 18: Subspace Subspace 子空間 若一組向量集合V，滿足以下三種性質，即可稱之為子空間(subspace)\n 向量集合V包含0向量(確保向量集合不是空集合) 向量集合V中，任取兩個向量，u和w，則u+w也在向量集合V中(滿足加法封閉性) 向量集合V中，取一個向量u，將它成上某\\數後，依然在向量集合V中(滿足乘法封閉性)  以上2,3可以簡單地說，也就是線性組合\n範例\nSpan 假設現在有一組向量集合S，我們把這個向量集合S中的所有向量拿出來做Linear Combinations，然後集合起來，這樣就產生另一個向量集合，叫Span S。\n我們現在稱這個Span S為向量集合V，此時，向量集合S產生了V，向量集合S也就是V的生成集\nSubspace Vs Span Null Space Linear Algebra Lecture 19: Basis 設向量集合V是Rn的一個子空間，那麼向量集合V的Basis要滿足以下兩個條件\n 是線性獨立的 可以組合出V的所有向量  比如說 $$ \\begin{bmatrix} 1 \\\\\n0\n\\end{bmatrix} \\begin{bmatrix} 0 \\\\\n1\n\\end{bmatrix} 是R^2的Basis $$\n因為這兩個向量是線性獨立的、且可以組合出R2的所有向量，因此是R2的Basis。由此可以發現，Basis不具備唯一性，只要可以滿足1、2都可以稱之為Basis\n","date":"2023-09-08T21:24:43+08:00","image":"https://i.imgur.com/WnjTSDF.png","permalink":"https://hoxtonhsu.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8%E7%AD%86%E8%A8%98/","title":"李宏毅線性代數筆記"},{"content":"GitHub網址 2024/05/24更新\nhttps://github.com/Hoxton019030/RabbitMQ_Practice/tree/prototype\nPrototype分支是個MVP(Minimum Viable Product)，使用了RabbitMq來接收前端傳來的一個訊息並打印出來，可以藉此對MessageQueue有個認識與回顧－\n前言 今天是第二天，學習RabbitMQ。第一次接觸到Message Queue是在御諾的時候，當時有個同事做了一個這個東西，在Sprint的結尾展示，那時候就覺得MessageQueue這個東西也太酷了，但一直沒有機會(懶)去接觸。\n什麼是Message Queue Message Queue(訊息佇列、消息隊列)，是一種用在應用程序之間傳遞消息的通訊是，Message Queue允許應用之間異步的發送和接收消息，並且不需要直接連接到對方\n什麼是RabbitMQ RabbitMQ是個基於AMQP(Advanced Message Queuing Protocal 高級消息隊列協議) ，用於應用程式之間通訊的中間層，Rabbit有四大核心\n 生產者：發送消息的應用程式 消費者：接受消息的應用程式 佇列：訊息在Message Queue中儲存的位置 交換機：訊息路由的一個組件，會依照我們的配置，把訊息分發給特定的佇列  AMQP也包含了四個核心組件\n 消息：包括消息頭、消息體、消息屬性 交換機：消息傳遞的中間件，將消息路由到一個或多個隊列中 佇列：用來儲存消息的資料結構 綁定：交換機和隊列的綁定  下載與安裝 以下適用於M1、M2\n使用brew安裝\n1  brew install rabbitmq   啟動rabbitMq\n1  brew services start rabbitmq   停止rabbitMq\n1  brew services stop rabbitmq   啟動後，可以在瀏覽器中輸入\nhttp://localhost:15672/\n即可訪問rabbitMq的畫面\n帳號密碼都是guest\n就可以看到rabbitMq的畫面了\n常用指令 創建使用者 tom為使用者名稱，tom60229為使用者密碼\n1  rabbitmqctl add_user tom tom60229   賦予使用者權限 將tom設成管理員\n1  rabbitmqctl set_user_tags tom administrator   實際使用 範例Code\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  public class Producer { public static void main(String[] args) throws IOException, TimeoutException { ConnectionFactory connectionFactory = new ConnectionFactory(); //服務地址  connectionFactory.setHost(\u0026#34;127.0.0.1\u0026#34;); //帳號  connectionFactory.setUsername(\u0026#34;guest\u0026#34;); //密碼  connectionFactory.setPassword(\u0026#34;guest\u0026#34;); //端口號  connectionFactory.setPort(5672); //創建連接  Connection connection = connectionFactory.newConnection(); //創建channel  Channel channel = connection.createChannel(); /** * 創建交換機 * 1. 交換機名稱 * 2. 交換機類型 direct, topic, fanout, headers * 3. 指定交換機是否需要持久化，如果設置為True，那麼交換機的元數據要持久化 * 4. 指定交換機在沒有隊列綁定時，是否刪除？ * 5. Map\u0026lt;String,Object\u0026gt;類型，用來指定我們交換機其他的一些機構話參數，我們在這裡直接設置成Null */ String exchangeName = \u0026#34;xc_exchange_name\u0026#34;; channel.exchangeDeclare(exchangeName, BuiltinExchangeType.DIRECT, true, false, null); /** * 生產一個隊列 * 1. 隊列名稱 * 2. 隊列是否需要持久化，但是要注意，這裡的持久化只是隊列名稱等這些元數據的持久化，不是隊列中消息的持久化 * 3. 表示隊列是不是私有，如果是私有的，只有唱見他的應用程序才能消費消息 * 4. 隊列在沒有消費者訂閱的情況下，是否自動刪除 * 5. 隊列的一些結構化訊息，比如說聲明死信隊列，磁盤隊列會用到 */ String queueName = \u0026#34;xc_queue_name\u0026#34;; channel.queueDeclare(queueName, true, false, false, null); /** * 將交換機與隊列綁定 * 1. 隊列名稱 * 2. 交換機名稱 * 3. 路由鍵，在我們直連模式下，可以為我們的隊列名稱 */ channel.queueBind(queueName, exchangeName, queueName); // 要發送的消息  String message = \u0026#34;Hello rabbitMQ\u0026#34;; /** * 發送消息 * 1. 發送到哪個交換機 * 2. 隊列名稱 * 3. 其他參數訊息 * 4. 發送消息的消息體 */ channel.basicPublish(exchangeName, queueName, null, message.getBytes()); channel.close(); connection.close(); } }   ​\n執行完後，訪問RabbitMQ的頁面，會發現Queue中確實存在一則Message\n這時在創建另一個Consumer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  package com.example.springbootinaction.rabbitmq; import com.rabbitmq.client.*; import java.io.IOException; import java.util.concurrent.TimeoutException; public class Consumer { public static void main(String[] args) throws IOException, TimeoutException { String exchangeName = \u0026#34;xc_exchange_name\u0026#34;; String queueName = \u0026#34;xc_queue_name\u0026#34;; ConnectionFactory connectionFactory = new ConnectionFactory(); //服務地址  connectionFactory.setHost(\u0026#34;127.0.0.1\u0026#34;); //帳號  connectionFactory.setUsername(\u0026#34;guest\u0026#34;); //密碼  connectionFactory.setPassword(\u0026#34;guest\u0026#34;); //端口號  connectionFactory.setPort(5672); //創建連接  Connection connection = connectionFactory.newConnection(); //創建channel  Channel channel = connection.createChannel(); //接收消息的回調函數  DeliverCallback deliverCallback = (consumerTage, message) -\u0026gt; { System.out.println(\u0026#34;接收到消息\u0026#34; + new String(message.getBody())); }; //取消消息的回調函數  CancelCallback cancelCallback = consumerTage -\u0026gt;{ System.out.println(\u0026#34;消息被中斷\u0026#34;); }; /** * 消費消息 * 1. 消費哪個隊列 * 2. 消費成功之後是否需要自動應答，true:自動應答 * 3. 接受消息的回調函數 */ channel.basicConsume(queueName,true,deliverCallback,cancelCallback); } }   確實有收到消息，重新整理rabbitMQ頁面後\n會發現已經沒有Messege在等待了\n交換機介紹 Direct 路由鍵與隊列名「完全匹配」交換機，通過與RoutingKey路由鍵將交換機與隊列進行綁定，消息被發送到exchange時，需要根據消息的RountingKey，來進行匹配，只將消息發送到完全匹配到此RountingKey的隊列，如果想要模糊匹配的話要用Topic。\n比如一個隊列綁定到交換機要求路由鍵為\u0026quot;key\u0026quot;，則只轉發RountingKey標記為\u0026quot;key\u0026quot;的消息，不會轉發\u0026quot;key1\u0026quot;、“key.\u0026quot; \u0026hellip;等等，他是完全匹配、單撥的形式\n以下為範例Code\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  public class ProducerDirect { public static void main(String[] args) throws IOException, TimeoutException { String exchangeName = \u0026#34;xc_exchange_name\u0026#34;; String queueName_1 = \u0026#34;xc_queue_name_1\u0026#34;; String queueName_2 = \u0026#34;xc_queue_name_2\u0026#34;; String queueName_3 = \u0026#34;xc_queue_name_3\u0026#34;; String queueName_4 = \u0026#34;xc_queue_name_4\u0026#34;; String key_1 = \u0026#34;key_1\u0026#34;; String key_3 = \u0026#34;key_3\u0026#34;; String key_4 = \u0026#34;key_4\u0026#34;; ConnectionFactory connectionFactory = new ConnectionFactory(); //服務地址  connectionFactory.setHost(\u0026#34;127.0.0.1\u0026#34;); //帳號  connectionFactory.setUsername(\u0026#34;guest\u0026#34;); //密碼  connectionFactory.setPassword(\u0026#34;guest\u0026#34;); //端口號  connectionFactory.setPort(5672); //創建連接  Connection connection = connectionFactory.newConnection(); //創建channel  Channel channel = connection.createChannel(); /** * 創建交換機 * 1. 交換機名稱 * 2. 交換機類型 direct, topic, fanout, headers * 3. 指定交換機是否需要持久化，如果設置為True，那麼交換機的元數據要持久化 * 4. 指定交換機在沒有隊列綁定時，是否刪除？ * 5. Map\u0026lt;String,Object\u0026gt;類型，用來指定我們交換機其他的一些機構話參數，我們在這裡直接設置成Null */ channel.exchangeDeclare(exchangeName, BuiltinExchangeType.DIRECT, true, false, null); /** * 生產一個隊列 * 1. 隊列名稱 * 2. 隊列是否需要持久化，但是要注意，這裡的持久化只是隊列名稱等這些元數據的持久化，不是隊列中消息的持久化 * 3. 表示隊列是不是私有，如果是私有的，只有唱見他的應用程序才能消費消息 * 4. 隊列在沒有消費者訂閱的情況下，是否自動刪除 * 5. 隊列的一些結構化訊息，比如說聲明死信隊列，磁盤隊列會用到 */ channel.queueDeclare(queueName_1, true, false, false, null); channel.queueDeclare(queueName_2, true, false, false, null); channel.queueDeclare(queueName_3, true, false, false, null); channel.queueDeclare(queueName_4, true, false, false, null); /** * 將交換機與隊列綁定 * 1. 隊列名稱 * 2. 交換機名稱 * 3. 路由鍵，在我們直連模式下，可以為我們的隊列名稱 */ channel.queueBind(queueName_1, exchangeName, key_1); channel.queueBind(queueName_2, exchangeName, key_1); channel.queueBind(queueName_3, exchangeName, key_3); channel.queueBind(queueName_4, exchangeName, key_4); // 要發送的消息  String message = \u0026#34;Hello rabbitMQ\u0026#34;; /** * 發送消息 * 1. 發送到哪個交換機 * 2. 隊列名稱 * 3. 其他參數訊息 * 4. 發送消息的消息體 */ channel.basicPublish(exchangeName, key_1, null, \u0026#34;key_1 message\u0026#34;.getBytes()); channel.basicPublish(exchangeName, key_3, null, \u0026#34;key_3 message\u0026#34;.getBytes()); channel.basicPublish(exchangeName, key_4, null, \u0026#34;key_4 message\u0026#34;.getBytes()); channel.close(); connection.close(); } }   執行完後長這樣\n接著去掉用Consumer去查看Messege\n改成呼叫queueName_2，接收到的仍是key_1的訊息，因為我們在生產者那邊，將queueName2與key_1進行綁定\nFanout 扇出類型的exchange，會將消息分發給所有綁定了此exchange的隊列，此時RountingKey參數無效，因此不管給哪個Queue送消息、屬於同一個exchange底下的都會共享\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89  package com.example.springbootinaction.rabbitmq.fanout; import com.rabbitmq.client.BuiltinExchangeType; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; import java.io.IOException; import java.util.concurrent.TimeoutException; public class ProducerFanout { public static void main(String[] args) throws IOException, TimeoutException { String exchangeName = \u0026#34;xc_exchange_fanout_name\u0026#34;; String queueName_1 = \u0026#34;xc_queue_name_fanout_1\u0026#34;; String queueName_2 = \u0026#34;xc_queue_name_fanout_2\u0026#34;; String queueName_3 = \u0026#34;xc_queue_name_fanout_3\u0026#34;; String queueName_4 = \u0026#34;xc_queue_name_fanout_4\u0026#34;; String key_1 = \u0026#34;key_1\u0026#34;; String key_3 = \u0026#34;key_3\u0026#34;; String key_4 = \u0026#34;key_4\u0026#34;; ConnectionFactory connectionFactory = new ConnectionFactory(); //服務地址  connectionFactory.setHost(\u0026#34;127.0.0.1\u0026#34;); //帳號  connectionFactory.setUsername(\u0026#34;guest\u0026#34;); //密碼  connectionFactory.setPassword(\u0026#34;guest\u0026#34;); //端口號  connectionFactory.setPort(5672); //創建連接  Connection connection = connectionFactory.newConnection(); //創建channel  Channel channel = connection.createChannel(); /** * 創建交換機 * 1. 交換機名稱 * 2. 交換機類型 direct, topic, fanout, headers * 3. 指定交換機是否需要持久化，如果設置為True，那麼交換機的元數據要持久化 * 4. 指定交換機在沒有隊列綁定時，是否刪除？ * 5. Map\u0026lt;String,Object\u0026gt;類型，用來指定我們交換機其他的一些機構話參數，我們在這裡直接設置成Null */ channel.exchangeDeclare(exchangeName, BuiltinExchangeType.FANOUT, true, false, null); /** * 生產一個隊列 * 1. 隊列名稱 * 2. 隊列是否需要持久化，但是要注意，這裡的持久化只是隊列名稱等這些元數據的持久化，不是隊列中消息的持久化 * 3. 表示隊列是不是私有，如果是私有的，只有唱見他的應用程序才能消費消息 * 4. 隊列在沒有消費者訂閱的情況下，是否自動刪除 * 5. 隊列的一些結構化訊息，比如說聲明死信隊列，磁盤隊列會用到 */ channel.queueDeclare(queueName_1, true, false, false, null); channel.queueDeclare(queueName_2, true, false, false, null); channel.queueDeclare(queueName_3, true, false, false, null); channel.queueDeclare(queueName_4, true, false, false, null); /** * 將交換機與隊列綁定 * 1. 隊列名稱 * 2. 交換機名稱 * 3. 路由鍵，在我們直連模式下，可以為我們的隊列名稱 */ channel.queueBind(queueName_1, exchangeName, key_1); channel.queueBind(queueName_2, exchangeName, key_1); channel.queueBind(queueName_3, exchangeName, key_3); channel.queueBind(queueName_4, exchangeName, key_4); // 要發送的消息  String message = \u0026#34;Hello rabbitMQ\u0026#34;; /** * 發送消息 * 1. 發送到哪個交換機 * 2. 隊列名稱 * 3. 其他參數訊息 * 4. 發送消息的消息體 */ channel.basicPublish(exchangeName, key_1, null, \u0026#34;key_1 fanout message\u0026#34;.getBytes()); //註解掉，其他的，來看看會變什麼樣 // channel.basicPublish(exchangeName, key_3, null, \u0026#34;key_3 message\u0026#34;.getBytes()); // channel.basicPublish(exchangeName, key_4, null, \u0026#34;key_4 message\u0026#34;.getBytes());  channel.close(); connection.close(); } }   執行後會出現一個新的交換機\n在Queue中多出了四個Queue\nWarning\n如果你的Queue有不該跳起來的卻跳了起來，很可能是你不小心綁定到了同一個exchange。如果你的xc_queue_name_fanout，一直沒跳起來，很可能是你的consumer持續在背景執行，一直消費你的Queue，記得關掉\n接著啟動消費者，來看看他拿到什麼\nTopic 主題類型交換機，此種交換機與Direct類似，也是需要透過routingKey路由鍵進行匹配分發，區別在Topic可以模糊匹配\n Topic中，將RoutingKey通過\u0026quot;.\u0026ldquo;來分為多個部分 \u0026ldquo;*\u0026quot;：代表一部分 \u0026ldquo;#\u0026quot;：代表0個或多個部分，如果綁定的路由為#時，則接受所有消息，因為路由鍵所有都匹配  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76  public class ProducerTopic { public static void main(String[] args) throws IOException, TimeoutException { String exchangeName = \u0026#34;xc_exchange_topic _name\u0026#34;; String queueName_1 = \u0026#34;xc_queue_topic_name_1\u0026#34;; String queueName_2 = \u0026#34;xc_queue_topic_name_2\u0026#34;; String queueName_3 = \u0026#34;xc_queue_topic_name_3\u0026#34;; String queueName_4 = \u0026#34;xc_queue_topic_name_4\u0026#34;; //key的名稱綁定有變！！！  String key_1 = \u0026#34;key_1.key2.key3.*\u0026#34;; String key_2 = \u0026#34;key_1.#\u0026#34;; String key_3 = \u0026#34;*.key_2.*.key_4\u0026#34;; String key_4 = \u0026#34;#.key_3.key_4\u0026#34;; ConnectionFactory connectionFactory = new ConnectionFactory(); //服務地址  connectionFactory.setHost(\u0026#34;127.0.0.1\u0026#34;); //帳號  connectionFactory.setUsername(\u0026#34;guest\u0026#34;); //密碼  connectionFactory.setPassword(\u0026#34;guest\u0026#34;); //端口號  connectionFactory.setPort(5672); //創建連接  Connection connection = connectionFactory.newConnection(); //創建channel  Channel channel = connection.createChannel(); /** * 創建交換機 * 1. 交換機名稱 * 2. 交換機類型 direct, topic, fanout, headers * 3. 指定交換機是否需要持久化，如果設置為True，那麼交換機的元數據要持久化 * 4. 指定交換機在沒有隊列綁定時，是否刪除？ * 5. Map\u0026lt;String,Object\u0026gt;類型，用來指定我們交換機其他的一些機構話參數，我們在這裡直接設置成Null */ channel.exchangeDeclare(exchangeName, BuiltinExchangeType.TOPIC, true, false, null); /** * 生產一個隊列 * 1. 隊列名稱 * 2. 隊列是否需要持久化，但是要注意，這裡的持久化只是隊列名稱等這些元數據的持久化，不是隊列中消息的持久化 * 3. 表示隊列是不是私有，如果是私有的，只有唱見他的應用程序才能消費消息 * 4. 隊列在沒有消費者訂閱的情況下，是否自動刪除 * 5. 隊列的一些結構化訊息，比如說聲明死信隊列，磁盤隊列會用到 */ channel.queueDeclare(queueName_1, true, false, false, null); channel.queueDeclare(queueName_2, true, false, false, null); channel.queueDeclare(queueName_3, true, false, false, null); channel.queueDeclare(queueName_4, true, false, false, null); /** * 將交換機與隊列綁定 * 1. 隊列名稱 * 2. 交換機名稱 * 3. 路由鍵，在我們直連模式下，可以為我們的隊列名稱 */ channel.queueBind(queueName_1, exchangeName, key_1); channel.queueBind(queueName_2, exchangeName, key_2); channel.queueBind(queueName_3, exchangeName, key_3); channel.queueBind(queueName_4, exchangeName, key_4); // 要發送的消息  String message = \u0026#34;Hello rabbitMQ\u0026#34;; /** * 發送消息 * 1. 發送到哪個交換機 * 2. 隊列名稱 * 3. 其他參數訊息 * 4. 發送消息的消息體 */ channel.basicPublish(exchangeName, \u0026#34;key_1\u0026#34;, null, \u0026#34;key 1 topic message\u0026#34;.getBytes()); channel.close(); connection.close(); } }   執行完後\nHeaders 幾乎跟Direct一樣，所以基本上用不到，有需要再來看\n在SpringBoot中使用 加入依賴\n1 2 3 4 5 6 7 8 9  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.rabbitmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;amqp-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.16.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;   加入配置文件\n注意，這邊記得要自己創建一個使用者，不要用guest，有可能會出錯== 不要問我為什麼會知道\n1 2 3 4 5  spring.rabbitmq.host=localhost spring.rabbitmq.port=5672 spring.rabbitmq.username=hoxton spring.rabbitmq.password=123456 spring.rabbitmq.virtual-host=test1   生成關於exchange、queue的，再將兩者綁在一起Bean\n2024/5/24 回頭來看，不知道為啥下面的都沒作用了，改用Configuration篇章的Code 就可以了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Configuration public class RabbitMQConfig { private final static String EXCHANGE_NAME = \u0026#34;my_boot_fanout_exchange\u0026#34;; private final static String QUEUE_NAME = \u0026#34;my_boot_fanout_queue1\u0026#34;; /** * 聲明交換機 * @return */ @Bean public FanoutExchange fanoutExchange() { return new FanoutExchange(EXCHANGE_NAME, true, false); } @Bean public Queue queue() { return new Queue(QUEUE_NAME, true, false, false); } @Bean public Binding queueBinding(FanoutExchange fanoutExchange, Queue queue) { return BindingBuilder.bind(queue).to(fanoutExchange); } }   Properties 1 2 3  rabbitmq.queue.name :hoxton_queue_name rabbitmq.exchange.name:hoxton_exchange_name rabbitmq.routekey.name:hoxton_queue_name   Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  package com.example.rabbitmq.configuration; import com.rabbitmq.client.BuiltinExchangeType; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; import jakarta.annotation.PostConstruct; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.io.IOException; import java.util.concurrent.TimeoutException; @Configuration public class RabbitMessageQueueConfiguration { private ConnectionFactory connectionFactory; @Value(\u0026#34;${rabbitmq.routekey.name}\u0026#34;) String routeKey; @Value(\u0026#34;${rabbitmq.exchange.name}\u0026#34;) String exchangeName; @Value(\u0026#34;rabbitmq.queue.name\u0026#34;) String queueName; @Bean public ConnectionFactory connectionFactory() { return connectionFactory; } @PostConstruct public void setupRabbitMQ() throws IOException, TimeoutException { // 使用 connectionFactory bean 创建连接  connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\u0026#34;127.0.0.1\u0026#34;); connectionFactory.setUsername(\u0026#34;hoxton\u0026#34;); connectionFactory.setPassword(\u0026#34;123456\u0026#34;); connectionFactory.setPort(5672); Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(exchangeName, BuiltinExchangeType.DIRECT, true, false, null); channel.queueDeclare(queueName, true, false, false, null); channel.queueBind(queueName, exchangeName , routeKey); String message = \u0026#34;Rabbit Mq啟動成功\u0026#34;; channel.basicPublish(exchangeName, queueName, null, message.getBytes()); channel.close(); connection.close(); } }   在配置\n個\nController 我們這邊用RestAPI的方式發送請求過去。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package com.example.rabbitmq.controller; import com.example.rabbitmq.producer.RabbitMQProducer; import com.example.rabbitmq.service.TestService; import lombok.RequiredArgsConstructor; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\u0026#34;rabbit\u0026#34;) @RequiredArgsConstructor public class TestController { private final TestService testService; @GetMapping(\u0026#34;/\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; sendMessage() { testService.sendMessageToRabbitMq(\u0026#34;我是來自前端的訊息\u0026#34;); return ResponseEntity.ok().body(\u0026#34;完成\u0026#34;); } }   Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package com.example.rabbitmq.service; import com.example.rabbitmq.producer.RabbitMQProducer; import lombok.RequiredArgsConstructor; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Service; @Service @RequiredArgsConstructor @Slf4j public class TestService { private final RabbitMQProducer rabbitMQProducer; public void sendMessageToRabbitMq(String message){ log.info(\u0026#34;發送消息到Rabbit Mq:{}\u0026#34;,message); rabbitMQProducer.sendMessage(message); } }   Producer 其中的rabbitTemplate是SpringBoot用來與rabbitMq交互的一個類\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package com.example.rabbitmq.producer; import lombok.RequiredArgsConstructor; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component @RequiredArgsConstructor @Slf4j public class RabbitMQProducer { private final RabbitTemplate rabbitTemplate; @Value(\u0026#34;${rabbitmq.routekey.name}\u0026#34;) String routeKey; @Value(\u0026#34;${rabbitmq.exchange.name}\u0026#34;) String exchangeName; @Value(\u0026#34;${rabbitmq.queue.name}\u0026#34;) String queueName; public void sendMessage(String message) { log.info(\u0026#34;呼叫到MessageQueueProducer\u0026#34;); rabbitTemplate.convertAndSend(exchangeName, routeKey, message); } }   接著再寫一個\nConsumer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package com.example.rabbitmq.comsumer; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.core.Message; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; @Component @Slf4j public class RabbitConsumer { /** * 監聽隊列：當隊列中有消息，則監聽器工作，處理接收到的訊息 * @param message */ @RabbitListener(queues = \u0026#34;${rabbitmq.queue.name}\u0026#34;) public void process(Message message) { byte[] body = message.getBody(); log.info(\u0026#34;呼叫到Consumer\u0026#34;); log.info(\u0026#34;接收到的消息\u0026#34; + new String(body)); } }   這個方法會去監聽指定Queue的Messege，並且做相應的處理\n目前這邊的方式就是把收到的訊息Print出來，並把那個Messege清空，請特別注意，這邊是由rabbit自動幫你ack(acknowledge)的，如果不想要的話也可以去設定把這部分關掉，這邊就不展示了。\n範例圖\n參考資料 1小时学会RabbitMQ！快速掌握RabbitMQ的使用与原理实战\n编程不良人】MQ消息中间件之RabbitMQ以及整合SpringBoot2.x实战教程,已完结!\n","date":"2023-09-08T03:00:58+08:00","image":"https://i.imgur.com/dQTmSCl.png","permalink":"https://hoxtonhsu.com/p/rabbitmq%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"RabbitMQ學習筆記"},{"content":"前言 前一陣子被保哥給Fire掉了，但老實說自己的工作表現真的不太好，這點也確實怪不了人，所幸很快就找到了下一份工作，新的工作有個很大的優點，就是需要學很多我之前想學，但又因為懶惰而沒有去學的技術，而Redis就是其中的一款。於是前輩就跟我說，可以利用等待帳號申請的這一兩個禮拜，把這些技術學一學\n 安裝AnotherRedisDesktopManager 如果你是Arm架構的電腦(沒錯，又是Macbook)，那可以去下載\nAnotherRedisDesktopManager\nhttps://github.com/qishibo/AnotherRedisDesktopManager\n如果出現什麼需要升級才可以打開的訊息，可以在terminal中輸入這段指令來處理\n1 2 3  sudo spctl --master-disable sudo xattr -rd com.apple.quarantine /Applications/Another\\ Redis\\ Desktop\\ Manager.app sudo spctl --master-enable   安裝Redis\n1  brew install redis   啟動 使用默認配置文件啟動 Redis 服務器\n1  redis-server   查看redis狀況\n1  brew services info reids   啟動redis服務\n1  brew services start redis   再次查看狀況\n1  brew services info reids   ![image-20230907132803857](/Users/hoxtonashes/Library/Application Support/typora-user-images/image-20230907132803857.png)\n確認被啟動起來\n接著輸入，啟動redis客戶端\n1  redis-cli   就可以進入到redis中了\nRedis的基本資料型別  String List Set Hash Stored Set  基本操作 連線到遠端的redis 1  redis-cli -h [host] -p [port]   進去之後可能會要你輸入密碼，不然不能操作\n1  AUTH [Password]   設置key-vale 1  set Hello World   依據key取出value 1  get Hello   查看目前有哪些key 1  keys *   刪除Key 1  DEL Hello   關閉服務 1  shutdown   介紹 基於記憶體進行存取，支持key-value的存儲形式，是使用C語言編寫的。由於是key-value的形式，結構非常簡單，沒有數據表的概念，直接用鍵值對完成數據的管理\nRedis支持5種數據類型\n  字符串\n  列表\n  集合\n  有序集合\n  哈希：以\n{key:\nkey:value,\nkey:value\n}的形式存在\n  常見名詞解釋 快存穿透(Cache Penetration) 假設我們在redis中從資料庫暫存了數據1,2,3，當用戶索要這些資料時，redis都能立刻反應，吐給用戶。但當用戶索要數據4時，由於資料庫本身沒有這筆資料，redis當然也不會有這筆資料，所以請求就來到了資料庫，不斷地跟要一筆不存在的資料，這就是快取穿透，相關的處理可以搜尋布林過濾器。\n快取雪崩(Cache Avalanche) Redis的一群資料同時expire了，此時又有用戶大量請求這些資料，於是大量請求進入資料庫，造成資料庫負擔過大\n與SpringBoot整合 加入相關依賴\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.7.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   配置相關的application.properties\n1 2 3 4 5  #redis配置文件 # redis本身就是一個Database的概念，所以不需要分成什麼1,2,3號數據庫，固定都是0 spring.redis.database=0 spring.redis.host=localhost spring.redis.port=6379   想要存進去的資料要實現Serializable的功能，因為你的資料是存在記憶體當中\n將資料加入redis中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package com.example.springbootinaction.controller; import com.example.springbootinaction.entity.User; import lombok.RequiredArgsConstructor; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RestController; @RestController @RequiredArgsConstructor public class UserController { private final RedisTemplate\u0026lt;String,User\u0026gt; redisTemplate; @PostMapping(\u0026#34;user\u0026#34;) public void save(@RequestBody User user) { redisTemplate.opsForValue().set(\u0026#34;user\u0026#34;, user, 10L, TimeUnit.SECONDS); //配置到期單位  } }   其中opsForValue、opsForHash、opsForSet\u0026hellip;其實就是對應redis存取的五種資料類型\n由於單例池中是沒有RedisTemplate\u0026lt;String,User\u0026gt;這顆Bean的(只有RedisTemplate而已)，於是我們要自己創造一個給他\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package com.example.springbootinaction.config; import com.example.springbootinaction.entity.User; import org.springframework.context.annotation.Bean; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Component; @Component public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, User\u0026gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate\u0026lt;String, User\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); template.setConnectionFactory(redisConnectionFactory); return template; } }   使用Postman將資料送出去\n送出去之後，在Terminal中輸入\n1  get user   會發現取了個寂寞，為什麼呢？因為redis在存進去的時候，會把我們的key做一個序列化，會在我們的keyname前面再加上一串字符\n所以說要取得的話，就是要再將序列化的字符串加上去，就取得到了\n之所以裡面的資料看起來像亂碼的原因，也是因為這些資料經過了序列化，不過不用擔心，我們在取出來的時候會再幫我們做一次反序列化的\n如果希望可以在redis裡面可以方便預覽的話，可以配置Serializer給RedisTemplate，變成json格式\n1 2 3 4 5 6 7 8 9  @Bean public RedisTemplate\u0026lt;String, User\u0026gt; userRedisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate\u0026lt;String, User\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; objectJackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); //配置序列化  template.setValueSerializer(objectJackson2JsonRedisSerializer); template.setConnectionFactory(redisConnectionFactory); return template; }   將資料從redis中取出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package com.example.springbootinaction.controller; import com.example.springbootinaction.entity.User; import lombok.RequiredArgsConstructor; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.web.bind.annotation.*; @RestController @RequiredArgsConstructor @RequestMapping(\u0026#34;user\u0026#34;) public class UserController { private final RedisTemplate\u0026lt;String,User\u0026gt; redisTemplate; @PostMapping() public void save(@RequestBody User user) { redisTemplate.opsForValue().set(\u0026#34;user\u0026#34;, user); } @GetMapping(\u0026#34;{key}\u0026#34;) public User get(@PathVariable(\u0026#34;key\u0026#34;) String key){ return redisTemplate.opsForValue().get(key); } }   將資料從redis中刪除 1 2 3 4 5  @DeleteMapping(\u0026#34;delete/{key}\u0026#34;) public Boolean delete(@PathVariable(\u0026#34;key\u0026#34;) String key) { return redisTemplate.delete(key); } }   與五種資料型別對應的操作 Value的操作 1 2 3 4 5  @GetMapping(\u0026#34;atom\u0026#34;) public Long atom() { ValueOperations\u0026lt;String, Integer\u0026gt; count = intergerRedisTemplate.opsForValue(); return count.increment(\u0026#34;count\u0026#34;,1); }   記得配置序列化設定\n1 2 3 4 5 6 7 8 9 10  @Bean public RedisTemplate\u0026lt;String, Integer\u0026gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate\u0026lt;String, Integer\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); GenericToStringSerializer\u0026lt;Integer\u0026gt; genericToStringSerializer = new GenericToStringSerializer\u0026lt;\u0026gt;(Integer.class); //配置序列化  template.setValueSerializer(genericToStringSerializer); template.setConnectionFactory(redisConnectionFactory); return template; }   如果不配置會出現\n1  org.springframework.dao.InvalidDataAccessApiUsageException: ERR value is not an integer or out of range   的問題，就是因為序列化的問題\nList的操作 1 2 3 4 5 6 7 8 9  @GetMapping(\u0026#34;list\u0026#34;) public List\u0026lt;User\u0026gt; listTest() { ListOperations\u0026lt;String, User\u0026gt; stringUserListOperations = redisTemplate.opsForList(); stringUserListOperations.leftPush(\u0026#34;list\u0026#34;, new User()); stringUserListOperations.leftPush(\u0026#34;list\u0026#34;, new User()); stringUserListOperations.leftPush(\u0026#34;list\u0026#34;, new User()); return stringUserListOperations.range(\u0026#34;list\u0026#34;, 0, 2); }   Set的操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @GetMapping(\u0026#34;set\u0026#34;) public Set\u0026lt;User\u0026gt; setTest() { SetOperations\u0026lt;String, User\u0026gt; stringUserSetOperations = redisTemplate.opsForSet(); User hoxton = new User(); hoxton.setUsername(\u0026#34;Hoxton\u0026#34;); User yiwen = new User(); yiwen.setUsername(\u0026#34;Selime\u0026#34;); stringUserSetOperations.add(\u0026#34;set\u0026#34;, hoxton); stringUserSetOperations.add(\u0026#34;set\u0026#34;, hoxton); stringUserSetOperations.add(\u0026#34;set\u0026#34;, yiwen); stringUserSetOperations.add(\u0026#34;set\u0026#34;, yiwen); Set\u0026lt;User\u0026gt; set = stringUserSetOperations.members(\u0026#34;set\u0026#34;); return set; }   有序Set的操作 塞進去的時候是312，取出來的時候是123\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @GetMapping(\u0026#34;zset\u0026#34;) public Set\u0026lt;User\u0026gt; zSetTest() { ZSetOperations\u0026lt;String, User\u0026gt; stringUserZSetOperations = redisTemplate.opsForZSet(); User hoxton1 = new User(); hoxton1.setUsername(\u0026#34;Hoxton\u0026#34;); hoxton1.setId(1L); User hoxton2 = new User(); hoxton2.setUsername(\u0026#34;Hoxton\u0026#34;); hoxton2.setId(2L); User hoxton3 = new User(); hoxton3.setUsername(\u0026#34;Hoxton\u0026#34;); hoxton3.setId(3L); stringUserZSetOperations.add(\u0026#34;zset\u0026#34;, hoxton3, 3); stringUserZSetOperations.add(\u0026#34;zset\u0026#34;, hoxton1, 1); stringUserZSetOperations.add(\u0026#34;zset\u0026#34;, hoxton2, 2); Set\u0026lt;User\u0026gt; zset = stringUserZSetOperations.range(\u0026#34;zset\u0026#34;, 0, 2); return zset; }   哈希 1 2 3 4 5 6 7  @GetMapping(\u0026#34;hash\u0026#34;) public User hashTest() { HashOperations\u0026lt;String, Object, User\u0026gt; hash = redisTemplate.opsForHash(); hash.put(\u0026#34;key\u0026#34;, \u0026#34;hashkey\u0026#34;, new User(1L)); return hash.get(\u0026#34;key\u0026#34;, \u0026#34;hashkey\u0026#34;); }   遇到的問題 配置快取後，出現java.lang.ClassCastException 解決方式：\n問題的原因是因為redis中的類轉換機制與SpringBoot中不同，換言之兩邊的要對得起來\n相關的配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  private Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; objectJackson2JsonRedisSerializer() { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.configure(MapperFeature.USE_ANNOTATIONS, false); objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false); // 此项必须配置，否则会报java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX  objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY); objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); return jackson2JsonRedisSerializer; } /** * 將redis跟SpringBoot做結合 * * @param redisConnectionFactory * @return */ @Bean public CacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) { Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; objectJackson2JsonRedisSerializer = objectJackson2JsonRedisSerializer(); RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration. defaultCacheConfig(). entryTtl(Duration.ofHours(1)) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(objectJackson2JsonRedisSerializer)); return RedisCacheManager.builder(RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory)) .cacheDefaults(redisCacheConfiguration).build(); }   參考資料 【趣话Redis第一弹】我是Redis，MySQL大哥被我坑惨了！\n","date":"2023-09-07T09:32:15+08:00","image":"https://i.imgur.com/hW7HRS8.png","permalink":"https://hoxtonhsu.com/p/redis%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"Redis學習筆記"},{"content":"前言 前陣子精蟲衝腦購買了Macbook，使用起來可以說是痛苦並痛苦的感覺。但在這段期間的摸索中，我確實有感受到Macbook系統某方面的好處(其實根本沒有)，也試著去將macbook調教成喜歡的模樣(其實就是windows的樣子)，以下是一些我認為必裝，不裝則根本沒辦法用的插件，有些是要付費的，但價格大約落在300之間，我認為是值得的。\nRayCast RayCast的好，用過的都知道，可以比較粗略地認為它就是一個更強大的spotlight，原先的spotlight更像是一個應用程式以及設定的快速入口，但RayCast則是將更多的功能打包進來，這些功能包括但不限於\n 剪貼簿 畫面分割 解除安裝程式 搜尋Gif，貼給同事 快速使用google搜尋  剪貼簿功能 剪貼簿是我最早需要，而接觸Raycast的功能，因為在日常辦公中，我常常需要複製重複性的東西來做一些驗證類事情，最早的時候，我使用的是一個叫clipBroad的插件，但使用一段時間之後還是覺得那個插件功能太爛了，後來使用Raycast之後，發現Raycast幾乎實現了我在Windows上的體驗，甚至超越Windows\n我在Raycast中將剪貼簿的快捷鍵設置成Option+V，意圖就在模仿windows快捷鍵的位置，RayCast的剪貼簿能夠儲存圖片，文字，並且圖片也支援預覽，文字也可以在上面進行複製，也可以透過上面的搜尋，來尋找想要找到的內容，比如說圖片的名稱，複製文字的內容等等，都可以在這邊找到\n畫面分割 畫面分割功能也是我常用的一個功能，最早的時候我是使用一個叫Rectangle的插件，那個插件其實也沒什麼問題，但就是Raycast也能做到，那就統一在RayCast上做處理了\n我主要就是設定成，靠左、靠右、靠上、靠下、全螢幕\n解除安裝程式 Ｍacbook本身的解除安裝，不知道為什麼有時候就是會有一些東西刪不掉，常常困擾我，後來在RayCast中也有提供類似一鍵刪除的功能，著實讓我方便很多\n快速搜尋Gif 這功能其實不是Raycast內建的，而是RayCast的工作坊提供的功能\n會特別介紹這個功能，是因為之前工作時，工作日誌的部分我們都會配上一個有趣的Gif，來讓晨會開心一點，所以這功能我也很需要，哈哈\n快速使用Google搜尋 RayCast中有一個叫做QuickLink的功能，簡而言之就是可以直接在RayCast中搜尋特定網域的內容，直接看圖片會比較快一點\n但這功能老實說我比較少用就是了\niShot iShot是一個截圖功能的插件，有分付費版跟免費版，付費版的價錢我記得是$320好像多兩個功能\n 對圖片做OCR辨識 滾動截圖不會有浮水印  這是我目前用過最舒服的截圖插件了，他的功能包括但不限於\n 截圖 滾動截圖 對截下來的圖片做立刻的編輯 釘選圖片至桌面 對圖片做OCR影像辨識 錄製Gif  在工作中，我常常需要回覆一些問題給同事，請同事處理，有時候用文字描述又很麻煩，這時候我會很需要用Gif的功能，在之前，我是使用一個叫做LIceCap的插件完成，這插件也沒啥問題，缺點就是太慢了，我需要先把邊框拉出來，然後存到桌面，我接著再去桌面複製下來貼上，真的太慢了，我後來找到的這個插件，可以讓我錄製Gif就像截圖一樣的便捷快速\n而截圖的當下也能立刻對圖片編輯，不需要再拉一個額外的視窗出來，這功能也深得我心\n底下也有些不同的功能，比如說都非常的實用，$320真的是非常的物超所值\nＭission Control + Mission Control 普拉斯，顧名思義，他就只是在Mac內建的任務管理功能上多一個功能，什麼功能呢？你可以直接在MIssion Control的頁面上把頁面關掉\u0026hellip;，或是用command+w來關掉程式，對，就是一個這麼基本的功能，我不知道為什麼Mac居然沒有做，它用起來的樣子就像這樣，雖然看起來很廢，但這個功能我幾乎每五分鐘就會用到一次，我記得這個東西價錢也是300，非常的\u0026hellip;物超所值\nAltTab 這個功能是為了解決一個問題，就是MacBook的替換頁面的邏輯實在不太符合我自己的使用情況，舉例說我目前開兩個IntelliJ的畫面，這時候我左邊的螢幕想要查一下資料，按了一下Alt+Tab之後，噹噹，我的主螢幕還有副螢幕全部都跳成Google頁面了\n於是我需要一個可以個別控制AltTab功能的插件，而這個插件就是為了處理這件事情而生的，安裝好後，你的Alt+Tab就會變成這樣的畫面\n基本上就是window的那套邏輯搬過來用，並且你可以在這個畫面中，直接Quit掉整個App，對於我這種實在不習慣看到很多App出現在畫面中的人，非常方便，並且你也可以Hover到圖標上，按下command+w，或是commnad+q，直接關閉、終止掉整個程式的運行\niBar 在介紹完了這麼多插件，M1、M2用戶最擔心的應該就是裝了那麼多插件，我的meun bar可以顯示嗎？沒錯，問就是不行，這問題官方雖然有出一個解決方案，但還是沒辦法有效的解決我的問題，在這之前我是用一個叫做hidden bar的東西，但用了一段時間之後發現他還是解決不了什麼問題，他只是把圖標縮在一起，當展開的時候還是會被瀏海給吃到，後來在iShot同公司的網頁上，找到了這個App，也是完美的解決了我想要處理的問題\n在使用過後，你可以將不希望長駐顯示的App 折疊在這個地方裡面，這樣就不會被瀏海(Notch)給遮擋住了\n結尾 以上是我對Macbook實用插件的一個介紹，如果有覺得不錯的插件，也歡迎介紹給我，謝謝大家\n","date":"2023-08-31T10:19:14+08:00","image":"https://i.imgur.com/ezUyxYS.png","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E8%AE%93mac%E7%9A%84%E4%BD%BF%E7%94%A8%E9%AB%94%E9%A9%97%E6%9B%B4%E5%8A%A0%E7%B5%B2%E6%BB%91%E6%88%91%E7%9A%84mac%E5%AF%A6%E7%94%A8%E6%8F%92%E4%BB%B6%E4%BB%8B%E7%B4%B9/","title":"如何讓Mac的使用體驗更加絲滑，我的Mac實用插件介紹"},{"content":" 這陣子到保哥的公司，過著天天被洗臉的日子，\n最近派給了一個批次檔的功能翻新，主要是將檔案從本地上傳到FTP或是將檔案從FTP下載下來的功能，趁著最近來練習一下Java相關的FTP套件，在練習的時候發現不知道為什麼，檔案上傳永遠都是return False，把錯誤訊息打印出來後，發現一直看到\nFTP 550 No such file or directory的錯誤\n 網路上查了很多東西，有人說把ftpClient設成enterLocalPassiveMode，還有setFileType(FTP.BINARY_FILE_TYPE)等等的問題，但這些我都有設。\n後來真的沒辦法，隨便亂調，調完之後發現是檔案名稱的問題，沒錯的，這一次又是因為檔案名稱是中文的關係，所導致的錯誤，只要將檔案名稱的中文去掉就可以囉！\n","date":"2023-08-17T22:03:06+08:00","image":"https://i.imgur.com/Zm0Sn6B.jpg","permalink":"https://hoxtonhsu.com/p/%E4%BD%BF%E7%94%A8apache%E7%9A%84ftp%E5%A5%97%E4%BB%B6storefile%E4%B8%80%E7%9B%B4%E5%9B%9E%E5%82%B3550%E7%9A%84%E5%95%8F%E9%A1%8C%E8%A9%B2%E8%A7%A3%E6%B1%BA/","title":"使用Apache的FTP套件，storeFile()一直回傳550的問題該解決"},{"content":"齊次方程(Homogenous Function)  當函數中的自變數變動一個倍數，整個函數可以整理為該倍數的某個次方倍，此函數即為齊次函數，而剛剛說的次方，就會稱為這個齊次函數之階數。\n判斷一個給定的函數是否為齊次函數，唯一的方法就是，「將自變數變動一個倍數，看看整個函數值會不會變動那個倍數的某個次方倍」，會，那這個函數就是齊次函數，不會，那他就不是齊次函數了！\n 給一方程\nAx=b\n若b等於0，則稱為齊次方程組，否則稱為非齊次(nonhomogeneous)，因此齊次方程使有零解(就是所有未知數都代0進去就有解了)\n線性獨立/線性相依 何謂線性獨立/線性相依，齊次方程只有零解的情況，即為線性無關，若存在非零解，則為線性相關。\n線性相關-\u0026gt;齊次方程有非零解-\u0026gt;行列式為0 線性無關-\u0026gt;其次方程只有零解-\u0026gt;行列式不為0\n若\n$$ k_{1}a_{1}+k_{2}a_{2}=0 \\\\\nA=(a_{1} a_{2}) =\\begin{bmatrix} 2 \u0026amp; 1 \\\n1 \u0026amp; 2 \\\n\\end{bmatrix} $$\n若能找到不為零的k1,k2(只要有一個不為零就可以)，則為線性相關。若只有0的話就是線性無關。 其幾何意義在於，是否能透過線性的延伸、壓縮，與其他的線性相加起來，組合出0向量。\n兩個平面向量，若線性無關則不共線\n兩個平面向量，若線性相關則共線\n餘因子 ","date":"2023-08-07T12:36:49+08:00","image":"https://i.imgur.com/sHKwuek.png","permalink":"https://hoxtonhsu.com/p/%E4%B8%80%E4%BA%9B%E9%97%9C%E6%96%BC%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8%E7%9A%84trivial/","title":"一些關於線性代數的Trivial"},{"content":"前陣子被公司抓去當了QA，不得不說QA真的很無聊，就是一直在按一些button，大概就是一些重複性高，又沒什麼產值的工作，剛好想到之前在前前公司有聽過Selenium這個東西，於是來研究一下。\n介紹 可以先看一下底下的gif，就可以更了解selenium的作用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import time from selenium import webdriver from selenium.webdriver import Keys from selenium.webdriver.common.by import By options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.google.com/\u0026#39;) search = driver.find_element(By.NAME, \u0026#39;q\u0026#39;) search.send_keys(\u0026#39;武嶺\u0026#39;) search.send_keys(Keys.ENTER) time.sleep(100)   這邊這段程式，就是指\n然後Chrome就會自己動起來了。有時候我們可能需要某些網站的資訊，但它本身不是走前後端分離，資訊都是透過session、cookie來傳遞，而不是json，像這種情況，如果對速度沒有特別的要求，就可以使用Selenium來處理。接著我們就以104網頁的爬蟲為範例，示範看看Selenium使用\n安裝 老樣子，使用Anaconda\n 創建conda環境  1  conda create --name selenium python=3.9 -y   進入環境  1  conda activate selenium   安裝所需要的pip  1  pip install selenium   查看pip是否安裝成功  1  pip list   開頭 程式碼放在這：https://github.com/Hoxton019030/Selenium\n先寫一段Demo用的Code\n1 2 3 4 5 6 7 8  from selenium import webdriver options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.google.com/\u0026#39;) driver.close() print(\u0026#34;成功\u0026#34;)   效果：\n讓我們現在把頁面改成104的頁面\n1 2 3 4 5 6 7 8 9 10  from selenium import webdriver options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.104.com.tw/jobs/search/?keyword=Java\u0026amp;order=1\u0026amp;jobsource=2018indexpoc\u0026amp;ro=0\u0026#39;) driver.close() print(\u0026#34;成功\u0026#34;)   接下來這樣就可以開啟104的頁面了，那接下來我們就是要透過driver這個物件，來找到我們目前頁面的一些資訊，我們可以使用\n1  driver.page_source   來查看頁面的一些資訊\n1 2 3 4 5 6 7 8 9 10 11  from selenium import webdriver options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.104.com.tw/jobs/search/?keyword=Java\u0026amp;order=1\u0026amp;jobsource=2018indexpoc\u0026amp;ro=0\u0026#39;) print(driver.page_source) driver.close() print(\u0026#34;成功\u0026#34;)   這個driver.page_source所包含的其實就是整個網頁的DOM，既然有html的東西，那接下來就要介紹各種不同的選擇器，來取得想要的資訊\n選擇器 Selenium提供了許多不同的選擇器，讓我們來定位我們的html內容，\n接下來會講幾個比較常用的，其實也就是css_selector跟class name，\nClass選擇器 我們現在想要找到每份職缺的title\n查看DOM之後我們發現，它的html class 為 js-job-link\n那我們就可以這樣寫\n1 2 3 4 5 6 7 8 9 10 11 12 13  from selenium import webdriver from selenium.webdriver.common.by import By options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.104.com.tw/jobs/search/?keyword=Java\u0026amp;order=1\u0026amp;jobsource=2018indexpoc\u0026amp;ro=0\u0026#39;) titles = driver.find_elements(By.CLASS_NAME, \u0026#34;js-job-link\u0026#34;) for title in titles: print(title.text) driver.close()   效果：\nCSS 選擇器 這是Selenium官方最為推薦的選擇方式，最大的優勢就在於它可以使用css選擇器來定位元素，比如說nth-child、first-child之類的，所以它可以找到幾乎所有的元素，比如說我想要找到工作的描述\n它的css選擇器就是這樣讀\n「想要找到tag為p，並且有job-list-item__info, b-clearfix, b-content 這些class名稱的地方」\n那python就是這樣寫\n1 2 3 4 5 6 7 8 9 10 11 12 13  from selenium import webdriver from selenium.webdriver.common.by import By options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.104.com.tw/jobs/search/?keyword=Java\u0026amp;order=1\u0026amp;jobsource=2018indexpoc\u0026amp;ro=0\u0026#39;) titles = driver.find_elements(By.CLASS_NAME, \u0026#34;js-job-link\u0026#34;) jobInfos = driver.find_elements(By.CSS_SELECTOR, \u0026#34;p.job-list-item__info.b-clearfix.b-content\u0026#34;) for element in jobInfos: print(element.text) driver.close()   其實觀察一下可以發現，Google的開發人員工具已經幫我們把這個地方的css selector標出來了\n我們可以直接複製貼上就好\n剛剛有提到說可以使用css selector來做更仔細的定位，那麼該怎麼用呢？以104中的工作要求為例\n我們注意到，它其實是一個ul的結構，想要挑出「工作經驗」這一個區塊的東西，想要用class選擇器來定位基本上不可能，這時候就要使用css selector來達到我們想要的效果，而這邊的寫法就是這樣\n1  experiences = driver.find_elements(By.CSS_SELECTOR,\u0026#34;ul.b-list-inline.b-clearfix.job-list-intro.b-content li:nth-child(3)\u0026#34;)   來通過選擇器找到li的第三個child，也就是工作經歷\nID 選擇器 id選擇器就是id選擇，使用方式就如同大家想的那樣，通常是用來定位一些unique的元素\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  from selenium import webdriver from selenium.webdriver.common.by import By options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.104.com.tw/jobs/search/?keyword=Java\u0026amp;order=1\u0026amp;jobsource=2018indexpoc\u0026amp;ro=0\u0026#39;) titles = driver.find_elements(By.CLASS_NAME, \u0026#34;js-job-link\u0026#34;) jobInfos = driver.find_elements(By.CSS_SELECTOR, \u0026#34;p.job-list-item__info.b-clearfix.b-content\u0026#34;) experiences = driver.find_elements(By.CSS_SELECTOR, \u0026#34;ul.b-list-inline.b-clearfix.job-list-intro.b-content li:nth-child(3)\u0026#34;) mainContent = driver.find_element(By.ID, \u0026#34;main-content\u0026#34;) print(mainContent.text) driver.close()   透過element來找到裡面的attribute 現在想要把每個工作的超連結取出來，要怎麼做呢？\n可以先透過選擇器選出想要的tag，變成一個webElement物件(相當於底下的hrefs)，然後再透過get_attribute來取得標籤內的值，我們就可以透過這樣的方式來取出想要的資料了\n1 2 3 4 5  hrefs = driver.find_elements(By.CLASS_NAME, \u0026#34;js-job-link\u0026#34;) for href in hrefs: link = href.get_attribute(\u0026#39;href\u0026#39;) print(link)   點擊的觸發 當我們取得這個頁面的資料完後，想要接著點擊下一頁，那我們該怎麼做呢？\n首先先透過選擇器，來選到下一頁的button\n1  link = driver.find_element(By.CLASS_NAME, \u0026#34;js-next-page\u0026#34;)   接著可以透過link.click()來觸發點擊事件，切換到下一頁\n疑！！幹幹幹幹幹，怎麼出錯了\n看了一下console區，它的回應是這樣\n「網頁中沒有可以互動的元素」，像這種情況多半是因為DOM元件還沒load進來，我們可以透過一些方式來延緩它加載的時間，最爛的做法其實就是用time.sleep()的方式來，但因為我現在只會用這個方式(✿◡‿◡)\n1 2 3 4 5 6 7 8 9 10 11 12  from selenium import webdriver from selenium.webdriver.common.by import By options = webdriver.ChromeOptions() driver = webdriver.Chrome() driver.get(\u0026#39;https://www.104.com.tw/jobs/search/?keyword=Java\u0026amp;order=1\u0026amp;jobsource=2018indexpoc\u0026amp;ro=0\u0026#39;) for i in range(10): time.sleep(2) link = driver.find_element(By.CLASS_NAME, \u0026#34;js-next-page\u0026#34;) link.click()   實際的程式碼 最後我們把上面的東西整合一下，並且把資料存到excel裡面，就可以達到我們想要的效果嚕\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  import time import openpyxl from selenium import webdriver from selenium.webdriver.common.by import By from JobDetail import JobDetail options = webdriver.ChromeOptions() options.add_argument(\u0026#39;--ignore-certificate-errors\u0026#39;) options.add_argument(\u0026#34;--test-type\u0026#34;) options.binary_location = \u0026#34;/usr/bin/chromium\u0026#34; driver = webdriver.Chrome() url = \u0026#34;https://www.104.com.tw/jobs/search/?https://www.104.com.tw/jobs/search/?ro=0\u0026amp;kwop=7\u0026amp;keyword=Java\u0026amp;expansionType=area%2Cspec%2Ccom%2Cjob%2Cwf%2Cwktm\u0026amp;area=6001001001%2C6001001007%2C6001002000%2C6001001003%2C6001001006%2C6001001002%2C6001001012%2C6001001004%2C6001001005\u0026amp;order=15\u0026amp;asc=0\u0026amp;page=1\u0026amp;mode=s\u0026amp;jobsource=2018indexpoc\u0026amp;langFlag=0\u0026amp;langStatus=0\u0026amp;recommendJob=1\u0026amp;hotJob=1\u0026#34; driver.get(url) driver.implicitly_wait(10) workbook = openpyxl.Workbook() sheet = workbook.active headers = [\u0026#34;職務名稱\u0026#34;, \u0026#34;公司名稱\u0026#34;, \u0026#34;相關描述\u0026#34;, \u0026#34;工作簡述\u0026#34;, \u0026#34;公司地址\u0026#34;, \u0026#34;工作經驗要求\u0026#34;, \u0026#34;網址連結\u0026#34;] sheet.append(headers) for i in range(113): # 頁面的interator try: titles = driver.find_elements(By.CLASS_NAME, \u0026#34;js-job-link\u0026#34;) companyNames = driver.find_elements(By.CSS_SELECTOR, \u0026#34;ul.b-list-inline.b-clearfix a\u0026#34;) hrefs = driver.find_elements(By.CLASS_NAME, \u0026#34;js-job-link\u0026#34;) # 這邊先註解掉，不知道怎麼把薪資抓出來 # tags = driver.find_elements(By.CLASS_NAME, \u0026#34;b-tag--default\u0026#34;) # stringTag = \u0026#34;\u0026#34; # for tag in tags: # stringTag += tag.text # jobInfos = driver.find_elements(By.CLASS_NAME, \u0026#34;job-list-item__info\u0026#34;) jobInfos = driver.find_elements(By.CSS_SELECTOR, \u0026#34;p.job-list-item__info.b-clearfix.b-content\u0026#34;) # for jobInfo in jobInfos: # print(jobInfo.text) addresses = driver.find_elements(By.CSS_SELECTOR, \u0026#34;ul.b-list-inline.b-clearfix.job-list-intro.b-content li:first-child\u0026#34;) experiences = driver.find_elements(By.CSS_SELECTOR, \u0026#34;ul.b-list-inline.b-clearfix.job-list-intro.b-content li:nth-child(3)\u0026#34;) job_details_list = [] for j in range(len(titles)): name = \u0026#34;\u0026#34; title = titles[j].text if \u0026#34;/\u0026#34; in title: break companyName = companyNames[j].text href = hrefs[j].get_attribute(\u0026#39;href\u0026#39;) jobInfo = jobInfos[j].text address = addresses[j].text experience = experiences[j].text job_detail = JobDetail(title, companyName, href, name, jobInfo, address, experience) job_details_list.append(job_detail) for job in job_details_list: rowData = [job.title, job.companyName, job.tags, job.jobInfo, job.address, job.experience, job.href] sheet.append(rowData) link = driver.find_element(By.CLASS_NAME, \u0026#34;js-next-page\u0026#34;) link.click() time.sleep(2) print(\u0026#34;目前處理到第\u0026#34;, i, \u0026#34;頁\u0026#34;) workbook.save(\u0026#34;test.xlsx\u0026#34;) print(\u0026#34;儲存\u0026#34;) except Exception as e: print(e) time.sleep(1) continue print(\u0026#34;儲存\u0026#34;) workbook.close() # for some in hrefs: # print(some.get_dom_attribute(\u0026#39;href\u0026#39;)) # print(titles) # time.sleep(10) # a = JobDetail() # for title in titles: # print(title.text) # for companyName in companyNameList: # print(companyName.text) # for tag in tags: # print(tag.text) # print(driver.page_source) # 取得上一頁的文章標題 # time.sleep(10) # driver.close()   這樣就可以囉！\n","date":"2023-08-03T00:15:02+08:00","image":"https://i.imgur.com/tsAfSod.png","permalink":"https://hoxtonhsu.com/p/selenium%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98-%E4%BB%A5104%E4%BA%BA%E5%8A%9B%E9%8A%80%E8%A1%8C%E7%82%BA%E4%BE%8B/","title":"Selenium學習筆記-以104人力銀行為例"},{"content":"最近很常在Hugo內寫一些數學式，比如說聯立方程，或是矩陣，微積分之類的，有時候會遇到Hugo中無法正確顯示畫面的情況，在這之前已經有參考很多人的文章了，比如說\n如何在 Hugo 內嵌 Latex 數學式\nMathJax Support 中文文檔\n其實不外乎就是加上script裡面，但是我遇到的情況是我已經加上去了，但卻還是沒辦法render出來，我呈現出來的畫面會像這樣\n明明是方程跟矩陣，但看起來就是怪怪的，爬了很多文章之後都找不到結果，後來到我使用的這個theme的Github頁面查看，就知道問題了\nkatex 分段函数不能正常显示\n其實原因就是因為我的SourceCode長這樣\n1 2 3 4 5 6 7 8  $$ \\begin{bmatrix} -1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; | \u0026amp; -20 \\\\ 1 \u0026amp; -1 \u0026amp; 0 \u0026amp; 0 \u0026amp; | \u0026amp; -10 \\\\ 0 \u0026amp; 1 \u0026amp; -1 \u0026amp; 0 \u0026amp; | \u0026amp; 20 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -1 \u0026amp; | \u0026amp; 10 \\\\ \\end{bmatrix} $$   在渲染的時候把\\\\視作跳脫字元處理掉了，所以只要在換行的地方加上跳脫字元的跳脫字元，這樣就可以了\n1 2 3 4 5 6 7 8  $$ \\begin{align*} x_{1} \u0026amp;+ 10 = x_{2} \\\\\\\\ x_{2} \u0026amp;= 5 + x_{3}\\\\\\\\ x_{3} \u0026amp;= 10+ x_{4} \\\\\\\\ x_{4} \u0026amp;+20=x_{1} \\end{align*} $$   結果圖就如下這樣 ：\n","date":"2023-07-27T11:51:18+08:00","image":"https://i.imgur.com/nnX2rBK.jpg","permalink":"https://hoxtonhsu.com/p/hugo%E4%B8%AD%E5%A6%82%E4%BD%95%E8%A7%A3%E6%B1%BAmathjax%E8%B7%91%E7%89%88%E5%95%8F%E9%A1%8C/","title":"Hugo中如何解決mathjax跑版問題"},{"content":"最近在學習線性代數，很感謝自己當初高中選的是自然組( •̀ ω •́ )✧，至少還保留一點交戰記憶，還有剛好是中原有教微積分的最後一屆商學院(我記得之後的都是教財務數學)，所以看到什麼導數、cosθ、之類的不至於太害怕。\n今天再寫的時候看到一題交大資工的考古題，覺得非常的實用，上網查了一下解法，順便當作個紀錄\n第一次看到的時候有點嚇到，看了一下解答之後還是不太清楚怎麼求出下面的聯立方程的\n$$ \\begin{align*} x_{1} \u0026amp;+ 10 = x_{2} \\\\\nx_{2} \u0026amp;= 5 + x_{3}\\\\\nx_{3} \u0026amp;= 10+ x_{4} \\\\\nx_{4} \u0026amp;+20=x_{1} \\end{align*} $$\n後來看了一下國外的教學，發現概念很簡單，一個圓環，進來的車流量必定等於出去的流量，所以x₂就是x₁再加上10，而x₃就等於x₂再減去開出去的20輛車，也就就是x₂-20=x₃。於是就可以列出增廣矩陣\n$$ \\begin{bmatrix} -1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; | \u0026amp; -20 \\\\\n1 \u0026amp; -1 \u0026amp; 0 \u0026amp; 0 \u0026amp; | \u0026amp; -10 \\\\\n0 \u0026amp; 1 \u0026amp; -1 \u0026amp; 0 \u0026amp; | \u0026amp; 20 \\\\\n0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -1 \u0026amp; | \u0026amp; 10 \\\\\n\\end{bmatrix} $$\n化成列梯陣 $$ \\begin{bmatrix} 1 \u0026amp; -1 \u0026amp; 0 \u0026amp; 0 \u0026amp; | \u0026amp; -10 \\\\\n0 \u0026amp; 1 \u0026amp; -1 \u0026amp; 0 \u0026amp; | \u0026amp; 20 \\\\\n0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -1 \u0026amp; | \u0026amp; 10 \\\\\n0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; | \u0026amp; 0 \\\\\n\\end{bmatrix} $$\n發現這個矩陣具有無窮多組解，Ax=B得x等於\n$$ \\begin{bmatrix} 20+t \\\\\n30+t \\\\\n10+t \\\\\nt \\\\\n\\end{bmatrix} $$\n那回頭來解題目\n題目1說可以化為strictly triangular matrix，答案是不可以的，因為對角元素不是全零\n 嚴格三角矩陣定義：是三角矩陣，但對角項均為零\n 題目二說可以化為那樣的簡化列梯陣，當然答案也是錯的\n題目三說這個線性系統是Consistent的，所謂的Consistent(一致)代表至少有一組解，那這邊是對的\n題目四，最大交通的是X2，因為它是30+t\n題目五問說如果現在所有的方向全部倒過來，那答案會一樣嗎，答案是對的，因為只是方向換過來，其實就只是在等號兩邊同乘負號而已\n","date":"2023-07-27T00:48:39+08:00","image":"https://i.imgur.com/wswxl2P.png","permalink":"https://hoxtonhsu.com/p/%E4%BB%A5%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8%E6%B1%82%E8%A7%A3%E8%BB%8A%E6%B5%81%E9%87%8F%E5%95%8F%E9%A1%8C/","title":"以線性代數求解車流量問題"},{"content":"前言 前一陣子面試了一家博奕業，他的第一題是這樣的\n給一整數陣列，並把陣列中的0移到最後，其餘的數字保持原來的順序。 例如輸入陣列{0,0,0,1,2,3,4,5,6,7,8}， (你不知道index) 請寫個方法可輸出為{1,2,3,4,5,6,7,8,0,0,0}\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public static void main(String[] args) { List\u0026lt;Integer\u0026gt; numbList = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(0,0,0,1,2,3,4,5,6,7,8)); List\u0026lt;Integer\u0026gt; numbList2 = new ArrayList\u0026lt;\u0026gt;(); for(Integer num :numbList){ if(num == 0){ /** * TODO * 尝试完成把 List中的0移到最後 */ numbList.remove(num); numbList2.add(num); } } System.out.println(numbList); }   至於具體來說到底要怎麼寫不是我想討論的重點，而是這題藏在魔鬼裡的細節\nConcurrentModificationException 當你實際執行後就會出現這個錯誤ConcurrentModificationException\n他說錯誤出現在第12行，但實際上錯誤並不是出現在第12行，應該是在第18行的位置，我們可以開Debugger，看起來會更明顯一點\n他回報了這個錯誤，那這個錯誤具體而言是什麼呢？\nConcurrentModificationException這個錯誤會發生在對遍歷的集合類進行刪除、增加時會出現這個併發修改錯誤，而會拋出這個錯誤的原因是因為\n集合類中的modCount跟expectModCount不相等而拋出的，由於本人才疏學淺，目前理解的概念像是這樣\n因為Java常見的集合類本身並不是執行緒安全(Thread Safe)的，因此會有兩個int，expectModCount像是去紀錄理論的修改次數，modCount像是去記錄實際修改的次數，當兩邊的數字Match不起來，就會拋出錯誤，提醒你因為執行緒不安全的關係導致你執行的結果會與預期有落差，這樣的行為也稱之為Fast-Fail，\n(圖片來自於網路)\n因為在remove這邊有modCount++的行為，導致兩邊值不同，因而拋出錯誤\n​\n參考連結 https://cloud.tencent.com/developer/article/1896820\n","date":"2023-07-23T14:59:22+08:00","image":"https://i.imgur.com/oHOBik5.png","permalink":"https://hoxtonhsu.com/p/%E5%B0%8D%E9%81%8D%E6%AD%B7%E4%B8%AD%E7%9A%84%E9%9B%86%E5%90%88%E9%A1%9E%E4%BF%AE%E6%94%B9%E6%9C%83%E6%9C%89%E4%BB%80%E9%BA%BC%E6%A8%A3%E7%9A%84%E5%95%8F%E9%A1%8C%E5%91%A2/","title":"對遍歷中的集合類修改，會有什麼樣的問題呢"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272  # Licensed to the Apache Software Foundation (ASF) under one# or more contributor license agreements. See the NOTICE file# distributed with this work for additional information# regarding copyright ownership. The ASF licenses this file# to you under the Apache License, Version 2.0 (the# \u0026#34;License\u0026#34;); you may not use this file except in compliance# with the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing,# software distributed under the License is distributed on an# \u0026#34;AS IS\u0026#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY# KIND, either express or implied. See the License for the# specific language governing permissions and limitations# under the License.## Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.## WARNING: This configuration is for local development. Do not use it in a production deployment.## This configuration supports basic configuration using environment variables or an .env file# The following variables are supported:## AIRFLOW_IMAGE_NAME - Docker image name used to run Airflow.# Default: apache/airflow:2.3.0# AIRFLOW_UID - User ID in Airflow containers# Default: 50000# Those configurations are useful mostly in case of standalone testing/running Airflow in test/try-out mode## _AIRFLOW_WWW_USER_USERNAME - Username for the administrator account (if requested).# Default: airflow# _AIRFLOW_WWW_USER_PASSWORD - Password for the administrator account (if requested).# Default: airflow# _PIP_ADDITIONAL_REQUIREMENTS - Additional PIP requirements to add when starting all containers.# Default: \u0026#39;\u0026#39;## Feel free to modify this file to suit your needs.---version:\u0026#39;3\u0026#39;x-airflow-common:\u0026amp;airflow-common# In order to add custom dependencies or upgrade provider packages you can use your extended image.# Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml# and uncomment the \u0026#34;build\u0026#34; line below, Then run `docker compose build` to build the images.image:${AIRFLOW_IMAGE_NAME:-apache/airflow:2.3.0}# build: .environment:\u0026amp;airflow-common-envAIRFLOW__CORE__EXECUTOR:CeleryExecutorAIRFLOW__DATABASE__SQL_ALCHEMY_CONN:postgresql+psycopg2://airflow:airflow@postgres/airflow# For backward compatibility, with Airflow \u0026lt;2.3AIRFLOW__CORE__SQL_ALCHEMY_CONN:postgresql+psycopg2://airflow:airflow@postgres/airflowAIRFLOW__CELERY__RESULT_BACKEND:db+postgresql://airflow:airflow@postgres/airflowAIRFLOW__CELERY__BROKER_URL:redis://:@redis:6379/0AIRFLOW__CORE__FERNET_KEY:\u0026#39;\u0026#39;AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION:\u0026#39;true\u0026#39;AIRFLOW__CORE__LOAD_EXAMPLES:\u0026#39;true\u0026#39;AIRFLOW__API__AUTH_BACKENDS:\u0026#39;airflow.api.auth.backend.basic_auth\u0026#39;_PIP_ADDITIONAL_REQUIREMENTS:${_PIP_ADDITIONAL_REQUIREMENTS:-}volumes:- ./dags:/opt/airflow/dags- ./logs:/opt/airflow/logs- ./plugins:/opt/airflow/pluginsuser:\u0026#34;${AIRFLOW_UID:-50000}:0\u0026#34;depends_on:\u0026amp;airflow-common-depends-onredis:condition:service_healthypostgres:condition:service_healthyservices:postgres:image:postgres:13environment:POSTGRES_USER:airflowPOSTGRES_PASSWORD:airflowPOSTGRES_DB:airflowvolumes:- postgres-db-volume:/var/lib/postgresql/datahealthcheck:test:[\u0026#34;CMD\u0026#34;,\u0026#34;pg_isready\u0026#34;,\u0026#34;-U\u0026#34;,\u0026#34;airflow\u0026#34;]interval:5sretries:5restart:alwaysredis:image:redis:latestexpose:- 6379healthcheck:test:[\u0026#34;CMD\u0026#34;,\u0026#34;redis-cli\u0026#34;,\u0026#34;ping\u0026#34;]interval:5stimeout:30sretries:50restart:alwaysairflow-webserver:\u0026lt;\u0026lt;:*airflow-commoncommand:webserverports:- 8080:8080healthcheck:test:[\u0026#34;CMD\u0026#34;,\u0026#34;curl\u0026#34;,\u0026#34;--fail\u0026#34;,\u0026#34;http://localhost:8080/health\u0026#34;]interval:10stimeout:10sretries:5restart:alwaysdepends_on:\u0026lt;\u0026lt;:*airflow-common-depends-onairflow-init:condition:service_completed_successfullyairflow-scheduler:\u0026lt;\u0026lt;:*airflow-commoncommand:schedulerhealthcheck:test:[\u0026#34;CMD-SHELL\u0026#34;,\u0026#39;airflow jobs check --job-type SchedulerJob --hostname \u0026#34;$${HOSTNAME}\u0026#34;\u0026#39;]interval:10stimeout:10sretries:5restart:alwaysdepends_on:\u0026lt;\u0026lt;:*airflow-common-depends-onairflow-init:condition:service_completed_successfullyairflow-worker:\u0026lt;\u0026lt;:*airflow-commoncommand:celery workerhealthcheck:test:- \u0026#34;CMD-SHELL\u0026#34;- \u0026#39;celery --app airflow.executors.celery_executor.app inspect ping -d \u0026#34;celery@$${HOSTNAME}\u0026#34;\u0026#39;interval:10stimeout:10sretries:5environment:\u0026lt;\u0026lt;:*airflow-common-env# Required to handle warm shutdown of the celery workers properly# See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagationDUMB_INIT_SETSID:\u0026#34;0\u0026#34;restart:alwaysdepends_on:\u0026lt;\u0026lt;:*airflow-common-depends-onairflow-init:condition:service_completed_successfullyairflow-triggerer:\u0026lt;\u0026lt;:*airflow-commoncommand:triggererhealthcheck:test:[\u0026#34;CMD-SHELL\u0026#34;,\u0026#39;airflow jobs check --job-type TriggererJob --hostname \u0026#34;$${HOSTNAME}\u0026#34;\u0026#39;]interval:10stimeout:10sretries:5restart:alwaysdepends_on:\u0026lt;\u0026lt;:*airflow-common-depends-onairflow-init:condition:service_completed_successfullyairflow-init:\u0026lt;\u0026lt;:*airflow-commonentrypoint:/bin/bash# yamllint disable rule:line-lengthcommand:- -c- |function ver() { printf \u0026#34;%04d%04d%04d%04d\u0026#34; $${1//./ } } airflow_version=$$(gosu airflow airflow version) airflow_version_comparable=$$(ver $${airflow_version}) min_airflow_version=2.2.0 min_airflow_version_comparable=$$(ver $${min_airflow_version}) if (( airflow_version_comparable \u0026lt; min_airflow_version_comparable )); then echo echo -e \u0026#34;\\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\\e[0m\u0026#34; echo \u0026#34;The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!\u0026#34; echo exit 1 fi if [[ -z \u0026#34;${AIRFLOW_UID}\u0026#34; ]]; then echo echo -e \u0026#34;\\033[1;33mWARNING!!!: AIRFLOW_UID not set!\\e[0m\u0026#34; echo \u0026#34;If you are on Linux, you SHOULD follow the instructions below to set \u0026#34; echo \u0026#34;AIRFLOW_UID environment variable, otherwise files will be owned by root.\u0026#34; echo \u0026#34;For other operating systems you can get rid of the warning with manually created .env file:\u0026#34; echo \u0026#34; See: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user\u0026#34; echo fi one_meg=1048576 mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg)) cpus_available=$$(grep -cE \u0026#39;cpu[0-9]+\u0026#39; /proc/stat) disk_available=$$(df / | tail -1 | awk \u0026#39;{print $$4}\u0026#39;) warning_resources=\u0026#34;false\u0026#34; if (( mem_available \u0026lt; 4000 )) ; then echo echo -e \u0026#34;\\033[1;33mWARNING!!!: Not enough memory available for Docker.\\e[0m\u0026#34; echo \u0026#34;At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))\u0026#34; echo warning_resources=\u0026#34;true\u0026#34; fi if (( cpus_available \u0026lt; 2 )); then echo echo -e \u0026#34;\\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\\e[0m\u0026#34; echo \u0026#34;At least 2 CPUs recommended. You have $${cpus_available}\u0026#34; echo warning_resources=\u0026#34;true\u0026#34; fi if (( disk_available \u0026lt; one_meg * 10 )); then echo echo -e \u0026#34;\\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\\e[0m\u0026#34; echo \u0026#34;At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))\u0026#34; echo warning_resources=\u0026#34;true\u0026#34; fi if [[ $${warning_resources} == \u0026#34;true\u0026#34; ]]; then echo echo -e \u0026#34;\\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\\e[0m\u0026#34; echo \u0026#34;Please follow the instructions to increase amount of resources available:\u0026#34; echo \u0026#34; https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#before-you-begin\u0026#34; echo fi mkdir -p /sources/logs /sources/dags /sources/plugins chown -R \u0026#34;${AIRFLOW_UID}:0\u0026#34; /sources/{logs,dags,plugins} exec /entrypoint airflow version# yamllint enable rule:line-lengthenvironment:\u0026lt;\u0026lt;:*airflow-common-env_AIRFLOW_DB_UPGRADE:\u0026#39;true\u0026#39;_AIRFLOW_WWW_USER_CREATE:\u0026#39;true\u0026#39;_AIRFLOW_WWW_USER_USERNAME:${_AIRFLOW_WWW_USER_USERNAME:-airflow}_AIRFLOW_WWW_USER_PASSWORD:${_AIRFLOW_WWW_USER_PASSWORD:-airflow}user:\u0026#34;0:0\u0026#34;volumes:- .:/sourcesairflow-cli:\u0026lt;\u0026lt;:*airflow-commonprofiles:- debugenvironment:\u0026lt;\u0026lt;:*airflow-common-envCONNECTION_CHECK_MAX_COUNT:\u0026#34;0\u0026#34;# Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252command:- bash- -c- airflowflower:\u0026lt;\u0026lt;:*airflow-commoncommand:celery flowerports:- 5555:5555healthcheck:test:[\u0026#34;CMD\u0026#34;,\u0026#34;curl\u0026#34;,\u0026#34;--fail\u0026#34;,\u0026#34;http://localhost:5555/\u0026#34;]interval:10stimeout:10sretries:5restart:alwaysdepends_on:\u0026lt;\u0026lt;:*airflow-common-depends-onairflow-init:condition:service_completed_successfullyvolumes:postgres-db-volume:  ","date":"2023-07-22T15:27:16+08:00","image":"https://i.imgur.com/ib3Y4zY.png","permalink":"https://hoxtonhsu.com/p/airflow%E7%9A%84dockerfile/","title":"Airflow的Dockerfile"},{"content":" Raycaset PicGo Mission Control Plus iShot iBar  ","date":"2023-07-17T14:41:10+08:00","image":"https://i.imgur.com/AfmJKUP.jpg","permalink":"https://hoxtonhsu.com/p/%E5%AF%A6%E7%94%A8%E7%9A%84macbook%E6%87%89%E7%94%A8%E7%A8%8B%E5%BC%8F/","title":"實用的Macbook應用程式"},{"content":"參考網址：https://www.bilibili.com/video/BV1ys411472E?p=1\u0026amp;vd_source=422eafa6570139128e44a83238959fa0\n","date":"2023-07-16T14:58:17+08:00","image":"https://i.imgur.com/vd5T3J2.png","permalink":"https://hoxtonhsu.com/p/%E4%BB%A5%E5%B9%BE%E4%BD%95%E6%84%8F%E7%BE%A9%E4%BE%86%E7%90%86%E8%A7%A3%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8/","title":"以幾何意義來理解線性代數"},{"content":"前言 在一開始接觸Javasript，想要試圖做出一個小專案的菜雞，一定都會遇到這個令人無語的問題\n1 2  var date=new Date() date.getMonth() // 0   當你是一月時，這會回傳0，當你是12月時，你會回傳11，Why? Javascript Why?\n抱著無聊的好奇心，我決定來去認真的查一下這個問題\n萬惡之源 大家都會說Java跟Javascript的關係猶如臘腸與臘腸狗，除了名字一樣，兩者並沒有任何差距。但知道兩者發展歷史的人應該會知道，這兩個程式語言在歷史的某段時間確實是有一點關係的，而這也是為什麼Javascript的getMonth會是-1的起因之一。\n大家都知道Javascript是Brendan Eich 用了十天就創造出來的語言，想當然而，這十天當然不是從無到有，當然是秉持著不自己造輪子，能抄就抄，能用就用的態度，在這種十天老闆就要看到成果的情形下，最現實的結果當然就是\n「隨便從什麼語言裡面抓一個Date出來用」\n而這個被選中的語言就是Java了\nhttps://twitter.com/BrendanEich/status/481939099138654209\nhttps://twitter.com/BrendanEich/status/771006397886533632\n而他引進的版本就是JDK1.0的Date.Util，在那時候\n1 2  Date date = new Date(); System.out.println(\u0026#34;date.getMonth() = \u0026#34; + date.getMonth());   這東西確實就是會印出當前月份-1的結果（其實到現在Java17依然也是，為了要示範我只找得到1.8版本的JDK了）\n隨著Java版本的更迭，已經用新的Calendar來平移getMonth()的方法了，但師承Java的Javascript仍然保留著Java最原汁原味的那一份歷史，\n後來Brendan Eich也補充到，從Java import Date的這件事情並不是出自他的手，而是來自於網景一名員工的小巧思\nhttps://twitter.com/BrendanEich/status/771006208949891072\n當之後有人在問為什麼Javascript的Ｍonth預設都會-1時，你就可以和對方分享這個小故事，並告訴對方寫程式要小心一點，難免你現在寫出來的Bug，在20年後變成大家習以為常的功能了\u0026gt;/////\u0026lt;\n","date":"2023-07-12T17:51:52+08:00","image":"https://i.imgur.com/nFBYwdj.png","permalink":"https://hoxtonhsu.com/p/%E7%82%BA%E4%BB%80%E9%BA%BCjavascript%E7%9A%84getmonth%E6%9C%83%E6%98%AF-1%E7%9A%84/","title":"為什麼Javascript的getMonth會是-1的"},{"content":"前一陣子在寫DiscordBot的時候，曾經在教學中看過這種寫法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class GymBotConfiguration { @Bean public \u0026lt;T extends Event\u0026gt;GatewayDiscordClient gatewayDiscordClient(final List\u0026lt;EventListener\u0026lt;T\u0026gt;\u0026gt; eventListeners){ final GatewayDiscordClient client = DiscordClientBuilder.create(token) .build() .login() .block(); for (EventListener\u0026lt;T\u0026gt; listener : eventListeners) { client.on(listener.getEventType()) .flatMap(listener::execute) .onErrorResume(listener::handleError) .subscribe(); } return client; } }   對於其中的寫法感到非常困惑，不知道為什麼回傳值前還會有泛型符號，直到最近在研究一些OpenSource的框架時，才又更了解這件事情。\n如何宣告泛型 在講這件事情之前，要先有個基礎知識，就是關於Java是如何宣告一個泛型Class的，其實就是在Class後面加上\u0026lt;T\u0026gt;就可以了\n1 2 3  public class Link\u0026lt;E\u0026gt; { }   如此一來，就可以在其他地方創建一個泛型的Link類\n1  Link link=new Link\u0026lt;Integer\u0026gt;;   現在我們在這個Link類裡新增一個方法\n1 2 3 4 5 6 7  public class Link\u0026lt;E\u0026gt; { public List\u0026lt;E\u0026gt; addToList(E t){ List\u0026lt;E\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(t); return list; } }   這個方法會把傳進來的值，包裝成一個ArrayList並回傳出去，而它參數的型別則是與Link的泛型一致，比如說\n1 2 3 4  public static main(String[] arg){ Link link=new Link\u0026lt;String\u0026gt;; List\u0026lt;String\u0026gt; list=link.add(\u0026#34;早安\u0026#34;); }   也就是說addToList這個方法的型別和Link的泛型型別是綁定在一起的。\n何謂回傳型別前的泛型 承上，因為方法的參數型別與類的泛型型別基本上綁定在一起，如果我宣告了一個Link\u0026lt;Integer\u0026gt;，我的addToList就只能吃Integer的參數，那為了要解決這種問題，就有了在回傳型別前的泛型的寫法，釋例如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Link\u0026lt;E\u0026gt; { public List\u0026lt;E\u0026gt; addToList(E t){ List\u0026lt;E\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(t); return list; } public\u0026lt;E\u0026gt;List\u0026lt;E\u0026gt; addToList2(E t){ List\u0026lt;E\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(t); return list; } }   可以看到addToList2這個方法的回傳值List\u0026lt;E\u0026gt;前，我加了一個\u0026lt;E\u0026gt;，先別管這個到底能做什麼，我們現在先使用這個方法看看\n這時候你發現了，addToList2能吃的參數變成Object類了，當我們輸入一個String\n輸入一個Double\n也可以輸入一個自定義的類\n可以感受到addToList跟addToList2的差異了嗎？沒錯，addToList2的泛型不受Link的影響，可以自己有自己的泛型\n應用 這樣的用法不只可以拿來用在泛型類裡的方法，也可以用在一個非泛型類，比如說\n1 2 3 4 5 6 7  public class Student { public List\u0026lt;Student\u0026gt; addPeopleList(Student student){ ArrayList\u0026lt;Student\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(student); return list; } }   今天我們希望這個addPeopleList的方法可以吃任何型別的參數，我們如果這樣寫是會報錯的\n原因就在於我們並沒有一個地方告訴編譯器，什麼是T，因為我們的Student類並不是一個泛型類，但實務上，我們又不太可能去修改原有的類，避免破壞掉一些東西，所以我們修改addPeopleList，讓它變成這樣\n如此一來，addPeopleList就可以吃任何型別的參數了，以上就是所謂的泛型方法約束。\n","date":"2023-07-11T00:03:03+08:00","image":"https://i.imgur.com/Y9pLlYY.png","permalink":"https://hoxtonhsu.com/p/java%E4%B8%AD%E5%9B%9E%E5%82%B3%E5%80%BC%E5%89%8D%E7%9A%84%E6%B3%9B%E5%9E%8B%E6%A8%99%E8%AD%98%E7%AC%A6%E6%98%AF%E4%BB%80%E9%BA%BC%E6%84%8F%E6%80%9D%E5%91%A2/","title":"Java中回傳值前的泛型標識符是什麼意思呢"},{"content":"最近換了一份新工作，發現我一直以來平淡無情的Maven原來也是有很多細節的（我一直以為就只是一個拿來自動下載Jar的無情機器而已），其實Maven的pom.xml的名稱其實就已經隱含了它的功能\nProject Object Model（專案物件模型）\n望文生義其實也可以感受到它就是用來管理專案、或專案與專案之間關係的一個檔案，這篇文章的主題是我想要了解Maven Module管理的部分\nMaven項目結構 超級POM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603  pom作为项目对象模型。通过xml表示maven项目，使用pom.xml来实现。 主要描述了项目：包括配置文件；开发者需要遵循的规则，缺陷管理系统，组织和licenses，项目的url，项目的依赖性，以及其他所有的项目相关因素。 \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; \u0026lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。--\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;!--被继承的父项目的构件标识符--\u0026gt; \u0026lt;artifactId/\u0026gt; \u0026lt;!--被继承的父项目的全球唯一标识符--\u0026gt; \u0026lt;groupId/\u0026gt; \u0026lt;!--被继承的父项目的版本--\u0026gt; \u0026lt;version/\u0026gt; \u0026lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。--\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。--\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app--\u0026gt; \u0026lt;groupId\u0026gt;asia.banseon\u0026lt;/groupId\u0026gt; \u0026lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。--\u0026gt; \u0026lt;artifactId\u0026gt;banseon-maven2\u0026lt;/artifactId\u0026gt; \u0026lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型--\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号--\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;!--项目的名称, Maven产生的文档用--\u0026gt; \u0026lt;name\u0026gt;banseon-maven\u0026lt;/name\u0026gt; \u0026lt;!--项目主页的URL, Maven产生的文档用--\u0026gt; \u0026lt;url\u0026gt;http://www.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。--\u0026gt; \u0026lt;description\u0026gt;A maven project to study maven.\u0026lt;/description\u0026gt; \u0026lt;!--描述了这个项目构建环境中的前提条件。--\u0026gt; \u0026lt;prerequisites\u0026gt; \u0026lt;!--构建该项目或使用该插件所需要的Maven的最低版本--\u0026gt; \u0026lt;maven/\u0026gt; \u0026lt;/prerequisites\u0026gt; \u0026lt;!--项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira--\u0026gt; \u0026lt;issueManagement\u0026gt; \u0026lt;!--问题管理系统（例如jira）的名字，--\u0026gt; \u0026lt;system\u0026gt;jira\u0026lt;/system\u0026gt; \u0026lt;!--该项目使用的问题管理系统的URL--\u0026gt; \u0026lt;url\u0026gt;http://jira.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;/issueManagement\u0026gt; \u0026lt;!--项目持续集成信息--\u0026gt; \u0026lt;ciManagement\u0026gt; \u0026lt;!--持续集成系统的名字，例如continuum--\u0026gt; \u0026lt;system/\u0026gt; \u0026lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。--\u0026gt; \u0026lt;url/\u0026gt; \u0026lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告）--\u0026gt; \u0026lt;notifiers\u0026gt; \u0026lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者--\u0026gt; \u0026lt;notifier\u0026gt; \u0026lt;!--传送通知的途径--\u0026gt; \u0026lt;type/\u0026gt; \u0026lt;!--发生错误时是否通知--\u0026gt; \u0026lt;sendOnError/\u0026gt; \u0026lt;!--构建失败时是否通知--\u0026gt; \u0026lt;sendOnFailure/\u0026gt; \u0026lt;!--构建成功时是否通知--\u0026gt; \u0026lt;sendOnSuccess/\u0026gt; \u0026lt;!--发生警告时是否通知--\u0026gt; \u0026lt;sendOnWarning/\u0026gt; \u0026lt;!--不赞成使用。通知发送到哪里--\u0026gt; \u0026lt;address/\u0026gt; \u0026lt;!--扩展配置项--\u0026gt; \u0026lt;configuration/\u0026gt; \u0026lt;/notifier\u0026gt; \u0026lt;/notifiers\u0026gt; \u0026lt;/ciManagement\u0026gt; \u0026lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。--\u0026gt; \u0026lt;inceptionYear/\u0026gt; \u0026lt;!--项目相关邮件列表信息--\u0026gt; \u0026lt;mailingLists\u0026gt; \u0026lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。--\u0026gt; \u0026lt;mailingList\u0026gt; \u0026lt;!--邮件的名称--\u0026gt; \u0026lt;name\u0026gt;Demo\u0026lt;/name\u0026gt; \u0026lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--\u0026gt; \u0026lt;post\u0026gt;banseon@126.com\u0026lt;/post\u0026gt; \u0026lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--\u0026gt; \u0026lt;subscribe\u0026gt;banseon@126.com\u0026lt;/subscribe\u0026gt; \u0026lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--\u0026gt; \u0026lt;unsubscribe\u0026gt;banseon@126.com\u0026lt;/unsubscribe\u0026gt; \u0026lt;!--你可以浏览邮件信息的URL--\u0026gt; \u0026lt;archive\u0026gt;http:/hi.baidu.com/banseon/demo/dev/\u0026lt;/archive\u0026gt; \u0026lt;/mailingList\u0026gt; \u0026lt;/mailingLists\u0026gt; \u0026lt;!--项目开发者列表--\u0026gt; \u0026lt;developers\u0026gt; \u0026lt;!--某个项目开发者的信息--\u0026gt; \u0026lt;developer\u0026gt; \u0026lt;!--SCM里项目开发者的唯一标识符--\u0026gt; \u0026lt;id\u0026gt;HELLO WORLD\u0026lt;/id\u0026gt; \u0026lt;!--项目开发者的全名--\u0026gt; \u0026lt;name\u0026gt;banseon\u0026lt;/name\u0026gt; \u0026lt;!--项目开发者的email--\u0026gt; \u0026lt;email\u0026gt;banseon@126.com\u0026lt;/email\u0026gt; \u0026lt;!--项目开发者的主页的URL--\u0026gt; \u0026lt;url/\u0026gt; \u0026lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色--\u0026gt; \u0026lt;roles\u0026gt; \u0026lt;role\u0026gt;Project Manager\u0026lt;/role\u0026gt; \u0026lt;role\u0026gt;Architect\u0026lt;/role\u0026gt; \u0026lt;/roles\u0026gt; \u0026lt;!--项目开发者所属组织--\u0026gt; \u0026lt;organization\u0026gt;demo\u0026lt;/organization\u0026gt; \u0026lt;!--项目开发者所属组织的URL--\u0026gt; \u0026lt;organizationUrl\u0026gt;http://hi.baidu.com/banseon\u0026lt;/organizationUrl\u0026gt; \u0026lt;!--项目开发者属性，如即时消息如何处理等--\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;dept\u0026gt;No\u0026lt;/dept\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!--项目开发者所在时区， -11到12范围内的整数。--\u0026gt; \u0026lt;timezone\u0026gt;-5\u0026lt;/timezone\u0026gt; \u0026lt;/developer\u0026gt; \u0026lt;/developers\u0026gt; \u0026lt;!--项目的其他贡献者列表--\u0026gt; \u0026lt;contributors\u0026gt; \u0026lt;!--项目的其他贡献者。参见developers/developer元素--\u0026gt; \u0026lt;contributor\u0026gt; \u0026lt;name/\u0026gt;\u0026lt;email/\u0026gt;\u0026lt;url/\u0026gt;\u0026lt;organization/\u0026gt;\u0026lt;organizationUrl/\u0026gt;\u0026lt;roles/\u0026gt;\u0026lt;timezone/\u0026gt;\u0026lt;properties/\u0026gt; \u0026lt;/contributor\u0026gt; \u0026lt;/contributors\u0026gt; \u0026lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。--\u0026gt; \u0026lt;licenses\u0026gt; \u0026lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。--\u0026gt; \u0026lt;license\u0026gt; \u0026lt;!--license用于法律上的名称--\u0026gt; \u0026lt;name\u0026gt;Apache 2\u0026lt;/name\u0026gt; \u0026lt;!--官方的license正文页面的URL--\u0026gt; \u0026lt;url\u0026gt;http://www.baidu.com/banseon/LICENSE-2.0.txt\u0026lt;/url\u0026gt; \u0026lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖--\u0026gt; \u0026lt;distribution\u0026gt;repo\u0026lt;/distribution\u0026gt; \u0026lt;!--关于license的补充信息--\u0026gt; \u0026lt;comments\u0026gt;A business-friendly OSS license\u0026lt;/comments\u0026gt; \u0026lt;/license\u0026gt; \u0026lt;/licenses\u0026gt; \u0026lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。--\u0026gt; \u0026lt;scm\u0026gt; \u0026lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。--\u0026gt; \u0026lt;connection\u0026gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) \u0026lt;/connection\u0026gt; \u0026lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读--\u0026gt; \u0026lt;developerConnection\u0026gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk \u0026lt;/developerConnection\u0026gt; \u0026lt;!--当前代码的标签，在开发阶段默认为HEAD--\u0026gt; \u0026lt;tag/\u0026gt; \u0026lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。--\u0026gt; \u0026lt;url\u0026gt;http://svn.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;/scm\u0026gt; \u0026lt;!--描述项目所属组织的各种属性。Maven产生的文档用--\u0026gt; \u0026lt;organization\u0026gt; \u0026lt;!--组织的全名--\u0026gt; \u0026lt;name\u0026gt;demo\u0026lt;/name\u0026gt; \u0026lt;!--组织主页的URL--\u0026gt; \u0026lt;url\u0026gt;http://www.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;/organization\u0026gt; \u0026lt;!--构建项目需要的信息--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--\u0026gt; \u0026lt;sourceDirectory/\u0026gt; \u0026lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。--\u0026gt; \u0026lt;scriptSourceDirectory/\u0026gt; \u0026lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--\u0026gt; \u0026lt;testSourceDirectory/\u0026gt; \u0026lt;!--被编译过的应用程序class文件存放的目录。--\u0026gt; \u0026lt;outputDirectory/\u0026gt; \u0026lt;!--被编译过的测试class文件存放的目录。--\u0026gt; \u0026lt;testOutputDirectory/\u0026gt; \u0026lt;!--使用来自该项目的一系列构建扩展--\u0026gt; \u0026lt;extensions\u0026gt; \u0026lt;!--描述使用到的构建扩展。--\u0026gt; \u0026lt;extension\u0026gt; \u0026lt;!--构建扩展的groupId--\u0026gt; \u0026lt;groupId/\u0026gt; \u0026lt;!--构建扩展的artifactId--\u0026gt; \u0026lt;artifactId/\u0026gt; \u0026lt;!--构建扩展的版本--\u0026gt; \u0026lt;version/\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/extensions\u0026gt; \u0026lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--\u0026gt; \u0026lt;defaultGoal/\u0026gt; \u0026lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;!--这个元素描述了项目相关或测试相关的所有资源路径--\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如${project.build.outputDirectory}）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--\u0026gt; \u0026lt;targetPath/\u0026gt; \u0026lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--\u0026gt; \u0026lt;filtering/\u0026gt; \u0026lt;!--描述存放资源的目录，该路径相对POM路径--\u0026gt; \u0026lt;directory/\u0026gt; \u0026lt;!--包含的模式列表，例如**/*.xml.--\u0026gt; \u0026lt;includes/\u0026gt; \u0026lt;!--排除的模式列表，例如**/*.xml--\u0026gt; \u0026lt;excludes/\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--\u0026gt; \u0026lt;testResources\u0026gt; \u0026lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--\u0026gt; \u0026lt;testResource\u0026gt; \u0026lt;targetPath/\u0026gt;\u0026lt;filtering/\u0026gt;\u0026lt;directory/\u0026gt;\u0026lt;includes/\u0026gt;\u0026lt;excludes/\u0026gt; \u0026lt;/testResource\u0026gt; \u0026lt;/testResources\u0026gt; \u0026lt;!--构建产生的所有文件存放的目录--\u0026gt; \u0026lt;directory/\u0026gt; \u0026lt;!--产生的构件的文件名，默认值是${artifactId}-${version}。--\u0026gt; \u0026lt;finalName/\u0026gt; \u0026lt;!--当filtering开关打开时，使用到的过滤器属性文件列表--\u0026gt; \u0026lt;filters/\u0026gt; \u0026lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--\u0026gt; \u0026lt;pluginManagement\u0026gt; \u0026lt;!--使用的插件列表 。--\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--plugin元素包含描述插件所需要的信息。--\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;!--插件在仓库里的group ID--\u0026gt; \u0026lt;groupId/\u0026gt; \u0026lt;!--插件在仓库里的artifact ID--\u0026gt; \u0026lt;artifactId/\u0026gt; \u0026lt;!--被使用的插件的版本（或版本范围）--\u0026gt; \u0026lt;version/\u0026gt; \u0026lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。--\u0026gt; \u0026lt;extensions/\u0026gt; \u0026lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。--\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;!--execution元素包含了插件执行需要的信息--\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标--\u0026gt; \u0026lt;id/\u0026gt; \u0026lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段--\u0026gt; \u0026lt;phase/\u0026gt; \u0026lt;!--配置的执行目标--\u0026gt; \u0026lt;goals/\u0026gt; \u0026lt;!--配置是否被传播到子POM--\u0026gt; \u0026lt;inherited/\u0026gt; \u0026lt;!--作为DOM对象的配置--\u0026gt; \u0026lt;configuration/\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;!--项目引入插件所需要的额外依赖--\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素--\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!--任何配置是否被传播到子项目--\u0026gt; \u0026lt;inherited/\u0026gt; \u0026lt;!--作为DOM对象的配置--\u0026gt; \u0026lt;configuration/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/pluginManagement\u0026gt; \u0026lt;!--使用的插件列表--\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--参见build/pluginManagement/plugins/plugin元素--\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId/\u0026gt;\u0026lt;artifactId/\u0026gt;\u0026lt;version/\u0026gt;\u0026lt;extensions/\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id/\u0026gt;\u0026lt;phase/\u0026gt;\u0026lt;goals/\u0026gt;\u0026lt;inherited/\u0026gt;\u0026lt;configuration/\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素--\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;goals/\u0026gt;\u0026lt;inherited/\u0026gt;\u0026lt;configuration/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;!--在列的项目构建profile，如果被激活，会修改构建处理--\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;!--根据环境参数或命令行参数激活某个构建处理--\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。--\u0026gt; \u0026lt;id/\u0026gt; \u0026lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。--\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;!--profile默认是否激活的标志--\u0026gt; \u0026lt;activeByDefault/\u0026gt; \u0026lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--\u0026gt; \u0026lt;jdk/\u0026gt; \u0026lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--\u0026gt; \u0026lt;os\u0026gt; \u0026lt;!--激活profile的操作系统的名字--\u0026gt; \u0026lt;name\u0026gt;Windows XP\u0026lt;/name\u0026gt; \u0026lt;!--激活profile的操作系统所属家族(如 \u0026#39;windows\u0026#39;)--\u0026gt; \u0026lt;family\u0026gt;Windows\u0026lt;/family\u0026gt; \u0026lt;!--激活profile的操作系统体系结构 --\u0026gt; \u0026lt;arch\u0026gt;x86\u0026lt;/arch\u0026gt; \u0026lt;!--激活profile的操作系统版本--\u0026gt; \u0026lt;version\u0026gt;5.1.2600\u0026lt;/version\u0026gt; \u0026lt;/os\u0026gt; \u0026lt;!--如果Maven检测到某一个属性（其值可以在POM中通过${名称}引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;!--激活profile的属性的名称--\u0026gt; \u0026lt;name\u0026gt;mavenVersion\u0026lt;/name\u0026gt; \u0026lt;!--激活profile的属性的值--\u0026gt; \u0026lt;value\u0026gt;2.0.3\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--\u0026gt; \u0026lt;file\u0026gt; \u0026lt;!--如果指定的文件存在，则激活profile。--\u0026gt; \u0026lt;exists\u0026gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/\u0026lt;/exists\u0026gt; \u0026lt;!--如果指定的文件不存在，则激活profile。--\u0026gt; \u0026lt;missing\u0026gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/\u0026lt;/missing\u0026gt; \u0026lt;/file\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;!--构建项目所需要的信息。参见build元素--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;defaultGoal/\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;targetPath/\u0026gt;\u0026lt;filtering/\u0026gt;\u0026lt;directory/\u0026gt;\u0026lt;includes/\u0026gt;\u0026lt;excludes/\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;testResources\u0026gt; \u0026lt;testResource\u0026gt; \u0026lt;targetPath/\u0026gt;\u0026lt;filtering/\u0026gt;\u0026lt;directory/\u0026gt;\u0026lt;includes/\u0026gt;\u0026lt;excludes/\u0026gt; \u0026lt;/testResource\u0026gt; \u0026lt;/testResources\u0026gt; \u0026lt;directory/\u0026gt;\u0026lt;finalName/\u0026gt;\u0026lt;filters/\u0026gt; \u0026lt;pluginManagement\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--参见build/pluginManagement/plugins/plugin元素--\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId/\u0026gt;\u0026lt;artifactId/\u0026gt;\u0026lt;version/\u0026gt;\u0026lt;extensions/\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id/\u0026gt;\u0026lt;phase/\u0026gt;\u0026lt;goals/\u0026gt;\u0026lt;inherited/\u0026gt;\u0026lt;configuration/\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素--\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;goals/\u0026gt;\u0026lt;inherited/\u0026gt;\u0026lt;configuration/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/pluginManagement\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--参见build/pluginManagement/plugins/plugin元素--\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId/\u0026gt;\u0026lt;artifactId/\u0026gt;\u0026lt;version/\u0026gt;\u0026lt;extensions/\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id/\u0026gt;\u0026lt;phase/\u0026gt;\u0026lt;goals/\u0026gt;\u0026lt;inherited/\u0026gt;\u0026lt;configuration/\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素--\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;goals/\u0026gt;\u0026lt;inherited/\u0026gt;\u0026lt;configuration/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--\u0026gt; \u0026lt;modules/\u0026gt; \u0026lt;!--发现依赖和扩展的远程仓库列表。--\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;!--参见repositories/repository元素--\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled/\u0026gt;\u0026lt;updatePolicy/\u0026gt;\u0026lt;checksumPolicy/\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled/\u0026gt;\u0026lt;updatePolicy/\u0026gt;\u0026lt;checksumPolicy/\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;id/\u0026gt;\u0026lt;name/\u0026gt;\u0026lt;url/\u0026gt;\u0026lt;layout/\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled/\u0026gt;\u0026lt;updatePolicy/\u0026gt;\u0026lt;checksumPolicy/\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled/\u0026gt;\u0026lt;updatePolicy/\u0026gt;\u0026lt;checksumPolicy/\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;id/\u0026gt;\u0026lt;name/\u0026gt;\u0026lt;url/\u0026gt;\u0026lt;layout/\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素--\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!--不赞成使用. 现在Maven忽略该元素.--\u0026gt; \u0026lt;reports/\u0026gt; \u0026lt;!--该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素--\u0026gt; \u0026lt;reporting\u0026gt; ...... \u0026lt;/reporting\u0026gt; \u0026lt;!--参见dependencyManagement元素--\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素--\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;!--参见distributionManagement元素--\u0026gt; \u0026lt;distributionManagement\u0026gt; ...... \u0026lt;/distributionManagement\u0026gt; \u0026lt;!--参见properties元素--\u0026gt; \u0026lt;properties/\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--\u0026gt; \u0026lt;modules/\u0026gt; \u0026lt;!--发现依赖和扩展的远程仓库列表。--\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;!--包含需要连接到远程仓库的信息--\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!--如何处理远程仓库里发布版本的下载--\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --\u0026gt; \u0026lt;enabled/\u0026gt; \u0026lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。--\u0026gt; \u0026lt;updatePolicy/\u0026gt; \u0026lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。--\u0026gt; \u0026lt;checksumPolicy/\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled/\u0026gt;\u0026lt;updatePolicy/\u0026gt;\u0026lt;checksumPolicy/\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库--\u0026gt; \u0026lt;id\u0026gt;banseon-repository-proxy\u0026lt;/id\u0026gt; \u0026lt;!--远程仓库名称--\u0026gt; \u0026lt;name\u0026gt;banseon-repository-proxy\u0026lt;/name\u0026gt; \u0026lt;!--远程仓库URL，按protocol://hostname/path形式--\u0026gt; \u0026lt;url\u0026gt;http://192.168.1.169:9999/repository/\u0026lt;/url\u0026gt; \u0026lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。--\u0026gt; \u0026lt;layout\u0026gt;default\u0026lt;/layout\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--\u0026gt; \u0026lt;pluginRepository\u0026gt; ...... \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;!--依赖的group ID--\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven\u0026lt;/groupId\u0026gt; \u0026lt;!--依赖的artifact ID--\u0026gt; \u0026lt;artifactId\u0026gt;maven-artifact\u0026lt;/artifactId\u0026gt; \u0026lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。--\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。--\u0026gt; \u0026lt;type\u0026gt;jar\u0026lt;/type\u0026gt; \u0026lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。--\u0026gt; \u0026lt;classifier\u0026gt;\u0026lt;/classifier\u0026gt; \u0026lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用--\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如${java.home}。--\u0026gt; \u0026lt;systemPath\u0026gt;\u0026lt;/systemPath\u0026gt; \u0026lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。--\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!--不赞成使用. 现在Maven忽略该元素.--\u0026gt; \u0026lt;reports\u0026gt;\u0026lt;/reports\u0026gt; \u0026lt;!--该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。--\u0026gt; \u0026lt;reporting\u0026gt; \u0026lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。--\u0026gt; \u0026lt;excludeDefaults/\u0026gt; \u0026lt;!--所有产生的报表存放到哪里。默认值是${project.build.directory}/site。--\u0026gt; \u0026lt;outputDirectory/\u0026gt; \u0026lt;!--使用的报表插件和他们的配置。--\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--plugin元素包含描述报表插件需要的信息--\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;!--报表插件在仓库里的group ID--\u0026gt; \u0026lt;groupId/\u0026gt; \u0026lt;!--报表插件在仓库里的artifact ID--\u0026gt; \u0026lt;artifactId/\u0026gt; \u0026lt;!--被使用的报表插件的版本（或版本范围）--\u0026gt; \u0026lt;version/\u0026gt; \u0026lt;!--任何配置是否被传播到子项目--\u0026gt; \u0026lt;inherited/\u0026gt; \u0026lt;!--报表插件的配置--\u0026gt; \u0026lt;configuration/\u0026gt; \u0026lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标--\u0026gt; \u0026lt;reportSets\u0026gt; \u0026lt;!--表示报表的一个集合，以及产生该集合的配置--\u0026gt; \u0026lt;reportSet\u0026gt; \u0026lt;!--报表集合的唯一标识符，POM继承时用到--\u0026gt; \u0026lt;id/\u0026gt; \u0026lt;!--产生报表集合时，被使用的报表的配置--\u0026gt; \u0026lt;configuration/\u0026gt; \u0026lt;!--配置是否被继承到子POMs--\u0026gt; \u0026lt;inherited/\u0026gt; \u0026lt;!--这个集合里使用到哪些报表--\u0026gt; \u0026lt;reports/\u0026gt; \u0026lt;/reportSet\u0026gt; \u0026lt;/reportSets\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/reporting\u0026gt; \u0026lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。--\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素--\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。--\u0026gt; \u0026lt;distributionManagement\u0026gt; \u0026lt;!--部署项目产生的构件到远程仓库需要的信息--\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素--\u0026gt; \u0026lt;uniqueVersion/\u0026gt; \u0026lt;id\u0026gt;banseon-maven2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;banseon maven2\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;file://${basedir}/target/deploy\u0026lt;/url\u0026gt; \u0026lt;layout/\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素--\u0026gt; \u0026lt;snapshotRepository\u0026gt; \u0026lt;uniqueVersion/\u0026gt; \u0026lt;id\u0026gt;banseon-maven2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Banseon-maven2 Snapshot Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot\u0026lt;/url\u0026gt; \u0026lt;layout/\u0026gt; \u0026lt;/snapshotRepository\u0026gt; \u0026lt;!--部署项目的网站需要的信息--\u0026gt; \u0026lt;site\u0026gt; \u0026lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置--\u0026gt; \u0026lt;id\u0026gt;banseon-site\u0026lt;/id\u0026gt; \u0026lt;!--部署位置的名称--\u0026gt; \u0026lt;name\u0026gt;business api website\u0026lt;/name\u0026gt; \u0026lt;!--部署位置的URL，按protocol://hostname/path形式--\u0026gt; \u0026lt;url\u0026gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web \u0026lt;/url\u0026gt; \u0026lt;/site\u0026gt; \u0026lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。--\u0026gt; \u0026lt;downloadUrl/\u0026gt; \u0026lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。--\u0026gt; \u0026lt;relocation\u0026gt; \u0026lt;!--构件新的group ID--\u0026gt; \u0026lt;groupId/\u0026gt; \u0026lt;!--构件新的artifact ID--\u0026gt; \u0026lt;artifactId/\u0026gt; \u0026lt;!--构件新的版本号--\u0026gt; \u0026lt;version/\u0026gt; \u0026lt;!--显示给用户的，关于移动的额外信息，例如原因。--\u0026gt; \u0026lt;message/\u0026gt; \u0026lt;/relocation\u0026gt; \u0026lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。--\u0026gt; \u0026lt;status/\u0026gt; \u0026lt;/distributionManagement\u0026gt; \u0026lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是\u0026lt;name\u0026gt;value\u0026lt;/name\u0026gt;。--\u0026gt; \u0026lt;properties/\u0026gt; \u0026lt;/project\u0026gt;   常用指令 顯示版本訊息  1  mvn -version    編譯Source Code  1  mvn compile   清除編譯完文件  1  mvn clean   打包成jar, war  1  mvn pakage   執行測試  1  mvn test   將打包的jar, war放到本地的repository,供其他項目使用  1  mvn install   查看啟用的profile  1  mvn help:active-profiles   Maven 命令參數 -D 傳入屬性參數 跳過單元測試 1  mvn pakage -Dmaven.test.skip=true   -P 使用指定的Profile配置 詳細請參考此影片\nhttps://www.bilibili.com/video/BV1Fz4y167p5?p=6\u0026amp;spm_id_from=pageDriver\u0026amp;vd_source=422eafa6570139128e44a83238959fa0\n在POM裡面定義了這些東西\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;!--不同环境Profile的唯一id--\u0026gt; \u0026lt;id\u0026gt;dev\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;!--profiles.active是自定义的字段（名字随便起），自定义字段可以有多个--\u0026gt; \u0026lt;profiles.active\u0026gt;dev\u0026lt;/profiles.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;prod\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profiles.active\u0026gt;prod\u0026lt;/profiles.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;test\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profiles.active\u0026gt;test\u0026lt;/profiles.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt;   1 2 3 4 5 6 7 8 9 10 11  server.port=8080 spring.h2.console.enabled=true spring.h2.console.path=/h2 spring.sql.init.mode=always spring.datasource.url=jdbc:h2:~/dev;AUTO_SERVER=true spring.datasource.driver-class-name=org.h2.Driver spring.datasource.username=sa spring.datasource.password=sa spring.jpa.database-platform=org.hibernate.dialect.H2Dialect spring.jpa.hibernate.ddl-auto=update   在編譯project時\n使用\n1  mvn clean package -Pdev   則可使用dev環境的properties來打包專案\n不需要再手動在application.properties中修改\n配置MultiModule ☆☆☆☆☆ 可參考至此Repository\nhttps://github.com/Hoxton019030/SpringBoot-MultiModule-MVC-Structure/tree/main\n在原有的專案中新增Module\n根目錄的POM檔就會有相應的Module引入\n1 2 3 4 5 6 7  ... \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;service\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;dao\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;controller\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; ...   而子模塊的POM檔會紀錄副模塊的資訊\n1 2 3 4 5 6 7 8  ... \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;Maven_MultiModulePractice\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; ...   如果不特別設置的話，Parent的dependency會被child-module的project給繼承使用，所以例如Lombok這種東西就可以配置在parent module中，而gson這種東西，就可以專門配置在service-module中，避免POM檔無限制的增長\n指定不同開發環境 https://github.com/Hoxton019030/SpringBoot-MultiModule-MVC-Structure\n在開發中，常常會需要不同的開發環境，比如說本地開發時，可能會連接本地的Database，當上線到雲端後，可能會需要連接雲端的VM，於是就可以在POM裡面去指定不同的環境、不同的情況、不同的作業系統會執行不同的application.properties，相關的配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;hoxton.multimodule\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;major\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources/resource-${env}\u0026lt;/directory\u0026gt; \u0026lt;!-- 這邊的env對應到(1)--\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;dev\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;env\u0026gt;dev\u0026lt;/env\u0026gt; \u0026lt;!--(1)--\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;local\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;env\u0026gt;local\u0026lt;/env\u0026gt; \u0026lt;!--(1)--\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;prod\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;env\u0026gt;prod\u0026lt;/env\u0026gt; \u0026lt;!--(1)--\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;!--這邊還有更多設定可以設定，比如說指定JDK版本、OS等等，但我現在懶得研究了--\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;artifactId\u0026gt;application\u0026lt;/artifactId\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;hoxton.multimodule\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;controller\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt;   接著就可以用\n1  mvn clean package -Pdev   1  mvn clean package -Pprod   1  mvn clean package -Plocal   來打包成不同的jar了\n","date":"2023-07-09T09:47:13+08:00","image":"https://i.imgur.com/VcZp2b7.png","permalink":"https://hoxtonhsu.com/p/maven%E8%A9%B3%E7%B4%B0%E7%A0%94%E7%A9%B6/","title":"Maven詳細研究"},{"content":"參考 參考影片如下 Apache Airflow for Data Science #1 - How to Install Airflow Locally in 10 Minutes\n教學  首先先下載Anaconda   Anaconda是一個開源的Python發行版本，旨在簡化Python開發和數據科學工作的流程。它包含了許多常用的Python套件和工具，並且提供了一個方便的環境管理系統。\nAnaconda包含了Python解釋器以及一個稱為Conda的包管理和環境管理系統。Conda可以用於安裝、升級和刪除Python套件，並可以管理不同版本的套件和它們之間的相互依賴關係。這使得在不同的項目中使用不同版本的套件變得容易，同時避免了套件之間的衝突。\n除了Python解釋器和Conda外，Anaconda還包含了許多常用的Python套件，如NumPy、Pandas、Matplotlib、SciPy等，這些套件在數據科學和科學計算領域非常流行。此外，Anaconda還提供了一個名為Jupyter Notebook的環境，用於交互式的編寫和執行Python代碼、數據可視化和文檔編寫。\n總的來說，Anaconda為Python開發者和數據科學家提供了一個便捷的工具集，使得安裝和管理Python套件變得更加容易，同時提供了一個豐富的生態系統，包含了許多常用的套件和工具，使得開發和數據科學工作更加高效和便利。\n 我個人是從這邊下載的\nhttps://docs.anaconda.com/free/anaconda/install/mac-os/\n這邊提供幾個常見的conda指令\n 查看版本  1  conda -V   查看環境列表  1  conda env list   啟動環境  1  conda activate \u0026lt;環境名\u0026gt;   退出環境  1  conda deactivate   創建虛擬環境  1  conda create --name airflow_env python=3.9 -y   如果成功的話，iterm2會顯示成這樣的畫面\n在terminal中執行指令  1  pip install \u0026#34;apache-airflow==2.2.3\u0026#34; --constraint \u0026#34;https://raw.githubusercontent.com/apache/airflow/constraints-2.2.3/constraints-no-providers-3.9.txt\u0026#34;   初始化資料庫  1  airflow db init   進入airflow資料夾中  1  cd ~/airflow   ls應該可以看到下面這些資訊\n創建airflow使用者  1  airflow users create --username admin --password admin --firstname hoxton --lastname Hsu --role Admin --email piyan@yahoo.com.tw   啟動Aiflow  1  airflow webserver --port 8080 -D   1  airflow scheduler -D   ","date":"2023-07-07T19:46:21+08:00","image":"https://i.imgur.com/FWgJzl6.png","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E5%9C%A8m1m2%E4%B8%AD%E5%AE%89%E8%A3%9Dairflow/","title":"如何在M1,M2中安裝Airflow"},{"content":"設方程式\n$$ 3x+2y=11 \\\n2x+2y=8 $$\n","date":"2023-07-06T21:17:25+08:00","image":"https://i.imgur.com/kuvQKCh.png","permalink":"https://hoxtonhsu.com/p/%E8%A1%8C%E5%88%97%E5%BC%8F%E7%82%BA%E4%BB%80%E9%BA%BC%E6%98%AFab-bc%E8%A1%8C%E5%88%97%E5%BC%8F%E4%B9%8B%E8%A7%A3%E6%9E%90/","title":"行列式為什麼是ab-bc?行列式之解析"},{"content":"前一陣子在公司被保哥唸了一頓，「只看Terminal而不看SourceTreeg是錯的，Tree才是Git的精髓！」\n於是決定來學一下如何用Terminal查看Tree。\n雖然不多人知道，但其實Git裡面是可以查看Git Tree的\n1  git log --graph   但這樣子只會顯示當前分支的資訊，很多時候我們想知道的是更Overview的東西，於是我們就需要完成一下我們的command line\n1  git log --graph --decorate --oneline --all   但這個指令實在是太長了，我們可以透過git alias來讓他更好輸入一點！\n1  git config --global alias.graph \u0026#39;log --graph --decorate --oneline --all\u0026#39;   完成後可以輸入\n1  git config --global --list   來看看我們是否有設定成功！\n設定好了後我們就可以透過\n1  git graph   來查看完整的Tree了 ！\n","date":"2023-07-03T16:09:33+08:00","image":"https://i.imgur.com/eESaO42.png","permalink":"https://hoxtonhsu.com/p/%E5%9C%A8termianl%E4%B8%AD%E9%A1%AF%E7%A4%BA%E5%AE%8C%E6%95%B4%E7%9A%84git-tree/","title":"在Termianl中顯示完整的Git Tree"},{"content":" Iterm2裡面，當我輸入\n1  git log --oneline   時，會在我的terminal上顯示出來，但當我退出後，這些資訊又不見，會讓我在rebase的時候遇到很多困難，上網查了一下之後發現有這個功能可已開起\n1  git config --global --replace-all core.pager \u0026#34;less -F -X\u0026#34;   這樣就可以持續顯示了\n","date":"2023-06-27T11:14:03+08:00","image":"https://i.imgur.com/nivCoDF.png","permalink":"https://hoxtonhsu.com/p/%E5%9C%A8iterm2%E4%B8%8A%E6%8C%81%E7%BA%8C%E9%A1%AF%E7%A4%BAlog-branch/","title":"在Iterm2上持續顯示log, branch"},{"content":"前言 前一陣子花了65,000買了一台Macbook，不得不說，使用體驗還是覺得像一坨答辯一樣，很多東西都要自己來。用了快一個月左右，還是有很多地方不適應，最直觀的體驗就是Terinal吧，Windows有一個非常強的Terminal介面叫做Window Terminal，它的畫面設計還有使用體驗，海放了Iterm不知道幾條街，尤其是window鍵+`，快速開啟Terminal的功能至今讓我難以忘懷。換到Mac上，我試著熟悉左右切換視窗的方式來模擬那熟悉的感覺，但切換的動畫的那一秒還是讓我煩躁不已。於是搜尋了一下，發現Iterm本身就有內建如同Window Terminal快速開啟Terminal的方式。｀\n設定 將Exculde from Dock\u0026hellip;的設定打開\n再將A hotkey opens a dedicated window \u0026hellip;打開\n設定你自己想要的快捷鍵，我就設成跟window一樣的設定了\n","date":"2023-06-15T16:32:19+08:00","image":"https://i.imgur.com/w12QKbR.png","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E8%AE%93iterm2%E6%93%81%E6%9C%89%E5%A6%82window-terminal%E8%88%AC%E7%9A%84%E7%B5%B2%E6%BB%91%E9%AB%94%E9%A9%97/","title":"如何讓Iterm2擁有如Window Terminal般的絲滑體驗"},{"content":"教學 可以先輸入\n1  env   來查看自己目前的環境變數有什麼\n再來透過\n1  vim ~/.bash_profile   來編輯bash_profile，編輯裡面的內容\n1  export DESKTOP=\u0026#34;$HOME/Desktop\u0026#34;   之後再輸入\n1  source ~/.bash_profile   1  vim ~/.zshrc   然後再開頭的地方加上\n1 2 3  if [ -f ~/.bash_profile ]; then source ~/.bash_profile fi   保存後退出，並輸入\n1  source ~/.zshrc   說明：https://www.twblogs.net/a/5eee14bd45d52357fb494be6\n原因解釋如下： bash的配置文件是.bashrc, zsh的配置文件是.zshrc，當你使用zsh作爲默認shell工具的時候，它啓動時並不會加載bash的這兩個配置文件.bashrc和.bash_profile，而只會 加載自己的配置文件.zshrc，爲了讓我們的配置文件生效，只能在.zshrc中添加上面的配置。\n如果不做上述設置，你就會發現，只有當你每次source ~/.bash_profile後纔會生效，下次重新打開zsh窗口，還是不生效。\n 這樣就可以囉！\n之後可以再輸入一次env，來確認環境變數有被加入到系統中\n結果展示 ","date":"2023-06-14T15:34:15+08:00","image":"https://i.imgur.com/O9emCTx.png","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E7%82%BAmac%E8%A8%AD%E5%AE%9A%E7%92%B0%E5%A2%83%E8%AE%8A%E6%95%B8/","title":"如何為Mac設定環境變數"},{"content":"在遠端的電腦上輸入\n1  sudo ufw allow 8081   將8081 Port曝露出來\n這樣外部就可以透過\nhttp://{ip-address}:8081/\n來訪問網站了\n","date":"2023-05-20T11:40:25+08:00","image":"https://i.imgur.com/qKt7ANw.png","permalink":"https://hoxtonhsu.com/p/%E5%B0%87linux%E7%9A%84port%E6%89%93%E9%96%8B%E8%AE%93%E5%A4%96%E9%83%A8%E5%8F%AF%E4%BB%A5%E8%A8%AA%E5%95%8F/","title":"將Linux的Port打開，讓外部可以訪問"},{"content":"前一陣子買了Mac，讓Mac可以用Terminal開啟IntelliJ，關於Mac的設定可以查看這篇文章，但這是一直遲遲沒有把windows也設定起來，但今天它來啦！\n實際演示 教學  將IntelliJ的bin加到Path中   PATH是一個包含多個路徑的環境變數，系統使用它來尋找執行檔案。當你在命令提示字元或終端中輸入一個命令時，系統會檢查這些路徑，看是否有包含該命令的可執行檔案。\n 1  setx PATH \u0026#34;%PATH%;C:\\Program Files\\JetBrains\\IntelliJ IDEA 2023.1.2\\bin\u0026#34;   切到IntelliJ的資料夾中  1  cd C:\\Program Files\\JetBrains\\IntelliJ IDEA 2023.1.2\\bin   ​\t其實做到這邊就差不多了，你已經可以使用\n1  idea .   ​\t來開啟檔案了，但如果這樣子你會發現你的termianl在啟動專案的時候就\t被佔用了，原因是因為這個指令是在用\\bin底下的idea.bat啟動，於是我\t們要改成用idea64.exe的方式來開啟檔案，需要做以下的步驟\n將名稱為idea的bat檔命名為idea64   其實要命名成什麼都沒差，不要再叫idea就好\n 將idea64.exe的檔案命名為idea  將idea64.exe.vmoptions命名為idea.exe.vmoptions   如果不改的話，會出現找不到intelliJ 找不到vm option的問題\n 這樣就可以用idea .來 開啟檔案了\n注意事項 這樣的修改會導致桌面的捷徑出現問題，因為我們把啟動的程式從idea64.exe重新命名成idea.exe了，所以需要重新建立一個新的桌面捷徑\n","date":"2023-05-19T20:56:38+08:00","image":"https://i.imgur.com/fkzGuEX.jpg","permalink":"https://hoxtonhsu.com/p/windows%E7%B3%BB%E7%B5%B1%E4%B8%AD%E4%BD%BF%E7%94%A8terminal%E9%96%8B%E5%95%9Fintellij/","title":"Windows系統中，使用Terminal開啟IntelliJ"},{"content":"前言 一直以來都覺得要在資料夾內搜尋是一件很麻煩的事情，原因是這樣的，我文章的資料夾長這樣\n他的排序基本上就是依照英文字母(或ASCII)的方式排序，但我更希望的是他可依照我創建的時間排序。我是可以在windons總管和Finder內指定想要的排序方式，但我在線上的Github.dev不能，於是我就想讓我的每篇文章在創建的時後，能夠在前面的資料夾內加上排序，最早創立的是1，其次是2，以此類推\u0026hellip;\n實際操作 詳細的shellscript語法如下\n1 2 3 4 5 6 7 8 9 10 11  echo \u0026#34;請輸入文章標題\u0026#34; read title # cd content/post/$title # 讀取資料夾內的檔案數量，為文章資料夾命名 file_count=$(ls -1 content/post| wc -l) file_count=\u0026#34;${file_count// /}\u0026#34; # 去除file_count包含的空白 titleWithNumber=$file_count-$title hugo new post/$titleWithNumber/index.md cd content/post/$titleWithNumber open index.md cd ../../..   需要關注的就是那個file_count，那段就是去讀資料夾內當前的檔案數並回報，值得注意的是他取出來的值前面是會帶一個空白的，比如說\n1  51   這樣子，所以需要再把它的空白去掉，這樣就可以在後面以字串串接的方式將文章的標題自動帶上編號了\n","date":"2023-05-19T15:06:55+08:00","image":"https://i.imgur.com/mdbKbaT.png","permalink":"https://hoxtonhsu.com/p/%E4%BD%BF%E7%94%A8shellscript%E8%AE%80%E5%8F%96%E8%B3%87%E6%96%99%E5%A4%BE%E4%B8%AD%E7%9A%84%E6%AA%94%E6%A1%88%E5%80%8B%E6%95%B8/","title":"使用shellScript讀取資料夾中的檔案個數"},{"content":"前言 前陣子買了Mac，影響我最大的應該就是不能再像Windows一樣，使用右鍵開啟專案了！因為公司的產品有兩個專案，我也常常把專案砍掉重抓，如果不能用右鍵開啟，那就得從中手動匯入，這樣子一來一往真的是靠北麻煩。\n如何使用Terminal開啟 其實網路上我看了很多教學，大概看了4、5天吧，到最後我才發現其實官網就有寫了，原來幸福的青鳥一直就在身邊，唉垃圾Mac\nhttps://www.jetbrains.com/help/idea/working-with-the-ide-features-from-command-line.html\n切換至/usr/local/bin/ 首先先切換至\n1  cd /usr/local/bin/   創建idea檔案 1  touch idea   編輯idea檔案中的內容 1 2 3  #!/bin/sh  open -na \u0026#34; IDEA.app\u0026#34; --args \u0026#34;$@\u0026#34;   Chat GPT對這段的解釋如下\n1 2 3 4 5 6 7  open: 這是 macOS 的一個內建命令，可以用來打開應用程式、檔案或網址。 -na: 這是 open 命令的兩個參數。其中 -n 表示「Open a new instance even if one is already running」，意思是無論是否已經有一個 IntelliJ IDEA 執行中，都要打開一個新的實例。而 -a \u0026#34;IDEA.app\u0026#34; 則指定了要打開的應用程式是 \u0026#34;IDEA.app\u0026#34;，即 IntelliJ IDEA 的應用程式。 --args \u0026#34;$@\u0026#34;: 這是傳遞給 \u0026#34;IDEA.app\u0026#34; 的參數。$@ 代表所有的命令列參數，這樣當你在終端機中輸入這個指令時，後面的任何參數都會被傳遞給 IntelliJ IDEA。 綜合起來，這個指令的目的是在 macOS 中打開一個新的 IntelliJ IDEA 實例，並將後面的參數傳遞給 IntelliJ IDEA。這樣你可以從終端機中直接啟動 IntelliJ IDEA，同時可以指定特定的專案或檔案來開啟。   這一步我個人覺得算是「寫一個script腳本」然後讓terminal去運行，可以輸入\n1  env   發現我們的PATH變數中有包含\n1  /usr/local/bin   也就是我們idea腳本所儲存的位置\n存擋後使用Chmod調整權限 輸入指令\n1  chmod 755 idea   \u0026ldquo;chmod 755\u0026rdquo; 是一個用於設置檔案或目錄權限的命令。在 Linux 和其他類 Unix 系統中，\u0026ldquo;chmod\u0026rdquo; 是改變檔案權限的指令，而 \u0026ldquo;755\u0026rdquo; 是一個表示權限的數字。\n在 \u0026ldquo;chmod 755\u0026rdquo; 中，\u0026ldquo;755\u0026rdquo; 是由三個數字組成的權限表示法。每個數字代表了不同的使用者類別和他們對檔案的權限。\n第一個數字（7）表示檔案所有者的權限。在這種情況下，7 表示所有者具有讀取、寫入和執行的權限（4 + 2 + 1）。 第二個數字（5）表示檔案所屬群組的權限。在這種情況下，5 表示群組具有讀取和執行的權限，但沒有寫入的權限（4 + 1）。 第三個數字（5）表示其他使用者（非所有者且非群組成員）的權限。在這種情況下，5 表示其他使用者具有讀取和執行的權限，但沒有寫入的權限（4 + 1）。 因此，\u0026ldquo;chmod 755\u0026rdquo; 的含義是將檔案設置為擁有者具有讀取、寫入和執行權限，群組成員和其他使用者具有讀取和執行權限，但不具有寫入權限。\n刷新頁面 確認mac os的檔案icon是否有更改成exec\n如果更改成功，就可以透過\n1  idea .   使用開啟檔案了 ！\n以下內容作廢，請勿參考，這是我錯的紀錄 如何在Mac中設置環境變數開啟IDEA\n在Terminal中輸入\n1  vim ~/.bash_profile   進入輸入畫面後，輸入以下資訊\n1  export PATH=\u0026#34;/Applications/ IDEA.app/Contents/MacOS:$PATH\u0026#34;   儲存後退出，並輸入\n1  source ~/.bash_profile   即可使用\n1  idea .   用Idea開啟當前目錄\n也可在terminal輸入\n1  env   來查看目前的環境變數，確定是否有加入PATH中\n1  open -na \u0026#34; IDEA.app\u0026#34; --args \u0026#34;$@\u0026#34;   ","date":"2023-05-18T21:22:51+08:00","image":"https://i.imgur.com/AEhodYS.png","permalink":"https://hoxtonhsu.com/p/%E5%9C%A8macbook-m1%E7%92%B0%E5%A2%83%E4%B8%8B%E4%BD%BF%E7%94%A8terimnal%E9%96%8B%E5%95%9Fintellij/","title":"在MacBook M1環境下使用Terimnal開啟IntelliJ"},{"content":"導因 M1的CPU是使用ARM架構，而有些電腦則是使用x86架構，並且因Docker是Run在OS上方，所以在執行Image時也要考慮作業系統的問題\n1  The requested image\u0026#39;s platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested   解決方法 在docker run啟動參數後加上--platform linux/amd64即可解決這個問題\n1  docker run --platform linux/amd64 -p 8080:8080 fe744192d855   解決方法二 幹你媽的，我發現run的時候還是不行，還是要在build就控制它的架構\n1  docker build . --platform linux/x86_64   ","date":"2023-05-13T19:09:41+08:00","image":"https://i.imgur.com/8XJ9XWE.png","permalink":"https://hoxtonhsu.com/p/arm%E6%9E%B6%E6%A7%8B%E8%88%87x86%E6%9E%B6%E6%A7%8B%E4%B8%8Bdocker%E5%95%9F%E5%8B%95%E5%95%8F%E9%A1%8C/","title":"ARM架構與x86架構下，Docker啟動問題"},{"content":"簡介 最近要換新工作了，正好新工作的公司有電腦補助，就趁這個機會把Macbook也買了，一拿到手之後發現超級難用，難用到靠北，真的不懂為什麼一堆人說好用。\n如何更改Termial預設路徑 預設情況下，Terminal路徑都是\n1  /Users/[使用者名稱]   但我希望他開啟的路徑是\n1  /Users/[使用者名稱]/Desktop   因此要到.zshrc去更改\n通常這個檔案都會放在\n/Users/[使用者名稱]底下，如果沒有的話可以自己創一個就好\n然後編輯裡面的內容，加上這段\n1  cd /Users/hoxtonashes/Desktop   這樣下次開啟的時候，預設的Terminal路徑就會是Desktop了\n","date":"2023-05-13T17:44:38+08:00","image":"https://i.imgur.com/ieJ6kkK.png","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E6%9B%B4%E6%94%B9mac-terminal%E7%9A%84%E9%A0%90%E8%A8%AD%E8%B7%AF%E5%BE%91/","title":"如何更改Mac terminal的預設路徑"},{"content":"在IntelliJ開啟以下的路徑\nSetting \u0026gt; Editor \u0026gt; File and Code Templates \u0026gt; Includes \u0026gt; File Header\n即可在這邊編輯創建Class的模板，一旦設定好後，當你創建一個新的Class時，IntelliJ就會在你的Class上插入這些資訊\n","date":"2023-05-12T15:41:07+08:00","image":"https://i.imgur.com/dEvsZm3.png","permalink":"https://hoxtonhsu.com/p/%E5%9C%A8intellij%E4%B8%AD%E8%A8%AD%E5%AE%9Aclass%E6%A8%A1%E6%9D%BF/","title":"在IntelliJ中設定Class模板"},{"content":"介紹 最近公司提倡使用rebase而非merge來合併分支，但在rebase的情況下，常常出現多種commit會有重複confict的情形發生，往往可能要解個2,30個conflict，一來一往可能會耗費許多時間，於是上網查了一下，發現有\n1  git rerere   這種神奇的指令\n這是由3個單字縮寫所組成的指令，分別是reuse、recorded 與 resolution。git rerere有點像是一個記憶吐司的概念，能夠記錄你之前解Conflict的方式，然後自動幫你套用到相同的地方。\n而這個rerere的行為預設是關閉的，想要打開的話可以輸入\n1  git config --global rerere.enabled true   來啟用，若不想要使用的話可以輸入\n1  git config --global --unset rerere.enabled   ","date":"2023-05-12T11:05:10+08:00","image":"https://i.imgur.com/FJcgPVI.png","permalink":"https://hoxtonhsu.com/p/git-rerere%E4%B9%8B%E4%BB%8B%E7%B4%B9/","title":"Git-rerere之介紹"},{"content":"依賴如下\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;   配置如下\n1 2 3 4 5 6 7 8 9 10  server.port=8080 spring.h2.console.enabled=true spring.h2.console.path=/h2 spring.sql.init.mode=always spring.datasource.url=jdbc:h2:~/dev;AUTO_SERVER=true spring.datasource.driver-class-name=org.h2.Driver spring.datasource.username=sa spring.datasource.password=sa spring.jpa.database-platform=org.hibernate.dialect.H2Dialect spring.jpa.hibernate.ddl-auto=update   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  server:port:8080spring:h2:console:enabled:truepath:/h2sql:init:mode:alwaysdatasource:url:jdbc:h2:~/test;AUTO_SERVER=true# ??????C/user/userName?????driver-class-name:org.h2.Driver#??driverusername:sapassword:sajpa:database-platform:org.hibernate.dialect.H2Dialecthibernate:ddl-auto:update  ","date":"2023-05-06T00:13:33+08:00","image":"https://i.imgur.com/xYmsInY.png","permalink":"https://hoxtonhsu.com/p/h2database%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%AA%94%E7%B4%80%E9%8C%84/","title":"H2Database之配置檔紀錄"},{"content":"設定環境變數 可以在此配置環境變數\n格式如下\n1  username=sa;password=sa   Application.properties之設置 使用${username}來獲取環境變數\n如下\n即可在專案中配置環境變數，並讓配置檔讀取\n","date":"2023-05-06T00:07:44+08:00","image":"https://i.imgur.com/lRrDIvY.png","permalink":"https://hoxtonhsu.com/p/%E5%9C%A8intellij%E8%A8%AD%E5%AE%9A%E7%92%B0%E5%A2%83%E8%AE%8A%E6%95%B8%E4%B8%A6%E8%AE%93application.properties%E8%AE%80%E5%8F%96/","title":"在IntelliJ設定環境變數，並讓Application.properties讀取"},{"content":"1  sudo lsof -i:8080\t  然後找到它的PID\n1  kill 31128   就可以了\n","date":"2023-05-03T16:25:22+08:00","image":"https://i.imgur.com/m3Lr6uG.png","permalink":"https://hoxtonhsu.com/p/macos%E5%A6%82%E4%BD%95%E7%B5%82%E6%AD%A2portprocess/","title":"MacOS如何終止port,process"},{"content":" 拆掉上次Commit  1  git reset HEAD^   ","date":"2023-05-03T14:01:35+08:00","image":"https://i.imgur.com/v0TYB05.png","permalink":"https://hoxtonhsu.com/p/git%E7%AD%86%E8%A8%98/","title":"Git筆記"},{"content":"參考影片\nDcard如何進行Cache 先Pass掉，\nDcard DataBase之選擇與調整 資料儲存類型、資料儲存量、資料是被大量儲存還是被修改?\nDcard之RDB選擇-Postgres\nMongGODB Dcard的通知、愛心，運用Mogodb的Sharding功能\nREDIS\n用來儲存User的Token，或是會大量被使用的資料\nCache實戰學習-Serving Post List\n除了最左邊的三張表以外，其他都是Materialize View，因為在實際取用文章時，學校、系所、性別相關的資訊、以及在哪一個看板，這樣的Materilize View在遇到Migration時就會遇到很大的問題，幾乎全部都要重寫\n使用Paging Service來替代Materlize View\nCase Studies Handle Reaction\n將Reaction的服務抽離出來，讓Loading降低\nQ\u0026amp;A\n","date":"2023-05-01T11:45:37+08:00","image":"https://i.imgur.com/dqGgQLi.png","permalink":"https://hoxtonhsu.com/p/dcard%E5%BE%8C%E7%AB%AF%E6%8A%80%E8%A1%93%E5%88%86%E4%BA%AB%E7%B4%94%E7%B4%80%E9%8C%84/","title":"Dcard後端技術分享－純紀錄"},{"content":"SpringBoot的Bean有三種注入方式\n @Autowired Constructor Injection Setting Injection  而官方推薦的是第二種的建構子注入，而Lombok有個註解叫做@RequiredArgsConstructor，它能夠產生一個只有final field的建構子\n就像這樣\n23行的@RequiredArgsConstructor，會創建MemberController底下的final field，也就是這樣\n1 2 3  public MemberController(MemberService memberService) { this.memberService = memberService; }   這樣一來我們的Service層跟Controller層就會更簡潔，當新的依賴進入後，不需要再重新寫一個建構子，只要將其宣告成final後，Lombok就會幫我們創建了\n","date":"2023-04-30T02:39:36+08:00","image":"https://i.imgur.com/1OBx1AG.png","permalink":"https://hoxtonhsu.com/p/%E7%B5%90%E5%90%88lombok%E5%AF%AB%E5%87%BA%E6%9B%B4%E6%95%B4%E6%BD%94%E7%9A%84%E7%A8%8B%E5%BC%8F%E7%A2%BC/","title":"結合Lombok寫出更整潔的程式碼"},{"content":"參考影片：Clean Architecture with Spring by Tom Hombergs @ Spring I/O 2019\n架構的目標  Facilitate Development Facilitate Deployment Facilitatte maintenance keep software soft keep frameworks of arm\u0026rsquo;s length keep options open  架構的終極目標 The Goal of software Achitecture is to minimize the lifetime cost of the software\n分層式(Layers)架構有什麼問題？ 分層架構是一種可靠的架構模式！但是如果沒有額外的限制，它們容易出現設計缺陷。 根據講者的經驗，我們有很多的架構是所謂的資料庫驅動設計(Database Driven design)\n在我們的Domain Layer，我們有Service Layer、Persistence Layer，裡面存在著我們的Entity以及JPA相關的一些資訊\n模糊的界線(Blurred Boundaries) 另一個關於Layer的議題是，我們通常會有一個工具類(utili)來封裝我們常用的一些函式庫，這些東西會在各層之間流竄，這樣會使得各層之間的關係越發模糊。\n難以測試 需要Mock很多東西，比如說Service、Repository。\n許多功能被隱藏起來了 假使我們有一個Order的系統，那我們所有對Order的CRUD都會集中在OrderService中，一旦這個方法有很多個，那麼很多方法(Functionality)就會被埋沒起來\n那麼如何解決這些問題呢 ？\nDo Circles Instead 再議SOLID設計模式 Dependency Inverision Principle 依賴反轉原則\n(左圖為Database Driven Development)\n影片戳記時間\n若要執行依賴反轉原則，那麼Domain層不應該依賴Persistence層，而是反轉過來，(Use Case等同於Service層)，\n這樣做的好處是什麼？我們可以選擇任何Code的依賴方向\nSingle Responsibility Priniciple 一個Class或一個Module只做一件事情\n一個Class或一個Module只能有一個原因被修改(Change)\n分層式架構下，若Persistence修改了，那麼Business層有很大機率也會連動修改，但在Clean Architecture的架構下，Persistence由於不處於最核心的部分(Entity)，因此不需要一起改動\n假使我們有一個Order Service，其中有三個user Roles，當其中一個User Roles改變後，我們就要去改動我們的Service\n但當我們把Service分割成不同的Use Cases，每一個Cases指對應一個Use Roles，那麼這個Use Case也只會有一個原因被修改\n Service應該被切割成許多不同的Use Case(First-Class Citizens)\n Only a Domain-Centric Architecture Allows Domian-Driven Design\nClean Architecture Hexagons 六角架構是Clean Architecture的具現化\n Input Port：對外暴露的API  use case class implements an input port, the input port is just a Java interface, then the use case class modifies the domain model\n問題時間：這個應用程式在做什麼？ 分層架構下，只透過Class名稱無法獲得有用的訊息\n六角架構中，將Service拆分成不同的Use Case，所有的職責會更加一目了然\n實作時間 Code連結：thombergs/buckpal\n\n\n\n\nSummary 如何強迫我們使用這個架構\n","date":"2023-04-25T10:24:57+08:00","image":"https://i.imgur.com/wlAKij1.jpg","permalink":"https://hoxtonhsu.com/p/spring%E4%B8%AD%E7%9A%84clean-architecture/","title":"Spring中的Clean Architecture"},{"content":"利用一個下午，把對Cherry Pick的一些問題整理成一篇文章，並且這個指令常常與Rebase, Merge兩者來對比，目前感覺如下\n   指令 merge rebase cherry pick     說明 將一條分支合進另一條分支中。不會破壞提交歷史的完整性，但缺點是合併後的提交歷史較為混亂，有時可能會產生冗長的提交歷史。 將當前分支與目標分支結合，並以目標分支為底(base)重新出發。將一個分支中的提交歷史應用到另一個分支上，使得目標分支中的提交歷史變得更加緊湊和簡潔 命令可以從一個分支中選擇單個提交，並將其應用到另一個分支上，通常用於需要特定提交的情況。只想要某個分支的某些commit，不希望把整個分支搬過來   指令 git merge salve git rebase main git cherry-pick c4   圖示      優點 簡單易操作，不破壞commit歷史 不產生多餘commit 與分支線 不會更動到Commit的歷史順序   缺點 會產生額外的分支合成線 不可以在共用分支上使用，否則將打斷commit順序，破壞commit完整性 若cherry pick commit過多，易產生重複的commit紀錄   應用場景 整合分支 用以取得別的分支整個進度 用以取得別的分支的個別進度    預覽 這是一個SpringBoot專案，Main分支目前長這樣，並且還有兩個協作者，分別是Hoxton跟Dallas\nSourceTree如下\nHoxton這個有四個Commit\n依序如下\n 創建MemberDao　f198 創建MemberService 185a 創建MemberController 310a 為MemberController新增一個方法 99b2 刪除MemberController fd8b  Dallas這個分支有兩個Commit\n 創建LoginContorller 7eb2 為LogingController新增一個方法 e92a  Main這個分支有一個Commit\n 創建README fce6  接下來在不同情境下，使用Cherry Pick，看看會有什麼結果與問題\n實際演練 Main需要hoxton的進度，其中有包含Main上未有的檔案(99b2) 結果：\n發生衝突，因Main上沒有MemberController。雖然最新的Commit 只有對MemberController更新，沒有創建MemberController的部分，但因為要Cherry Pick的關係，所以還是會把MemberController創建起來，並且其內容是最新的內容至於Service、Dao則不會帶過來，因為那是屬於別的Commit的，因此最終是長這樣，綠色部分是新增的部分\n hoxton-310a 創建Member Controller\n  hoxton-99b2 在Member Controller新增方法\n Main只需要Hoxton的幾個進度，其中的commit並非連續(310a, f198) 結果：\n將MemberController與Dao創建進來，其中不包含Dao，因為Cherry-pick的部分不包含，注意到的是，因為Cherry pick時我們的指令是這樣\n1  git cherry-pick 310a f198   因此Commit 的順序調換了，變成先Controller在Dao\n檔案長這樣\nMain只需要Hoxton的幾個進度，其中的commit並非連續(f198, 310a) 結果：\n將MemberController與Dao創建進來，其中不包含Service，因為Cherry-pick的部分不包含，注意到的是，因為我們Cherry Pick的指令如下\n1  git cherry-pick f198 310a   因此Commit 順序與hoxton上分支的順序一樣\n檔案長這樣\nCherry-pick一個只有刪除檔案的commit，是否能成功 fd8b這個Commit是將MemberController刪掉，在Main上cherry Pick後會發生什麼事情呢?\n結果\n結果：\n顯示\n Bad revision\n 直接不讓cherry-pick，我猜多半是因為這個Commit只有包含刪除，因此沒辦法pick\nCherry-pick一個範圍的commit，最終的結果呈現如何? 1  git cherry-pick f198 .. fd8b   結果：\n假設現在Dallas需要Hoxton的Commit，它合進去Main後會長什麼樣子呢? 如果兩邊合進Main之後會長怎麼樣呢？會不會兩邊都有重複的Commit導致畫面很亂呢?\n結果：\n會，合進去後會有許多重複的commit，因為Cherry pick過去後，雖然看起來一樣，但它們的Hash Code已經有所不同，因此會有重複的情形發生\n","date":"2023-04-16T17:30:28+08:00","image":"https://i.imgur.com/n1qX6TQ.gif","permalink":"https://hoxtonhsu.com/p/cherry-pick%E7%9A%84%E4%B8%80%E9%BB%9E%E7%A0%94%E7%A9%B6/","title":"Cherry Pick的一點研究"},{"content":"本文參考至MyBatis入門教學\n以及my-batis官方文件\n新增Maven依賴 1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   XML配置內容  此為預設的模板\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;https://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/example/BlogMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt;   檔案大概配置成這樣\nXML具體配置內容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;https://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;org.h2.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:h2:~/cherry;AUTO_SERVER=true\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;sa\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;sa\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;org/example/BlogMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt;   配置BlogMapper.xml 於專案中，此Xml用以儲存SQL語句\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;https://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;BlogMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectBlog\u0026#34; resultType=\u0026#34;Blog\u0026#34;\u0026gt; select * from Blog where id = #{id} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   ","date":"2023-04-16T16:01:05+08:00","image":"https://i.imgur.com/wG62XWP.jpg","permalink":"https://hoxtonhsu.com/p/mybatis%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"MyBatis學習筆記"},{"content":"導因 通常是因為在JPA的地方使用了@GeneratedValue(strategy = GenerationType.AUTO)這個註解，這個註解會由資料庫自動(AUTO)去配置，如果資料庫有就沒問題，但有些資料庫可能會沒有，比如說我用的資料庫是PostgresSQL就會出現這個問題\n解決方式\n將@GeneratedValue(strategy = GenerationType.AUTO)更改，更改為@GeneratedValue(strategy = GenerationType.IDENTITY)即可\n","date":"2023-04-16T03:55:44+08:00","image":"https://i.imgur.com/kdTSaSC.png","permalink":"https://hoxtonhsu.com/p/springboot%E5%95%9F%E5%8B%95%E6%99%82%E5%87%BA%E7%8F%BEmissing-table-hibernate-sequence%E4%B9%8B%E8%A7%A3%E6%B1%BA%E6%96%B9%E6%B3%95/","title":"SpringBoot啟動時，出現Missing table hibernate sequence之解決方法"},{"content":"前言 連假實在有點無聊，打算來手寫一個SprintBoot專案，來加深自己對這種IoC框架的理解，我打算把這個框架叫做Winter，象徵我每況愈下的人生，唉\nSprintBoot 單例池 本章所用到的程式碼存放在這\nhttps://github.com/Hoxton019030/Winter/tree/bean-scan-and-beandefinition\n一切開始的地方，Main 啟動類的寫法如下\n1 2 3 4 5  public class Main { public static void main(String[] args) { WinterApplicationContext applicationContext = new WinterApplicationContext(AppConfig.class); } }   這邊看到兩個陌生的Class，WinterApplicationContext，以及AppConfig。先講AppConfig是什麼，它是Winter的配置類，我們會在這邊去配置我們Winter Bean的位置在哪邊，所以我們要加上@ComponentScan這個註解，讓我們的Winter框架知道它要去什麼package底下找到Bean。這邊我們就先創這個Class就好，目前先不會寫到它。\nAppConfig 1 2 3 4 5 6 7  /** * Winter的配置文件 */ @ComponentScan(\u0026#34;org.hoxton.service\u0026#34;) public class AppConfig { }   @ComponentScan 1 2 3 4 5  @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface ComponentScan { String value() default \u0026#34;\u0026#34; ; }   用來示意我們的Winter框架，要去哪邊找到我們的Bean，我們的Bean都會寫在org.hoxton.service這個路徑下面。\n@Component 這個大家熟的吧，將當前類變成一個Spring Bean的註解\n1 2 3 4 5 6  @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface Component { String value() default \u0026#34;\u0026#34;; }   @Scope 標示當前類所要創建的Bean是一個單例還是一個Prototype的Bean\n1 2 3 4 5  @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface Scope { String value(); }   UserService 用來假設MVC架構中的Service層\n1 2 3 4  @Component(\u0026#34;userService\u0026#34;) @Scope(\u0026#34;singleton\u0026#34;) public class UserService { }   WinterApplicationContext 這個類就是SpringBoot框架中的容器類，我們接下來要來手寫一個容器類，首先先創這個類出來，並且它要吃一個Class參數作為Constructor\n1 2 3 4 5 6 7  public class WinterApplicationContext { private Class configClass; public WinterApplicationContext(Class configClass){ this.configClass=configClass; } }   接下來我們寫一個方法，叫做Scan，這個Scan方法會去得到@ComponentScan這個註解的值，取得要掃描的Package路徑，取得路徑之後，會去掃描路徑底下有哪些類有被@Component這個註解所修飾，並且會去找尋@Scope這個註解，得知哪些Bean是Singleton，哪些Bean是prototype，將這些資訊放入\n1  private ConcurrentHashMap\u0026lt;String, BeanDefinition\u0026gt; beanDefinitionMap = new ConcurrentHashMap\u0026lt;\u0026gt;();   這個ConcurrentHashMap中\n步驟  從Config類中取得ComponentScan註解的值，其值即為路徑  1 2 3 4 5 6  private void scan(Class configClass) { // 從Config類中取得ComponetScan註解的值，其值即為路徑  ComponentScan componentScanAnnotation = (ComponentScan) configClass.getAnnotation(ComponentScan.class); String path = componentScanAnnotation.value(); }    使用類加載，讀出Class檔案的資訊  1 2 3 4 5 6 7 8 9 10 11  private void scan(Class configClass) { // 從Config類中取得ComponentScan註解的值，其值即為路徑  ComponentScan componentScanAnnotation = (ComponentScan) configClass.getAnnotation(ComponentScan.class); String path = componentScanAnnotation.value(); //掃描 org.hoxton.service  // 類加載器 (Class Loader)  // Java中有三種類加載器，以及對應的加載路徑  // BootStrap ---\u0026gt; jre/lib  // Ext ---\u0026gt; jre/ext/lib  // App ---\u0026gt; classpath ---\u0026gt; \u0026#34;C:\\Program Files\\Java\\jdk-11\\bin\\java.exe\u0026#34; \u0026#34;-javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2.2\\lib\\idea_rt.jar=5445:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2.2\\bin\u0026#34; -Dfile.encoding=UTF-8 -classpath C:\\Users\\hoxton\\Desktop\\Winter\\target\\classes org.hoxton.Test 編譯器顯示的資訊  }    BeanDefinition  我們先來討論一個東西叫做BeanDefinition，這個類用來描述一個Bean的資訊，我們目前讓這個類盡量簡單一點，我們只需要紀錄一個Bean它的類型以及它的作用範圍\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  public class BeanDefinition { /** * 當前Bean類型 */ private Class clazz; /** * 當前Bean作用範圍 */ private String scope; public BeanDefinition() { } public BeanDefinition(Class clazz, String scope) { this.clazz = clazz; this.scope = scope; } public Class getClazz() { return clazz; } public void setClazz(Class clazz) { this.clazz = clazz; } public String getScope() { return scope; } public void setScope(String scope) { this.scope = scope; } }   使用類加載器，依照@ComponentScan的值，去掃描底下的Bean，  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  private void scan(Class configClass) { ComponentScan componentScanAnnotation = (ComponentScan) configClass.getAnnotation(ComponentScan.class); String path = componentScanAnnotation.value(); //掃描路徑  //掃描 org.hoxton.service  // 類加載器 (Class Loader)  // Java中有三種類加載器，以及對應的加載路徑  // BootStrap ---\u0026gt; jre/lib  // Ext ---\u0026gt; jre/ext/lib  // App ---\u0026gt; classpath ---\u0026gt; \u0026#34;C:\\Program Files\\Java\\jdk-11\\bin\\java.exe\u0026#34; \u0026#34;-javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2.2\\lib\\idea_rt.jar=5445:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2.2\\bin\u0026#34; -Dfile.encoding=UTF-8 -classpath C:\\Users\\za546\\Desktop\\Winter\\target\\classes org.hoxton.Test 編譯器顯示的資訊  ClassLoader classLoader = WinterApplicationContext.class.getClassLoader(); //app加載器  URL resource = classLoader.getResource(\u0026#34;org/hoxton/service\u0026#34;); //使用類加載，掃苗檔案下的.class檔  File file = new File(resource.getFile()); if (file.isDirectory()) { File[] files = file.listFiles(); for (File f : files) { String fileName = f.getAbsolutePath(); if (fileName.endsWith(\u0026#34;.class\u0026#34;)) { //若檔案以.class結尾即為.class檔，則進入流程判斷  String className = fileName.substring(fileName.indexOf(\u0026#34;org\u0026#34;), fileName.indexOf(\u0026#34;.class\u0026#34;)); className = className.replace(\u0026#34;\\\\\u0026#34;, \u0026#34;.\u0026#34;); Class\u0026lt;?\u0026gt; clazz = null; try { clazz = classLoader.loadClass(className); } catch (ClassNotFoundException e) { throw new RuntimeException(e); } if (clazz.isAnnotationPresent(Component.class)) { //類上若有@Component註解，代表為一個Bean  //表示這個類是個Bean  // ...? Class -- \u0026gt; bean ?  // 解析類，判斷當前Bean是單例Bean還是Prototype的Bean，生成BeanDefinition  Component componentAnnotation = clazz.getDeclaredAnnotation(Component.class); String beanName = componentAnnotation.value(); //取得@Component的值(bean名)  //BeanDefinition- Bean定義  BeanDefinition beanDefinition = new BeanDefinition(); //取得一個BeanDefinition物件  beanDefinition.setClazz(clazz); if (clazz.isAnnotationPresent(Scope.class)) { Scope scopeAnnotation = clazz.getDeclaredAnnotation(Scope.class); beanDefinition.setScope(scopeAnnotation.value()); } else { beanDefinition.setScope(SINGLETON); //沒加Scope註解，預設為單例  } beanDefinitionMap.put(beanName, beanDefinition); // 將beanDefinition放進ConcurrentHashMap中  } } } } }   我們先來稍微預覽一下整個Class完成後會長什麼樣子，讓大家更有一個概念  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126  public class WinterApplicationContext { final String SINGLETON =\u0026#34;singleton\u0026#34;; private Class configClass; /** * 一個單例池，存放Spring Bean */ private ConcurrentHashMap\u0026lt;String, Object\u0026gt; singletonPool = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * 存放所有Spring Bean的定義 */ private ConcurrentHashMap\u0026lt;String, BeanDefinition\u0026gt; beanDefinitionMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * @param configClass Winter的配置文件 */ public WinterApplicationContext(Class configClass) { this.configClass = configClass; //解析配置類  // ComponentScan註解解析 -\u0026gt; 掃描路徑 -\u0026gt; 掃描 ---\u0026gt; BeanDefinition ---\u0026gt; BeanDefinitionMap  scan(configClass); for (String beanName : beanDefinitionMap.keySet()) { BeanDefinition beanDefinition = beanDefinitionMap.get(beanName); //如果bean scope是單例，則放進單例池中  if(beanDefinition.getScope().equals(SINGLETON)){ Object bean = createBean(beanDefinition); singletonPool.put(beanName, bean); } } } public Object createBean(BeanDefinition beanDefinition){ Class clazz = beanDefinition.getClazz(); try { Object instance = clazz.getDeclaredConstructor().newInstance(); return instance; } catch (InstantiationException e) { throw new RuntimeException(e); } catch (IllegalAccessException e) { throw new RuntimeException(e); } catch (InvocationTargetException e) { throw new RuntimeException(e); } catch (NoSuchMethodException e) { throw new RuntimeException(e); } } private void scan(Class configClass) { ComponentScan componentScanAnnotation = (ComponentScan) configClass.getAnnotation(ComponentScan.class); String path = componentScanAnnotation.value(); //掃描路徑  //掃描 org.hoxton.service  // 類加載器 (Class Loader)  // Java中有三種類加載器，以及對應的加載路徑  // BootStrap ---\u0026gt; jre/lib  // Ext ---\u0026gt; jre/ext/lib  // App ---\u0026gt; classpath ---\u0026gt; \u0026#34;C:\\Program Files\\Java\\jdk-11\\bin\\java.exe\u0026#34; \u0026#34;-javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2.2\\lib\\idea_rt.jar=5445:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2.2\\bin\u0026#34; -Dfile.encoding=UTF-8 -classpath C:\\Users\\za546\\Desktop\\Winter\\target\\classes org.hoxton.Test 編譯器顯示的資訊  ClassLoader classLoader = WinterApplicationContext.class.getClassLoader(); //app加載器  URL resource = classLoader.getResource(\u0026#34;org/hoxton/service\u0026#34;); //使用類加載，掃苗檔案下的.class檔  File file = new File(resource.getFile()); if (file.isDirectory()) { File[] files = file.listFiles(); for (File f : files) { String fileName = f.getAbsolutePath(); if (fileName.endsWith(\u0026#34;.class\u0026#34;)) { String className = fileName.substring(fileName.indexOf(\u0026#34;org\u0026#34;), fileName.indexOf(\u0026#34;.class\u0026#34;)); className = className.replace(\u0026#34;\\\\\u0026#34;, \u0026#34;.\u0026#34;); Class\u0026lt;?\u0026gt; clazz = null; try { clazz = classLoader.loadClass(className); } catch (ClassNotFoundException e) { throw new RuntimeException(e); } if (clazz.isAnnotationPresent(Component.class)) { //表示這個類是個Bean  // ...? Class -- \u0026gt; bean ?  // 解析類，判斷當前Bean是單例Bean還是Prototype的Bean，生成BeanDefinition  Component componentAnnotation = clazz.getDeclaredAnnotation(Component.class); String beanName = componentAnnotation.value(); //BeanDefinition- Bean定義  BeanDefinition beanDefinition = new BeanDefinition(); beanDefinition.setClazz(clazz); if (clazz.isAnnotationPresent(Scope.class)) { Scope scopeAnnotation = clazz.getDeclaredAnnotation(Scope.class); beanDefinition.setScope(scopeAnnotation.value()); } else { beanDefinition.setScope(SINGLETON); } beanDefinitionMap.put(beanName, beanDefinition); } } //  } } } public Object getBean(String beanName) { // 依照beanName去判斷是單例Bean還是Prototype Bean  if (beanDefinitionMap.containsKey(beanName)) { BeanDefinition beanDefinition = beanDefinitionMap.get(beanName); if (beanDefinition.getScope().equals(SINGLETON)) { Object bean = singletonPool.get(beanName); return bean; } else { //創建bean對象嗎?  Object bean = createBean(beanDefinition); return bean; } } else { throw new NullPointerException(\u0026#34;沒有這個Bean\u0026#34;); } } }   接下來我們繼續回到WinterApplicationContext這個Constructor，我們已經把我們Package底下的Bean掃描完，放進beanDefinitionMap中，那我們接下來要依照這個Map，創建SINGLETON的bean，接著把SINGLETON的Bean放進singletonPool中，這個singletonPool也就是Spring中的單例池  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public WinterApplicationContext(Class configClass) { this.configClass = configClass; //解析配置類  // ComponentScan註解解析 -\u0026gt; 掃描路徑 -\u0026gt; 掃描 ---\u0026gt; BeanDefinition ---\u0026gt; BeanDefinitionMap  scan(configClass); for (String beanName : beanDefinitionMap.keySet()) { //遍整個beanDefinitionMap，找出單例的Bean，放進singletonPool中  BeanDefinition beanDefinition = beanDefinitionMap.get(beanName); //如果bean scope是單例，則放進單例池中  if(beanDefinition.getScope().equals(SINGLETON)){ Object bean = createBean(beanDefinition); singletonPool.put(beanName, bean); } } }   撰寫createBean方法會吃一個BeanDefinition為參數，這個方法會用BeanDefinition的Clazz創建一個Class，接著調用class底下的getDeclaredConstructor()取得建構子，並用newInstance()方法創造出一個那個bean的物件出來  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public Object createBean(BeanDefinition beanDefinition){ Class clazz = beanDefinition.getClazz(); try { Object instance = clazz.getDeclaredConstructor().newInstance(); return instance; } catch (InstantiationException e) { throw new RuntimeException(e); } catch (IllegalAccessException e) { throw new RuntimeException(e); } catch (InvocationTargetException e) { throw new RuntimeException(e); } catch (NoSuchMethodException e) { throw new RuntimeException(e); } }   到Main中，使用getBean來取得singletonpool中的Bean  1 2 3 4 5 6 7 8 9 10  public class Main { public static void main(String[] args) { WinterApplicationContext applicationContext = new WinterApplicationContext(AppConfig.class); System.out.println(\u0026#34;可以看到這三個的值是一模一樣的，代表這幾個物件都是同一個\u0026#34;); System.out.println(applicationContext.getBean(\u0026#34;userService\u0026#34;)); System.out.println(applicationContext.getBean(\u0026#34;userService\u0026#34;)); System.out.println(applicationContext.getBean(\u0026#34;userService\u0026#34;)); } }   這樣就是一個基礎的SprintBoot 單例池的創建\nAutowired之實現原理 To Be Continued \u0026hellip;\n","date":"2023-04-01T19:40:36+08:00","image":"https://i.imgur.com/1G2G1o4.png","permalink":"https://hoxtonhsu.com/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%AF%ABsprintboot%E6%A1%86%E6%9E%B6/","title":"手把手教你寫SprintBoot框架"},{"content":"SpringBoot中想要從Application.properties中取的值，有兩種常見的方式，其中一種是利用@Value的方式\n@Value 1 2  @Value(\u0026#34;${app.version}) String version   Enviroment 另一種則是透過 Enviroment物件來取的\n1 2 3 4 5  private final Environment env; public String getAppVersion() { return environment.getProperty(\u0026#34;app.version\u0026#34;); }   以取值的表現形式來看 在某些情形下，我們可能會從applicaiton.properties中取出一個陣列值，比如說\n1  language=en,zh,jp   這時如果使用Enviroment來取，取出來的值會一個String，需要再透過轉換，將它變為一個String\n1 2 3 4 5 6 7 8 9 10 11  @Autowired private Environment env; public String[] getMyArrayProperty() { String propertyValue = env.getProperty(\u0026#34;my.array.property\u0026#34;); if (propertyValue != null) { return propertyValue.split(\u0026#34;,\u0026#34;); } else { return new String[0]; } }   但如果用@Value的方式來取值，則可以在宣告變數時，聲明它是一個String或是一個String[]，避免後續的轉換\n1 2  @Value(\u0026#34;${language}\u0026#34;) private String[] myArray;   以單元測試角度來看 這兩個表現形式幾乎一模一樣，都可以取得想要的部分，但最大差別就在單元測試時，由於@Value這個取值方式有賴將整個SpringBoot專案啟動才可以注入，在單元測試的環境下並沒有辦法做到這件事情。但相反的，由於Environment本身屬於一個外部依賴，我們可以很好的替代掉他\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Service public class VersionService { Environment environment; public VersionService(Environment environment) { this.environment = environment; } public String getEunoExAppVersion() { return environment.getProperty(\u0026#34;eunoex.version\u0026#34;); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14  @ExtendWith(MockitoExtension.class) class VersionServiceTest { @Mock Environment environment; @InjectMocks VersionService versionService; @Test void getAppVersion_everythingFine_returnSuccessfully() { given(environment.getProperty(any())).willReturn(\u0026#34;v1.2.0\u0026#34;); String ExAppVersion = versionService.getAppVersion(); System.out.println(\u0026#34;AppVersion = \u0026#34; + AppVersion); } }   大概Guy4這樣\n","date":"2023-03-24T01:41:57Z","image":"https://i.imgur.com/UDvSvgw.png","permalink":"https://hoxtonhsu.com/p/%E8%AB%96value%E8%88%87environment%E4%B9%8B%E5%84%AA%E5%8A%A3/","title":"論@Value與Environment之優劣"},{"content":"安裝window terminal 至Microsoft Store安裝window terminal\n安裝Cmder Cmder載點\n並將它解壓縮後放置\n%USERPROFILE%/AppData/Roaming\n中\n也就是\nC:\\Users\\you_userName\\AppData\\Roaming\n設定環境變數 接著設定環境變數\n1 2  變數名稱：CMDER_ROOT 變數值：%USERPROFILE%/AppData/Roaming/cmder   1 2  變數名稱：ConEmuDir 變數值：%USERPROFILE%/AppData/Roaming/cmder/vendor/conemu-maximus5   設定window Termianl\n打開設定\n按左下角的開啟JSON檔案\n將下列這段貼上至JSON檔中的這個位置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;background\u0026#34;: \u0026#34;#2E3436\u0026#34;, \u0026#34;commandline\u0026#34;: \u0026#34;cmd.exe /k %CMDER_ROOT%\\\\vendor\\\\init.bat\u0026#34;, \u0026#34;font\u0026#34;: { \u0026#34;face\u0026#34;: \u0026#34;Cascadia Code\u0026#34;, \u0026#34;size\u0026#34;: 10.0 }, \u0026#34;guid\u0026#34;: \u0026#34;{6d953325-a939-475d-a151-940cbd0302fb}\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;%CMDER_ROOT%\\\\icons\\\\cmder.ico\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Cmder\u0026#34;, \u0026#34;padding\u0026#34;: \u0026#34;15\u0026#34;, \u0026#34;startingDirectory\u0026#34;: \u0026#34;%USERPROFILE%/Desktop\u0026#34; }   就像這樣子\n接著重開window terminal就可以囉~\n","date":"2023-03-21T10:40:57+08:00","image":"https://i.imgur.com/l3t70N4.png","permalink":"https://hoxtonhsu.com/p/%E5%9C%A8window-terminal%E4%B8%AD%E4%BD%BF%E7%94%A8cmder/","title":"在window Terminal中使用Cmder"},{"content":"前情提要 最近在學習zabbix時，安裝在Linux系統下時，透過Postman是可以正常取得資料的\n但是當我用Docker把Zabbix架設在Window環境下時卻一直出現\n1  File not found.   的錯誤\n發現錯誤 兩邊的版本、設置、Server Port都一樣，完全不知道到底發生了什麼問題，後來是透過網頁的開發人員工具才發現一小處的不同\n這是Linux環境下的API請求\n這是Window下的API請求\n聰明的你一定發現了，肏你媽的這兩個API請求的URL完全不一樣啊，幹你媽的\n解決方法 我個人猜應該是Docker在部屬的時候，不知道為什麼裡面檔案的結構層級直接跳過了\\zabbix這一層，直接變成http://localhost/api_jsonrpc.php的路徑。\n將URL改成正確地之後就能正常訪問了\n","date":"2023-03-16T06:41:23Z","image":"https://i.imgur.com/AP3wJLN.png","permalink":"https://hoxtonhsu.com/p/%E4%BD%BF%E7%94%A8docker%E5%9C%A8window%E6%9C%83%E5%87%BA%E7%8F%BE%E7%9A%84file-not-found%E5%95%8F%E9%A1%8C/","title":"使用Docker在window會出現的File Not Found問題"},{"content":"如果依照存在即合理的說法來看，Switch的存在確實是有解決一些問題，比如說一些要依照不同情況來回傳不同結果的Function，相較於用冗長的if-else，選擇用Switch確實是個不錯的解法。但當今天的Switch Case會增長的情況，在選擇使用它就會違反了OCP(開放擴充、封閉修改)的原則，亦即每次有新的情況出現，我們就得回頭去改Switch語法，新增不同的case，一來一往增加了維護的負擔，這邊分享一個我把switch語法拆解的方式，以供紀錄這樣子。\n情境 我在設計一款可以連結不同SQL Engine的程式，當用戶選擇了不同的SQL Engine，我能夠執行不同資料庫的語法來返回結果，圖示如下\n修改前 這是我的設計\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @RestController public class DatasourceController { DatabaseService databaseService; public DatasourceController(DatabaseService databaseService) { this.databaseService = databaseService; } @GetMapping(\u0026#34;/query\u0026#34;) public String query(@RequestBody QueryRequest queryRequest) throws SQLException, JsonProcessingException, ClassNotFoundException { return databaseService.query(queryRequest); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  @Service public class DatabaseServiceImp implements DatabaseService{ DatabaseDao databaseDao; public DatabaseServiceImp(DatabaseDao databaseDao) { this.databaseDao = databaseDao; } @Override public String query(QueryRequest queryRequest) throws SQLException, JsonProcessingException, ClassNotFoundException { String databaseName = queryRequest.getDatabaseEngine(); databaseDao = getDatabaseDao(databaseName); return databaseDao.connect().query(queryRequest.getQuery()); } private DatabaseDao getDatabaseDao(String databaseName) { switch (databaseName){ case \u0026#34;Postgres\u0026#34;: return new PostgresDaoImpl(); case \u0026#34;MsSql\u0026#34;: return new MySQLDaoImpl(); default: throw DatabaseNotFoundException.createDatabaseNotFoundException(\u0026#34;Not this Database\u0026#34;); } } }   1 2 3 4 5 6 7 8 9 10 11  @Repository public interface DatabaseDao { DatabaseDao connect() throws SQLException, ClassNotFoundException; void close() throws SQLException; String query(String query) throws SQLException, JsonProcessingException; }   我在Service層的地方會有一個methodgetDatabaseDao，來依照輸入的databaseName來將不同的Dao賦值進filed中，首先這有兩個問題\n 當資料庫在擴充時，必須要回頭修改getDatabaseDao，增加修改的成本 無法利用SpringBean的IoC，每次有新的Request近來，都會創造一個Dao的Object存在於記憶體中，造成記憶體空間的浪費  修改後 因此後來的修改必須得改善上面兩點，必須要符合OCP的規則，我只要新增新的Dao，而毋需修改就有的程式碼，並且還要使用SpringBean，以下是修改後的版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  @Service public class DatabaseServiceImp implements DatabaseService { DatabaseEngineDao databaseEngineDao; List\u0026lt;DatabaseEngineDao\u0026gt; databaseDaoList; public DatabaseServiceImp(List\u0026lt;DatabaseEngineDao\u0026gt; databaseDaoList) { this.databaseDaoList = databaseDaoList; } @Override public String query(QueryRequest queryRequest) throws SQLException, JsonProcessingException, ClassNotFoundException { String databaseName = queryRequest.getDatabaseEngine(); databaseEngineDao = getDatabaseDao(databaseName); return databaseEngineDao.connect().query(queryRequest.getQuery()); } private DatabaseEngineDao getDatabaseDao(String databaseEngine) { for (DatabaseEngineDao databaseDao : databaseDaoList) { if (databaseEngine.equals(databaseDao.getDatabaseEngineName())) { return databaseDao; } } throw DatabaseNotFoundException.createDatabaseNotFoundException(\u0026#34;Not Found This DatabaseEngine，請檢查是否有相應的databaseEngineName在DAO中\u0026#34;); } }   1 2 3 4 5 6 7 8  @Repository public interface DatabaseEngineDao { DatabaseEngineDao connect() throws SQLException; void close() throws SQLException; String query(String query) throws SQLException, JsonProcessingException; public String getDatabaseEngineName(); }   將原本的DatabaseDao databaseDao;修改為，List\u0026lt;DatabaseEngineDao\u0026gt; databaseDaoList;，在SpringBoot啟動時，將所有的DatabaseEngineDao類配置進databaseDaoList中，讓springBoot控制object的創建，並且將getDatabaseDao改寫，改成去for-each databaseDaoList，尋找List中是否有名稱符合的SQL Engine。並在DatabaseEngineDao Interface處新增getDatabaseEngineName，讓每個實作它的Impl都必須去完成這個method，完成了OCP的原則。\n","date":"2023-03-14T00:31:03+08:00","image":"https://i.imgur.com/rfkvgRO.png","permalink":"https://hoxtonhsu.com/p/%E9%81%8B%E7%94%A8arraylist%E8%88%87%E8%87%AA%E5%8B%95%E9%85%8D%E7%BD%AE%E5%B0%87swich%E8%AA%9E%E6%B3%95%E6%8B%86%E8%A7%A3/","title":"運用ArrayList與自動配置將Swich語法拆解"},{"content":"參考網址：監控大挑戰 - 以 Zabbix 為例\n為什麼選擇Zabbix? 目前常見的監控軟體有三者\n Zabbix Cacti Nagios  NagiOs的介面 Cacti的介面 Zabbix的介面    監控產品 Zabbix Nagios Cacti     圖形介面 好看 不是特別好 還行   監控性能 併發監控，對CPU要求較高 併發監控，對CPU要求較高 輪詢監控，效能低   配置難度 較低，有圖形化介面使用 需使用CommandLine 需使用CommandLine   自動發現 支持 不支持 不支持   異常通知方式 Email,簡訊,webhook,Line\u0026hellip; Email,簡訊,webhook,Line\u0026hellip; 較弱，預設只支援Email    Zabbix是什麼 Zabbix是一種開源的網絡監視和警報系統，用於監視各種網絡設備，包括服務器、網絡設備和應用程序等。Zabbix提供了一個可擴展的架構，可用於監視多個位置的數千個設備。\nZabbix支持各種監視方式，包括SNMP、JMX、IPMI和VMware監視，還可以通過自定義監視腳本進行擴展。Zabbix還提供了一個強大的報警系統，可以通過電子郵件、SMS和其他方式發送警報，以便快速解決問題。\nZabbix還提供了一個用戶友好的Web界面，可以輕鬆設置監視器和警報。Zabbix的開源設計使其成為一個非常有用的監視解決方案，可以滿足各種規模的企業和組織的需求\nZabbix術語 Zabbix Server\n Zabbix server是agent程序報告系統可用性、系統完整性和統計數據的核心組件，是所有配置訊息、統計訊息和操作數據的核心儲存器  Zabbix資料庫存取\n 所有配置訊息和Zabbix收集到的數據都被儲存在資料庫中  Zabbix Web介面\n 為了從任何地方和任何平台都可以輕鬆地訪問Zabbix，我們提供基於Web的Zabbix介面，該介面是Zabbix Server的一部分，通常(但不一定)跟Zabbix Server運行在同一台物理主機上  Zabbix Proxy 代理服務器\n Zabbix Proxy可以替Zabbix Server收集性能和可用性數據。Proxy代理服務器是Zabbix軟體可選擇部屬的一部分，當然，Proxy代理服務器可以幫助單台Zabbix Server分擔負載壓力  Zabbix Agent 監控代理\n Zabbix agent 監控代理，部屬在監控目標上，能夠主動間空本地資源和應用程序，並將收集到的數據報告給Zabbix Server  Zabbix數據流\n 監控方面，為了創造一個監控項(item)用於採集數據，必須先創建一個主機(host) 告警方面，在監控項裡面創造觸發器(trigger)，通過觸發器(trigger)來觸發告警動作(action)。因此如果你想收到Server XCPU負載過高的告警，必須滿足   為Server X創建一個Host並關聯一個用對CPU進行監控的監控項(item) 創建一個Trigger，設置成當CPU負載過高時會觸發 Trigger被觸發，發送告警郵件  雖然看起來有很多步驟，但是使用模板的話操作起來其實非常簡單，Zabbix這樣的設計使得配置機制非常靈活易用\n主機(Host)\n 一台你想監控的網路設備，用IP和域名表示  主機組(host Group)\n 主機的邏輯組；包含了主機和模板。一個主機裡的主機和模板之間並沒有任何直接的關聯，通常在給不同用戶組的主機分配權限時，使用主機組  監控項(item)\n 你想要接收的主機的特定數據，一個度量數據  觸發器(Trigger)\n 一個被用於定義問題閾值和\u0026quot;評估\u0026quot;監控項接受到的數據的邏輯表達式，當接收到的數據高於閾值時，觸發器從OK變成Problem狀態。當接收到的數據低於閾值時，觸發器保留/返回一個OK的狀態  事件(Event)\n 單次發生的需要注意的事情，例如觸發器狀態改變，或是發現有監控代理自動註冊  異常(Problem)\n 一個處在異常狀態的觸發器  動作(Action)\n 一個對事件做出反應的預定義的操作 一個動作由操作(例如發出通知)和條件(當時操作正在發生)組成  升級(Escalation)\n 一個在動作內執行操作的自定義場景；發生通知／執行遠程命令的序列  媒介(Media)\n 發送告警通知的手段；告警通知的途徑  通知(Notification)\n 利用已選擇的媒體途徑把跟事件相關的訊息發送給用戶  遠程命令(remote command)\n 一個預定義好的，滿足一些條件的情況下，可以在被監控主機上自動執行的命令  模板(template)\n 一組可以被應用到一個或多個主機上的實體(監控項、觸發器、圖形、聚合圖形、應用、LLD、Web場景)的集合 模板的任務就是加快對主機監控任務的實施；也可以使監控任務的批量修改更簡單。模板是直接關連到每台單獨的主機上  應用(Application)\n 一組監控項組成的邏輯分組  Web場景(Web Scenario)\n 利用一個或多個HTTP請求來檢查網站的可用性  前端(FrontEnd)\n Zabbix提供的Web介面  Zabbix API\n Zabbix API允許你使用JSON RPC協議(是一個無狀態且輕量級的遠程過程調用Remote Procedure Call 傳送協議，其傳遞內容透過JSON為主)來創建、更新和獲取Zabbix對象(如主機、監控項、圖形和其他)信息或者執行任何其他的字定義的任務  Zabbix Server\n Zabbix軟件實現監控的核心程序，主要功能是與Zabbix proxies和Agents進行交互、觸發器計算、發送告警通知、並將資料集中保存  Zabbix Agent\n 一個部屬在監控對象上的，能夠主動監控本地資源和應用的程序 Zabbix Agent部屬在監控的目標上，主動監測本地的資源和應用(硬體驅動、記憶體、處理器統計等等) Zabbix Agent收集本地的操作訊息並將資料報告給Zabbix Server用於進一步處理。一旦出現異常(比如硬碟空間已滿或者有崩潰的服務器Process)，Zabbix Server會主動警告管理員指定機器上的異常。Zabbix Agents的極端高校源於他可以利用本地系統調用來完成統計數據的收集  被動(Passive) 和 主動(Active)檢查\n Zabbix Agent可以執行被動和主動兩種檢查方式   被動檢查(Passive Check)模式中Agent應答數據請求，Zabbix Server(或者Proxy)詢問Agent資料，如CPU負仔狀況，然後Zabbix Agent回傳結果 主動檢查(Active Checks) 處理過程將相對複雜。Agent必須首先從Zabbix server索取監控項列表以進行獨立處理，然後週期性的發送新的值給Server  執行被動或主動檢查是通過選擇相應的監測項目類型來配置的。Item Type. Zabbix Agent處理監控項類型有Zabbix agent和 Zabbix Agent(Active)\nZabbix Proxy\n 一個幫助Zabbix server收集數據，分擔Zabbix Server負擔的程式 Zabbix Proxy是一個可以從一個或多個受監控設備收集監控數據，並將訊息結果發送到Zabbix Server的Process，基本上是代表Server工作的。所有收集的數據都在本地進行快取，然後傳送到Proxy所屬的Zabbix Server。 部屬Proxy是可選的，但是可能會非常有益於分散單個Zabbix Sever的負載，如果只有Proxy收集數據，Server上的進程就會減少，CPU消耗和磁碟I/O負載 Zabbix Proxy是完成遠端區域，分支機構，沒有本地管理員的網路集中監控的理想解決方案 Zabbix Proxy需要使用獨立的資料庫  使用Docker安裝 Zabbix 首先先點到下列網站 https://www.zabbix.com/documentation/5.0/en/manual/installation/containers\n並在這邊選擇要使用的版本 這次是使用官網提供的，也就是用mysql當database的版本\n並按照下列的cmd指令輸入，下面的參數，若有需要變可以在自行修改\n1  docker network create --subnet 172.20.0.0/16 --ip-range 172.20.240.0/20 zabbix-net    1  docker run --name postgres-server -t -e POSTGRES_USER=\u0026#34;zabbix\u0026#34; -e POSTGRES_PASSWORD=\u0026#34;zabbix_pwd\u0026#34; -e POSTGRES_DB=\u0026#34;zabbix\u0026#34; --network=zabbix-net --restart unless-stopped -d postgres:latest    1  docker run --name zabbix-snmptraps -t -v /zbx_instance/snmptraps:/var/lib/zabbix/snmptraps:rw -v /var/lib/zabbix/mibs:/usr/share/snmp/mibs:ro --network=zabbix-net -p 162:1162/udp --restart unless-stopped -d zabbix/zabbix-snmptraps:alpine-5.0-latest    1  docker run --name zabbix-server-pgsql -t -e DB_SERVER_HOST=\u0026#34;postgres-server\u0026#34; -e POSTGRES_USER=\u0026#34;zabbix\u0026#34; -e POSTGRES_PASSWORD=\u0026#34;zabbix_pwd\u0026#34; -e POSTGRES_DB=\u0026#34;zabbix\u0026#34; -e ZBX_ENABLE_SNMP_TRAPS=\u0026#34;true\u0026#34; --network=zabbix-net -p 10051:10051 --volumes-from zabbix-snmptraps --restart unless-stopped -d zabbix/zabbix-server-pgsql:alpine-5.0-latest    1  docker run --name zabbix-web-nginx-pgsql -t -e ZBX_SERVER_HOST=\u0026#34;zabbix-server-pgsql\u0026#34; -e DB_SERVER_HOST=\u0026#34;postgres-server\u0026#34; -e POSTGRES_USER=\u0026#34;zabbix\u0026#34; -e POSTGRES_PASSWORD=\u0026#34;zabbix_pwd\u0026#34; -e POSTGRES_DB=\u0026#34;zabbix\u0026#34; --network=zabbix-net -p 443:8443 -p 80:8080 -v /etc/ssl/nginx:/etc/ssl/nginx:ro --restart unless-stopped -d zabbix/zabbix-web-nginx-pgsql:alpine-5.0-latest   透過termianl訪問Container中的資料庫，以psql為例 1  docker exec -it [containerId] bash    1  psql -U zabbix -h localhost zabbix   當全部都設置好後\n訪問 http://localohst/ 即可訪問Zabbix頁面\n帳號：Admin 密碼：zabbix\n在Window下安裝 Zabbix Agent 這邊待補啦，不過先講一下Zabbix的Server端要怎麼對應\n​\tHost Name：要和當初設定Agent的Name一致\nGroup：Templates/Operating systems\nAgent：當Agent的那一台主機的IP\nTemlate：Template OS Windows by Zabbix agent\nAPI的使用 可以到下列的網站使用線上的Zabbix API Test\nhttps://sbcode.net/zabbix/zabbix-api-test-form/\nurl都是 http://localhost/api_jsonrpc.php，差別在於Body的內容\n測試用API，用以返回版本號 1 2 3 4 5 6 7  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;apiinfo.version\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;auth\u0026#34;: null, \u0026#34;params\u0026#34;: {} }   返回的結果\n1 2 3 4 5  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;5.0.32\u0026#34;, \u0026#34;id\u0026#34;: 1 }   登入用的API，用來取得Token 1 2 3 4 5 6 7 8 9 10  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;user.login\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;Admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;zabbix\u0026#34; }, \u0026#34;id\u0026#34;: 1, \u0026#34;auth\u0026#34;: null }   返回的結果\n1 2 3 4 5  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;1a6022b1a01b787b2129d011763c73e6\u0026#34;, \u0026#34;id\u0026#34;: 1 }   result就是Token值\n返回目前存在的Agent 記得把Auth的值改成login返回的token\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;host.get\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;output\u0026#34;: [ \u0026#34;hostid\u0026#34;, \u0026#34;host\u0026#34; ], \u0026#34;selectInterfaces\u0026#34;: [ \u0026#34;interfaceid\u0026#34;, \u0026#34;ip\u0026#34; ] }, \u0026#34;id\u0026#34;: 2, \u0026#34;auth\u0026#34;: \u0026#34;1a6022b1a01b787b2129d011763c73e6\u0026#34; }   返回的結果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: [ { \u0026#34;hostid\u0026#34;: \u0026#34;10084\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Zabbix server\u0026#34;, \u0026#34;interfaces\u0026#34;: [ { \u0026#34;interfaceid\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;127.0.0.1\u0026#34; } ] }, { \u0026#34;hostid\u0026#34;: \u0026#34;10438\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Ian\u0026#34;, \u0026#34;interfaces\u0026#34;: [ { \u0026#34;interfaceid\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;192.168.100.51\u0026#34; } ] }, { \u0026#34;hostid\u0026#34;: \u0026#34;10440\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Bill\u0026#34;, \u0026#34;interfaces\u0026#34;: [ { \u0026#34;interfaceid\u0026#34;: \u0026#34;4\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;192.168.100.57\u0026#34; } ] }, { \u0026#34;hostid\u0026#34;: \u0026#34;10439\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Jess\u0026#34;, \u0026#34;interfaces\u0026#34;: [ { \u0026#34;interfaceid\u0026#34;: \u0026#34;3\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;192.168.100.51\u0026#34; } ] } ], \u0026#34;id\u0026#34;: 2 }   Zabbix API介紹 https://sbcode.net/zabbix/zabbix-api-test-form/\n在很多的API Parameter中，會常常看到\n1  {\u0026#34;output\u0026#34;: \u0026#34;extend\u0026#34;}   這段。這句話的意思是這樣的 output代表你想要返回的value值有什麼下面會有詳細的介紹 而extend則代表「請提供給我，更多的資訊」，詳細的差異如下\n我們假設 host.get的返回值為下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: [ { \u0026#34;hostid\u0026#34;: \u0026#34;10084\u0026#34;, \u0026#34;proxy_hostid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Zabbix server\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;disable_until\u0026#34;: \u0026#34;1679972679\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;Get value from agent failed: cannot connect to [[127.0.0.1]:10050]: [111] Connection refused\u0026#34;, \u0026#34;available\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;errors_from\u0026#34;: \u0026#34;1679019319\u0026#34;, \u0026#34;lastaccess\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;ipmi_authtype\u0026#34;: \u0026#34;-1\u0026#34;, \u0026#34;ipmi_privilege\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;ipmi_username\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ipmi_password\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ipmi_disable_until\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;ipmi_available\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;snmp_disable_until\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;snmp_available\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;maintenanceid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;maintenance_status\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;maintenance_type\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;maintenance_from\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;ipmi_errors_from\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;snmp_errors_from\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;ipmi_error\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;snmp_error\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jmx_disable_until\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;jmx_available\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;jmx_errors_from\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;jmx_error\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Zabbix server\u0026#34;, \u0026#34;flags\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;templateid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;tls_connect\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;tls_accept\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;tls_issuer\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;tls_subject\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;tls_psk_identity\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;tls_psk\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;proxy_address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;auto_compress\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;inventory_mode\u0026#34;: \u0026#34;-1\u0026#34; } ], \u0026#34;id\u0026#34;: 2 }   但我們並不想要那麼多資訊，我們可能只想要其中幾項，比如說proxy_hostid,status而已，那我們就可以把我們Parameters的參數修改成這樣\n1  {\u0026#34;output\u0026#34;: [\u0026#34;hostid\u0026#34;,\u0026#34;proxy_hostid\u0026#34;]}   回傳的結果就會變成這樣 使用Zabbix來取得CPU Utilization (in %)  先使用host.get來取得所有host資訊  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;host.get\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;output\u0026#34;: [ \u0026#34;hostid\u0026#34;, \u0026#34;host\u0026#34; ], \u0026#34;selectInterfaces\u0026#34;: [ \u0026#34;interfaceid\u0026#34;, \u0026#34;ip\u0026#34; ] }, \u0026#34;id\u0026#34;: 2, \u0026#34;auth\u0026#34;: \u0026#34;7cdc68d62750b0ed7ae693d1d7a52466\u0026#34; }   返回的結果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: [ { \u0026#34;hostid\u0026#34;: \u0026#34;10084\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Zabbix server\u0026#34;, \u0026#34;interfaces\u0026#34;: [ { \u0026#34;interfaceid\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;127.0.0.1\u0026#34; } ] }, { \u0026#34;hostid\u0026#34;: \u0026#34;10438\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Ian\u0026#34;, \u0026#34;interfaces\u0026#34;: [ { \u0026#34;interfaceid\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;192.168.100.51\u0026#34; } ] }, { \u0026#34;hostid\u0026#34;: \u0026#34;10440\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;Bill\u0026#34;, \u0026#34;interfaces\u0026#34;: [ { \u0026#34;interfaceid\u0026#34;: \u0026#34;4\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;192.168.100.57\u0026#34; } ] } ], \u0026#34;id\u0026#34;: 2 }   透過item.get取得hostId的資料  假設我們現在要找到hostId=10440的資料，我們的API BODY要這樣送\n1 2 3 4 5 6 7 8 9 10 11 12  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;item.get\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;output\u0026#34;:[\u0026#34;name\u0026#34;,\u0026#34;description\u0026#34;,\u0026#34;lastvalue\u0026#34;], \u0026#34;filter\u0026#34;:{ \u0026#34;hostid\u0026#34;:\u0026#34;10440\u0026#34; } }, \u0026#34;id\u0026#34;: 2, \u0026#34;auth\u0026#34;: \u0026#34;7cdc68d62750b0ed7ae693d1d7a52466\u0026#34; }   其中 output的值代表，只顯示name,description,lastvalue這幾個key的資料，filter則代表我只要key-value為hostid:10440的資料\n返回的結果很長，這邊講個大概就好\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: [ { \u0026#34;itemid\u0026#34;: \u0026#34;37631\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Interface Intel(R) Ethernet Connection (14) I219-V(乙太網路): Outbound packets with errors\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The number of outgoing packets with errors on the network interface.\u0026#34;, \u0026#34;lastvalue\u0026#34;: \u0026#34;0\u0026#34; }, { \u0026#34;itemid\u0026#34;: \u0026#34;37632\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Interface Intel(R) Ethernet Connection (14) I219-V(乙太網路): Inbound packets discarded\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The number of incoming packets dropped on the network interface.\u0026#34;, \u0026#34;lastvalue\u0026#34;: \u0026#34;0\u0026#34; }, { \u0026#34;itemid\u0026#34;: \u0026#34;37633\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Interface Intel(R) Ethernet Connection (14) I219-V(乙太網路): Inbound packets with errors\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The number of incoming packets with errors on the network interface.\u0026#34;, \u0026#34;lastvalue\u0026#34;: \u0026#34;0\u0026#34; }, { \u0026#34;itemid\u0026#34;: \u0026#34;37634\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Interface Intel(R) Ethernet Connection (14) I219-V(乙太網路): Bits received\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Incoming traffic on the network interface.\u0026#34;, \u0026#34;lastvalue\u0026#34;: \u0026#34;6431168\u0026#34; } ... //以下略.. }   找到CPU Utilization的資訊  搜尋關鍵字 CPU\n這邊，那個lastValue其實就是最新的CPU使用率，這樣就成功取得CPU的使用率囉！\n取得CPU Utilization的使用率  API Body如下\n1 2 3 4 5 6 7 8 9 10 11  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;history.get\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;history\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;itemids\u0026#34;: \u0026#34;37631\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;extend\u0026#34; }, \u0026#34;auth\u0026#34;: \u0026#34;7cdc68d62750b0ed7ae693d1d7a52466\u0026#34;, \u0026#34;id\u0026#34;: 1 }   返回的結果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: [ { \u0026#34;itemid\u0026#34;: \u0026#34;37568\u0026#34;, \u0026#34;clock\u0026#34;: \u0026#34;1679900528\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;5.186729\u0026#34;, \u0026#34;ns\u0026#34;: \u0026#34;297585693\u0026#34; }, { \u0026#34;itemid\u0026#34;: \u0026#34;37568\u0026#34;, \u0026#34;clock\u0026#34;: \u0026#34;1679900648\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;6.917095\u0026#34;, \u0026#34;ns\u0026#34;: \u0026#34;233421931\u0026#34; } // ... 略 ] }   使用Docker安裝，可能導致API路徑不正確 最近在學習zabbix時，安裝在Linux系統下時，透過Postman是可以正常取得資料的\n但是當我用Docker把Zabbix架設在Window環境下時卻一直出現\n1  File not found.   的錯誤\n發現錯誤 兩邊的版本、設置、Server Port都一樣，完全不知道到底發生了什麼問題，後來是透過網頁的開發人員工具才發現一小處的不同\n這是Linux環境下的API請求\n這是Window下的API請求\n聰明的你一定發現了，肏你媽的這兩個API請求的URL完全不一樣啊，幹你媽的\n解決方法 我個人猜應該是Docker在部屬的時候，不知道為什麼裡面檔案的結構層級直接跳過了\\zabbix這一層，直接變成http://localhost/api_jsonrpc.php的路徑。\n將URL改成正確地之後就能正常訪問了\n","date":"2023-03-13T05:40:02Z","image":"https://i.imgur.com/7g77ZiN.png","permalink":"https://hoxtonhsu.com/p/zabbix%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AD%86%E8%A8%98/","title":"Zabbix的一些筆記"},{"content":"介紹 PicGo是個開源的圖片上傳程式(並非平台)，由於設定快速，效果簡單而深受我的喜愛，決定寫一篇文章來介紹這東西該怎麼使用\n安裝 我們使用Choco來安裝，Choco是一個Window系統的檔案下載工具，可以做類似npm的功能，以下是它的安裝方式。\n使用系統管理員執行CMD，並輸入以下的指令\n1  Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://community.chocolatey.org/install.ps1\u0026#39;))   即下載成功，若下載成功，可以輸入\n1  choco --version   來查看是否安裝成功\n若Choco安裝沒問題，則可以透過以下指令安裝picGo，若跳出什麼無法存取，則請記得要使用系統管理員身分執行\n1  choco install picgo   使用 我有點懶得打，就錄成Gif了，這邊其實就是去Imgur的\nhttps://imgur.com/account/settings/apps\n這邊，去設定你的一個ClinetId\n然後把它貼到設定ClinetId那一欄就可以\n並且我也會推薦將上傳的快捷鍵調成Ctrl+Alt+V\n這樣當你按下Win+Shift+S，截圖後，只要按下Ctrl+Alt+V，圖片就會自動幫你上傳至Imgur囉\n","date":"2023-03-08T20:56:55+08:00","image":"https://i.imgur.com/teYQFXk.png","permalink":"https://hoxtonhsu.com/p/%E5%8F%AA%E8%A6%81%E6%8C%89%E5%80%8B%E9%8D%B5%E5%9C%96%E7%89%87%E7%AB%8B%E5%88%BB%E4%B8%8A%E5%82%B3%E8%87%B3%E9%9B%B2%E7%AB%AF-picgo%E4%BB%8B%E7%B4%B9/","title":"只要按個鍵，圖片立刻上傳至雲端 PicGo介紹"},{"content":"前言 每次在新電腦上使用Git的時候都會跳這個東西出來，但一直不知道這是啥，這次來研究一下\n總結 這東西其實是因為如果要推東西上去或是拉Private專案下來的話，會需要做認證(Credential)的部分，而這個視窗其實就是在問你，你所提供的這些登入資訊想存在哪邊?\n會建議就用預設的manager-core就好，如果想存在磁碟中的話就選store，如果想存在Cache就選cache 這樣就可以囉\n如果已經存了，那可以輸入以下的指令來調整\n 查看目前的credential.helper 是什麼  1  git config credential.helper    將credential.helper 的設定改掉  1  git config --global credential.helper manager-core    設定帳號密碼  由於自2021年後，GitHub不在提供使用帳號密碼的認證方式，要使用Token進行認證，帳號輸入自己的Github帳號，而密碼則是輸入自己的Token，這樣就設定成功囉！\n","date":"2023-03-08T20:48:18+08:00","image":"https://i.imgur.com/PFJUZO4.png","permalink":"https://hoxtonhsu.com/p/git%E5%9C%A8%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8%E7%9A%84credentialhelperselector%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%A8%AD%E5%AE%9A%E5%91%A2/","title":"Git在第一次使用的credentialhelperselector該怎麼設定呢"},{"content":"參考網站\n這篇文章是以Postgres SQL的語法為主，其他RDB的語法略有不同\n什麼是Store Procedure 預存程序（Stored Procedure）是一種資料庫對象，它是一個預編譯的SQL程式碼，可以在資料庫中存儲並重複使用。它通常由一系列SQL語句和編程邏輯組成，可以接受輸入參數、返回輸出參數和結果集。存儲過程通常由數據庫管理員或開發人員編寫和維護，並且可以在數據庫中執行。\n存儲過程有以下幾個優點：\n 提高了數據庫性能：存儲過程是預編譯的，一旦編譯就會存儲在數據庫中，執行速度快。此外，存儲過程可以減少客戶端與服務器之間的通信，從而降低網絡延遲，提高數據庫性能。 提高了數據安全性：存儲過程可以在數據庫層面上實現安全控制，可以限制某些用戶或角色的操作權限，從而保證數據的安全性。 代碼復用：存儲過程可以被多個應用程序或者腳本重複調用，從而實現代碼復用，減少重複編寫代碼的時間和工作量。 事務處理：存儲過程可以封裝事務處理邏輯，當多個SQL語句需要在一個事務中執行時，可以使用存儲過程將它們封裝在一個事務中，從而保證了數據的一致性和完整性。 簡化了複雜的操作：存儲過程可以將多個SQL語句組合成一個操作，從而簡化了複雜的操作，使得應用程序更易於開發和維護。  存儲過程可以實現很多功能，比如：\n 數據庫的備份和還原 數據庫的複製和同步 數據庫的日誌記錄和監控 數據庫的查詢優化 數據庫的數據加密和解密 數據庫的數據清洗和轉換 數據庫的業務邏輯實現 數據庫的存儲和檢索過程中的錯誤處理 數據庫的報表生成和匯出等。  Procedure與Function之差異 在PostgreSQL中，function和procedure都是儲存運算邏輯的物件，它們在設計目的和使用方式上略有不同。\nFunction主要是用於執行一個特定的計算或邏輯，返回一個單一的值或一個結果集，並且可以在SELECT語句、WHERE語句等中使用。Function可以返回一個或多個結果集，但只能返回一個值作為輸出，因此它被稱為有返回值的Function。\nProcedure主要用於執行一連串的操作，不返回結果集，通常是用來執行複雜的業務邏輯，如事務處理、資料庫管理等。Procedure可以執行INSERT、UPDATE、DELETE等數據操作，但是不能作為SELECT語句的一部分使用。Procedure不返回任何值或結果集，因此它被稱為無返回值的Procedure。\n在設計時，需要根據實際需求選擇使用哪種物件。如果需要執行一個特定的計算或邏輯，並返回一個結果集，則使用Function。如果需要執行一連串的操作並且不需要返回結果集，則使用Procedure。\n更直接的不同是，Procedure並沒有定義它自身的回傳值，連Returns void都沒有，而Function是有回傳值的，即使是Returns Void也是有回傳值\n創建procedure的語法 1 2 3 4 5 6 7  create or replace function test() LANGUAGE plpgsql AS $$ BEGIN END $$;   若加入RETURNS VOID則會回報錯誤\n創建Function的語法 1 2 3 4 5 6 7  create or replace function test() LANGUAGE plpgsql AS $$ BEGIN END $$;   若不指定回傳值，則會報錯誤function result type must be specified\n定界符$$ (delimiter) 在SQL中，兩個美元符號（$$）用來定義一個區塊或一個標識符（identifier）。\n例如，可以使用$$來.定義一個存儲過程或函數的主體。在$$之間的所有內容都被視為存儲過程或函數的主體，可以包含SQL語句、流程控制語句等。\n另外，$$還可以用來定義一個標識符，例如，可以使用$$來定義一個變量或一個標識符的名稱。在$$之間的所有內容都被視為標識符的名稱，可以包含字母、數字和下劃線等字符。使用$$定義標識符時，可以幫助區分保留字和自定義的標識符，以及避免標識符中包含空格等特殊字符所帶來的問題。\n1 2 3 4 5 6 7 8  CREATE FUNCTION myfunc(x INT, y INT) RETURNS INT AS $$ BEGIN RETURN x + y; END; $$ LANGUAGE plpgsql; -- 在這個例子中，$$ 用來定義函數的主體。CREATE FUNCTION 指令創建了一個名為 myfunc 的函數，它接受兩個整數參數 x 和 y，返回它們的和。 RETURN 指令用於返回函數的值。  -- 在這裡，$ 用作定界符，它定義了函數的主體。如果不使用定界符，則在函數主體中使用分號 ; 可能會導致錯誤。使用定界符可以幫助區分不同的 SQL 區塊，從而更好地組織和管理 SQL 代碼。   使用Terminal操作Postgres SQL 有兩種方式，一種是用psql的Shell，另一種則是用powershell\n使用psql的Shell 打開psql\n輸入相應的資訊\n使用powerShell 首先先下載Postgres SQL，接著在把環境變數加入至電腦中，路徑大概會如下\n1  C:\\ProgramFiles\\PostgreSQL\\14\\bin   即可在Termianl中操作postgres SQL\n如以下指令\n查看當前Psql有什麼Database 1  psql -l   連結進入Database 1 2 3 4 5 6  psql [dbname] psql -U [role] [dbname] # 以 postgres 的 role 登入 postgres 的 database psql -U postgres # 使用 postgres 的 role 登入 的 postgres 這個 database psql -U aaronchen minicare_demo # 以 aaronchen 的 role 登入 minicare_demo 這個 database psql -U postgres -d minicare_demo   1 2  psql -h localhost -p 5432 -U postgres school ## psql -h localhost -p 5432 -U \u0026lt;your_username\u0026gt; \u0026lt;your_database\u0026gt;   (與之對應的Server設定)\n連結成功後的畫面 可以輸入\n1  \\dt   來查看該database底下的table\n 在 psql 中，\\ 符號是一個特殊的字元，稱為 \u0026ldquo;psql 內部命令前綴\u0026rdquo;。當您在 psql 終端機中輸入以 \\ 開頭的命令時，psql 將解釋這個命令，並執行對應的操作。\n以下是幾個常用的 psql 內部命令：\n \\c: 切換到另一個數據庫 \\dt: 列出當前數據庫中的所有表格 \\d table_name: 查看指定表格的結構 \\q: 退出 psql 終端機 \\! clear: 清空psql 終端機畫面  當您想要使用 psql 內部命令時，必須在命令前加上 \\ 符號。例如，要列出當前數據庫中的所有表格，您可以輸入 \\dt。\n如果您想要輸入以 \\ 開頭的普通文本，而不是 psql 內部命令，則必須在 \\ 前面再加上一個 \\ 符號。例如，如果您想要在 SQL 陳述句中使用反斜線（\\）字元，則必須將其寫成 \\\\。\n請注意，在某些情況下，psql 內部命令前綴 \\ 可能會和 SQL 語句的關鍵字混淆。例如，CREATE TABLE 陳述句中的 TABLE 關鍵字後面如果不加引號可能會被 psql 認為是一個內部命令。為避免這種情況，建議在使用關鍵字時加上引號，例如 \u0026quot;TABLE\u0026quot;。\\\n 基本上這個terminal就是我們的Query Tool，所以是可以在這邊做CRUD的，如下\n常用的psql 指令  \\q - 退出 psql 命令行界面。 \\c \u0026lt;database_name\u0026gt; - 連接到指定的數據庫。 \\dt - 列出當前數據庫中的所有表格。 \\d \u0026lt;table_name\u0026gt; - 列出指定表格的詳細信息，包括列名、類型和約束等。 \\du - 列出所有用戶帳號的詳細信息，包括用戶名、權限和群組等。 \\dp - 列出所有表格的權限設置。 \\timing - 啟用或禁用查詢執行時間的顯示。 \\set - 列出或設置 psql 的配置選項。 \\i \u0026lt;file_path\u0026gt; - 從指定的檔案載入 SQL 命令。 \\e - 打開外部編輯器編輯當前緩衝區中的 SQL 命令。 \\! clear: 清空psql 終端機畫面 \\dt: 查看所有表格 \\df: 查看資料庫中的所有函數以及Stored Procedure \\ef: 編輯現有的函數，可能你寫錯了還是啥的 ☆修改完後，存檔退出記事本，進到terminal要加上 \\g 才會把這個修改go出去，不然你怎麼改都是沒有用ㄉ，血與淚的教訓Q_Q \\sf: 查看更詳細的函數內容，s stand for show  dt, du, df的d代表Describe的縮寫，用以顯示資料庫的資料\nStored Procedure的實戰 首先創造表格\n1 2 3 4 5  CREATE TABLE users ( id SERIAL PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) NOT NULL UNIQUE );   插入資料\n1 2 3 4 5  INSERT INTO users (name, email) VALUES (\u0026#39;John Doe\u0026#39;, \u0026#39;john.doe@example.com\u0026#39;), (\u0026#39;Jane Doe\u0026#39;, \u0026#39;jane.doe@example.com\u0026#39;), (\u0026#39;Bob Smith\u0026#39;, \u0026#39;bob.smith@example.com\u0026#39;);   返回值為空的Function 先創建一個無關緊要的stored procedure來感受一下它的作用吧，我們創造一個function，用來返回今天的日期，語法如下\n1 2 3 4 5 6 7 8 9 10  CREATE OR REPLACE FUNCTION -- 創建stored procedure的起手式。 get_current_date() -- 函式名稱 RETURNS DATE -- 該函式的返回值，若未指定則為Return Null AS -- 用以分明函數聲明與函數體，AS上面的是函數聲明，AS下面的是函數體 $$ -- 定界符，參照上方說明 BEGIN RETURN CURRENT_DATE; -- 函數體 END; $$ -- 定界符，參照上方說明 LANGUAGE plpgsql; -- 不加這個就是默認使用SQL語言，只能使用一些比較簡單的語法，加了這個之後就可以作流程控制、循環、異常處理等等...   接著呼叫它\n1  SELECT get_current_date();   回傳特定資料的function 該function會返回參數值的使用者的相關資訊\n1 2 3 4 5 6 7  CREATE OR REPLACE FUNCTION get_user_info(user_id INTEGER) RETURNS TABLE (name VARCHAR(255), email VARCHAR(255)) AS $$ BEGIN RETURN QUERY SELECT users.name, users.email FROM users WHERE id = user_id; END; $$ LANGUAGE plpgsql;   更新資料的function 1 2 3 4 5 6 7 8  CREATE OR REPLACE FUNCTION public.update_user_info(user_id integer, name character varying, email character varying) RETURNS void LANGUAGE plpgsql AS $$ BEGIN UPDATE users AS u SET name = $2, email = $3 WHERE u.id = $1; END; $$   變數宣告 :=來進行變數宣告，=在postgresSQL比較像是用來比較\n1 2 3 4 5 6 7 8 9 10 11 12  CREATE OR REPLACE FUNCTION my_function(param1 integer, param2 integer) RETURNS integer AS $$ DECLARE var1 integer := 0; var2 integer := 0; BEGIN var1 := param1 + 1; var2 := param2 + 2; RETURN var1 * var2; END; $$ LANGUAGE plpgsql;   WHILE 語法 1 2 3 4 5 6 7 8 9 10 11 12 13 14  CREATE OR REPLACE PROCEDURE public.factorial(IN n INT, OUT result BIGINT) LANGUAGE plpgsql AS $$ DECLARE i INT := 1; BEGIN result := 1; WHILE i \u0026lt;= n LOOP result := result * i; i := i + 1; END LOOP; END; $$;   IF語法 1 2 3 4 5 6 7 8 9 10 11 12  CREATE OR REPLACE PROCEDURE example_if_proc (a INT) AS BEGIN IF a \u0026lt; 0 THEN DBMS_OUTPUT.PUT_LINE(\u0026#39;a is negative\u0026#39;); ELSIF a = 0 THEN DBMS_OUTPUT.PUT_LINE(\u0026#39;a is zero\u0026#39;); ELSE DBMS_OUTPUT.PUT_LINE(\u0026#39;a is positive\u0026#39;); END IF; END;   將SELECT出來的值儲存在一變數中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  CREATE OR REPLACE PROCEDURE public.get_customer_info( IN customer_id INTEGER, OUT customer_name VARCHAR(50), OUT customer_email VARCHAR(50) ) LANGUAGE plpgsql AS $$ BEGIN SELECT name, email INTO customer_name, customer_email FROM customers WHERE id = customer_id; IF NOT FOUND THEN RAISE EXCEPTION \u0026#39;Customer not found\u0026#39;; END IF; END; $$;   將資訊打印出來(print) 1 2 3 4 5 6 7 8 9  CREATE OR REPLACE procedure sayHello() RETURNS void LANGUAGE plpgsql AS $$ DECLARE BEGIN RAISE NOTICE \u0026#39;hello word:\u0026#39;; END; $$   ","date":"2023-03-01T09:45:17+08:00","image":"https://i.imgur.com/1BTtOUL.png","permalink":"https://hoxtonhsu.com/p/storeprocedure%E8%B7%9Fpsql%E7%9A%84%E7%AD%86%E8%A8%98/","title":"StoreProcedure跟PSQL的筆記"},{"content":"參考影片：為你自己學GitLab CICD\n為何選擇Jenkins？ 目前市面上有三種CI/CD的工具，分別是\n Github Action GitLab CI/CD Jenkins  而他們各自的難易度如下：\nGithub Action Jenkins GitlabCICD 三者之比較     Github Action GitLab CI/CD Jenkins     優點 簡單易用，可以透過組合 Actions 來設定 CI/CD 流程。集成與 GitHub 相當良好，方便地與其他 GitHub 工具整合。 功能齊全，涵蓋了版本控制、需求管理、測試、打包、部署等。內建了測試覆蓋率分析、版本回溯、網路推送等工具。支援更多的發佈平臺和語言，可以支援更多不同的開發團隊。 功能強大，擁有豐富的插件系統，可以滿足多種 CI/CD 需求。社區活躍，有大量社區插件可以使用。可以自定義工作流程，靈活應對複雜需求。   缺點 設定複雜的流程可能會比較困難。有些功能，比如說高級的權限管理，可能比較弱。 較為複雜，可能會花費一些時間來學習和設定。有些功能，例如高級的安全性，可能會有額外的費用。 相對較難學習和使用，不如 GitHub Actions 和 GitLab CI/CD 簡單易用。配置和管理相對複雜，需要一定的技術支持。    為什麼CI/CD重要，它做了哪些事情？\n 在還沒有CI/CD的流程之前，部屬一個web大概是這樣   CI/CD建立完成後，開發人員只需要專注在任務的完成，而不需要做重複的部屬工作  名詞解析 Pipeline 就是腳本(script)的意思，用來設計CICD的流程，一個常見的pipeline如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  # 稱之為階段，可以為每個Job分配階段，常見的比如說有測試階段、打包階段、部屬階段等等，每個job都屬於一個階段 stages: - linter - testing - building - deploy # 工作流 workflow: rules: - if: $CI_COMMIT_BRANCH ==\u0026#34;main\u0026#34; #若發生什麼事 when: always #則做什麼事 - when: never #不然則做什麼 # 變數，就是那個變數，可以寫在外層的就是全域變數，寫在Job裡面的就是Job變數 variables: host_name: \u0026#34;hoxton\u0026#34; # 稱之為Job Helloworld: # Job名稱 image: ruby:3.1.2-alpine3.16 #指定要用什麼image來跑，等同於Executor variables: # Job變數 my_name: \u0026#34;hello kitty\u0026#34; stage: linter # 這個Job是什麼階段的 script: # 要執行什麼樣的腳本 - echo \u0026#34;hello world, GitLab! $my_name\u0026#34; - echo \u0026#34;hello world, GitLab! $host_name\u0026#34; - chmod +x ./run.sh - ./run.sh run_unit_tests: # Job名稱 stage: testing # 這個Job是什麼階段的 needs: # 決定Job的順序 - Helloworld # 在這些Job完成後才會去做run_unit_tests的Job script: # 要執行什麼樣的腳本 - echo \u0026#34;執行單元測試\u0026#34; before_script: #在執行腳本之前需要執行什麼腳本 - echo \u0026#34;安裝套件\u0026#34; - echo \u0026#34;設定資料庫連線\u0026#34; after_script :#在執行腳本之後需要執行什麼腳本 - echo \u0026#34;刪除不必要的檔案\u0026#34; bad_job: # Job名稱 stage: testing # 這個Job是什麼階段的 script: # 要執行什麼樣的腳本 - echo \u0026#34;bad_job\u0026#34; build_docker_images: # Job名稱 only: # 指定Job只會在什麼分支執行 - main stage: building # 這個Job是什麼階段的 script: # 要執行什麼樣的腳本 - echo \u0026#34;building docker images\u0026#34; deploy_to_production: # Job名稱 except: # 指定Job不在什麼分支執行 - dev # 分支名稱 stage: deploy # # 這個Job是什麼階段的 script: # 要執行什麼樣的腳本 - echo \u0026#34;deploy to production\u0026#34;   Runner 大概等同於「要用哪台電腦來執行Pipeline」，以下可以證明\n欲執行的script\n1 2 3 4 5  print-location: tags: - euno script: - echo \u0026#34;$HOSTNAME\u0026#34;   若不指定要有用哪台電腦執行，則gitlab會提供，但這時候就是在使用gitlab所提供的服務，免費帳戶每月超過40小時即到達上限，因此需要去註冊一個Runner\n 如何註冊一個Runner  可以參考GitLab的官方文件 https://docs.gitlab.com/runner/install/\n在Ubuntu系統下\n1 2  curl -L \u0026#34;https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh\u0026#34; | sudo bash   接著執行\n1  sudo apt-get install gitlab-runner   Executor 代表pipeline所運行的環境，可以是shell，也可以是Docker容器，端看目的而定，但千萬要記得，要執行指定的Executor，也要看自己的電腦或VM有沒有這個環境，之前有遇到一個問題是，我在本地起了一個runner，但一直說找不到pwsd的指令，此時要到gitlab-runner安裝的資料夾去調整toml檔案，將shell改成用powershell運行，因為window下沒有pwsd這個指定\n如何使用GitLab的CI/CD工具 在專案底下新增.gitlab-ci.yml的檔案，裡面的格式長這樣\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  # 稱之為狀態stages:- linter- testing- building- deploy # 稱之為JobHelloworld:stage:linterscript:- echo \u0026#34;hello world, GitLab!\u0026#34;run_unit_tests:stage:testingscript:- echo \u0026#34;執行單元測試\u0026#34;before_script:- echo \u0026#34;安裝套件\u0026#34;- echo \u0026#34;設定資料庫連線\u0026#34;after_script:- echo \u0026#34;刪除不必要的檔案\u0026#34;bad_job:stage:testingscript:- epaewjdqwebuild_docker_images:stage:buildingscript:- echo \u0026#34;building docker images\u0026#34;deploy_to_production:stage:deployscript:- echo \u0026#34;deploy to production\u0026#34;  把Image推上Gitlab 問題彙整 Got permission denied while trying to connect to the Docker daemon socket at unix:/// \u0026hellip; 解決方法：\n在vm中輸入\n1  usermod -aG docker gitlab-runner   \u0026ldquo;usermod -aG docker gitlab-runner\u0026rdquo; 這個指令是用來將 \u0026ldquo;gitlab-runner\u0026rdquo; 用戶加入 \u0026ldquo;docker\u0026rdquo; 群組。 \u0026ldquo;-a\u0026rdquo; 選項用於將用戶附加到指定的群組， \u0026ldquo;-G\u0026rdquo; 選項用於指定群組。\n這通常是為了允許 \u0026ldquo;gitlab-runner\u0026rdquo; 用戶在 GitLab Runner 管理的 CI/CD 流程中執行 Docker 容器。 通過將用戶加入 \u0026ldquo;docker\u0026rdquo; 群組，用戶可以在不需要權限升級的情況下運行 Docker 指令。\n請注意，\u0026ldquo;usermod\u0026rdquo; 指令的確切語法和行為可能因您使用的作業系統而異。 請查閱您的作業系統的文檔以獲取更多信息。\ndenied : requested access to the resource is denied. 八成是你的push沒有寫好，可以參考下面的樣子\nrunner會將target檔案刪掉，導致dokcer build不起來 GitLab CICD runner在執行每次作業時(Job)，為了保持互相的獨立性，會將Job所產生的檔案，切換至下個檔案時刪除，例如\n1  mvn clean package   時會產生/target的資料夾，在下一個Job時就會被刪除，如下\n此時可以在pipeline裡面加上這段\n1 2 3  artifacts: paths: - temp/*.jar   這樣就代表在下一次Job時，這個目錄底下的東西並不會被刪除\n","date":"2023-02-06T19:50:08+08:00","image":"https://i.imgur.com/b9bWXWs.jpg","permalink":"https://hoxtonhsu.com/p/gitlab-ci/cd%E7%AD%86%E8%A8%98/","title":"GitLab-CI/CD筆記"},{"content":"步驟 產生key的方式 1  ssh-keygen   儲存Key的位置 要改就改，不改就是預設的\n是否要針對privateKey設置密碼 使用這組Key時需不需要額外使用密碼，不輸入就是空白\n查看產生的key .pub後綴的就代表是pubKey\n進入主機內，將private Key加入 在.ssh底下會有一個authorized_keys的檔案 將privateKey放入其中就好\n輸入\n1  cat id_rsa.pub   來查看\n此時將這串複製下來，貼到GitHub的SSH Key設定\n接著只要上傳是使用SSH方式上傳，就不需要再登入github了\n","date":"2023-02-05T21:06:21+08:00","image":"https://i.imgur.com/8ocM55M.png ","permalink":"https://hoxtonhsu.com/p/%E4%BD%BF%E7%94%A8ssh%E4%BE%86%E9%80%A3%E5%8B%95gitscm/","title":"使用SSH來連動GITSCM"},{"content":"緣起 年假實在太無聊了，有點廢到連書都讀不下去，就打開Netflix想看看有什麼好看的，原本想看初戀First Love的，但無奈我對於愛情類型的東西實在沒什麼太大的興趣，正好看到了wednesday出現在推薦名單上，稍微看了一下預告，覺得Wednesday這種厭世到極限的人設深得我心，再搭配上女配角伊妮形成的反差，兩邊的對比實在太過強烈，讓我忍不住好奇到底這部在演什麼，於是就點進去了。\n先講結論，我覺得整部人設滿分，劇情真的不行，後面劇情感覺沒一個人是用腦袋在做事的，看完只覺得我的智商被狠狠的強暴了一遍。\n前面四集算是蠻多記憶點的，比如說舞會、拉大提琴、雕像爆破等等，對於星期三的角色塑造也算豐滿(就是個怪胎)。但無奈到後面幾集感覺整部劇情的調性就開始脫離了Addams Family的那種黑色幽默。\n首先是第五集，這一集家庭探訪日，校長要求Addams一家去做心理諮商，我本以為可以看到她們一家人「與眾不同」的那面，比如說互相挖苦、愛彼此愛到要殺死對方的那一種關心方式，但沒想到話鋒一轉，她們一家人居然整整齊齊的認真在做一場諮商，當問到Gormoz年輕時是否真的殺過人，Morticia還牙起來，要Wedensday不要再繼續追問下去了。\n當時心裡在想，這家人不是一群outcast嗎？怎麼突然間會這麼嚴肅地在講這件事情？整場諮商下來完全沒有任何Addams Family的感覺，跟一般家庭沒什麼不同的地方。直到後面謎題揭曉時，我還想說這麼嚴肅肯定是有什麼天大的事情所以才不能說，原來就只是爸爸幫媽媽背黑鍋而已，請問這件事情有必要瞞著Wednesday嗎？有必要故弄玄虛嗎？\n緊接著到第六集，莫名其妙的Xavier跟Tyler都對Wednesday暈船，而且暈船的不清，相繼說出什麼「舞會過後，我只想忘掉妳，卻都忘不掉」\n「雖然可能是我的錯覺，星期三，但你明明不停對我明示暗示」，我的天，我以為點進來是黑色幽默的懸疑片，沒想到點進來的原來是三角戀修羅場連續劇，再回頭看看前面的劇情，實在不覺得星期三跟這兩人的互動有什麼地方會讓人暈船的，可能這兩人都是易暈體質吧，只能說Wednesday有海王天份，深諳各種小心機吧，有一幕好像是Xavier看到Wednesday跟Tyler去舞會還是啥的，再生悶氣，沒想到Wedensday居然問Xavier到底在不開心什麼，我當時心裡在想「你這不是很懂嗎？海王Wednesday」，只能說男人終究是抵抗不了神祕正妹的邀請，唉。\n到了後面進入主線，Wednesday騙Enid跟Tyler想要出去，結果實際上是去Gates家調查，結果調查不順遭到Hyde的攻擊，結尾時看到Enid生氣的對Wedensday說「你根本不在乎你身邊的人，你只在乎你自己」時，我心裡想說終於啊，有人終於講出實話了，結果下一集Enid又活蹦亂跳的來找Wednesday聊天，不只是這幕，其實之前也有很多類似的劇情\nWednesday搞了些什麼讓大家很不爽，結果過沒幾集大家又主動來找Wednesday聊天，道歉。奇怪，到底為什麼要跟她道歉啊，難道人長得正就可以這樣子嗎。\n接著劇情在往下走，發現更加弱智，星期三指認Xavier就是兇手，結果實際上抓錯了，我個人認為沒問題，畢竟人總是有出錯的時候，而且確實很多證據都指向Xavier。但當Wednesaday說她抓錯，Tyler才是兇手時，她的快樂夥伴依然是無條件地相信Wednesday，甚至連證據都沒提供，她的快樂夥伴沒有絲毫的懷疑她講得到底是真是假，整個抓捕過程細絲極恐，我甚至覺得，假使Tyler不是兇手，Wednesday說Ajax是兇手，那群快樂夥伴也是會很樂意地把Ajax抓起來上供給Wednesday。也就是說其實星期三的行為根本是村霸的行為吧，說你有罪就有罪，抓犯人不靠腦袋而是靠拳頭，全程硬A，甚至最後抓犯人還是靠幻視才抓到的，0邏輯思考、解謎。\n到最後一集則是弱智情節大集合，知道主謀是Thornhill老師，校長用變形術變成Tyler的樣子去跟Wednesday包圍她，結果校長在Thornhill面前解除變形後，我本以為會有什麼刺激的對決畫面，結果Thornhill只是提起「手中」的針筒，就往校長的「脖子」刺下去，校長就死了，那到底為什麼要變形接近老師啊，不能躲在旁邊聽就好嗎？退一萬步來說，校長你真的不是在演嗎？你身高190，老師身高155，能不能反應一下啊，結果就這樣死了，完全沒有任何推進劇情的作用，校長在不在那個場景對於劇情影響都不大，真的就只是為了過來死而已。\n後來Crackstone復活，我本以為會有什麼超炫的技能，結果完全沒有，戰力值低落到我甚至認為Nevermore學生每個人都衝上去，他就會活活當場被打死在現場，就只有進Nevermore後放個火焰風暴後，接著就拿起法仗當一個進戰法師，跟Wednesday近身平A起來，不知道是不是腦袋還沒熱起來，忘記自己是一個法師，應該拉開距離，或是趁隙放個什麼魔法之類的，最後還被Bianca從後面背刺，當他轉過去打飛Bianca後，接著又被Wednesday背刺，看到這幕的時候我還以為在看周星馳的零零漆大戰金鎗客，這種古靈金怪槍的幽默沒想到也被洋人發揚光大去了。最後Thornhill老師拿了一把槍走出來時，我心裡在想「終於啊！大人，時代變了，該拿槍了」，結果拿槍抖了老半天，講了一堆話就是沒開下去，結果後面被蜜蜂叮的時候才開槍，真的不是當年腦子進水嗎？Crackerstone復活後不就叫你閉嘴，警告你話太多了嗎？結果最後還是沒把他的話聽進去，難怪不成大氣。\n最後快樂大結局，該發糖的發糖、該狼化的狼化，Xavier繼續暈船Wednesday，結尾還送了台Iphone給Wednesday，看到這幕時，我忽然想起知道為什麼Xavier一開始會懷疑自己被Bianca蠱惑，從劇情表現上看起來他確實是暈到神智不清，我也懷疑他最後真的被星期三蠱惑了，印證了那句「星期三虐我千百遍，我仍待她如初戀」，鋼鐵星期三粉實至名歸。\n結尾 認真回想了一下，整部劇情最大該吐槽的點就是Wednesday身邊的人對她近乎盲目的包容，校長包容她、警長包容她、狼妹包容她、男配也包容她，Wednesday至始至終除了小手外，幾乎沒對任何人道過歉，也沒深刻的反省，但就是所有的人都會莫名其妙的原諒她，毫無邏輯與深度可言。第二季出的話我應該還是會看，畢竟人設實在太香了，希望第二季不要在虎頭蛇尾了。\n","date":"2023-01-29T17:20:08+08:00","image":"https://i.imgur.com/C9FgAaF.jpg","permalink":"https://hoxtonhsu.com/p/wednesday-%E6%98%9F%E6%9C%9F%E4%B8%89%E8%88%87%E5%A5%B9%E7%9A%84%E6%9A%88%E8%88%B9%E5%A4%A5%E4%BC%B4%E5%80%91/","title":"Wednesday 星期三與她的暈船夥伴們"},{"content":"前言 記得在某次外勤的時候，那時候好像是要做稅抽還是要查什麼東西，需要用客戶的電腦SAP裡面查一些資料，可是我按了老半天，一直出現錯誤，迷迷糊糊地從那些文字中拼湊出一些單詞，只記得有什麼SQL Error，當時把這件事情跟客戶的會計反應，他旋即請了工程師過來處理，弄了一下之後跟我說需要明天才會好，要我明天再去撈\n(範例，非當事錯誤)\n後來這幾年工作上常常接觸到資料庫的東西，最近又想起這件事來，也總算知道當時遇到的錯誤是什麼了我猜是IP連不到。因此繼續趁著年假這個真的不知道做什麼事的時間點來科普一下ERP系統後面的東西，SQL DataBase是什麼？\n什麼是SQL 首先要知道SQL怎麼發音，我都念SQL，但也有些人念SQL，SQL的念法是，C闊(Ess-cue-ell')。SQL這個詞的由來有人說沒意義，就是叫SQL，也有人認為是有意義的，也就是Structured Query Language(結構化查詢語言)的縮寫。簡而言之SQL就是用來跟資料庫(Database)溝通的一種Syntax(語法)，SQL與資料庫的關係像魔法師與魔法書的關係，魔法師透過詠唱咒語(SQL語法)來使用魔法書(Database)的能力。\n第一次接觸到SQL是在大四大三的時候吧，那時候好像有個系必修是什麼資訊概論類似的課程，老師上課的時候有提到一個東西，他的介面是隻海豚，然後有很多奇怪的按鈕，\n當時的我完全不知道這些是啥，甚至連SQL是什麼都沒有半點頭緒，那門課我記得我只負責處理一些很瑣碎的事情，其他都靠我同學Carry過的XD。結果沒想到逃的了一時，逃不了一世，現在天天都會看到，感嘆命運多舛啊。\n話說回來，所以什麼是SQL呢？他是用來做什麼的？我們首先先來講一下什麼是關聯式資料庫。大家應該有上過學吧，學校裡，有班級、有學生、有班導，有科任老師，這些東西都是互相有關聯的，比如說一個班導可以有很多學生，但每個學生只能有一個班導，一個科任老師也可以有很多學生，每個學生也可以有很多的科任老師。用來記錄這些資訊的資料庫就是所謂的關聯式資料庫注：有關聯式就會有非關聯式資料庫，但這部分我就不熟了。\n(注：我事後回來看，我覺得這樣設計有很多問題，其實可以在精簡一點的，大佬就別鞭太大力了）\n畫成關聯圖大概就是長這樣，原諒我畫的真的有點醜，不過大概看的出來它們彼此有哪些關係吧？學生跟班級、導師、科任老師有關聯、班級跟學生還有班導有關聯、班導跟科任老師沒有關聯(其實這邊設計的不太好，會違反資料正規化，但只是示範而已）。SQL Database我們每天都會碰到，比如說你每天上車逼的悠遊卡，你的卡號就被記在政府的悠遊卡SQL Database裡面，只要你遺失後，就會把你的那筆資料拉出來，標注已遺失。或是會計師考試報名時，會給你一組准考證號碼，所以考試院的SQL資料庫裏面，也會有這筆准考證的資料，這筆資料包含你的身分證、考試成績等等，只要涉及資料儲存的部分，其實背後都有資料庫的存在，也包含你的手機裡面的通訊錄等等，裡面都有小型的資料庫在裡面處理你的information。\nSQL的實作 多說無益，我們就用線上版的SQL編輯器來看看SQL是怎麼運作的吧，建議這邊點開我上面的HackMd，我有用Gif的方式錄影下來。\n線上的SQL編輯器：https://sqliteonline.com/\n點進去後會看到裡面長這個樣子，時間寶貴，我把左邊的欄位講一下就好，其實左邊就是各是各樣的SQL Database，不同的Database都有一些特性\n SQLite：輕量化的SQL資料庫，常用於手機端。 MariaDB：MySQL的作者獨立出來開發的SQL資料庫 PostgreSQL：也是SQL資料庫 MSSQL：微軟開發的SQL資料庫，會有微軟的奧援  當然不只這些，像常聽到的Oracle，不只有做ERP系統，其實還有做SQL資料庫，當然Oracle做的不止這些。話說回來，這些語法都大同小異，但為了方便各位，我們這次就用SQLite做示範，因為這個頁面一點進來就是SQLite了。\n這個紅色框框的地方就是讓我們打SQL語法的部分，我們先來創一些資料吧！秉持著能交給別人做的事情絕對不自己來的原則，這部分我們請ChatGPT來幫我們就好：）\nChatGPT產生的語法如上，這邊先講解一下會出現的名詞代表的意思，首先\n Table：近似於Excel裡面的活頁表，每個活頁表都拿來描述不同的東西，比如說學生這張Table就是拿來存放跟學生有關的資料，比如說姓名、學號之類的東西。 DROP：近似於刪除  1 2 3 4 5 6 7 8  CREATE TABLE Student ( Name TEXT,　ClassTeacherName TEXT, StudentID INTEGER, ClassroomID INTEGER, Birthdate DATE, Subjects TEXT );   這樣的語法代表創建一張名為Student的表格，裡面要有\n 名為Name的欄位，資料型別是文字 名為ClassTeacherName的欄位，資料型別是文字 名為StudentID的欄位，資料型別是數字 名為ClassroomID的欄位，資料型別是數字 名為Birthdate的欄位，資料型別是DATE(日期，亦即只能存放日期格式的東西) 名為Subjects的欄位，資料型別是文字  資料型別代表這個欄位只能存什麼東西，如果資料型別是數字，就代表只能存在羅馬數字，如果輸入 天氣 就會出錯\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  -- 如果已經存在這些表就刪除，確保每次都是產生全新的Table DROP TABLE IF EXISTS demo; DROP TABLE IF EXISTS Student; DROP TABLE IF EXISTS Teacher; DROP TABLE IF EXISTS Classroom; DROP TABLE IF EXISTS SubjectTeacher; -- Create Student table CREATE TABLE Student ( Name TEXT, ClassTeacherName TEXT, StudentID INTEGER, ClassroomID INTEGER, Birthdate DATE, Subjects TEXT ); -- Create Teacher table CREATE TABLE Teacher ( Name TEXT, TeacherID INTEGER, ClassroomID INTEGER ); -- Create Classroom table CREATE TABLE Classroom ( ClassroomID INTEGER, ClassID INTEGER ); -- Create SubjectTeacher table CREATE TABLE SubjectTeacher ( Name TEXT, TeacherID INTEGER, Subject TEXT );   完成後我們可以看到我們的左邊就出現很多的東西，就代表我們成功創建了Table喔！\n但此時Table裡面的東西都是空的，我們試著塞一些資料進去Table裡面吧，這邊再次邀請我們的勞模ChatGPT\n這邊的INSERT其實就是新增資料進去的意思。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  -- Insert data into the Teacher table INSERT INTO Teacher (Name, TeacherID, ClassroomID) VALUES (\u0026#39;John Smith\u0026#39;, 1, 101); INSERT INTO Teacher (Name, TeacherID, ClassroomID) VALUES (\u0026#39;Jane Doe\u0026#39;, 2, 102); INSERT INTO Teacher (Name, TeacherID, ClassroomID) VALUES (\u0026#39;Bob Johnson\u0026#39;, 3, 103); -- Insert data into the Classroom table INSERT INTO Classroom (ClassroomID, ClassID) VALUES (101, 1); INSERT INTO Classroom (ClassroomID, ClassID) VALUES (102, 2); INSERT INTO Classroom (ClassroomID, ClassID) VALUES (103, 3); -- Insert data into the SubjectTeacher table INSERT INTO SubjectTeacher (Name, TeacherID, Subject) VALUES (\u0026#39;John Smith\u0026#39;, 1, \u0026#39;Math\u0026#39;); INSERT INTO SubjectTeacher (Name, TeacherID, Subject) VALUES (\u0026#39;Jane Doe\u0026#39;, 2, \u0026#39;Science\u0026#39;); INSERT INTO SubjectTeacher (Name, TeacherID, Subject) VALUES (\u0026#39;Bob Johnson\u0026#39;, 3, \u0026#39;English\u0026#39;); INSERT INTO SubjectTeacher (Name, TeacherID, Subject) VALUES (\u0026#39;Bob Johnson\u0026#39;, 3, \u0026#39;History\u0026#39;); -- Insert data into the Student table INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Alice Smith\u0026#39;, \u0026#39;John Smith\u0026#39;, 1, 101, \u0026#39;2000-01-01\u0026#39;, \u0026#39;Math, Science\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Bob Brown\u0026#39;, \u0026#39;John Smith\u0026#39;, 2, 101, \u0026#39;2001-01-01\u0026#39;, \u0026#39;Math, English\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Charlie Johnson\u0026#39;, \u0026#39;Jane Doe\u0026#39;, 3, 102, \u0026#39;2002-01-01\u0026#39;, \u0026#39;Science, History\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;David Wilson\u0026#39;, \u0026#39;Jane Doe\u0026#39;, 4, 102, \u0026#39;2003-01-01\u0026#39;, \u0026#39;Science, English\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Eve Davis\u0026#39;, \u0026#39;Bob Johnson\u0026#39;, 5, 103, \u0026#39;2004-01-01\u0026#39;, \u0026#39;English, History\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Frank Miller\u0026#39;, \u0026#39;John Smith\u0026#39;, 6, 101, \u0026#39;2005-01-01\u0026#39;, \u0026#39;Math\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Gary Moore\u0026#39;, \u0026#39;Jane Doe\u0026#39;, 7, 102, \u0026#39;2006-01-01\u0026#39;, \u0026#39;Science\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Helen Anderson\u0026#39;, \u0026#39;Bob Johnson\u0026#39;, 8, 103, \u0026#39;2007-01-01\u0026#39;, \u0026#39;English, History\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;Irene Thomas\u0026#39;, \u0026#39;John Smith\u0026#39;, 9, 101, \u0026#39;2008-01-01\u0026#39;, \u0026#39;Math, Science\u0026#39;); INSERT INTO Student (Name, ClassTeacherName, StudentID, ClassroomID, Birthdate, Subjects) VALUES (\u0026#39;James Hernandez\u0026#39;, \u0026#39;Jane Doe\u0026#39;, 10, 102, \u0026#39;2009-01-01\u0026#39;, \u0026#39;Science, English\u0026#39;);   完成後，在Table上面點選右鍵，選擇SELECT即可這張表的所有屬性喔 ！\n 教室Table   學生Table 這邊也違反資料庫正規化，一個應該只塞一筆資料的原則，我的subject塞了複數筆資料，但單純Demo而已，有點懶得改了    科任老師Table  老師Table\n  SQL語法的介紹 我們一樣在框框裡面操作\n1  SELECT * FROM Teacher   這個語法的意思就是 SELECT選擇 *全部欄位 FROM來自 Teacher這張表，翻成白話文的意思就是，幫我選出Teacher這張表的全部內容，當然我們也可以再複雜一點，比如說\n1  SELECT * FROM Teacher WHERE teacherid = 2   也就是從Teacher這張表裡面選出TeacherId為2的欄位\n1  SELECT * FROM Student WHERE subjects LIKE \u0026#39;%Math%\u0026#39;   當然我們再複雜一點點，這個語法會找出所有在Student這張Table裡面subjects欄位裡有Math的學生，聽起來有點繞口對吧XD，接著我們就把這些語法組合起來，試著找看看\n1 2 3 4  SELECT Student.* FROM Student JOIN SubjectTeacher ON Student.ClassTeacherName = SubjectTeacher.Name WHERE Birthdate BETWEEN \u0026#39;2001-01-01\u0026#39; AND \u0026#39;2005-12-31\u0026#39; AND SubjectTeacher.Subject = \u0026#39;Math\u0026#39;   我們再複雜一點點點點，我們想找出所有在2001年至2005年出生，並且有修Math的學生，看到這邊這個語法大家是不是有點感覺了，是不是很像我們去撈資料常常用到的，要撈發生在本年度的100018應付帳款全部資料XD。其實背後的SQL語法就像這樣子。\n當然實際上的情況SQL語法還會更複雜一點，因為這些這是關聯式資料庫，彼此間可能可以關聯到很遠很遠的Table，只是為了做科普而已就不弄得那麼複雜了。另外SQL Syntax(語法)也不只SELECT，常見的還有UPDATA, DELETE, CREATE等等，只是這些審計人員一般不會碰到。\n結語 其實沒啥想講的，只是覺得很閒而已，想說趁年假時後把想寫的東西寫一寫，順便也當科普一樣，感覺會計這個圈子好像很少人在寫科普或是知識介紹的東西，就花個一兩個小時的時間寫一下，如果對SQL有興趣的話，可以去載來玩看看\n MySQL：全英介面，一開始可能不太友好，但網路上資源最多 MSSQL：微軟的SQL，有中文介面，但網路上資源相對較少，其實SQL的語法都大同小異，但其實還是有一些不同處 PostgreSQL：通常不會用這個入門，我個人覺得它GUI的介面很爛，我用這個的話通常都是用Terminal SQLite：不太推薦，因為這算是輕量化版的，有很多資料型別是特規的。  我文章常提到的資料庫正規化介紹如下\nhttps://ithelp.ithome.com.tw/articles/10229472\n忙季加油！債見\n","date":"2023-01-26T17:50:33+08:00","image":"https://i.imgur.com/6aiiDXi.png","permalink":"https://hoxtonhsu.com/p/oraclesap%E9%BC%8E%E6%96%B0%E6%B7%BA%E8%AB%87%E9%80%99%E4%BA%9Berp%E8%83%8C%E5%BE%8C%E7%9A%84%E6%98%AF%E4%BB%80%E9%BA%BC-sql%E8%B3%87%E6%96%99%E5%BA%AB/","title":"Oracle?SAP?鼎新?淺談這些ERP背後的是什麼-SQL資料庫"},{"content":"想講一些實用的，但卻很少人知道的一些電腦使用的功能，知道這些對做底稿、翻憑證不會有太大的幫助，但會用的話我個人覺得可以節省很多時間，供大家參考。\n快速關機 window+D：回到桌面\n在桌面Alt+F4即可跳出關機選項\n記得當初在外勤的時候，只要組長說撤的時候我就會用最快的速度關機XD，那時候同事都問我怎麼用的，這就是訣竅，當然也可以選擇重新啟動或休眠，看自己喜好決定。\n截圖 window+shift+s\n這個應該最基本，在Window10以上的系統可以透過這個shortcut來打開截圖視窗，就拿來貼圖片給組長，跟組長說我哪邊不會QQ\n快速打開Excel, Word, 記事本, 小畫家,計算機\u0026hellip; Window+R：跳出執行選項\n在裡面輸入以下的內容已打開不同的Application\nmspaint：打開小畫家\nnotepad：記事本\nwinword：word\nexcel：excel\n計算機：calc\n快速打開工作列的應用程式 window+1\n可以打開工作列的第一個應用\nwindow+2\n可以打開工作列的第二個應用，以此類推\u0026hellip;\n這個指令我大部分都是用來開Chrome，或是Excel之類的東西\n瀏覽器快速選擇搜尋列 打開Chrorm後，打alt+D就可以定位到搜尋列，並且在這邊按Ctrl+1,2,3\u0026hellip;即可切換至不同的頁面，通常是我拿來打混摸魚的時候用的，Ctrl+T則可以打開新的分頁，所以兩個和再一起就是，開啟一個新分頁並搜尋，如果旁邊有人過來就立刻Ctrl+w關閉當前頁面，避免摸魚被抓包。\n","date":"2023-01-26T00:31:43+08:00","image":"https://i.imgur.com/Ln2xqzT.png","permalink":"https://hoxtonhsu.com/p/%E6%B7%BA%E8%AB%87%E4%B8%80%E4%BA%9B%E5%AF%A6%E7%94%A8%E7%9A%84%E5%BF%AB%E6%8D%B7%E9%8D%B5/","title":"淺談一些實用的快捷鍵"},{"content":"前言 年假回老家實在是太無聊了，想把這幾年學到的東西分享一下，希望可以幫助一些莘莘學子，能用更有效率的方式來整理筆記。\n記得大二或是大三的時候很沉迷於作筆記這件事情，最喜歡做的事情，就是用一兩個下午把那個禮拜所上的成會或是中會整理成筆記，以利後面的複習。不得不說當時這樣做的回饋還不錯，當時中會跟成會的成績都還算不錯。\n（當時很認真的筆記）\n紙本筆記的缺點 這樣的筆記在當時應付期中考期末考還行，因為這些筆記可能都是一兩個月寫的，都還算有印象，但是當我準備研究所的時候就發現幾個問題了，首先\n 難以搜尋：面對海量的資料，我很難在第一時間找到我需要的資訊，比如說我想要找一個利息資本化的定義，以及它的細項，我除非前一陣子剛寫，或是我版面真的寫得很好，不然我不能第一時間的找到我想要的資訊。比如說稅法的部分就分成很多塊，比如說遺產稅贈與稅等等的，數量真的太多，且稅率也類似，常常找不到自己想要的地方。 難以擴充：紙質的筆記一旦寫下去之後就難以修改，無法滿足我越來越多的知識積累，比如說大家都知道的金融資產那一個章節，可能光一個範例就可以寫個2,30個也不為過，每個範例可能都有一些細節要抄進筆記裡面，這樣日積月累下去，那一頁的筆記越記越多、越寫越亂不易閱讀。 耗時：耗時是最大的問題，一頁的筆記我可能需要寫個半小時，雖然說寫的當下其實就記得很清楚了，但是卻非常的消耗時間，往往做完這些筆記我的假日就這樣沒了，實在是不太行，且手寫筆記非常吃手寫的品質，如果心一旦亂起來，亂寫一通，那這筆記基本上閱讀不能，只是寫給當時的自己看的，不利日後準備研究所或是會計師考試。  雖然1、2的問題都可以透過Ipad的手寫筆記來解決一些問題，但最大的問題就是第3點，當時有嘗試過很多方式，比如說用excel來記筆記(但儲存格不方便修改與擴充)，或是用word來寫，但word真的非常不適合拿來寫筆記，首先，work本身是不支援你打出類似分錄格式的東西的，就算可以，那個代價我記得也很大，其次，光是格式的部分可能就要設定個老半天，再加上在寫筆記的途中還需要移動滑鼠去調整現在想要的是\n      或是\n       這樣的格式真的有點打斷思緒。\n因此我的需求是這樣\n 方便撰寫，希望不需要去切什麼格式 支援圖片上傳，可以讓我傳圖片上去，可能有些範例或是老師在黑板上畫的東西，需要做成筆記來看 要可以讓我打類似分錄的東西  後來出社會工作後，接觸到Markdown這個東西真的驚為天人，並且是有一點相見恨晚，如果在學期間知道這個東西的話做筆記應該會更高效快速一點。首先先來介紹一下Markdown是什麼吧\nMarkdown介紹 Markdown 是目前非常普遍用來撰寫文檔的語言，一開始的目標就是使用「易讀易寫的純文字格式編寫文件」，此初衷讓使用者可以專注在文字的本身，而不需要透過其它工具來切換格式。以 Word 撰寫文檔來說，就必須透過上方的工具列來切換標題、列表、粗體、斜體等等；而 Markdown 並沒有這樣的工具列，完全都是使用標示符號來完成這些需求。\nMarkdown是一種輕量級標記式語言，創始人為約翰·格魯伯。它允許人們使用易讀易寫的純文字格式編寫文件\n由於Markdown的輕量化、易讀易寫特性，並且對於圖片，圖表、數學式都有支援，目前許多網站都廣泛使用Markdown來撰寫說明文件或是用於論壇上發表訊息。如GitHub、Reddit、Discord、Diaspora、Stack Exchange、OpenStreetMap 、SourceForge、簡書等，甚至還能被用來撰寫電子書。\n參考自維基百科以及https://www.casper.tw/development/2019/11/23/ten-mins-learn-markdown/\n先來看看如果我把會計的筆記轉成Markdown的話看起來會是怎麼樣吧，因為Dcard不支援markdown，可以點這邊預覽看看\nhttps://hackmd.io/@Celeast/ryyXXyosi\n第七章 彈性預算、直接成本與管理會計 本章學習重點\n 了解各差異的差異 基於差異分析所做的決策判斷  名詞定義\n 靜態預算(Static Budget)：在預算期間開始時，基於預計產出水準所做的預算所做的預算 靜態預算差異：在靜態預算中，實際結果與預期數之間的差異 彈性預算(Flexible Budget)：預算期間內按實際產出水準計算出預算收入與預算成本之預算  ．\n．\n．\n1 2 3 4  flowchart LR B[實際投入數量x實際價格] \u0026lt;--價格差異--\u0026gt; 實際投入數量x預算價格 \u0026lt;--效率差異--\u0026gt; C[實際產出下所允許之預算投入x預算價格] B \u0026lt;--彈性預算差異--\u0026gt;C       變動 歸納 評論     固定制造成本可以做為存貨成本嗎? 不可 可以 基本問題   有生產數量差異嗎? 沒有 有 對基準產能水準的選擇，只在歸納成本法下影響營業利益的衡量     分錄   原料\t10,000\n​\t應付帳款\t10,000\n  在製品\t30,000\n製造費用 1,000\n​\t原料\t31,000\n  產成品\t50,000\n​\t在製品\t50,000\n 課堂範例：\nＭarkdown語法介紹 上面是我把我的會計筆記轉成Markdown格式，可以看到Markdown支援了幾點\n 列表式的清單 用來舉例的黑點 重點的醒目提示 分層式的標題，標出章節重點 支援表格(注：markdown的表格語法非常反智，通常我都是用快捷鍵生成) 支援流程圖的繪製 支援數學式(這邊沒有示範到，不過Markdown是有支援高等數學的運算式的) 支援圖片上傳，可以讓我把版書或是題目直接貼上去  接下來帶大家認識一下Markdown的一些語法\n首先是標題的語法，輸入#再加上一個空格會產生標題，就像現在這樣\n在文字前加上1. 2. 3. 則會變成列表\n文字之間加上**則可重點醒目\n在文字前加上+則會變成黑點\n在文字前加上\u0026gt;則可做為補充說明，我就是用這個語法來寫分錄的\n顯示圖片的語法則是這樣\n裡面的內容填上自己的圖片連結就可以了，如何把圖片上傳上去我後面會說。\nMarkdown的語法還有很多很多，不只有我上面提到的這些，有興趣的同學可以參考這邊\nhttps://www.casper.tw/development/2019/11/23/ten-mins-learn-markdown/\n我該怎麼寫Markdown呢？ markdown是工程師蠻常會接觸到一個標籤式語言，如果你開心的話用記事本也是可以寫Markdown的喔，但是效果會不太好閱讀而已，目前markdown我自己認為比較常見的有幾種\n  Vscode\n這是我最初拿來寫markdown的工具，但它本身不是專門拿來寫markdown的，不支援一些熱鍵以及圖片上傳，後面就被我拋棄了\n  HackMd\nHackMd是一個網頁版的markdown編輯器，簡單來講就是你寫上去後，東西就是直接存在雲端，且圖片複製貼上就會自動幫你上傳到網路上了，非常的便捷以及快速，好像是台灣人開發的，最重要的是它免費，也是最常見的方式。\n  Typora\n這是我目前主力所使用的Markdown編輯器，跟HackMd最大的不同就是它是一個所見及所得的編輯器，上述兩款其實都是把畫面分成兩邊，左邊是Markdown語法，右邊則是渲染後的結果，而typora則是在你輸入完後直接幫你渲染好，也就是所寫及所見，是它最大的特色。\n但相比之下它就有幾個缺點\n 要錢，最直觀的問題就是它是一個付費的程式，屬於買斷制一次500，支援三台設備同時使用 本身不支援圖片上傳，想要用它來做圖片上傳需要懂一些控制台指令以及Json格式的 本身的檔案都在local端，需要自己手動丟上雲端(我個人是丟到github上面，然後用bat檔自動上傳)    還可以提供一點，我會把一些真的沒辦法用文字或是Markdown語法表示的東西寫在平板的GoodNote上面，在把連結分享出來，然後截圖下來貼上去，看起來就像這樣\n結語 當然還有不只這些，我沒記錯的話Notion本身也有支援(但我不熟)以及obsidian也是一個寫Markdown的工具，我之所以會選Typora只是因為我喜歡有更大的空間，不喜歡畫面被分成左右兩邊而已。\n作筆記的方法有很多，不做的、用紙寫的、用平板寫的，都可以，沒有誰優誰劣，Markdown也有它的限制在，比如說它就不能寫資產負債表、也不能寫T字帳，沒有一個方法是最佳解的，只要找到自己喜歡的方式都可以，這篇文章只是拋磚引玉，希望提供自己的一些想法供大家參考，也歡迎各位一起討論，祝大家新年快樂，忙季加油！\n","date":"2023-01-22T23:15:25+08:00","image":"https://i.imgur.com/c968Ywa.png","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E8%A3%BD%E4%BD%9C%E6%9C%83%E8%A8%88%E7%9A%84%E9%9B%BB%E5%AD%90%E7%AD%86%E8%A8%98markdown%E7%9A%84%E4%BB%8B%E7%B4%B9/","title":"如何製作會計的電子筆記？Markdown的介紹"},{"content":"最近在新電腦上安裝了Docker結果發現一直卡在這個畫面\n後來研究了一下發現應該是wsl沒有裝好的原因，後來安裝好之後，在把Window Update要我Update的東西全部更新一次，就可以執行成功了，推測應該是window版本沒更新，導致不支援wsl的關係。\n","date":"2023-01-21T00:52:36+08:00","image":"https://i.imgur.com/xgUpP8O.png)","permalink":"https://hoxtonhsu.com/p/docker_desktop_starting%E5%95%8F%E9%A1%8C%E8%A7%A3%E6%B1%BA/","title":"Docker_Desktop_Starting問題解決"},{"content":"名詞解釋 Container Docker Container 是一種軟體容器，它可以在其中運行應用程式和其他服務。它使用操作系統級別的虛擬化，可以在單一的物理主機上運行多個容器，並且每個容器都有自己的運行環境和資源。\nDocker Container 是一種軟體容器，它可以在其中運行應用程式和其他服務。容器具有輕量級、可移植性和隔離性等特點。容器是通過在操作系統內核中運行的容器引擎來實現的。\nDocker容器主要是使用了Linux 的 Namespaces 和 Control groups（cgroups） 技術來實現隔離，這兩種技術可以將一個實體主機上的資源限制給每個容器，而容器內部則是共用一個kernel，因此容器比虛擬機器輕量且速度較快。\nDocker容器是基於鏡像(Image)來建立與運行的，一個鏡像可以是一個基礎鏡像或是由其他鏡像所建立而來。當執行docker run 指令時，會從鏡像建立一個容器，並在容器內執行指定的應用程式或服務。\n不僅如此，Docker容器還支援網路、儲存卷的映射，使得容器可以與外部通訊，也可以存取本地端的資料。\n透過Docker容器,我們可以將應用程式、服務和其所需的環境打包在一起，並且可以在不同的環境中運行，提高了應用程式的可移植性和彈性。\nImage Docker Image 是 Docker 容器的基礎，它是一個只讀的模板，包含了容器運行所需的所有檔案、設定和程式。當執行 docker run 指令時，Docker 會從 Image 建立一個新的容器並在其中執行指定的應用程式或服務。\nDocker Image 可以通過構建或下載的方式創建，構建的方式可以使用 Dockerfile 來描述如何構建一個 Image。而下載的方式則可以從 Docker Hub 或其他的 registry 下載。\nVolume Docker Volume 是 Docker 的一種功能，用於管理容器中的數據。容器本身是輕量級的，數據是不能永久存在的，而 Volume 則是可以永久存在的。\nDocker Volume 可以被掛載到容器上，並且可以在容器內部存儲數據。當容器停止運行或者被刪除時，Volume 中的數據仍然可以保留下來。這樣就可以在重啟容器或建立新容器時，繼續使用之前存儲的數據。\n並且Volume裡面的資料是可以和Host分享的，兩邊的資料呈現鏡像的雙向對應，在Host新增的東西會在Container出現，Container新增的資料也會在Host裡面出現\n常用指令 搜尋Image 1  docker search postgres   查看目前的image 1  docker image ls   或是\n1  docker images   執行docker image 1  docker run [imageName][:tag]   後面的:latest是版本號，可加可不加，沒加的話預設就是latest\n刪除images 1  docker rmi [imageId]   在Detached mode下執行 1  docker run -d nginx   所謂的Detached mode亦即啟動後會不會占用你的terminal，可以看一下下面的git，可以比較兩者間的差異\n 沒有-d   有-d  打包成docker image 1  docker build -t drink-more-water:latest .   -t 是 tag的縮寫，hello-docker是這個tag的名稱，.代表dockerfile在當前的目錄下，如果Dockerfile不在當前目錄，則這邊要改變。latest則是版本號，可加可不加，不加的話預設是latest\n查看目前運行的Container 1  docker ps   ps是process status的意思\n或是\n1  docker container ls   ​\t查看目前運作中(running)的Container 1  docker ps   或是\n1  docker ps -a   查看底下全部的Container不論啟動與否\n進入Container與之互動 1  docker exec -it [ConatinerId]] bash   bash有可能沒有，有可能是sh，要自己到/bin裡面看\n停止Container 1  docker stop [ContainerId]   ​\n啟動停止的Container\n1  docker start [ContainerId]   刪除Container 1  docker rm [ContainerId]or[NAMEs]   也可以輸入很多個Id，一次刪個爽\n還有更猛的\n1  docekr rm -f $(docker ps -aq)   直接用參數的方式全刪。\n暴露port 1  docker run -p 5432:5432 posgres   前面的5432是你自定義的localhost:5432，而後面的5432則是容器裡面的port號\n暴露已經Running,Stopping 的Container的Port 沒有這個方法，只有\n1  docker run postgres   的這個時候你才可以把port暴露出來\n一次性查看Container的Log紀錄 1  docker logs [ContainerId]   這條指令只會顯示過去的紀錄，後續的logs不會更新\n持續查看Container的Log紀錄 1  docker logs -f [ContainerId]   這條不只會顯示過去的，還會動態更新現在的log\n執行Docker-compose 1  docker compose up -d   -d 代表是否背景執行，不佔用terminal\n停止並刪除Docker-compose的Container 1  docker compose down   將Dokcer Images Push至Dockerhub 首先先登入dockerhub\n1  docker login   再將想要推上去的docker Image重新命名\n1  docker tag [Image Name] DockerHub帳號/Image Name   接著push上去 dockerhub\n1  docker push DockerHub帳號/Image Name   想要使用image的話就執行pull\n1  docker pull DockerHub帳號/Image Name   在Docker啟動Ubuntu   下載 ubuntu 的image\n1  docker pull ubuntu   或是可以\n1  docker run ubuntu   就會自動從docker hub載下來了，但這樣只是把ubuntu的image拉到我們的docker裡面，它本身是沒有啟動的\n  在docker中運行ubuntu\n1  docker run -it ubuntu     使用apt(advanced package tool)安裝nano(Linux text editor)\n用apt載任何東西前都建議先update\n1  apt update   1  apt install nano     Exposing Port 輸入docker ps可以看到以下資訊\n其中的PORTS 80/tcp的意思，容器對外公開的網路端口是 80/tcp，表示這個容器對外公開的網路端口是80，並且是基於TCP協議的。這意味著當外部網路瀏覽器連接到http://localhost或http://時，將會連接到容器內部的 Nginx Web 伺服器。想要讓容器的端口對外開放，就需要exposing它，否則直接打localhost:80是沒有用的。\n我們可以使用以下的方式將8080 連接到80/TCP\n1  docker run -d -p 8080:80 nginx   其中的8080:80的意思是指將主機的 8080 端口映射到容器的 80 端口。也就是說，當外部網路瀏覽器連接到 http://localhost:8080 時，將會連接到容器內部的 Nginx Web 伺服器。\n你也可以不只Exposing一個Port，可以Exposing多個port給80\n1  docker run -d -p 8080:80 -p 3000:80 nginx   Container的管理 當我們啟動、並Stop一個Container，實際上如果依照我們剛剛的作法，我們是不斷的創造新的Container，輸入docker ps -a 即可看到目前存在的Container(不論running or Stopping)，或是在Desktop docker裡面也都可以看到\n我們可以透過\n1  docker rm [ContainerId]   來真正意義上的移除Container，而不是停止它\n可以使用docker ps -aq ，這個指令只會秀出ContainerId，可以刪更爽，直接複製貼上就好\n還有更爽的方式，用$(docker ps -aq)的方式 傳遞參數\n為Container命名 建議命名一下，比較好找，只支援英文，不支援中文\n1  docker run --name hoxtonPractice -d -p 8080:80 nginx   Volume的使用 讓資訊可以在host與Container共享的一個功能\n範例：\n首先在桌面上創建一個名為website的資料夾，裡面有個index.html，內容如下\n1  \u0026lt;h1\u0026gt;hello docker and volume\u0026lt;/h1\u0026gt;   接著將terminal切至/website底下，然後輸入\n1  docker run --name website -v ${PWD}:/usr/share/nginx/html:ro -d -p 8080:80 nginx     -v是 Docker 中的 volume 指令，它用於將主機上的目錄或檔案掛載到容器中。配合後面的${PWD}:/usr/share/nginx/html，意思就是將當前目錄的內容掛載(Mount)到容器中的 /usr/share/nginx/html 目錄下。這樣設定後，當主機上的目錄內容變更時，容器中的 /usr/share/nginx/html 目錄內的內容也會隨之更新。\n  :ro 是指將主機上的目錄或檔案掛載到容器中的目錄或檔案，並設定為只讀模式。\n  ​\t這意味著在容器中將無法寫入或修改掛載的目錄或檔案，只能讀取。這可以避免對主機上的檔案造成損壞或不\t必要的變更。\n /usr/share/nginx/html 是 Nginx 預設的網站根目錄。  結果如下：\n也因為Volume是鏡像對應，因此修改host的檔案，container的內容物也會同步更新\n我們可以用以下的指令來訪問看看Nginx的檔案\n1  docker exec -it website bash    docker exec 是 Docker 的命令行工具，用於在運行中的容器內執行命令。 -it 這兩個選項表示要互動式地執行命令，並且讓輸入和輸出保持連接。 website 是容器的名稱或 ID。 bash 是要在容器內執行的命令，這裡是啟動 Bash shell。也可以改成ls，就變成ls了，玩法很多，自行摸索  在Nginx裡面新增檔案，移除檔案，會發現host的資料夾檔案也同步更新\n不同的Container使用相同的Volume 1  docker run --name website-copy --volumes-from website -d -p 8081:80 nginx    \u0026ndash;volumes-from [ContainerName]：將這次要啟動的Container使用和website一樣的Volume  Dockerfile Dockerfile是一個文本文件，它包含了創建Docker image所需的指令。這些指令可以包括例如：\n 從哪個基礎鏡像建立新鏡像 安裝需要的軟體 設置環境變量 添加應用程序文件 定義容器啟動時執行的命令  透過Dockerfile, 可以自動化的建立一個環境，方便在不同的環境上部署，使用者可以更方便的管理環境，以及減少部署錯誤的機會。\n例如，如果你有一個Java應用程序需要在多個不同的服務器上運行，你可以使用Dockerfile創建一個包含Java執行時環境的镜像，然後在每個服務器上執行這個镜像，這樣就能保證每個服務器上都有相同的環境。\n試著把剛剛寫的volume打包成一個image，首先在/website的資料夾裡面新增一個名稱一定要是dockerfile的檔案\n裡面的檔案結構長的像這樣子\n1 2  FROMnginx:latestADD . /usr/share/nginx/html   FROM：指定了基礎Image是nginx，後面的latest是指版本號。Dockerfile中必須要有FROM指令，它是一切的根本，它指定了基礎Image環境。舉例來說，這邊指定用最新版的nginx，那麼我們的鏡像會基於這個最新版的nginx環境運行 ADD：將本地目錄中的文件複製到鏡像中的指定目錄。在這個例子中是將本地目錄中的所有文件複製到鏡像中的/usr/share/nginx/html目錄。它的功能跟COPY有點像，但是COPY用法比較單純，只能複製本地文件和目錄到鏡像中，而ADD指令還可以解壓縮tar文件並將其中的文件複製到鏡像中。  ​\t值得注意的是\n1  ADD . /usr/share/nginx/html  這行指的是，將當前目錄的所有東西(以一個.表示)加入至Container中的/usr/share/nginx/html目錄中。在這個例子中就是將\n這些東西ADD進/usr/share/nginx/html裡面。\n當Dockerfile寫好後，要開始bulid它，步驟如下\n1  docker build -t website:latest .   這個命令是在使用 Docker 建立一個新的鏡像檔，並標記為 \u0026ldquo;website:latest\u0026rdquo;。 \u0026ldquo;.\u0026rdquo; 表示當前目錄下的 Dockerfile 檔案將會被用來建立映像檔。這個命令將會建立一個名為 \u0026ldquo;website\u0026rdquo; 並且標記為 \u0026ldquo;latest\u0026rdquo; 的鏡像檔。  Build完後就會出現一個image了，輸入\n1  docker images   就可以查看目前擁有的images\n並且可以這個image可以運行我們剛剛對index的設定，輸入\n1  docker run --name website -p 8080:80 -d website:latest   注意：這邊不需要再為website設置volume，因為我們已經將需要的東西打包進image裡面了。\n輸入完後，在URL的地方輸入localhost:8080就可以看到我們剛剛設置的東西了。\ngif如下\n​\n實際演練 NodeJs 前置作業 安裝Node.js，這邊安裝為了快速，就直接用Choco來裝了，Choco的安裝如下\n  在Terminal中輸入，記得要以系統管理員身分輸入\n1  Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://community.chocolatey.org/install.ps1\u0026#39;))     安裝完後安裝nodeJs\n1  choco install nodejs     安裝完後隨便創一個資料夾，這邊命名叫做user-service-api\n  切換到該資料夾底下，並且npm init它\n1  npm init     接著安裝express\n1  npm install --save express     用好後檔案結構長這樣\n  在該目錄底下新增一個index.js的檔案，內容如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  const express = require(\u0026#39;express\u0026#39;) const app = express() const port = 3000 app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.json([{ name: \u0026#39;Bod\u0026#39;, email: \u0026#39;bob@gmail.com\u0026#39; }]) }) app.listen(port, () =\u0026gt; { console.log(`Example app listening on port ${port}`) })     使用nodejs運行\n1  node index.js     成功後進入localhost:3000即可看到下列畫面\n  如此一來前置作業就完成了\n製作DockerFile 在目錄底下新增dockerfile，內容如下\n1 2 3 4 5  FROMnode:latestWORKDIR/appADD . .RUN npm installCMD node index.js   WORKDIR：若Container有/app這個資料夾，則使用它，若沒有，則創造它。   ADD . .： 将当前目录中的文件复制到镜像中的 /app 目录。 RUN npm install： 在鏡像中运行 npm install 命令，安装应用程序所需的依赖项。 CMD node index.js：设置镜像启动时运行的命令，这里是运行 node index.js。  為什麼要分成RUN跟CMD呢？有幾個原因，首先RUN跟CMD的用途本身就不一樣，RUN主要是在創建image中執行命令，並將結果保存在image中，它主要用來安裝依賴、配置應用程式或其他操作。則是用來說明Image創建完成後要執行的動作。簡而言之，RUN是在創建Image中過程所執行的，而CMD則是在Image創建完成後所執行的。\n並且，一個DockerFile可以有很多RUN指令，但只能有一個CMD指令，因為Container只能運行一個CMD指令\n使用Image 接著創建鏡像\n1  docker build --tag user-service-api:latest .   創建完之後啟動鏡像\n1  docker run --name user-api -d -p 8080:3000 user-service-api:latest   這邊的8080:3000是指，將我們容器裡面原本配置的3000端口暴露出來，以8080來接收。\n因為3000是指在Container裡面的端口，host想要讀到它，必須將Container的端口暴露出來。因此localhost:3000會找不到東西，只有打localhost:8080才會有我們要的內容\nDockerIgnore 做完上面這些操作後，我們的檔案結構長這樣\n然後我們的Dockerfile長這樣\n1 2 3 4 5  FROMnode:latestWORKDIR/appADD . .RUN npm installCMD node index.js  比較之後發現一件事情，RUN npm install會創建node_modules資料夾，但我們在ADD時已經把node_modules加入進去，等於說我們重複創建了兩次node_modules，這種情況就類似gitIgnore，需要排除掉重複的資料夾\ndockerIgnore的寫法\n1 2 3  node_modulesdockerfile.git  這樣就可以把這些檔案排除在外了\nCaching \u0026amp; Layers DockerFile裡面的每一個CML都是一個Layer，每個Layer都用來Caching`\n1 2 3 4 5  FROMnode:latestWORKDIR/appADD . .RUN npm installCMD node index.js  可以看到這邊的Step1, Step2都對應著CML的指令\u0026hellip;\n而Cache的點就在於，其實除了ADD . . 以外(原始碼每次打包時都會有更動)，其實WORKDIR, RUN npm install這些指令其實都是重複的，我們每次打包都需要再重複執行一次，這樣很沒**效率 **\n於是Dokcer就會把這些重複的事情Caching起來，只要沒有改變就不會重複再做，就會看到上面的Using Cache了\nALPINE 翻譯的意思是高山\n我剛剛打包的Image檔案已經快逼近一個G了，很明顯我們其實不需要那麼多的東西，Alpine版本的就是一個非常小的鏡像。\n實際安裝ALPINE 1  docker pull node:lts-alpine   兩者的Size差了快十倍\nDocker Compose 將後端與資料庫一起包一包 一個Project不可能只由一個後端組成，肯定是要由後端、前端、以及資料庫三者組合，甚至更甚者可能會有10,20個的部件需要去組合，那麼一個一個run container這件事情就變得相當缺乏效率。為了處理這件事情，於是有了Docker-Compose的概念出現。\nDocker-Compose大概就像這樣，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  version:\u0026#39;3.7\u0026#39;services:db:container_name:postgres-for-dockerpracticeimage:postgresenvironment:POSTGRES_PASSWORD:rootPOSTGRES_USER:rootPOSTGRES_DB:rootvolumes:- ./pgdata:/var/lib/postgresql/dataports:- \u0026#39;5432:5432\u0026#39;backend:container_name:backend-for-dockerpracticeimage:shopdepends_on:- dbports:- \u0026#39;8080:8080\u0026#39;  和dockerfile一樣存在於專案根目錄中\n他類似於一個配置檔，用以告訴Docker要啟動哪些Container，以及它們之間的交互關係，以上面的Docker-compose.yml來說明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  version:\u0026#39;3.7\u0026#39;//要使用的dokcer-compose版本，有分很多版，比如說1.0,2.0，但目前主流是3.0，所以照著寫就好services://每一個起起來的Container有一個特殊的名字，叫做service，這個yaml檔就有兩個service，分別叫db跟backenddb://可自定義的service名稱，高興叫啥就叫啥，但這個名字會與你在application.properties裡描述的名稱有對應關係，可以看看下面的附圖，第四行的url:jdbc:postgresql://db:5432/shop，其中的db就是service的名稱container_name:postgres-for-dockerpractice //自定義的名稱，想叫啥就叫啥，這名稱會是你的Container名稱image:postgres //要使用哪個image作為基底environment:POSTGRES_PASSWORD:45002502POSTGRES_USER:postgresPOSTGRES_DB:shopvolumes:- ./pgdata:/var/lib/postgresql/dataports:- \u0026#39;5432:5432\u0026#39;//要暴露出來的端口backend://可自定義的service名稱，高興叫啥就叫啥，但這個名字會與你在application.properties裡描述的名稱有對應關係。container_name:backend-for-dockerpractice //自定義的名稱，想叫啥就叫啥，這名稱會是你的Container名稱image:shop //要使用哪個image作為基底，這個是我自己docker build -t shop:latest . 所創建出來的imagedepends_on:- db //這意味著，你這邊的service會等到db這個service完成後才會進行部屬。ports:- \u0026#39;8080:8080\u0026#39;// 暴露出來的端口  ▲第四行的db與services的名稱有對應。\n▲上述的docker-compose啟動後顯示的樣子。\n常用的指令\n啟動當前目錄的docker-compose\n1  docker compose up   關閉當前目錄的docker-compose\n1  docker compose down   ","date":"2023-01-18T21:47:50+08:00","image":"https://i.imgur.com/JdDwgHn.png ","permalink":"https://hoxtonhsu.com/p/docker%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/","title":"Docker學習筆記"},{"content":"前陣子在網路上找看看有沒有什麼實用的Git指令，無意間看到這個功能。\n只要在Github的頁面按下 \u0026gt; ，就可以開啟網頁版的Vscode囉，不過有個小缺點就是，Vscode開啟時介面語言是依據你瀏覽器的語言所決定，所以如果想要使用英文版的Vscode就要把Chrome的語言設定成英文喔。\n這樣開啟後最直觀的好處就是可以直接在Github上以Vscode編輯程式碼，做快速的修改，瀏覽起來也比較快，不然原本網頁在看的話速度非常的慢！並且也可以在上面做衝突的處理。\n","date":"2023-01-11T23:27:27+08:00","image":"https://i.imgur.com/Gckim1N.png","permalink":"https://hoxtonhsu.com/p/%E4%BD%A0%E7%9F%A5%E9%81%93%E5%97%8E%E7%8F%BE%E5%9C%A8github%E4%B8%8A%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8vscode%E5%96%94/","title":"你知道嗎?現在Github上也可以使用Vscode喔！"},{"content":"前言 整理一下工作上有用過，並覺得實用、比較少人提過的一些Git指令。\nGit指令  退回到上一個Commit，數字可以更改，1就是上一次，改成三的話就是三次前的Commit  1  git checkout HEAD~1   退回上一次的Commit，重複輸入的話會往復循環  1  git checkout -   將本次修改合併至上次Commit，如果有漏掉的提交會常用這個指令  1  git commit --amend --no-edit   ","date":"2023-01-06T14:15:51+08:00","image":"https://i.imgur.com/nCGDuUc.png ","permalink":"https://hoxtonhsu.com/p/%E5%AF%A6%E7%94%A8%E7%9A%84git%E6%8C%87%E4%BB%A4/","title":"實用的Git指令"},{"content":"開頭 Java中的例外分為受檢例外與非受檢例外(RuntimeExcetption)兩大類，可以先看到這張圖。\n所謂的非受檢例外就是指繼承了RuntimeException的Exception，這類的Exception發生，而非受檢例外就是指沒有繼承RuntimeException的Exception。可以看下列的圖片\n何謂受檢例外與非受檢例外 受檢例外之所以叫受檢例外，就在於這些例外是工程師必須明確檢查並處理的例外，例如讀取檔案時發生的FileNotFoundException，這類的Exception，JVM沒有辦法進行處理，因此需要工程師去做處理。而RumtimeException則是指那些工程師不需要去明確處理的Exception，比如說NullPointerException, ArrayIndexOutOfBoundsException，這類的例外都是繼承自RuntimeException，可以由JVM進行處理，當然要處理也是可以的，比如說這樣\n(可以看到左邊第13行的方法，沒有被try..catch包住也沒事，因為該方法拋出的例外是NumberFormatException，這個例外繼承了RuntimeException，因此不用try\u0026hellip;catch處理也沒關係，JVM會自動幫我們處理，如果要放到try\u0026hellip;catch的話，則是在catch段裡去catch NumberFormatException)\n將方法放入try\u0026hellip;catch之後，因為catch是抓RuntimeException，所以被抓到後會print出catch error。\n另外比較實務上的說法即是，受檢例外(checked Exception)是可被修復的例外，可以試看看retry，而不可修復的例外就是非受檢例外(RunTimeException)，這種時候就代表程式出了問題，有bug，需要工程師下來進行處理，把問題處理掉\n來源：2021 IT 鐵人 Day 09 單元測試與例外處理\n那如果一個method會拋出受檢例外，而在該method中又沒有做處理，則會需要呼叫它的那一個method進行處理。\n右邊的方法實際上不會拋出IOException，所以會顯示為灰色的，這邊只是作為Demo先寫上去。可以看到畫面左邊的地方，此時IDE跟我們報錯，說這個方法會拋出一個IOException，要我們進行處理，因為IOException是一個受檢例外，JVM本身沒有能力可以進行處理。\n大概先這樣，其他想到後補。\n","date":"2022-12-27T15:12:58+08:00","image":"https://i.imgur.com/dwbYvaF.png","permalink":"https://hoxtonhsu.com/p/java%E4%B8%AD%E7%9A%84throwthrowstry...catch%E5%8F%97%E6%AA%A2%E4%BE%8B%E5%A4%96%E8%88%87%E9%9D%9E%E5%8F%97%E6%AA%A2%E4%BE%8B%E5%A4%96/","title":"Java中的throw,throws,try...catch，受檢例外與非受檢例外"},{"content":"序言 參考資料：\nAgile Hsinchu 2022.11 - 〈你就是不寫測試，才會沒時間〉線上導讀\n測試有時間再寫？你就是不寫才會沒時間！\n你就是都不寫測試才會沒時間：Kuma 的 30 天 Unit Test 手把手教學，從理論到實戰 （Java 篇）\nTDD(Test-Driven Development)是一個軟體開發的模式，它的概念很簡單，就是先寫測試在寫程式，\n這樣的事情會讓我們覺得不可思議，因為我們一直以來寫程式的方式都是先寫程式，而測試則是有時間才再補的東西。那改成先寫測試會有什麼好處呢？這部分我們等等再來談，我們先討論TDD最核心的部分—單元測試(Unit Test)。\n單元測試在TDD的作用是什麼 ​\t一開始在認識單元測試的時候，許多人的想法都會認為說，單元測試可以避免Bug，可以提升程式碼的品質。確實這些都是Unit Test的好處，但卻不是最核心的關鍵，單元測試最重要的點在於幫助我們重構現有的程式架構。\n​\t我們在經手一個項目的時候，第二個月的理解一定會比第一個月的理解更深，第三個月的理解也一定會比第二個月的理解更加深刻，可能三個月前所使用的架構，在三個月後，隨著業務規模的擴展、需求的增加，而需要去新增新的程式，或是改變原有的設計，因而漸漸不敷使用，在這樣的情形下，若沒有單元測試的保護支持我們重構，讓我們確保每一步的Design都沒有破壞原有程式的設計，工程師會變得去害怕修改舊有的程式碼，因而導致不敷使用的架構繼續生長下去。\n(▲ 程式能跑，但還能在更好）\n​\t如果只是這樣子還沒什麼問題，畢竟就只是把東西一個接著一個地疊上去，頂多就是不好維護而已。但實際上的開發中，是很常出現改Ａ壞Ｂ這種情況的，在沒有單元測試的保護下，工程師在開發中是不會知道自己更新的這段程式碼會對某些程式造成影響，往往要等到合併後才能出現問題，所以會出現一種情況就是前期開發的都很順利，而越到後面Dead Line，效率就越發下降，因為工程師在開發的當下不知道自己新增的功能到底會不會對別人造成影響。而有了測試的保護，我們可以在寫程式的時候就知道現在程式的運行狀況，今天這樣子的修改會不會導致其他程式跑不起來，如果跑不起來那單元測試就不會過，這樣的回饋是立即性的回應，而不需要等到合併後大家才知道。\n(▲ 隨著開發時間的增加，TDD的優勢會更凸顯出來）\nAgile與TDD  講到Agile就會講到瀑布式開發(WaterFall)，但你知道嗎？其實從來都沒有瀑布式開發這種事情喔。\n 瀑布式開發是來自於Winston Royce在1970所提出的論文Managing the Development of Larger Software Systems被提出，但事實上這個開發模式在這篇論文的下一行就被Winston Royce否決了。\n I believe in this concept, but the implementation described above is risky and inivites failure. The problem is illustrated in Figure 4 .\n我相信這個概念，但照著這上面的流程做的話是高風險且易導致錯誤的，原因就如第四張圖所示\n ​\t(▲Figure 4)\n The testing phase which occurs at the end of the development cycle is the first event for which timing, stotage, input/output transfers, etc, are experienced as distinguished from analyzed. These phenomena are not precisely analyzable. There phenomena are not precisely analyzable. They are not the solutions or the satndard partial differential quations of mathematical physics for instatnce. Yet if there phenomena fail to satisfy the various external constraints, then invariablt a major redesign is required . A simple octal patch or redo of some isolated code will not fix there kinds of difficulties. The required design changes are likely to be so disruptive that the software requiremnets upon which the design is based and which provides the rationale for everything are violated. Either the requirements must be modified, or a substantial change in the design is required. In effect the development process has returned to the origin and one can expect up to a 100-percent overrun in schedule and/or costs\n在開發流程的最後一個階段-測試，第一個遇到的事情就是時序、儲存，輸出輸入，這些現象情況無法準確的分析，這些不像數學物理的解答，或是標準偏微方程，然而，如果存在不能滿足各種外部約束的現象，則不可避免地需要進行重大的重新設計，一個簡單的八進制補丁或一些孤立代碼的重做不會解決這些困難，所需的設計更改可能會造成破壞，以至於違反了設計所基於的以及為所有事情提供基本原理的軟件要求。 要么必須修改要求，要么需要對設計進行實質性更改。 實際上，開發過程已經回到原點，預計進度和/或成本會超支 100%。\n Winston Royce在瀑布模型提出的當下其實就否認了它的意義，但後續被一些人拿來當作開發的窠臼，也導致了這種開發模式往往會在完工時出現重大的危害。Winston Royce認為，在最後的測試階段是充滿著未知與不確定性，到最後會反覆著在測試、程式修改、確認需求這三個階段來回擺盪，這樣三個階段的來回擺盪是不是有點似曾相似呢？沒錯，就是TDD的概念\n什麼是TDD TDD是一個開發模式而不是測試模式，TDD的測試模式是由\n 寫一個會錯的測試 寫一個剛好會過的程式 重構  ​\t這三者循環，對應Winston Royce對瀑布模型提出的弊端，也就是測試、修改程式、確認需求，也因此TDD是一個可以讓問題早期浮上水面的開發方式，為什麼？因為這樣的開發方式要求我們對業務邏輯的需求有充分的了解，這樣我們才可以寫測試，一旦需求明確了，那麼寫出程式就只是時間的問題了。\n​\t另一方面，也是因為TDD的開發模式，我們每一個Code都有單元測試的保護，我們可以隨時重構我們的程式碼而毋須擔心程式被我們改錯，是的，沒錯，TDD的一個核心概念就在於任何時候都可以重構我們的程式碼，因為人對於系統的了解，會隨著開發時間的增加而了解的越深刻，半年前的Code到了現在可能越看越不順眼，另一方面，隨著業務規模的提升，我們早期的設計可能也會越不敷使用，若沒有單元測試的保護，我們重構的成本會隨著產品的規模的提升而提升，而發展到一定規模的情況下，重構變成遙不可及的夢想。\n​\t也是因為有單元測試的保護，我們才可以真正的去設計我們的程式，常見的S.O.L.I.D，以及23種設計模式的使用，如何根據不同的情境套用不同的設計模式，這就是工程師有價值的地方，可以說單元測試的撰寫完整了整個物件導向的程式設計。\n","date":"2022-12-04T22:22:06+08:00","image":"https://i.imgur.com/2xteh3C.png","permalink":"https://hoxtonhsu.com/p/%E6%B7%BA%E8%AB%87%E6%B8%AC%E8%A9%A6%E9%A9%85%E5%8B%95%E9%96%8B%E7%99%BC/","title":"淺談測試驅動開發"},{"content":"在Junit5中，有對一些Junit的測試的註解進行調整\n比如說\n    Junit4 Junit5     測試用框架的選擇 @RunWith(MockitoJUnitRunner.class) @ExtendWith(MockitoExtension.class)    當測試會使用到SprintBoot框架時，應該要使用@ExtendWith(SpringExtension.class)，@MockBean來調用\n若測試不想涉及SprintBoot的時候@ExtendWith(MockitoExtension.class)，以及@Mock, @InjectMocks，並且使用MockMvcBuilders.standaloneSetup來設置獨立測試，以下是Code的示範\n1 2 3 4 5 6 7 8  \u0026lt;!-- https://mvnrepository.com/artifact/junit/junit --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.12\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.extension.ExtendWith; import org.mockito.InjectMocks; import org.assertj.core.api.Assertions; import org.mockito.Mock; import org.mockito.junit.jupiter.MockitoExtension; import org.springframework.test.web.servlet.MockMvc; import org.springframework.test.web.servlet.setup.MockMvcBuilders; import static org.assertj.core.api.Assertions.assertThat; /** * @author Hoxton on 2022/11/30 */ @ExtendWith(MockitoExtension.class) public class UserControllerTest { @Mock //Controller調用的Service  UserService userService; @InjectMocks //要測試的Cotroller  UserController userController; MockMvc mockMvc; //模擬Mvc  @BeforeEach public void setMockMvc(){ MockMvcBuilders.standaloneSetup(userController).build(); } @Test void testMethod_situation_returnWhat(){ given(someObject.someMethod()).willReturn(\u0026#34;someting\u0026#34;); // ... 設置  MockHttpServletResponse response = mvc.perform(get(\u0026#34;someUrl\u0026#34;)).andReturn().getResponse(); assertThat(\u0026#34;something\u0026#34;).isEqualTo(\u0026#34;thatThing\u0026#34;); } }   ","date":"2022-11-30T13:30:27+08:00","image":"https://i.imgur.com/4qePz5L.png ","permalink":"https://hoxtonhsu.com/p/%E5%A6%82%E4%BD%95%E5%B0%87junit%E7%9A%84%E6%B8%AC%E8%A9%A6%E7%B2%92%E5%BA%A6%E6%8E%A7%E5%88%B6%E5%9C%A8%E6%9C%80%E5%B0%8F%E5%96%AE%E5%85%83/","title":"如何將Junit的測試粒度控制在最小單元"},{"content":"最近業配公司，讓公司老闆買了IDEA讓我們後端工程師來使用，因此技術分享做了一次IDEA的主題，在這邊把技術分享的一些內容做成文章，分享一下\n推薦的Plugin    Plugin名稱 截圖     One Dark Theme\n佈景主題    \n按鍵提示    Rainbow Brackets\n括弧顏色顯示    Nyan Progress Bar讀取條改變    WakaTime\n工作的紀錄     要改的設定    Code Completion\nAlt+.\n      Second Basic Alt+/\n    Type-Match-Completion\nAlt+;\n    Run F10\n 就Run   Terminal Alt+`\n| |    更改Terminal Bash CMD or Window terminal    更改TODO 模板\n     實用的快捷鍵    功能 預覽     sout,souv\n快速印出    搜尋 Shift+shift 快速列出所有可能，快速定位   切換分頁\nCtrl+E 預設快捷鍵，會列出最近開啟的分頁   選擇檔案\nAlt+F1然後按1\n若不想選擇按Esc退回Editor    快速選取區塊\nCtrl+W    快速選取方法\nAlt+↑    查看根源\nCtrl+B    快速定位錯誤\nF2    查看變數提示\nCtrl+P    修改\nShift+F6    內建GitBlame功能\n對行數右鍵選擇gitBlame    萬能鍵Context Action\n引入變數、錯誤修正\u0026hellip;     ","date":"2022-11-10T23:52:33+08:00","image":"https://i.imgur.com/zyn4XVp.png","permalink":"https://hoxtonhsu.com/p/idea%E7%9A%84%E4%BB%8B%E7%B4%B9/","title":"IDEA的介紹"},{"content":"推薦的Plugin    Plugin名稱 截圖     One Dark Theme\n佈景主題    \n按鍵提示    Rainbow Brackets\n括弧顏色顯示    Nyan Progress Bar讀取條改變     要改的設定          Code Completion Alt+.\n    Second Basic Alt+/\n    Run F10\n 就Run   Terminal Alt+`\n| |    更改Terminal Bash CMD or Window terminal    更改TODO 模板\n     實用的快捷鍵    功能 預覽     搜尋 Shift+shift 快速列出所有可能，快速定位   切換分頁\nCtrl+E 預設快捷鍵，會列出最近開啟的分頁   選擇檔案\nAlt+F1然後按1\n若不想選擇按Esc退回Editor    快速選取區塊\nCtrl+W    快速選取方法\nAlt+↑    內建GitBlame功能\n對行數右鍵選擇gitBlame     ","date":"2022-10-23T20:40:49+08:00","image":"https://i.imgur.com/Fx9nanx.png","permalink":"https://hoxtonhsu.com/p/intellij%E4%BB%8B%E7%B4%B9/","title":"IntelliJ介紹"},{"content":"最近在研究C++，但發現我的CLion不知道為什麼只能有一個Main方法，後來網路上查了一下之後發現好像是因為CMake的關係。\n 錯誤訊息\n 後來研究了一下，發現只要在Project底下的CMakeList.txt加上這段就可以了\n1 2 3 4 5 6  file (GLOB files *.cpp) foreach (file ${files}) string(REGEX REPLACE \u0026#34;.+/(.+)\\\\..*\u0026#34; \u0026#34;\\\\1\u0026#34; exe ${file}) add_executable (${exe} ${file}) message (\\ \\ \\ \\ --\\ src/${exe}.cpp\\ will\\ be\\ compiled\\ to\\ bin/${exe}) endforeach ()    完整的圖片如上\n 加入之後記得要Reload CMake Project\n","date":"2022-10-17T18:09:43+08:00","image":"https://i.imgur.com/aGwtINt.png","permalink":"https://hoxtonhsu.com/p/clion%E7%9A%84mutilmain/","title":"CLion的MutilMain"},{"content":"[058]\n作業系統怎麼念？筆記看熟，蓋起來唸，念架構，可以自己把章節結構畫出來\n申論題平常在練習時，假設一天練習十題的情境下，\n3題動手去寫，剩下7題把架構畫出來就好\n[TOC]\nChapter1 Intruduction 管理硬體的軟體就是作業系統，硬體包含CPU，Memory，I/O設備等等…作業系統就是負責管理這些硬體的系統。一個電腦系統可以被粗略的劃分成下面四個組件：\n 硬體(hardware) 作業系統(operating system) 應用程式(application programs) 使用者(user)  Hardware 包括CPU(Central Processing Unit)，記憶體(Memory)，Input/output設備…提供給系統基本的計算資源\nOperating System 負責協調硬體與應用程式，給不同的使用者\nApplication Programs 例如Word，Excel，Chrome之類的應用程式，來處理使用者的計算問題(Computing Problems)\n補充：\n Bare Machine(裸機): 純粹只有硬體組成，沒有OS及System Programs Extended Machine: Bare Machine加上OS/system programs   In Memory  Command Interpreter(命令解譯器)    Multiprogramming System  定義：系統允許多個Jobs(Process)同時執行，即是Multiprogramming   主要目的：提高CPU Utilization 作法：透過Job Scheduling or CPU Scheduling技術達成  example：當執行中的process waiting for I/O completed, 則OS可將CPU切換給另一個process執行，避免CPU idle 。\n即只要系統內有夠多的工作存在，則CPU IDLE的機會就下降\nMulitiprogramming Degree之定義   系統內的Process的數目：一般而言，Degree越高，CPU利用率就越高。  (Note：Virtual Memory Thrashing狀況除外)\n 多個Process的定義、以及如何執行\n Concurrent execution(並行)：一顆CPU，大家一起輪番使用   Parallel execution(平行)：多顆CPU或是Multi-core(多核)，各自執行    Time-Sharing System 分時系統\n定義：又叫Multitasking[恐龍本如是說]\n It\u0026rsquo;s a logical extension of Multiprogeamming system\n 與Multiprogramming的最大差異：CPU的切換頻率極高\n  Time-Sharing System features\n 強調對User Response的時間要短(\u0026lt;1秒) 適用於user interactive的Computing/ Environment 對每一個process都公平    Main Frame(主機)\n CPU Scheduling採取RR的排班法則(第四章會介紹) 使用Virtual Memory的技術，擴展Logical Memory Space 使用Spooling的技術(不太會考)實現I/O Device的共用，類似現代的Buffering技術，讓每個user，皆以為自己有專屬的的Computer  Multiprocessors System 定義：又叫Multiprocessing or Paraller or Tightly-coupled system(緊密耦合系統)\nfaeture：\n 一個機器(or MotherBoard)內，有多個Processors(or CPUs) 這些CPUs彼此共享此機器的Memory,Bus,I/O-Device, power-supplier etc\u0026hellip; 通常受同一Clock之時脈控制 由同一個OS管理 processors之間的溝通大都採shared Memory方式  Benefits(好處)：\n Increased Throughput：產能增加 Increased Reliability：可靠度的提升 Economy Of Scale：運算能力的擴充比較好  　分析如下：\nIncreased Throughput：\n可支持多個工作在不同CPU上平行執行(paraller Computing)，注意，N顆CPU之產能絕對小於1顆CPU產能xN倍，意即CPU數量的提升與產能的提升並非線性成長。原因是因為\n Resource Contetion(資源的競爭) Processors間的Communication會抵消產能  Increased Reliability:\n某一顆CPU壞了，則System不會因此而停頓，因為其他CPU仍可運作\n Graceful degradation(漸進式的滅亡)   System不至因為某些Hardward/Software之元件故障而停頓，仍然保有持續運作的能力，這性質就稱為fail-soft   Fault-Tolerant system(容錯系統)考試不太會考\n 具有graceful degradation性質之系統就叫做Fault-Tolerant system，想要達成容錯的技術需要有兩件事情的支援   要有backup的系統，切換也要流暢    Economy of Scale:\n運算能力擴充符合經濟效益\n ∵N顆CPU在一部機器內，與N部機器相比，成本較便宜∵這些CPUs共享同一機器之Memory, Bus, I/O-Device, etc  Two SubType in Multiprocessors System  SMP(Symmetric MultiProcessors) 對稱的 ASMP(Asymmetric MultiProcessors) 非對稱的  SMP\n定義：每個Processor的工作能力是相同的(Identical)，且每個CPU都有對等、平等的權利來存取資源\n優點：\n 可靠度較ASMP高，因工作能力相同，即使其中一個cpu掛了也可以被立刻取代 效能較高  缺點：\n SMP的OS設計開發較為複雜(互斥存取的機制設計,資源的競爭)  ASMP\n定義：每個Processor之工作能力不盡相同，通常是採取Master-Slave的架構(恐龍本有時候會寫成Boss-Employee\nMaster-Processor負責工作分派及資源分配，監督Slaves等管理工作\nSlave Processors負責執行工作\n優點：ASMP的OS設計開發較為Simple，∵與Simple-Cpu Os版類似\n缺點：\n 可靠度低，Master CPU如果壞了，就會停擺，直到另一顆CPU被Train接手 效能較低∵Master CPU是瓶頸  Multiprocessors System VS MultiCores CPU 從作業系統來看差異不大，主要差異是硬體的差異(主要)，以OS來看，你裝了一顆兩核的CPU，OS會視作兩顆CPU；裝四核的視作四顆CPU\n MultiProcessors  MultiCores CPU  優點\n Power Saving：相較MultiProcessor，在一個CPU上提供兩個Core的能源耗損會比在一張板子上提供兩顆CPU的能源耗損還來得低。 Speed比較快(∵處在同一個晶片內資料傳輸速度較快)  Distribute System 定義：又叫Loosely-Coupled system(鬆散耦合系統)，主要的Feature如下\n  多部機器彼此透過Network(or Bus)相互串連\n  每部機器之CPU有各自私有的Memory, Bus, I/O-Device, etc 並非共享\n  各CPU之Clock時脈控制不一定相同\n  各CPU上之OS也不一定相同\n  各Processors之間的溝通大都採**\u0026ldquo;Message Passing\u0026rdquo;**方式\n Message Passing (類似講電話)\nStep\n 建立Communication Link Message 相互傳輸 釋放Link     Advantage of Distribute-System  Increased Throughput(支持Paraller Computing) Increased Reliability(一個掛掉，還有其他可以擋) Resource Sharing(資源共享因此成本降低)   支持\u0026quot;Client-Server\u0026quot; Computing Model之實施\n Server(伺服器)：提供某些服務的機器 example: mail server, file server ,DNS,printer server, computing server \u0026hellip; Client：本身不提供服務，且它需要某些服務時，則發請求至Server, Server服務完再將結果回傳Client    Note\nPeer-to-Peer model：peer意指同時具有server及Client的角色，英文意思是同等的、對等的\n Remote sites Communication的需求被滿足 example：email, FTP via Internet  Real-Time System (即時系統)\n分成兩種\n Hard real-time System Soft real-time System  Hard real-time system 定義：This system must ensure the critical tasks complete on time，即工作必須在規定的時間限制內完成，否則即算失敗\n舉例：軍事防衛系統、核能安控系統、工廠自動化生產\u0026hellip;\n設計考量：\n 所有時間延遲之因素皆須納入考量 eg：sensor data 傳輸速度、運算速度、Signal的傳輸 etc，確保這些時間的加總能夠滿足時間deadline的要求 所有會造成處理時間過久或無法預測之設備或機制，盡量少採用或不用 eg：Disk不用或少用、Virtual Memory 絕對不採用 就CPU Scheduling設計(Ch4)而言，需先考量Schedulable與否，再進行排程(eg rate-monotonic, EDF scheduling)，確定CPU能負荷再進行排程 Time Sharing system 無法與之並存(Time sharing是屬於Multitasking，可以同時執行多個程序，並透過一些風勢去優先執行某些程序，而Hard real-time比較像單運算系統，要求在指定時間內完成，因此更專注於單一程序的執行，由於這兩個系統有這樣的差異，因此無法共榮) OS所造成的Dispatch latency etc. 宜降低(interrupt的處理, system call的請求)，一般實務上，hard-real-time system，鮮少有OS的存在(幾乎不存在)，尤其是embedded real-time system，因需要及時的響應 現行的商用OS不支援Hard real-time features 通常都是客製化的特殊設計eg : Linux, Unix, Window, Apple Os, Solaris etc  ​\nSoft real-time system 定義：This system must ensure the real-time process get the hightest priority than the others and retain(維持) this priority level unit it completed\n舉例：Multimedia System, Simulation system, VR system, etc\n設計考量：\n 就 CPU Scheduling 設計(ch4)而言，  必須支持preemptive priority scheduling 不可提供Aging技術(活得越久，priority越高)   盡量降低kernel的Dispatch latency time 可支援virtual memory 並存，但前提是real-time-process的全部pages必須皆待在memory中，直到完工，高優先權的Process不要使用virtual memory 與Time-sharing system 可以並存，eg：solaris 一般商用OS都支援Soft-real-time system  Batch System 定義：將一些較不緊急，定期性、非交談互動性的Job，累積成堆，再分批次，送入系統處理\n舉例：庫存系統、報稅系統、掃毒、磁碟重組、清算系統\u0026hellip;\n主要目的：提高resource utilization，尤其是在冷門時段，不適合用在real-time-system, user-interactive application eg：電腦遊戲\nHand Held system 定義：單手可掌握操作的系統\n Hardware 天生之限制，帶來software必須配合之處     Hardware天生限制 Software必須配合之設計     Slower processor\n(背後之限制)\n1. power 供應的問題，電供不足\n2. 散熱系統的設計 運算不能太複雜，要簡單   Memory空間有限 程式的Size要小，不用的記憶體要立刻釋放   DisplayMonitor很小 顯示的內容要有所刪減    Chapter2 Computer System Architecture I/O Operating And Hardware Resources Protection  學習路線   I/O運作方式\n Polling I/O\nInterrupted I/O\nDMA\n Interrupt機制處理與種類\nHW Resource Protection\n 基礎建設\n Dual Model Operation\nPrivileged Instruction\n I/O\nMemory Protection\nCPU\n  I/O Operating Polling I/O I/O Polling(輪巡,詢問式) I/O\n定義：又叫Busy_waiting I/O or Programmed I/O\n步驟如下\n I/O Request 給 OS (執行中的Process不會自己做I/O) OS收到請求後，(可能)會暫停此Process執行，並執行對應的System Calls. Kernel 的 I/O-subsystem(專門用來處理I/O的請求，只是個過水而已)會Pass此請求給Device driver Divice Driver 依此請求，設定對應的I/O Commands參數給Device Controller Device Controller 啟動監督I/O-Device之I/O運作進行 在這段時間內，OS(可能)將CPU切給另一個process執行 然而，沒人主動去告訴CPU I/O的執行狀況，因此CPU在執行process工作過程中，卻要不斷去Polling Device Controller，已確定I/O運作是否完成或有I/O error  缺點：\n CPU耗費大量時間用於polling I/O Device Controller上，並未全用於process execute上，故CPU utilization低、throughput不高  Interrupted I/O Interrupted (中斷,中斷式)I/O I/O\n定義：\n步驟如下：\n  I/O Request 給 OS (執行中的Process不會自己做I/O)\n  OS收到請求後，(可能)會暫停此Process執行，並執行對應的System Calls.\n  Kernel 的 I/O-subsystem(專門用來處理I/O的請求，只是個過水而已)會Pass此請求給Device driver\n  Divice Driver 依此請求，設定對應的I/O Commands參數給Device Controller\n  Device Controller 啟動監督I/O-Device之I/O運作進行\n  在這段時間內，OS(可能)將CPU切給另一個process執行\n  當I/O運作完成，Device Controller 會發出 I/O-Completed Interrupt 通知OS(CPU)\n  OS收到中斷後(可能)會暫停目前Process的執行(因有些Interrupt優先權可能很低，可以先暫時不處理)\n  OS必須查詢 Interrupt Vector，確認何種中斷發生，同時也要找到該中斷的服務處理程式(ISR：Interrupt Service Routine)的位址(每一個中斷都有一個對應的中斷處理服務程式\n  Jump to ISR位址 執行ISR\n  ISR完成後，return control to kernel，kernel也許做一些通知工作\n  恢復(resume)原先中斷前的工作執行或交由CPU Scheduler決定\n  優點：CPU不須耗費時間用於Polling I/O-Device，而是可以用於Process execute上，CPU utilization提升，throughout提高，improve the system performance\n缺點：\n Interrupt之處理仍需耗費CPU time，如果 I/O運作時間 小於 Interrupt處理時間，則使用Interrupt I/O就不划算，不如使用polling I/O 若中斷的頻率過高，則大量的中斷處理會占用幾乎全部的CPU Time，則系統效能會很差 CPU仍需耗費一些時間用於監督I/O-Divice與Memory之間的Data Transfer過程  DMA (Direct Memory Access) I/O  定義：DMA Controller 負責 I/O-Device(設備)與Memory 之間的Data transfer(傳輸)工作，過程中不需CPU之參與監督，因此CPU有更多時間用於Process execute上  優點：\n CPU Utilization更高 適合用在Block-Transfer oriented I/O-Device上(代表中斷發生的頻率不致於過高 eg:Disk, 磁碟的控制器會和DMA的控制器兩個會相互合作，磁碟控制器會去指揮磁碟的運作，讀出來的資料會通知DMA的控制器，DMA會把資料輸進Memory裡) 不是用於Byte-transger oriented I/O-Device  缺點：\n 引進DMA Controller會增加HW設計複雜度(Complicated the HW design)   原因：DMA的Controller會跟CPU競爭爭奪Memory(記憶體)、Bus(匯流排)的使用權，若DMC Controller 占用了memory , Bus 時，CPU要被迫等待\n補充：DMA Controller通常採用\u0026quot;Cycle Stealing\u0026quot;技術 (or Interleaving)與CPU 輪番(交替)使用memory跟Bus，如果CPU與DMA Controller發生conflict(同時要用Memory 與 bus)，則會給DMA較高的的優先權\n  通常系統會給予「對該資源需求量、頻率等較小」的對象有較高的優先權，這樣會獲得\n 平均等待時間較小 平均產能較高  的好處\n  機器指令的Stages (CPU執行的幾個階段)\n     IF DE FO EX WM     IF：Instruction Fetch 抓指令：根據Programming Counter的值，到記憶體去把指令抓出來  DE：Decode 解碼：知道這條指令到底做什麼事情 FO：Fetch Operands 抓取運算元：運算元可能來自記憶體、也可能來自暫存器 Ex：Execution　執行 WM：Write Result to Memory　將結果寫入記憶體      CPU會不會Memory Access（到記憶體抓東西） DMA要用Memory     IF 會 衝突(Conflict)   DE 不會（指令已經拿出來放到IRinstructor registor) OK，歡迎   FO 可能 (運算元有可能在Registor，也有可能放在Memory) OK，或有衝突   EX 不會 (ALU去做了) OK，歡迎   WM 可能 (結果有可能寫回Memory也有可能是暫存器) OK，或有衝突    Cycle Stealing：當CPU會使用或不會使用Memory Access時，DMA都會去爭奪Memory的使用權，亦為Stealing(偷)，因為DMA擁有最高使用權。\nDMA Six Steps (早:中央、清華、交大)\n Device Driver User Process 告訴 I/O subsystem(kernel)告訴 Device Driveris told to transfer Disk data to Buffer address X Device Driver tells disk controller to transfer C bytes from disk to Buffer at address X從磁碟讀C byte的量，分配到記憶體位址X的地方 Disk controller initiates DMA Transfer Disk controller sends each byte to DMA controller DMA transfer bytes to Buffer X in creasing memory address and decreasing Counter utill Counter =0 When C=0, DMA interrupts CPU to signal transfer compeletion  Life cycle of I/O-request via Interrupted I/O Blocking and Non-Blocking I/O Blocking(會暫停的) and Non-Blocking(不會暫停的)I/O\n 所謂的Blocking的意思是，當User process發出I/O請求之後，接下來這個prcess就會suspend，直到這個I/O被完成\n Blocking-I/O: (等於Synchronous)：Process suspended until I/O completeed\n 優：Easy to use and understand, process在waiting的時候，可以把CPU放出去給其他process做使用 缺：Insufficient for some needs  Non-Blocking I/O： I/O calls returns as much as available I/O請求發出去後，控制權立刻返回給user process\n example：user interface, data copy Implemented via multi-threading Returns quickly with count of Bytes read or written  Asynchronous-I/O: (屬於Non-blocking)：Process runs while, I/O executes\n Difficult to use I/O subsystem signals process when I/O-completed  Asynchronous與Non-Blocking的小差異 Asynchronous I/O：整個I/O完成，才通知Process\nNon-Blocking I/O：I/O完成Data return as much as possible (能回傳就回傳， 少量即可回傳)\n舉例說明：userProcess發出100 byte的I/O請求\n Asynchronous的方式，會將100byte的I/O做完後，才告訴Process做完了 Non-Blocking的方式，每讀25Byte就通知一次， 逐步回報給Process，會發出比較多次的Interrupt  Interrupt Policy and  當Interrupt發生，OS之處理Steps如下：  OS收到中斷後(若此中斷要被立即處理，則OS會暫停目前Process之執行，且保存其Status and Registers Contents) OS會依照Interrupt ID(No.)查詢Interrupt Vector中斷向量表，確認何種Interrupt發生，且找出其ISR的位址 Jump to ISR 位址，執行ISR ISR完成後，控制權返回Kernel OS會恢復(resume)中斷之前Process之執行     Interrupt種類\n  早期恐龍分為三種\n External Interrupt：CPU以外的周邊設備、控制卡、etc，所發出的中斷  例：I/O-Completed, I/O-error, Machine-check,\nInternal Interrupt：CPU在執行Process過程中，遭遇重大錯誤而引發  例：Divide-by-zero除以零、執行非法的特權指令、etc\nSoftware Interrupt：user process 在執行中，若須要OS提供服務時，發出此類型的中斷，目的是通知作業系統，請它執行對應的服務請求  例：I/O-request 好比是KTV的服務鈕，按下去就會有人過來問你要幹嘛\n  現在恐龍分為兩種\n Interrupt：硬體所產生就叫Interrupt Trap：軟體所產生的就叫Trap    例：設備發出I/O-Completed,I/O-Error,Machine-check,etc及Time-out by Timer\n用途主要有二\n Catch the arithematic error  例：Divide-by-zero, 執行非法特權指令, illegal memory access\n user process 執行需要OS提供服務時，也會發trap通知OS  例：I/O　Request\n分成兩類背後哲學：中斷之間也有優先權高低之分  Maskable Interrupt遮罩：此類中斷發生後，可被Ignored或延後處理不一定要馬上處理  例如：Software-interrupt   Non-Maskable不可遮罩：此類中斷必須立刻處理  Internal interrupt(重大error), I/O-error,etc        Hardware Resources Protection  基礎建設  Dual-modes operation(雙重模式) Privilege instructions    Dual-modes operation 定義：System之運作模式至少(可再往下分，依照系統設計的必要性)可被區分為2種modes\n kernel mode user mode  kernel mode\n又叫做system mode, supervisor mode, privileged mode, monitor mode(早期有，現移除)，代表此刻是kernel取得系統控制(取得CPU執行權)，允許privilege instructions(特權指令)在此mode下執行\nuser mode\n代表user process取得CPU執行，在此mode,不允許執行privilege instructions(特權指令)，若執行則會發生trap的重大錯誤\n此外，Dual-modes必須要有HW的支持，才可實現\n例如：CPU內會有Mode Bit，用以區分現在是哪個mode當CPU在執行機器指令時，IF、DE...之類的階段，若解碼完發現是個特權指令，這時候Control unit就要檢查目前的mode bit，判斷是否可不可以執行，若不行就丟出一個interrupt，不允許執行\nPriveleged instruction(特權指令) 定義：任何可能會造成系統重大危害的指令，可設為特權指令(端看工程師如何設計)，只可以在Kernel Mode去執行，不可以再User mode下執行，一旦在User Mode下執行，會發Trap通知OS，將此user process terminates.\n如果把所有的指令設為特權指令，好處就只有超級安全，因為這些指令都只有OS可以做，如果user想做就只能委託OS執行，但這樣performance會很差，因為所有事情都要給OS處理\n例如：\n  Turn-off(Disable) interrupt, clear memory, I/O instruction(for I/O protection),Timer值 set/change (for CPU protect)\n  Base/Limit register 修改/set (for memory protection)\n  Change mode from user mode to kernel mode\n  1 2 3 4 5 6 7 8  1). Set value of Timer 2). Read the clock 3). Claer memory 4). Turn-off interrupt 5). Switch from user to monitor mode 哪些是特權指令? 1,3,4,5     1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  1. Change to user mode 2. Change to monitor mode 3. Read from monitor memory 4. Write into monitor memory 5. Fetch an instruction from memory 6. Turn on timer interrupt 7. Turn off timer interrupt 哪些是特權指令? 2,4,7 詳解： 6. 本身就是打開的，因為要做CPU的保護 7. 但關掉不是 有爭議的部分 3. user process去讀kernel process的資料，恐龍認為是，因為kernel裡面掌管所有Process的information，而process間不應該各個process的狀態 5. 從Monitor memory(Kernel)裡面去讀指令出來，恐龍認為不是，因為就算抓了，但你的mode不是Privilege instruction就會把你擋掉     為什麼Dual-mode跟Privilege Isntruction可以構成保護基礎 所有會危害OS的操作都是在Kernel 發生，因此不可以放任user可以直接操作Kernel\nI/O-Protection 目的：由於I/O運作較為繁瑣複雜，為了降低user processes 操控I/O之複雜度`，讓user processes去處理應用的問題，I/O則交由OS去處理；及避免user process對I/O-Devices之不當操作，胡搞瞎搞，因此才有I/O protection。簡單來講就是不要讓user processes去操作I/O\n作法：把所有I/O指令皆設為privileged instruction配合Dual-modes, 一律讓user process委託 kernel執行I/O運作\nMemory Protection 目的：防止user process 存取其他user processes 之 memory area 及 kernel memory area\n作法：(以 contiguous Memory Allocatation 為例) 針對每個Process, kernel會提供一套Registers：叫base/limit register, 其中\n Base register紀錄Process之起始位址 Limit register紀錄Process之大小  將來Process執行，會進行下列的Checking\n 為什麼Address的判斷是由Hardware來做而不是OS來做呢？\n因為交給OS來做就會產生中斷interrupt，又因程式在執行的時候對記憶體的存取是很頻繁的，兩個影響之下會導致你的CPU一直被interrupt打擾，因此交給Hardware來做會比較符合成本一點。\n 並且，還要將 Base與Limit register 值之set/change須設為\u0026quot;Privilege Code(特權指令)\u0026quot;，避免user Process把Base跟Limit的位址直接改成無限，這樣就完成了Memory的Protection\nCPU Protection 目的：防止user process無限期/長期佔用CPU而不釋放\n作法：利用Timer實施，同時OS會規定Process使用CPU time之最大配額值(MAX. Time Quantum)\n當process 取得CPU後，Timer初值即設為Max Time Qauntum值，隨著Process執行 time增加, Timer值會逐步遞減，直到Timer值為0, Timer會發出 Time-out的interrupt通知OS，OS便可強迫此process放掉CPU，此外，Timer值之set/change 也須設為特權指令\nOS Structure Operating-System  OS之Development\n OS應提供的服務項目\nOS之服務元件種類\nSystem Calls之介紹(使用者程式跟OS之間溝通的介面)\nOS之Structure種類\n Simple\nMore Complex than simple\nLayered Approach\nMicrokernel\nModule\nHybrid(混合?)\n 設計原則：Policy與Mechanism policy管行為,比較常變，例如數值的變動; mechanism負責處理how,比較不會變,例如邏輯的判斷 \nVirtual Machine介紹\n  System Call 定義：作為執行中user process與kernel之間的溝通界面，當user process需要OS提供某種服務時，會先trap通知OS，並帶入System call ID(No)及所需參數，然後OS執行對應的System call\n It\u0026rsquo;s a programming Interface to the services privided by the OS\n 用舉例來講的話\n Trap = 服務紐 System call = 服務項目  System Call的種類(中央考過類似的題目)\n  Process Control eg：建立、終止、暫停、恢復執行process, set/read attribute File Management eg：建立、read, write, open, close, delete \u0026hellip; Device Management eg：建立、read, write, open, close, delete \u0026hellip; Information of Maintenance eg：取得系統日期/時間、取得Process屬性 etc Communications eg: Processes之間的通訊而且只針對Message Processing方式提供服務 Protection　eg: Hw resources protection, File access contorller, etc   System Call的參數(Parameters)傳遞方式：3種方式\n 利用暫存器(Registers)保存參數  優點：  最簡單 存取速度最快( without memory access)   缺點:  不適用於大量參數之情況     利用Memory，以一個Block(Table)儲存這些參數，並將這些表格的起始位址置於1個Register中，Pass給OS  優點:  適用於大量參數   缺點:  存取速度較慢，且操作較為麻煩     利用Stack將參數push入此Stack, OS再pop from stack, 以取得參數  優點:  適用於大量參數之情況 也很簡單   缺點:  Stack的空間須要預先準備，避免stackoverflow      OS之系統架構分類 OS之Structure種類\n Simple: MS-DOS系統\nMore Complex than simple: UNIX系統\n Limited by Hardware functionality The original UNIX had limited structuring The UNIX 包含兩個Separate parts  System Programs The Kernel     Beyond simple but not fully layered(分層)  Layered Approach\n  定義：採取Top-Down方式，切割系統功能/元件，以降低複雜度。元件/模組之間呼叫關係分層\n即上層可以使用下層的功能，但下層不可以使用上層的功能。完成後要使用Bottom-up方式進行測試，debugging(由底層一路往外測)\n  層次的劃分沒有明確規定\n  優點：\n 降低設計複雜度 有助於分工 測試、除錯、維護容易    缺點：\n 很難做到精準的分層劃分 若Layer數太多，則System performance is very poor( 切到四層剛好、五層太多，極限中的極限是七層)    Microkernel(微核心)：由CMU(卡內基-美隆大學)率先提出，代表產品：Mach o.s。它們認為UNIX的服務項目太多、太龐大，不利移植\n 定義：將Kernel中一些Non-essential services(比較不是那麼基本、重要、必要)，自Kernel當中移除，改成在User Mode(Site)提供這些服務，以System programs方式存在，如此一來，可以得到一個比較小的kernel，稱之為microkernel, 一般而言，Microkernel提供下列三個minimum service：   Porcess Controll Memory Management(不包括Virtual memory) Process Communications(提供message Processing服務而已)   Benefits(好處)   Easier to extend a microkernel  服務的增加/刪除是容易的，因為這些服務是在user site執行，所以服務的增、刪不需要牽扯到Kernel也要變更，即使要，也是少量   Easier to port the OS to new architectures  因為Kernel很小，所以移植到新的硬體平台之更改幅度不大(因為只有三個服務run在kernel)   More Reliable  萬一某一個服務在執行中掛掉了，充其量只是相當於一個user process死掉而已，所以對HW, kernel, 其他user process沒有不良影響，因為把大部分的服務移到user mode去做了，因此更加安全、可靠   More secure  萬一某一個服務在執行中掛掉了，充其量只是相當於一個user process死掉而已，所以對HW, kernel, 其他user process沒有不良影響，因為把大部分的服務移到user mode去做了，因此更加安全、可靠     缺點   Performance overhead of user space to kernel space communication(效能較差)，因為process Communication充斥大量訊息傳遞   Note：microkernel的相反詞：Monolithic kernel\n定義：所有的Services皆須Run in kernel mode，大部分的商用OS幾乎都是Monolithic kernel，因為如果把所有的service移到user site去做，那它的控制就會很低。當這個控制力很低的時候，user或program就可以自己去Inhence一些東西，影響OS\n優點、缺點：和microkernel相反\n Module\n Many OS implement loadable(有需要才載入) kernel modules use Object-oriented approach Each core component is separate Each talks to the others over known interface Each is loadable as heeded within the Kernel 簡而言之：similar to Layers but with more flexible, 效能更好  例如：Linux, solaris, etc \u0026hellip;\nHybrid(混合?)：現在作業系統很難純粹歸屬於某一型\n Linux(中央考過) and Solaris 是 Monolithic (所有東西都run在kernel mode)，且也是Modular for dynamic loading 例：windows mostly monolithic，有時針對不同客戶需求，會再加上microkernel for subsystem 例：Apple Mac Os 也是混合的  kernel 包含\n Mach microkernel\n部分的BSD UNIX\nI/O Kit\ndynamic Loadable module(叫做 kernel extension)\n  Virtual Machine 定義：利用sofeware技術模擬出一份與底層HW一模一樣的功能介面之抽象代理器(abstract machine)，稱之Virtual Machine模擬的方式類似於CPU schdueling \n名詞解析：\nHost：undelying hardware system, os\nVMM(Virtual Machine Manage)或Hypervisor：creates and managing/ runs virtual machines\nGuest：process provided with virtual copy of the host\n 恐龍本之其他英文\n Abstract hardware of a single computer into several different execution environments Similar to layered approach, But layer crates virtual machine(VM)   優點\n  作為測試開發中的OS，提供一個良好的負載平台，具有下列好處：\n 其他user, user processes工作，仍可持續運作，不須暫停 萬一測試中的OS不穩定、掛掉/失敗了，也不會影響host Hw, OS, 其他user processes 之工作，因為只是相當於一個user process fails而已，不會對system有重大危害   同一部Host Hardware上可以執行多個OS running on 多個virtual machines，這樣可以節省成本\n  Consolidation(合併)：在 Cloud computing environment，我們會用有限的機器，建立為數注眾多的virtual machines，我們可以依VM上的Applications之執行負擔輕重，調用Host machines資源，做因應的支援，有需要就在加開，沒需要就關掉，做資源的合併與調度\n  VM較為安全(如果VM被病毒入侵，不致擴散，因為各VM之間是相互獨立的)\n  可以Freeze, suspend, running VM, 及Clone(複製) VM\n    VMM的Implementation\nHypervisor : 虛擬機管理程式\n  Type0 Hypervisor(硬體層次)：\n Hardware-based solutions via firmware  例如：IBM LPARS and Oracle LDOMs      Type1 Hypervisor(Kernel Mode層次)\n  OS-like software\n 例：VMware ESX, Joyent SmartOS, Crtrix XenServer    general purpose OS that provide VMM functions (services)\n 例如Microsoft Window Server with HyperV, Redhat Linux with KVM      Type2 Hypervisor(user mode層次)：\n Applications level provides VMM functionality\neg. Paraller Desktop, Oracle VirtualBox\n    還有一些其他的變形上面那三類都是要創造跟底層硬體(Host HW)一樣的Virtual Machine，但下面這些卻不是\n Paravirtualization☆考試重點\n The guest OS need modify to work in cooperation with VMM to optimize performance presents guest(run 在virtual Machine上的都叫guest) with similar but Not identical to Host Hardware Guest must be modified(必須要被修改才可以用) to Run ON Paravirtualization virtual hardware    Programming-environment virtualization\n  VMMs do not virtualize, HW but instead create on optimized virtual system .(創造全新的Virtual Machine)\neg. Java virtual machine(JVM), Microsoft .NET\nJVM is a SPECification(規格), not an implementation\n規範\n Class Loader(把bype code load下來) Class verifier(驗證器，驗證byte Code安不安全，比如是否包含pointer) Java interpreter(執行byte code)      Emulators：Allow application written for one HW to run on a very different HW such as different type of CPU。例：PS4模擬器、3DS模擬器\n  Application containment (底層沒有Virtual Machine，而是 創造執行環境，而不是模擬)\neg. Oracle Solaris Zones BSD Jails, IBM AIX WPARs application\nPolicy(政策、策略 ) 與 Mechanism\n  Policy定義\n \u0026ldquo;What\u0026rdquo; to be proovided 經常改變、朝令夕改    Mechanism定義\n How to do that The underlying(基本的) mechanism甚少改變或不變    設計原則：\nPolicy與Mechanism宜separate，以增進system flexibility\n  舉例\n    運用Timer作為CPU protection \u0026gt; Mechanism Max.Time Quantum大小制定 \u0026gt; Policy     CPU排版採Priority Scheduling 排班 \u0026gt; Mechanism Priority大小之定義 \u0026gt; Policy      Chapter 3 System Structure 這個部分和第二章寫在一起了\nChapter4 Process Management And Thread Management  Process 定義與Progeam比較\nPCB內容 考試重點\nProcess State Transition Diagram (S.T.D)考試重點\nScheduler的種類(解釋名詞)\n 長期\n短期\n中期\n Context Switching (解釋名詞)\nDispatcher, Dispatch latency(較少考)\nProcess Controller Operations(UNIX, System Call為主的程式追蹤) 考試重點\n評估CPU Scheduling 效能的好或不好的5個Criteria(清大喜歡考)\n各種CPU 排班法則(7個)介紹及相關名詞(Starvation,Aging,Preemptive,Non-preemptive,Convoy effect) 考試重點\n特定System的排班設計\n MultiProcessors System\nReal-time System\n Soft (考申論題)\nHard(考計算題)\n  Thread Management\n Process Definition 定義：A program in execution[恐]\n Process 建立後，其主要組成有：  Process No(ID): Process被生成出來時，會有一個Process Id，作為識別 Process State Code Section, Data Section：Process占用的 Memory Space Programming Counter(PC)：程式計數器，告訴我們現在這個Process執行到哪裡，裡面放下一條指令的位址 Stack CPU Register value 是OS 分配 **Resource(CPU,I/O-Divice, Memory) **之對象單位：跟Thread的差別   與Program(程式)的比較     Process Program     執行中的程式 Just a File stored in storage device   \u0026ldquo;Active\u0026rdquo; entity(活動中、執行中) \u0026ldquo;Passive\u0026rdquo; entity(沒有活動的)    Process Control Block (PCB內容)\n定義：OS為了管理所有Processes，會在Kernel memory中，替每個Process，各自準備一個Block(Table, 表格)，用來記錄Process之所有相關資訊\nPCB的主要內容有(要背，考選擇)：\n  Process No(ID)：是Unique(唯一的)\n  Process state：eg. ready, running, wait, etc\n  Programming Counter：內放 the next instruction\u0026rsquo;s address\n  **CPU Registers：eg. 紀錄使用到的暫存器的值 eq. Accumulator, PSW(Process Status Word), Stack Top ,etc **\n  CPU Scheduling Info：eg. Process 的優先權，First-In First-Out(FIFO)\n  Memory Management Info(隨OS的記憶體管理方法不同，紀錄不同資訊)：eg. Base/Limit register或 Page Table 或 Segment Table\n  Accounting Info：eg. Process已使用了多少CPU Time, 哪些資源, 還剩多少資源,多少CPU Time可以用 Note：目的\n 計算使用量，記帳、收＄\nAdministrator 調教Performance的依據\n   I/O Status Info：eg. process已經發出多少I/O-Request, 完成 狀況如何，占用那些I/O Resource(目前還沒釋放的)\n  Process State Transition Diagram 狀態轉換圖(S.T.D)\n目的：描述Process之Life Cycle，用來記錄Process建立，到它被終止之間，所發生的事\n各個版本的STD定義都不太一樣\n  [恐] 5個State的STD [Stalling]7個State STD (比恐龍多兩個狀態) [Stalling] UNIX的STD   5 Steps of State Transition Diagram 要會畫，會說明，超基礎，考出來是送分題\n   State Description     New(Create) Process被建立，已分得PCB的空間，尚未載入記憶體、未取得記憶體資源，因應Batch的系統   Ready Process在記憶體了，且OS已經把它放到Ready Queue內，且具有資格爭奪CPU   Running Process取得CPU 執行中   Wait(Block) 表示Process待在waiting Queue中，Waiting For I/O-Completed or event occurs, 不會與其他Processes 競爭CPU   Exit(Terminate)(Zombie)(Abort) Process完成工作，正常結束或異常終止，可能其PCB尚未回收，因為要等其父親(Parent Process)Collect 該子process之成果後，才會回收PCB Space其他資源(Memory, CPU, I/O-Devices)已回收       Transition Description     1. 也叫Admit，當Memory Space足夠時，可由Long-term Scheduler(in Batch System，因為放在Job Queue裡頭)，決定將此Job載入到Memory中   2. 也叫Dispatch,由short-term scheduler(CPU Scheduler)決定，讓高優先權的Process取得CPU控制權   3. 也叫Time-Out/Interrupt，執行中的Process會因某些事件發生而被迫放棄(不是自願的)CPU，回去Ready Queue, eg. Time-Out, Interrupt發生,更高優先權的Process到達，插隊   4. 叫wait for I/O-Completed or event occurs(自願放棄CPU)   5. I/O-Completed 或 Event occurs   6. Process完工或異常終止 (自願放棄CPU)    7 Steps of State Transition Diagram[Stalling] 補上Middel Term Scheduler\n為了解決一個問題\n當記憶體被占滿了，有一個更高優先權的Process近來，該如何處理？\n把wait狀態的process踢出去，放到磁碟去保存\n   State Description     Blocked/Suspend Process被Swap Out到 Disk中暫存，即Blocked(asleep) in Disk   Ready/Suspend event occurs or I/O-Completed, READY IN DISK       Transition Description     Suspend(Swap Out) 當Memory空間不足，又有其他高優先度的Process需更多Memory空間時，會由Medium-Term Scheduler決定將Blocked Process或低優先權的Process Swap out到Disk，以空出Memory Space   Activate(Swap In) 當Memory space有空，Medium-term scheduler可將它們Swap In回memory中，Ready for execution   Suspend(Swap Out) 支持此Transition之理由有二\n1.所有Blocked Processes皆Swap out後，Memory Space仍不足時\n2. 所有Blocked State Processes之優先權，皆高於Ready State Process時       Transition Description     1 把從在磁碟睡覺的process拉到記憶體裡面睡覺，This is a poor design，但仍可支持，理由如下：若所有Blocked/suspend` state之Processes優先權皆高於ready/ suspend processes, 且OS believes them will become ready soon |   2 It\u0026rsquo;s also a poor design 但可支持之理由如下：若有一個高優先權的process從blocked/suspend變成ready/suspend時，則OS可以強迫低優先權但已執行的process放棄CPU的使用以及Memory的空間，供高優先權使用    UNIX STD[Stalling] Scheduler Type(Important)    Long-term Scheduler\n 定義：又叫Job Scheduler，目的是從Job Queue中挑選一些Jobs載入到Memory中 特色：  執行頻率最低，所以才叫長期 可以調控Multiprogramming Degree 可以調控 I/O-Bound Job與CPU-Bound Job之混合比例(下面有解釋) Batch System採用，但是real-time system以及time-sharing不會採用這種機制。因為real-time系統處理的process都是比較緊急的，因此就需要直接丟進memory去執行。而time-sharing系統要求對每一個user公平，沒有優先度需要處理，如果memory不夠則調用virtual memory，因此time-sharing系統只存在medium-term以及short-term      Short-term Scheduler：\n 定義：又叫CPU Schduler或Process Scheduler，目的是從Ready Queue中挑出一個高優先權的process，分派CPU，給CPU執行 特色：  執行速度是三者裡面最高的 無法調控Multiprogramming Degree，因為它不是負責將程式load進memory與Swap out出去的人 無法調控I/O-Bound Job與CPU-Bound Job之混合比例，頂多決定誰要先做，不能決定比例 所有的 System採用      Medium-term Scheduler(最常被考)：\n  定義：Time-Sharing System採用，當Memory空間不足，且又有其他高優先權Processes需要Memory Space時，此Scheduler會啟動，它會挑選一些Processes(eg. Blocked Process, 低優先Process) 將其Swap Out到Disk中，保存，以空出Memory Space，供其他Process使用，將來等到有足夠的Memory Space released後，此Scheduler可再將它們Swap In 回Memory, ready for execution\n  特色：\n  執行速度是三者裡面居中的\n  可以調控Multiprogramming Degree，因為它不是負責將程式load進memory與Swap out出去的人\n  可以法調控I/O-Bound Job與CPU-Bound Job之混合比例，頂多決定誰要先做，不能決定比例\n  Time-Sharing System採用\n       Multiprogramming Degree：系統內的Process的數目：一般而言，Degree越高，CPU利用率就越高。\nI/O-Bound Job與CPU-Bound Job   I/O-Bound(受限) Job\n定義：此類型工作大都是需要大量的I/O operation(resource)，但對於CPU Time(Computation)需求很少，因為其工作效能受限於I/O-Device之速度，稱之I/O-Bound，對CPU有最高優先權，因為它占用CPU的時間最短\n例如：Data Base Management, 財報的處理列印\n  CPU-Bound(受限) Job\n定義：需要大量的CPU計算，產生數筆資料，對I/O有最高優先權，因為它占用CPU的時間最短\n例如：氣象預估、科學模擬\n  如果OS發現I/O-Bound過多，則會透過Schduler來調控兩者之間的比例\nContext Switching   定義：當CPU要從Running Process切給另一個Process使用之前，Kernel必須**保存(Store) Running Process的目前狀態資訊(eg. Programming Counter的值，Stack的值，CPU Register的值，etc)，即存回此Process之PCB **。且要載入(restore)另一個Process之狀態資訊from此Process PCB，這樣的行為就叫做Context Switching，Context Switch本身是一個額外的負擔，因為需要花CPU的時間去做切換，不能用在Process的執行上，因此時間大多取決於硬體的因素居多(eg. Register的數量夠不夠，Memory存取指令速度\n  如何將低Context Switching負擔\n 如果Register的數量足夠多，則可以讓每一個Process皆有自己的(Private) Register Set，OS只要切換Point指向另一個process之Register Set 即可完成Context Swtitching without memory store/restore ，因為速度夠快。但這個方法不太切實際，因為Register的成本關係 使用Multithreading機制。 讓System process及User Process各自擁有自己的Register set，如此兩者之切換只要Registers Set的Pointer即可    Dispatcher And Dispatch Latency 分派器與分派延遲\n  定義：Dispatcher，此一模組的目的是要將CPU控制權授予經由CPU Scheduler依據CPU排班法則所選出之Process，選好後CPU Scheduler會將工作交給CPU Dispatcher，主要的工作項有下列三項\n Context Switching Change Mode from to Kernel mode to User Mode Jump to the execution entry of that selected proces  上述這三個工作所耗費的時間總和就是Dispatch Latency\n  希望Dispatch Latency越短越好，這些Process可以盡早開工\n  Process Control Operations☆☆☆☆☆ Lession 1 Theory   定義：Process建立、終止、暫停、恢復執行、設定／修改／讀取 Process Attributes值 etc.\n上述這些皆是OS應該提供的服務(i.e System Call)\n  Procss是可以建立自己的Process(Child Process)，目的是要Child Process做工作\n  Child Process所做的工作，可以分為2類：\n 與Parent 相同的工作(子承父業) 特定工作(與Parent不同)    Parent與Child之間的互動關係為：\n  Concurrent execution(交錯使用，通常是執行第一類的工作(子承父業)) Parent waits for Child until child terminated(等著收割Child的成果)     Child Process 所須的資源由何處取得?\n  OS供應(這種情況OS會去限制每個process最大可產生多少個Child Process) Parent供應(整個家族Process的資源都是共享，Parent Process的Sharing Time有一小時，那麼整個家族的Sharing Time 就是一個小時     Parent 若終止，則Child Process會如何處理?\n   一併終止(最常被使用) ：稱之為Cascading(層疊的) termination\n  Parent Process死了，但Child Process存活，那Child的資源由以下兩者提供\n   向OS取得資源\n  向祖先Process取得資源\n        Lession 2 Example - UNIX System Call  fork()：此System call. 用以建立 Child Process，而fork()之傳回結果，對象如下   失敗：因為資源不足(記憶體不夠，PCB也不夠)，無法建立，會傳回負值(-1)給OS, then Pass to parent process，通常失敗的話，OS也會順便把Parent process砍死\n成功：OS會傳回一個值，用以區分child or parent：\n 0值：給child process\n.\u0026gt; 0值：給Parent，且此值為Child Process ID\n    wait()：此System Call用以暫停Process execute, 直到某個事件發生，eg. 父等子直到子終止 。\n  exit()：此System Call用以終止Process的執行，回收其資源但PCB的空間可能還留著，直到父把子的結果回收回來才回收通常exit(0)表示正常終止，exit(-1)表示異常終止。子Process做完工作後，子Process要自己發出一個exit的System Call，讓OS來殺掉子Process。\n  execlp()或exec(), execve()：此system call用於請OS載入特定的binary code(可執行的檔案)，來執行。這個System call可以交由子process執行，讓子process執行特定的工作，去執行之後就不會再回來執行原程式下面的指令了，因為已經去執行特定的工作了\neg. execlp(\u0026ldquo;目錄名稱\u0026rdquo;,\u0026ldquo;檔名\u0026rdquo;,參數)\n  getpid()：此System Call用以取得Prcess的Id\n  ​\t說明：\n​\tOS會配置child process memory space, 此空間是占用不同的記憶體空間，且子process的Data section 及 code section內容均來自父process的copy, initially。\n​\t若子process所作之工作與父process相同，則fork()完，就已經達成目的。\n​\t若子process要做特定工作(與父process不同)，則子process必須執行execlp()這個system call\n​\tLession3 Programming 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  //例題1；建立Child process執行ls命令檔，且父等子完成後才列印Child completed  void main(){ int pid ; pid = fork(); if(pid\u0026lt;0){ printf(\u0026#34;fork fails \\n\u0026#34;); exit(-1); //爸爸自己自殺  }else if (pid ==0){ //兒子要做的事情  execlp(\u0026#34;/bin/ls\u0026#34;,\u0026#34;ls\u0026#34;,null); exit(); //這段code不會執行，原因是因為execlp()會把process指向/bin/ls的binary code，接著就是去執行那段binary code了，就不會回來執行這個exit();  }else //pid \u0026gt;0{  //爸爸要做的事情  wait(); //父Process子Process直到子Process終止 子Process做完工作後，子Process要自己發出一個exit的System Call，讓OS來殺掉子Process。  printf(\u0026#34;child Completed\u0026#34;); exit(); }; { //不管怎樣都會執行的地方  } }\t  1 2 3 4 5 6 7 8 9 10 11 12 13 14  //例題2 假設Parent, child 之process ID為2600, 2603 求line A, B, C, D 印出值 void main(){ pid-t pid, pid1; //pid-t: 一個名為pid 的type，就是整數，是C語言的寫法  pid-fork(); //pid 放的是子process的ID， pid1放的是自己process的ID  if(pid==0){ pid1=getpid(); printf(pid); //A 0  printf(pid1); //B 2603  }else if(pid \u0026gt;0){ pid1=getpid(); printf(pid); //C 2603  printf(pid1); //D 2600  } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //例題3 問A的值value是多少  int value =5; void main(){ pid-t pid; pid = fork(); if(pid ==0){ value +=15; return 0; }else if(pid \u0026gt;0){ wait(null); print(value); //A=5 就算是global的變數，也是只能在自己的process作用  return 0; } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  //例題4 求列印結果 (1.) void main(){ int pid; pid =fork(); if(pid==0){ printf(\u0026#34;A\\n\u0026#34;); }else //pid \u0026gt;0{  printf(\u0026#34;B\\n\u0026#34;); } } Ans: 父與子是並行的，因為父process沒有wait(), 因此答案可能是AB或BA (2.) void main(){ int pid; pid =fork(); if(pid==0){ printf(\u0026#34;A\\n\u0026#34;); }else //pid \u0026gt;0{  printf(\u0026#34;B\\n\u0026#34;); wait(); } printf(\u0026#34;C\\n\u0026#34;); } Ans: ACBC,ABCC,BACC,   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  //例題5 假設Count，是一個父與子Process的共享變數 ，初值為5 (1.) void main(){ int pid; pid=fork(); if(pid==0){ count++; printf(count); }else if (pid \u0026gt;0){ wait(); count--; printf(count); } } Ans.6,5 (2.) //父與子並行 void main(){ int pid; pid=fork(); if(pid==0){ count++; }else if (pid \u0026gt;0){ count--; } printf(count); } Ans. 45,54,55 //這是基本情況  //以高階程式語言的角度來看，count++實際上是兩條code  //count+1跟count=count+1  //先加然後再附值  //如果以組合語言的角度來看，就是三行code  //LOAD R1, Count  //INC R1, 1;  //STORE Count,R1  //但Process沒有辦法保證這三條Code會連續做完，有可能做到一半就被另一個Process搶走了  //所以還有一種情況是+1完之後，還來不及Assign，CPU就被另一個Process搶走了  Ans.66,44,46,64   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  //例題6 (1.) How mant processes are created? (include main()) void main(){ fork(); fork(); fork(); } Ans.8 (2.) void main(){ if(fork()==0){ //等同於 pid=fork(); if(pid ==0) ....  fork(); fork(); } fork(); } Ans.10 (3.) void main(){ fork(); if(fork()\u0026gt;0){ fork(); }else if(fork() ==0){ fork(); fork(); } } Ans.14 (4.) void main(){ for(i=0;i\u0026lt;3;i++){ if(fork()==0){ fork(); fork(); fork(); } } } Ans.729 (5.) void main(){ for(i=0;i\u0026lt;3;i++){ if(fork()==0){ fork(); }else if(fork() \u0026gt; 0){ if(fork()==0){ fork(); } } } } (6.) void main(){ int a =2; fork(); a--; printf(a); if(fork()==0){ a--; printf(a); fork(); }else{ a++; fork(); printf(a); } } (i.) printf(a)共做了幾次? (ii.)印出0的有幾次? (iii)印出1的有幾次? (iiii.)印出2的有幾次?   例題1\n例題2\n例題3\n例題4\nparse1parse2\nparse3\n例題5\nparse1\nparse2,3\n例題6\nEvalue CPU Scheduling Performance 5 criteria    CPU utilization：cpu花在Process exec time / CPU total time(process exec time + context switching time+ idle time)\n 舉例：Process平均花5ms在exec上 ,context switching = 1ms,則CPU utilization = 5/5+1 =5/6    Throughput(產能)：單位時間內完成的Job數目\n  Waiting Time(等待時間，考試重點)：process花在ready queue中等待獲得CPU之等待時間加總\n  Turnaround Time(完成時間)：從Process進入(到達)到它工作完成的這段時間差值\n  Response Time(回應時間)：自user(user process) input 命令/Data 給系統到系統產生第一個回應的時間差，沒有一個特定的量法去量它，稱之Time-sharing system, user-mteractive, application特別重視這一塊\n   由上述得知，排班的目標必是，**利用度越高、產能越高，時間相關的東西越短越好 **\nCPU排班法則行為介紹   FIFO SJF SRTF Priority RR Multilevel Queues Multilevel Feedback Queues (MFQs)   FIFO法則   定義：到達時間最小的process，優先取得CPU\n  例如：\n   Process CPU(burst) Time 要花的CPU time     P1 24   P2 3   P3 3    到達時間皆為0(從一開始就到了)\n到達順序為：P1, P2, P3(擺到ready queue的順序)\nQuestion\n 畫出Gantt Chart 求Avg. waiting time 求Avg. Turnaround Time    分析\n  排班效能最差，即Waiting time \u0026amp; Turnaround time 最長\n  可能會有**Convoy Effect(護衛效應：許多Processes 均在等待一個需要很長CPU time之process 完成工作，才能取得CPU，造成Avg waiting time 很長之不良效應) **\n  公平\n  No Starvation\n (沒有飢餓現象：Process因為長期無法取得完工所需各式資源，導致它遲遲無法完工，形成Indefinite Blocking 現象，稱之Starvation，容易發生在不公平對待之環境，若再加上Preemptive機制，則更是容易發生，補償方案：\u0026ldquo;Aging(老化)\u0026ldquo;技術，隨著Process待在System內的時間逐漸增加，我們也逐步提高此process的優先權，故可取得Process Resources完工，因為不會Starvation。注意：Soft real-time System不採用Aging，因為Soft real-time system是為了確保real-time process取得最高優先權，如果加入Aging機制，就有可能有process的priority高於real time process)    Non-preemptive(不可插隊；不可搶奪)法則\n  版本1(白話文)\n  Non-preemptive法則\n 定義：除非執行中的process自願放掉CPU，其他Process才會有機會取得CPU，否則就只能wait，不可逕自搶奪CPU 例如：完成工作、Wait for I/O-completed after issue I/O-request 優點：  Context Switching的次數比較少，因為不可插隊，所以Switching的頻率小很多 process之完工時間點較可預期(Predictable)，因為不可插隊 比較不會有Race Condition Problem   缺點：  排班的效能較差，因為可能有Convoy effect 不適合用在Time-sharing System, Real time System，因為這兩個都需要插隊的機制      Preemptive法則\n 定義：執行中的Process有可能被迫放棄CPU，回到ready Queue，將CPU切給別人使用，eg. Time-out, interrupt etc 優點：  排班效益較佳，平均waiting/ turnound Time較小，可以把耗時較長的Process Preemptive掉 適用於Real-time sysem(要能夠把real time 的process插入進去) 及Time-Sharing System   缺點：  完工時間較不可預期 Context Switching次數多，負擔較重 須注意Race Condition之發生        版本2：從CPU排班決策(啟動)之時機點來做區分(可以參考 State Transition，以下是五種情況做解說)\n  Running \u0026mdash;\u0026gt; Block eg: wait for I/O completed [自願放棄] Running \u0026mdash;\u0026gt; Ready eg: time-out [被迫放棄] Wait \u0026mdash;\u0026gt; Ready eg: I/O-completed [尊爵不凡的process醒來了，所以要啟動CPU scheduling，獲得CPU，低優先權的process被迫放棄CPU] Running \u0026mdash;\u0026gt; Exit eg:完成工作 [自願放棄]   所以若排班決策之啟動點只包含1,4，未包含2,4，則為Non-preemptive,否則preempt。\nNote：凡是 xxx \u0026mdash;\u0026gt; ready 皆列入preemptive元素(選項)，所以\nready/suspend \u0026mdash;\u0026gt; ready\nNew \u0026mdash;\u0026gt; Ready\n皆列入preemptive\n      SJF(Shortest Job First)法則   定義：具有最小的CPU TIME之Process，優先取得CPU，若都一樣小，則採FIFO。\n  例如：\n   Process CPU Time     P1 6   P2 8   P3 7   P4 3    Process到達時間皆為0，求Avg waiting time\n  分析：\n  排班效益最佳(optimal)，即Avg waiting/ turnaround time最小\n  說明：Why optimal?\n因為Short Job所減少的等待時間必定\u0026gt;= Long-Job所增加的等待時間，因為平均等待時間會最小\n    不公平，偏好short Job\n  可能會Starvation(for long Job)\n  可以分成\n Non-preemptive \u0026mdash;\u0026gt; SJF做代表\nPreemptive \u0026mdash;\u0026gt; 另外叫做SRTF法則\n   較不適合用在Short-term scheduler(比較不恰當啦，但你要用也是可，因為Short-term scheduler執行頻率太高，所以很難在極短的時間間隔內去預估出精確的CPU Burst time for each process 且排出最小值，不易真正呈現出SJF之行為，反倒是適合用long-term scheduler\nShort time scheduler是指專門負責處理短暫的工作的計劃程序。這些工作通常會在短短的時間內完成，並且有許多工作要求同時進行。在這種情況下，使用short job first（SJF）法則來處理工作可能不是最佳選擇。這是因為SJF法則是基於工作預計完成時間的，並假設工作的預計完成時間是可以預先知道的。但是，在short time scheduler中，大多數工作的預計完成時間都是未知的，因此無法準確地應用SJF法則。另一個原因是，SJF法則會將短工作放在優先執行的位置，因此會把許多短工作排在一起。在short time scheduler中，這可能會導致許多短工作之間的競爭，從而導致效率降低。總的來說，short time scheduler更適合使用其他計劃策略，例如基於先進先出（FIFO）或基於最短剩餘時間（SRT）的策略，來處理短暫的工作。)\n 如何評估process之the next cpu burst time?\n  公式(加權指數平均公式)\n    t0 t1 t2 t3      實際值 20 10 40 20    預估值 20(一開始還沒預估，所以都是抓t0的值)    ?    T0 T1 T2 T3 T4      意義:　       SRTF,SRJF,SRTN( Shortest Remaining-Time Job First(Next))   定義：即為Preemptive-SJF法則，即剩餘CPU Burst Time(CPU完成一次短時間工作所需的時間)最小的 Process，取得CPU。也就是若新到達的Process其CPU Burst TIme 小於目前執行中process剩下的CPU time, 則新到達之Process可以**插隊(preemption)**執行。\n  舉例：\n   Process 到達時間 CPU Time     P1 0 8   P2 1 4   P3 2 9   P4 3 5    求Avg waiting Time for\n  SRTF\n  SJF(不可插隊)\n  FIFO\n    分析：\n 與SJF相比，SRTF之平均waiting/Turnaround time會比較小(SRTF是SJF的一個子類，因為SRTF可插隊，所以會有最小的waiting time, 但是付出較大的Context Switching的overhead(負擔) 不公平，偏好Short remaining-time Job 會有Starvation的問題 Preemptive法則    Priority法則   定義：可參數化的法則，具有Highest Priority之Process，優先取得CPU，若多個Process權值相同，則以FIFO為準，也有分成Non-preemptive, Preemptive的差異。\n  舉例：不可插隊\n   Process CPU time Priority No.     P1 10 3   P2 1 1   P3 2 3   P4 1 4   P5 5 2    且，Priority No越小，優先權越大The Smaller Priority No. Implies the higher priority。求Avg waiting Time\n  分析：\n  是一個具參數化的法則，即給予不同的priority高低定義，可展現出不同的排班行為。\n   Priority定義 行為     抵達時間越早，優先權更高 FIFO   CPU　Time越小，優先權越高 SJF   剩餘時間越小，優先權越高 SRTF    因此FIFO, SJF, SRTF都是屬於Priority的一種\n  不公平\n  會有Starvation (可用Aging去解決)\n  分為Non-preemptive, preemptive兩種\n    RR(Round Robin)法則(考試重點)   定義：Time-Sharing System採用，OS會規定一個CPU time Quantun(or Slice)，當Process取得CPU執行後，若未能在此Quantum內完成工作，則Timer會發出\u0026quot;Time-out\u0026rdquo; interrupt通知OS，OS會強迫此process放掉CPU，且回到ready queue中，等待下一輪再取得CPU執行，每一輪之中，process是以FIFO排隊方式取得CPU\n  舉例1：\n   Process Cpu time     P1 8   P2 4   P3 9   P4 5    到達時間皆為0，順序是P1~P4, 使用RR(Quantum=4), 求Avg waiting time\n舉例2:\n   Process Arrival Time Cpu Time     P1 0 10   P2 2 5   P3 7 3   P4 13 8      舉例3:\n   Process Arrival time 行為     P1 0 5CPU+6I/O+4CPU   P2 3 15CPU   P3 8 3CPU+10I/O+9CPU   P4 14 8CPU    Quantum= 5，問turnaound time ? waiting time ?\n 注意：有些題目是有爭議的  ​\teg.\n   Process 到達 CPU time     P1 0 6   P2 4 9   P3 8 6    ​\t採RR(Q=4)\n​\t  分析：\n Time-sharing System 採用 也是一個可參數化的法則(ie. Quantum) 公平 No starvation preemptive法則(Real-Time, Time-Sharing適用，RR超過Quantum time後會被迫回到ready    舉例2\nQuantum=∞\n則RR會變成FIFO法則\u0026mdash;\u0026gt; 排班效能很差\n注意：也因此，FIFO屬於RR的一種\n  舉例3\nQuantum =極小值\n則Context Switching太頻繁，CPU Utilization會很低\n依經驗法則，若Quantum值能讓**80%**的Job在Quantum內完成，效能較佳。\n  補充：RR雖然是公平的，但也可支持差異化(優先權差異)之實現，How do you achieve this?\nAns.\n 針對高優先權Process在ready Queue中置入多個PCB pointer 指向此Process，使得每一輪當中，它有多次取得CPU之機會 針對高優先權Process給予較大的Time Quantum    MultiLevel Queues(多層佇列)法則   定義：\n 將原本單一一條ready queue變成多條ready queues且高、低優先權不同 Queues之間的排班法則，通常採取Preemptive and Priority法則 每個Queue 可以有自己的排班法則 eg. RR Process一旦被置入於某個Queue中，就不可(不允許)在不同ready queues之間移動    舉例：I/O-Bound與CPU-Bound Job你會置於哪個Queue中?\nAns：I/O-Bound Job \u0026mdash;\u0026gt;Q1\n  ​ CPU-Bound Job \u0026mdash;\u0026gt;Q3\n  分析：\n  可參數化的項目眾多1. Queue的數目 2. Queue之間的排班法則 3. 每個Queue自己的排班法則 4. Process被放入哪個Queue之Criteria ，有助於排班設計及效能調校之Flexibility\n  不公平\n  有Starvation(被放在Q3 的Process永世不得翻身，因為Process一旦被置入於某個Queue中，就不可(不允許)在不同ready queues之間移動☆☆☆☆☆\n  Preemptive\n    MultiLevel Feedback Queues(MFQs)(多層回饋佇列)  定義：與MultiLevel Queue相似，差別：允許Process 在不同Queues 之間移動，可採取類似Aging技術，甚至可以搭配降級的做法，來避免Starvation 分析：  可參數化的項目眾多1. Queue的數目 2. Queue之間的排班法則 3. 每個Queue自己的排班法則 4. Process被放入哪個Queue之Criteria 5.Process在不同佇列之間移動的規則，有助於排班設計及效能調校之Flexibility 不公平 不會有Starvation(被放在Q3 的Process永世不得翻身，因為Process一旦被置入於某個Queue中，就不可(不允許)在不同ready queues之間移動☆☆☆☆☆ Preemptive    小結   哪些是Non-preemptive法則\nAns. FIFO,SJF,SRTF, Non-preemptive priority\n  哪些是No Starvation\nAns. FIFO, RR, MFQs\n  哪些包含於(∊)關係是錯的\n  ​\tA. FIFO ∊ Priority\n​\tB. SJF ∊ Priority\n​\tC. FIFO ∊ RR\n​\tD. SJF ∊ RR\n​\tE. RR ∊ MFQs 是喔，MFQs的參數可以設定成一條Queue\n​\tAns. (D)\n補充 CPU Utilization計算 例1.\n假設採RR排班\nTime Quantum值= Q\nContext Switch Time = S\nProcess 平均執行每隔T時間會發出I/O-request, 求下列Case之CPU Utilization(cpu花在Process exec time / CPU **total time(process exec time + context switching time+ idle time)** )\n  0 \u0026lt; S \u0026lt; T \u0026laquo;Q\n  0\u0026lt;S\u0026lt;Q\u0026laquo;T\n  ​\t 0\u0026lt;S=Q \u0026laquo;T\n  Q非常小\n  例2. [恐] (看不懂)\n10個I/O-Bound Tasks(很花I/O)\n1 個CPU-Bound Tasks(很花CPU)\nI/O-Bound task執行每隔1ms 發出 I/O-request，每個I/O-運作花10ms\nContext Switching Time = 0.1 ms, 求CPU utilization, 採RR法則\n  Quantum = 1ms\n  Quantum = 10ms\n  ​\t寫完之後會發現有個info沒有用到「每個I/O-運作花10ms 」，因為有CPU-Bound的存在，所以不存在idle Time，如果不存在CPU-Bound，則可能存在idle的情形，就需要考慮這種情形\n特殊系統之排班設計考量 Multiprocessors System   Multiprocessors分為\n  ASMP(非對稱的，Master-slave架構) \u0026mdash;\u0026gt; 沒有什麼特殊設計，嘻嘻，因為只有Master這個CPU去看ready queue以及job的assign，所以其實沒啥特殊設計\n  SMP(對稱式) \u0026mdash;\u0026gt;\n  每個CPU共享同一條Ready Queue，當CPU完成某Process後，就去存取ready Queue，取走一個Process執行。設計重點：必須提供ready queue的互斥存取機制，若未提供，則可能發生Process重複執行或Process被ignored(無人執行)之錯誤。\n例如：CPU去取得Process之工作如下\n 取得(read) Ready Queue, Frond End的process之PCB Pointer 刪除此Process Pointer from Queue     CPU1 CPU2     T1: step1: 取得P1 PCB pointer T2:step1取得P1 PCB pointer   T3: Dequeue執行 T4: Dequeue執行    設計重點：\n 必須提供ready Queue的互斥存取機制 不須考量Load Balancing    每個CPU有自己的Ready Queue\n每個CPU只會檢查自己的ready Queue, 有工作就執行，無工作就idle\n設計重點：\n 不須有互斥存取的考量，一旦發生idle，則把其他CPU的queue調整過來 需考量Load Balancing，避免有CPU沒事，有CPU很忙。通常使用兩種機制來調整CPU Loading  Push migration(移轉) Pull migration(移轉)          Processor affinity  定義：在multiprocessors system中，當process已決定某CPU上執行，則在他執行過程當中，盡量不要將之移轉到其他CPU上執行(除非有其必要，eg. processor BAD, load Balancing, etc)避免CPU內之cache等內容要複製，且刪除，影響到效能表現，可以有  Hard affinity：規定process不可移轉 Soft affinity：盡可能不轉，但不強制限制，若有需要還是可以轉    Real-Time System排班設計考量 Hard real-time system   排班設計考量\nStep\n  先確定這些工作是否schedulable(可排程化，CPU可以負荷的了)\n  確定可schedulable後，然後在考慮是否可以滿足各工作的DeadLine\n兩個排班法則\n Rate-Montonic scheduling EDF(Earliest Deadline First)法則      Schedulable與否之判斷公式：\n例：有下列4個Real-time event. 其CPU burst time,Period Time 分別是：\n   CPU Burst Time Period Time     20ms 80ms   50ms 100ms   30ms 30ms   Xms 1Sec    ，則在Schedulable要求下，x不可超過?ms\nAns\n  怎麼排程以滿足個工作DeadLine after Schedulable?\n  Rate-Monotonic法則\n  採取Static priority(一旦process的優先權高低順序訂定了，就不會再改變) 且 preemptive 法則\n  Period Time愈小，優先權越高\n  舉例\n   Process Period Time CPU time     P1 50 20   P2 100 35    Q1. schedulable與否?\nQ2. 若規定P2的優先高，且preemptive, 這樣是否滿足DeadLine?這題感覺怪怪的，不懂\n​\tQ3. 採用Rate-Monotonic, 是否滿足Deadline?\n​\t  分析：\n 並不保證可以滿足DeadLine 在Static priority要求下，它是Optimal(若它無法滿足DeadLine,其他Static priority 法則也是無法滿足      EDF(Earliest Deadline First)\n  定義：採用Dynamic priority 且Preemptive\n  規定：DeadLine越小(早)優先權越高\n  舉例：\n   Process Period CPU Time     P1 50 25   P2 80 35    是否滿足Deadline?\n  Rate-Monotonic\n  EDF\n    分析：\n EDF保證是optimal in the schedulable case(任何工作都可以滿足 DeadLine) 理論上，CPU utilization 可達100%，但實際上不可能，因為有Context switching, interrupt handling 等額外負擔        Soft real-time system   定義：這個系統要確保real-time的process取得最高優先權，同時，這個real-time的process priority不能做衰減\n  就CPU Scheduling Design 而言，必須\n 支援preemptive-priority 不支援Aging技術 盡可能降低Kernel Dispatch latency time, 使得real-time process可以及早開工    降低kernel Dispatch latency\n  困難度(緣由) ：大部分的OS，皆不允許當kernel正在執行System Call or 其他System processes時，被user process任意插隊(preemption)，目的是為了確保kernel Data Structures的正確性(即不要有Race Condition)，然而此種做法，對於Soft real-time system極為不利\neg. 假設目前kernel 正在執行一個Long-time system call(eg. I/O operation)，而此時real-time process到達/fork(),它必須等到kernel完成此long-time system call後，才能取得CPU，所以\nDispache latency太長，要解決此一問題，原則是: 必須插隊kernel 且要保障kernel Data Structure之正確性\n方法\n  Preemption Point：\n 定義：在此System calls code中，加入一些Preemption Point(在此時點插隊時，Kernel是安全的)將來，System call執行時若遇到Preemption Point ，System call會先暫停，Kernel會檢查此時是否還有real-time process存在/到達，若有，則Kernel system call暫停執行，CPU分派給real-time Process使用，若無，則System Call繼續執行，直到遇見下一個Preemption Point 缺點：System Call中可以加入的Preemption Point數目不夠多，因為Dispatch Latency仍然很長。    Kernel可隨時被real-time process插隊，但要對於Kernel的共享Data Structure/resoruce提供嚴謹的互斥存取(Synchronization 機制)，以確保資料之正確性(當P1對某個Data進行操作，執行到一半時被real-time process給搶走，此時會把該Data給Lock住，不讓real-time process操作該Data，以保護資料)\n  缺點：可能造成Priority Inversion問題(優先權反轉)，高優先權的Process所須的共享Data/resources恰好被一些低優先權的Process把持，無法存取(所以互斥存取控制之故)，造成高優先權等待低優先權Process之情況(即高process要等低process釋放這些共享Data/resource)\n當高優先權的Process因為遲遲等不到Lock解除，會因為time-out的關係而放棄CPU，此時可能有其他中優先權的Process取得CPU的使用權，因此低優先權的Process完成不了，進而完成對共享Data/resources之使用進而Release, 所以高優先權process被迫要等一段很久的時間\n  解決方法：Priority Inheritance\n 定義：讓低優先權的Process暫時繼承高優先權之權值，使得低優先權Process可以很快取得CPU完成對共享Data/Resouce之使用，並release them. 同時，也立刻恢復其原本的低權值          Real-time system之Dispatch Latency 組成 Dispatch Latency有兩個phase組成\n Conflict Phase：  Preempts kernel 低優先權realse高優先權所需之Data/resource   Dispatch Phase  Context Switching Change mode to user Mode Jump    Thread Management(貝多芬)  Thread( or Multithreading)定義、優點\nProcess(Single-Threaded) vs Thread (Multithreading)\nuser-level thread 與 kernel-level thread\nMultithreading Model(3種)\nMultithreading issue\n fork()\nsignal delivery\nThreads pool\n 程式追蹤(PThread library)\n Thread   定義：又叫lightweight-process(傳統的process就叫heavyweight process)，是OS分配CPU time 之對象單位**(恐：It\u0026rsquo;s a basic unit of CPU Library)**\n  Thread 建立後，其私有的(private)內容組成包含有(都是與執行相關的)\n Programming Counter CPU registers value Stack Thread ID, State, etc \u0026hellip;(Note: record in TCB[Thread Control Block])此外，同一個Process內不同之Threads彼此共享此Process的  Code Section(合稱Memory space, address space) Data Section(合稱Memory space, address space) other OS resources eg. open files, I/O resources ,singal, etc \u0026hellip;      圖示\n  MultiThreading Model\n  Process = Single-Threaded Model\nNote: 類比\nProcess \u0026mdash;\u0026gt; 汽車\nThread \u0026mdash;\u0026gt; 引擎\n汽車會有一個引擎，也可以有很多，MutliThread就像是一部車子有多個引擎，然後共享車子有的配件(儀表板、方向盤等等)。CPU Time是以Thread為對象在畫分\n    優點(Benefits)\n Responsiveness：當Process內執行中的Thread被Blocked，則CPU可以切給此Process內其他available Threads 執行，故整個Process不會被Blocked，仍持續Going, 所以Multithreading用在user-interactive application, 可增加對User 之回應程度 Resource Sharing：因為Process內之多條Threads 共享此Process code section，所以在同一個Memory space上可有多個工作同時執行 Economy：因為同一個Process內之不同Threads彼此共享此Process的memory 及 other OS resources, 因為Thread 之 私有成分量少，故Thread之Creation, Context Switching fast, Thread management cost is cheap(fork一個Process的成本遠大於複製一個Thread) Scalability(Utilization of Multiprocessors Architecture)：可以做到同一個Process內之不同Threads可以在不同CPUs上平行執行，所以可以增加對Multiprocessors System之效益(平行程度)提升    Process Vs Thread  其實是在比Singal Thread and MultiThread\n Thread的的優點\n   Process Thread     Heavyweight process Lightweight process   Single-Threaded Model MultiThreading Model   是OS分配Resource之對象單位 是OS分配CPU Time之對象單位   不同的Process不會有共享的Memory及Other Resources (除了Shared Memory溝通之外) 同一個Process內之Threads彼此共享此Process之memory 及Other Resources   若Process內的single Thread is Blocked, 則整個Process亦Blocked 只要Process內尚有Available Thread可執行，則整個Process不會被Blocked   Process之Creation context Switching慢，管理成本高 Thread快，成本低   對於MultiProcessors架構之效益發揮較差 較佳    Thread的的缺點\n   Process Thread     Process無此議題(除非是採用Shared Memory溝通) 因為同一個Process內之Threads彼此共享此process Data Section，因此必須對共享的Data 提供互斥存取機制，防止race Condition    Philosophy Process與Thread沒有功能差異，只有效能差異(你會的，我也可以，你不會的，我也不會)。\n哪些工作適合用MultiThreads?\nAns. 一個時間點有多個工作要執行。例：Client-server Model(同時有人過來要檔案，看檔案)\n哪些工作不適合用MultiThreads?\nAns. 一個時間點最多只有一個工作可以做。例：命令解譯器(eg. UNIX 之 Shell)\nThread分類：user-Thread與Kernel-Thread 區分角度：**Thread Management工作(如：Thread Creation, Destroy, Suspend, wakeup, Scheduling, Context Switching, etc)**由誰負責\n  User-Level Thread\n 定義：Thread Management是由在User Site之Thread Library提供APIs, 供User Process呼叫使用，進而管理，稱之 Kernel 完全不知道(is Unaware of) Use-Level Threads 之存在Note：只知有Process(Singal-Threaded) Thread management不須Kernel介入干預**(kernel unware user-thread)** 優點：There creation, context switching 等，Management is fast 成本較低 缺點：  當Process內某條執行中的user-thread is blocked(eg. i/o)，會導致整個Process亦被Blocked(即使process內還有其他available threads)這個process都是user Thread，發出一個blocking的system call, kernel會認為是這個Single process發出的請求，因為kernel不知道process裡頭還有其他user Thread的存在，於是就把整個process block住，CPU切到其他process去執行 MultiProcessors架構效益發揮較差(因為無法做到process內之多條user-threads平行執行，但這樣也是有好處的，整個thread的管理不需要kernel的干預，不需要再user, kernel間切換，降低管理的成本)   例：舉凡Thread library皆是user-threads(eg. POSIX 的 PThread library是規格，只在UNIX系統上, Mach的C-Thread Library, Solaris2以上的 UI Thread Library及Green Thread Library).    Kernel-Level Thread\n  定義：Thread Management完全由kernel負責，Kernel知道每一條Thread之存在並進行管理\n  優缺點與user-thread相反\n  例：大部分OS皆支援 (Windos系列 etc. 2000, Xp, UNIX, LINUX, Solaris)\n  舉例：[Module版]\n CPU Time依分配對象數，平均分配(10個人就分10%，20個人就分5%) 則Pa, Pb各分到?%CPU Time，if All Threads are  User Thread：kernel只知道有兩個Process要來搶CPU，來分CPU Time，Pa,Pb各分50% Kernel Thread：kernel知道有5條Thread要分CPU time，1條分20%，Pa分到3條，所以是60%, Pb是40%        MultiThreading Model [恐龍本獨有] 恐龍本用來詮釋user Thread跟Kernel Thread的見解\n[user thread mapping kernel thread的數目]\n  Many-to-One Model One-to-One Model Many-to-Many Model    Many-to-One   定義：This model maps many use threads to one kernel Thread. Thread Management is done in use space 優、缺點：如同user thread 例：thread library皆是 圖示：  One-to-One Model   定義：This model maps each use Threads to a kernel Thread. Thread Management is done in use space 優點：同kernel thread 缺點：  Slower Process每建立一條user-thread, system就必須配合生一條kernel thread與之，所以user thread數目眾多，系統負擔會很重，耗資源   例：Window NT, Window2000, OS/2, Linux(個人電腦系列幾乎都是ONE-TO-ONE)  Many to Many   定義：This model maps many use Threads to a small or equal number of kernel Thread. Thread Management is done in use space 優點：同前述kernel thread, 負擔也不像one to one的model來的重 缺點：1. slower 2. 製作設計上，較為複雜  MultiThreading Issue 原本Single Thread沒這問題\n fork() issue   Signal delivery(傳送) issue\n Signal：it is used in UNIX to notify(通知) the process that a particular event has occurred  當process收到signal通知後，它必須處理(可由process自己處理或交給default signal handler處理)\n Signal的種類\n Synchronous signal[自作自受，這件事情是由你這個Process發生的，所以Signal就是發給你]eg. Divide-by-zero, illegal memory access, Asynchronous signal[池魚之殃，事情不是你做的，但別人發出，卻是砍你] eg. ctrl-c by administrator, time-out by timer   Signal Delivery issue\n4個options\n 發給那個thread   發給大家\n  發給一些threads\n  發給一個thread，這個thread再把signal轉派給大家\n        Threads Pool\n 緣由：在Client-Server Model中，當Server 收到Client\u0026rsquo;s request後，Server才建立Thread去服務此一請求，然而Thread creation 仍須耗用一些時間，所以對client 之回應不是那麼迅速 解法：採用Thread pool機制，process(server)先建立一些Threads，置於threads pool中，當收到Client\u0026rsquo;s request後，就從Thread pool中指派一條 available thread去服務此請求，不須creation回應較fast，當此Thread 完成工作以後，再回到Threads pool中Stand By 如果Threads Pool中無可用的Threads，則Client\u0026rsquo;s request 須等待 缺點：  萬一Process事先生出過多的Threads in the Thread pool, 對System resource耗用很高，Note:通常ＯＳ會限制Threads pool size      Thread程式追蹤 (以PThread library為例)\n例：P4-49\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #include \u0026lt;Pthread.h\u0026gt;int sum; void *runner (void * param){ sum =0; for(int i=1;i\u0026lt;=upper;i++){ sum+= i; Pthread-exit(0); //thraed終止  } }; main(){ Pthread-t tid; //tid就代表Thread的id  Pthread-attr_t arrt; //代表attribute屬性 Thread attributes set  ... Pthread-attr-init(\u0026amp;attr) ;//取得attr 初始值  ★Pthread-create(\u0026amp;tid, \u0026amp;attr, runner, argv[1]); //根據attr 屬性值建立一條Thread，Id記在tid中，執行runner()副程式  Pthread-join(tid, NULL); //main() thread 在此等待，直到tid thread結束  printf(sum); }   例：P4-50 程式二\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  int value = 0; void main(){ int pid ; pthread-t tid; Pthread_arrt_t attr; pid = fork(); //create child process  if(pid==0){ //子prcess要做的事情  pthread_create(\u0026amp;tid, \u0026amp;attr , runner,NULL); //子Process去create一條thread  printf(value); //line C  }else if(pid \u0026gt; 0){ wait(); printf(value); //line P  } } void *runner(){ value =5; pthread_exit(); }   例 p4-70\n1 2 3 4 5 6 7 8 9 10 11  shared by threads A. static local variables(共享) B. program text/exec, binary (code sec)共享 C. register value of CPU(私有) D. heap memory (code+ Data sec memory space)共享 E. Programming Counter (私有) F. Stack memory(私有) G. Open Files(共享) H. I/O resources(共享) I. local variable(私有) J. Global variables(共享)   Chapter 5 DeadLock   定義：成立的四個必要條件，例子, 與Starvation做比較\n  Deadlock的處理方法\n  Deadlock Prevention ★★★★ Deadlock Avoidance(Banker\u0026rsquo;s Algo★★★★★) Deadlock Detection and Recovery★★ Ignores it .     定理★★★★★：\n  相關圖形\n Resource Allocation Graph(RAG)+3點結論★★★★★\nClaim edgy+RAG(for Avoidance)\nwait for Graph(for Detection)★\n   DeadLock   定義：系統中存在一組Processes彼此形成循環等待之情況，造成這些Processes皆無法往下執行(和starvation不同，Starvation還有一絲可能會做到)，並降低Throughput之現象。\n  死結成立的4個必要條件(4 necessary condition)，即缺一個，死結就不會發生. Ex. if there 4 conditions are true, then the deadlock will arise. Ans. False，都有不代表一定會發生\n  Mutual Exclusion\n互斥性質，這是對Resource(正在搶奪的資源)而言，具有此性質的Resouce，在任何時間點最多只允許一個Process持有使用，不可多個process同時持有/使用。\n例：大多數的資源皆具此性質，eg. CPU, Memory, Disk, printer, etc \u0026hellip;\n例：read-only file：不具互斥性質\n  Hold \u0026amp; wait\n持有並等待，Process持有部分資源，且又在等待其他Process持有的資源\n  No preemption\n不可搶奪，**Process不可以任意剝奪其他Process所持有的資源，**必須等到對方釋放資源後才有機會取得資源若可Preemption，則必無DeadLock，頂多只有Starvation\n  Circular Waiting\n循環等待，系統中存在一組Processes形成循環等待之情況，eg.\n  恐龍本：4 implies 2\n其他版本：4 implies 1,2,3eeeee\nex. Why Singl-process不會造成DeadLock?\nA：因為Circular waiting 不存在，只少要有兩個process才可以形成循環等待，因此四個必要條件有一個不符合，即不會造成DeadLock\n  例子：\n  與Starvatiom比較\n不同點：\n   DeadLock Starvation     一組Processes形成Circular waiting，造成這些Processes皆無法往下執行，Waiting forever Process因為長期無法取得完工所需的各式資源，造成它遲遲無法完工，有完工的機會喔，只是機會渺茫   會連帶造成throughput低落 與throughput高低無關   有4個必要條件，其中一定是No preemptive 容易發生在Preemption的環境(沒有一定，只是容易)   解法有prevention, Avoidance, Detection \u0026amp; recovery 採用Aging技術防止    相同點：\n   DeadLock 7 Starvation     皆是資源分配管理機制設計不恰當相關。        Resource Allocation Graph(R.A.G)  資源分配圖\n   定義：令Ｇ=\u0026lt;V,E\u0026gt; 有向圖代表RAG，其中\n  Vertex(頂點)：有兩個類型：\n  Process：以O來表示\n  Resource：以表示\n其中\u0026rdquo;·\u0026ldquo;數目代表The Number of instances\n    Edge(邊)：分為２種edge：\n Allocation Edge： Requset Edge：      例子 ：\n  RAG的三點結論☆☆☆☆☆必考  No Cycle則No DeadLock 有Cycle不一定有死結 例：因為P3一定可以完工，會釋放1個R2, 可佩給P2，此時圖無Cycle，No DeadLock 除非(若)每一類型的資源，皆為Single instance(單一數量)，則有Cycle必為死結  DeadLock處理方式   DeadLock Prevention DeadLock Avoidance(避免) Banker\u0026rsquo;s Algo DeadLock Detection \u0026amp; Recovery   1.2\n  優點：\n 保證System is Deadlock free (or never enters the deadlock state)    缺點：\n 對Resource的使用/取得限制多，因為resource utilization 偏低，連帶throughput 也偏低 可能造成Starvation    3\n 優點：  Resources utilization相對較高. throughput也連帶較高   缺點：  System有可能進入DeadLock state Detection \u0026amp; Recovery之cost相當高    DeadLock Prevention  原則：破除4個必要條件之其中一個，則死結必不發生    破除 \u0026ldquo;Mutual Exclusion\u0026rdquo; -\u0026gt; 兩個字「辦不到」！因為這是Resource與生俱來(inheritance)的性質\n  破除 \u0026ldquo;Hold \u0026amp; wait \u0026quot; - \u0026gt; 兩個方法(protocols)可用，想辦法讓Hold不成立，或是讓Wait不成立\n OS實施規定：除非Process可一次取得全部所需資源，才准許持有資源，否則不得持有任何資源，但這樣子會有資源利用度低的問題(明明可用，但卻要等到全部都可以用才可以使用) OS實施規定：Process可先持有部分資源，但當Process要申請其他資源時，必須Release持有的全部資源(不再Hold)，才可提出申請。但資源利用率一樣很低，因為有可能會把即將要使用的資源釋放出去    破除\u0026quot;No preemption\u0026rdquo;　-\u0026gt; 改為\u0026quot;preemption\u0026rdquo; 即可, eg. based on priority-level\n  ☆☆☆☆☆破除\u0026quot;Circular waiting\u0026quot; -\u0026gt; 方法叫做\u0026quot;resource ordering\u0026quot; ，\n  OS會賦予每一個類型資源一個Unique(唯一的)Resource id\n  OS會規定Process必須按照Resource Id Ascending(遞增、遞減都行，你爽就好)的方式對資源提出申請\n   持有的 欲申請的 允許或不允許     R1 R3 允許   R5 R3 必須先放到R5，才可提R3(因為不符合遞增)   R1,R5 R3 必須先放到R5，才可提R3(因為不符合遞增)    WHY?\npf：假設在這樣的規定下，系統仍存在一組Processes形成Circular waiting如下\n依規定，我們可以推導出資源ID大小關係如下\nr0 \u0026lt; r1 \u0026lt; r2 \u0026lt; \u0026hellip; \u0026lt;rn \u0026lt; r0\n竟推出 r0 \u0026lt;r此一矛盾式子，因此Circular waiting必不存在\n    Deadlock Avoidance   定義：當某個Process提出某些資源申請時，則OS必須執行Banker\u0026rsquo;s Algorithm，以確定倘若分配給process其申請資源後，System未來處於safe state，若Safe則核准其申請，否則(unsage)則否決其申請，process必須等一段時間後，再重提申請。\n  Deadlock是unsafe之subset\n  Banker\u0026rsquo;s Algo ☆☆☆☆☆ 本章的計算題都在這 Banker's Alog and Safety Algo\n  定義：使用的Data Structures\n  看不懂的話直接看下面範例比較快\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  假設 n：process個數 m: resource種類數 1. Request i ：［1..m］of int -\u0026gt; Pi提出之各式資源申請量 2. Allocation : n*m martrix -\u0026gt; 各個process目前持有的各式資源數量 3. MAX: n*m martrix -\u0026gt; 各process完工所需之各式資源最大數量 4. Need：n*m martrix(自己算) -\u0026gt; 各process尚須(欠)各式資源數量才能完工，因此Need= MAX -Allocation 5. Avaliable：[1..m]of int -\u0026gt; 系統目前可用的，各式資源數量，因此Available=資源總量-Allocation 舉例說明：假設有人來貸款3,000萬，那麼Requesti =3000萬、Allocation就是自己的存款，假設這邊是2,000萬，想買一棟9,000萬的房子，這9,000萬就是他的MAX，那麼Need= 9,000-2,000= 7,000萬，Available 就是銀行目前金庫裡能借給你的錢，這邊假設是10,000萬。 Step1. Check Request \u0026lt;= Need ?若成立，則往下執行，若不成立，則終止Process。 Request=3,000萬，Need= 7,000萬。這樣就是合理的，但假設你今天需求7,000萬，可是卻貸了3,000兆，遠超於你的需求，那就有問題了 Step2. Check Request \u0026lt;=Available?若成立，則往下執行，若不成立，則Pi waits until resouce availalbe 概念就是你去貸3,000萬，可是銀行金庫目前的錢不夠，需要你稍等一下 Step3 (試算) 假設貸款成功 Allocation = Allocation + Request Need = Need - Request Available = Available - Request Step4 依上述試算值，必須執行 \u0026#34;safety\u0026#34; algo，若回傳\u0026#34;Safe\u0026#34; state則核准Pi此次申請。若回傳\u0026#34;unsafe\u0026#34; state，則否決Pi此次申請。Pi必須等一段時間再重提申請     Safety Algorithm   Data Structures used 除上述之外，另外加入\n  Work:[1..m] of int -\u0026gt; 表系統目前可用Resources之累計數量\n  Finish:[1..m] of Boolean -\u0026gt; 針對Process\nFinish[i]=\nTrue: 表Pi可完工\nFalse: 表Pi尚未完工\n∀1\u0026lt;=i\u0026lt;=n\n    Procedures\nStep\n  設定初值\nWork = Available\nFinish[i]皆為False\n∀1\u0026lt;=i\u0026lt;=n\n  看可否找到Pi滿足：\n Finish[i]為False且 Needi \u0026lt;= Work (我所需要的資源，)  若可找到，則進3,否則則進4\n  設定Finish[i]=True，且Work= Work + Allocationi, then, 回到2\n  Check Finish Array, 若皆為True，則傳回Safe State，否則傳回Unsafe state\n    範例\n1 2 3 4 5 6  5個Process(P0,P1,P2,P3,P4) 3種resource(A,B,C) 資源量(A,B,C) = (10,5,7) 1. 求出Need及Available 2. P1提出(A,B,C)= (1,0,2)申請，是否核准?Why?   Ans.\n Allocation-各個Process身上所持有的資源      A B C     P0 0 1 0   P1 2 0 0   P2 3 0 2   P3 2 1 1   P4 0 0 2     MAX- Process完成工作最多所需要的資源數量分別是多少      A B C     P0 7 5 3   P1 3 2 2   P2 9 0 2   P3 2 2 2   P4 4 3 3     Need= MAX-Allocation      A B C     P0 7-0=7 5-1=4 3-0=3   P1 3-2=1 2-0=2 2-0=2   P2 6 0 0   P3 0 1 1   P4 4 3 1     Available= 系統目前還剩的可用資源數，資源總量()-已經配置出去的(Allocation出去的)     A B C     10-(2+3+2)=3 5-(1+1)=3 7-(2+1+2)=2    Request=(1,0,2), Banker\u0026rsquo;s Algo\n  Check Request \u0026lt;= Need ? (你所要求的小於你真正需要的，亦即你買東西只要500，不能跟銀行借到500萬)\n  Check Request \u0026lt;= Available (你要的借的錢是否小於銀行本身所持有的錢，亦即如果你要借1億，但銀行只有一百萬)?\n  (試算)\nP1:\nAllocation = \u0026lt;2,0,0\u0026gt;+\u0026lt;1,0,2\u0026gt;(申請量) = \u0026lt;3,0,2\u0026gt;\nNeed = \u0026lt;1,2,2\u0026gt; - \u0026lt; 1,0,2\u0026gt;(申請量) = \u0026lt;0,2,0\u0026gt;\nAvailable = \u0026lt;3,3,2\u0026gt; - \u0026lt;1,0,2\u0026gt;(申請量) = \u0026lt;2,3,0\u0026gt;\n  依上述調整值，來執行\u0026quot;Safety\u0026quot; Algo\n   Allocation      A B C     P0 0 1 0   P1(要調整) 3 0 2   P2 3 0 2   P3 2 1 1   P4 0 0 2     MAX      A B C     P0 7 5 3   P1 3 2 2   P2 9 0 2   P3 2 2 2   P4 4 3 3     Need      A B C     P0 7 4 3   P1(要調整) 0 2 0   P2 6 0 0   P3 0 1 1   P4 4 3 1     Available     A B C     2 3 0    Safety Algo\n  初值的設定\n  Work = Abailable = \u0026lt;2,3,0\u0026gt;\n  Finish\n   0 1 2 3 4     F F F F F      尋找有沒有Process還沒完成工作，並且它的needi \u0026lt;= work的\n  可找到P1滿足Finish[i]= False且Need \u0026lt;=work\n  ​\t設定Finish[i]=True，且Work= Work+Allocation = (2,3,0) + (3,0,2) = (5,3,2) , then goto 2 work = (2,3,0) \u0026gt; (5,3,2)  ​\t 選擇P3滿足 Need\u0026lt;= Work，且Finish[i] = False\n  設定Finishj[3]=True，且Work=(5,3,2) +(2,1,1) = (7,4,3), then goto 2\n  \u0026hellip; 以此類推，P0, P2, P4皆可Finish，直到大家都Finish，因此大家都滿足了。\n  Check Finish陣列，因為皆為True，所以傳回Safe State，因此核准P1此次的申請\n  列出上述其中一組Safe SequenceSafe Sequence/ Safe State定義：至少可以找到\u0026gt;=1組，Safe Sequence，成為Safe State，否則unsafe state。代表OS未來依此Processes順序可分配各Process所need的資源，使得大家皆可順利完工\nAns. P1,P3,P0,P2,P4\n  依現在狀況，若P4提出(3,3,0)申請，是否核准?why? (練習題)\nAns. Banker\u0026rsquo;s algo\n  Check Request (3,3,0) \u0026lt;= Need(4,3,1) 通過\n Need      A B C     P0 7 4 3   P1 0 2 0   P2 6 0 0   P3 0 1 1   P4 4 3 1        ​\t2. Check Request4(3,3,0) \u0026lt;= Available (2,3,0)?\n​\t不成立，因為無法核准，可用資源不足\n 依現在情況，若P0提出(0,2,0)，是否核准? Ｗhy?\nAns. Banker\u0026rsquo;s Algo\n  快速跑過，確認可以過，資源分配改變如下\n  Allocation\n    A B C     P0 0 3 0   P1 3 0 2   P2 3 0 2   P3 2 1 1   P4 0 2 2      Need\n    A B C     P0 7 2 3   P1 0 2 0   P2 6 0 0   P3` | 0 | 1 | 1 |      P4 4 3 1      Available\n   A B C     2 1 0        執行Safety\u0026rsquo;s algo\n 設定初值，Work=(2,1,0) 找尋是否有符合Needi \u0026lt;= Work 的Process，且還有Process為False**(不通過)**，所以unsafe      範例二\n  Allocation\n    A B C     P0 0 3 0   P1 3 0 2   P2 3 0 2   P3 2 1 1   P4 0 0 2      Need\n    A B C     P0 7 2 3   P1 0 2 0   P2 6 0 0   P3 0 1 1   P4 4 3 1      Available\n   A B C     2 1 x      求x的最小值，使其成為Safety\n 設置初值，work= (2,1,x) 找尋 Need \u0026lt;= work 找到了，P3，先暫定x=1 (2,1,1) P3因為可以完成，完成後資源就可以釋放出來，因此work (2,1,1) \u0026gt; (4,2,2) 繼續找尋Need \u0026lt;=work 找到了，P1 P1因為可以完成，完成後資源就可以釋放出來，因此work(4,2,2) \u0026gt; (7,2,4) \u0026hellip;往復循環，以此類推  ​\nx= 1;\nBanker\u0026rsquo;s Algo 之 Time Complexity 先講結論，複雜度就是O(n^2*m)\n(n: Process 數目, m:resource 種類數)\nBanker\u0026rsquo;s Algo Time Complexity\nStep\n O(m)Check Request \u0026lt;= Need  O(m) Check Request \u0026lt;=Available O(m)試算 Run safety algo 設置初值work -\u0026gt; 1~m的一維陣列，因此複雜度為O(m)。Finish -\u0026gt;1~n的一維陣列，因此複雜度為 O(n) 先來看看Safety\u0026rsquo;s algo的步驟  ​\t第一次最多會檢查n次，再來第二次檢查n-1次\u0026hellip;\n​\t=(n+1)n/2個Processes。每次檢查Need \u0026lt;=Work 花O(m)的時\t間，最多花O(n^2*m) time\n花O(n) Check Finish  因此複雜度就是O(n^2*m)\n針對每一項類型資源，皆為Single-instance情況下，有較簡易的Avoidance作法   利用RAG，搭配Claim edge(宣告邊)使用\n  Claim edge:\n代表Pi未來會對Rj提出申請(即表MAX/NEED之意義)\n  Steps：\n當Pi提出Rj申請後\n  檢查有無Pi對Rj的這條宣告邊(Claim edge)存在，若有，則goto2否則，終止Pi\n  Check Rj是否Available，若是，則goto3，否則Pi waits(變成申請邊)\n  (試算)暫時把宣告邊改為配置邊  執行safety\u0026rsquo;s Algo, check 圖中是否有cycle存在\n若沒有，則為safe -\u0026gt; 可核准\n有Cycle，則為unsafe -\u0026gt; 否決\n    例：\n  若P1提出R2之申請，是否核准?\nAns.\n  若P2提出R2之申請，是否核准?\n    補充：Deadlock是unsafe之subset(或unsafe有可能導致死結，也有可能不會導致死結)\n  可能不會死結\nans. 搞不好P1在提出R2的申請時，就使用完R1了，這時就不會有死結。或是P2在P1提出申請之前就使用完R2了，此時也不會有死結。\n  可能會有死結\nans. P1立刻對R2提出申請，此時RAG有Cycle，且資源都是Single Instance\n  也就是說死結產生與否取決於宣告邊在哪個moment提出申請\n​\n定理 系統若有n個processes，m個resource量(單一種類)滿足下列2個條件：\n  1≦MAXi≦m(每個process的最大需求量至少要有1個，最多不超過m)\n  且所有n個process的Maxi加總，小於n+m\n$$ \\sum_{i=1}^nMAXi\u0026lt;(n+m) $$\n則System is Deadlock free.\n  例1. 有6部printers被process使用，每個process最多需要2部printers才可以完工，則System 最多允許?個process執行以確保deadlock Free?\nans. m=6, Max=2\n開始跑定理\n  1 ≦ Maxi ≦ m -\u0026gt; 1 ≦ 2 ≦ 6成立\n  $$ \\sum_{i=1}^nMaxi\u0026lt;(n+m) $$\n  ​\t所以2n\u0026lt;n+6，n\u0026lt;6，Ans:　最多５個processes\n​\n詳解\n  所謂死結的發生，就是系統已經將所有的資源都投入下去，但依然沒有產出，不會有一個系統是佔據著資源不分配，看著底下的Process進入Deadlock還很開心\n  應此將資源分配下去後，就是長這樣\n  Process取得2個Resource後就可以執行，執行完後又釋放2個Resource給其他的Process使用\n  持續的把Resource分配給Process\u0026hellip; 往復循環，即可完成。\n  若很不幸的是，如果今天是6個Process，就會發生死結\n  推導公式，若今天題目改成，每個Process需要3台印表機，現在有10部列表機，最多能允許幾個Process(MAX=3, m=10)\n3n\u0026lt;n+10\n=2n\u0026lt;10\n=n\u0026lt;5\n  ​\tans. n=4\n例2. 證明：\n​\tproof：假設資源全部配置出去\n$$ 即\\sum_{i=1}^n Allocationi = m $$\n​\t又因為\n$$ \\sum_{i=1}^nNeedi = \\sum_{i=1}^nMaxi-\\sum_{i=1}^n Allocationi(Banker\u0026rsquo;s Algo) \\\n= \\sum_{i=1}^nMaxi-m \\\n∴\\sum_{i=1}^nMaxi=\\sum_{i=1}^nNeedi+m $$\n​\n​\t再依據條件(2)\n$$ \\sum_{i=1}^nMaxi \u0026lt; (n+m) \\\n∴\\sum_{i=1}^nNeedi+m\u0026lt;(n+m) \\\n$$\n​\t得出這個結論\n$$ ∴ \\sum_{i=1}^nNeedi \u0026lt; n $$\n​\t此事代表至少有\u0026gt;=1個Process之Needi為0，代表Process可以完工，且Pi至少會Release出\u0026gt;=1個Resource**(∵條件(1) -\u0026gt; MAX\u0026gt;=1,而Needi=0 ∴Allocation \u0026gt;=1)**使得剩下的Process當中又會有\u0026gt;=1個process之Need為0又可以完工。使得剩下的process中又會有\u0026gt;=1個Process之Need為0又可以完工，依此類推，所有Process皆可完工，∴Deadlock Free\n解釋的數學式子如下，類似離散的鴿籠原理\n$$ \\sum_{i=1}^{n-1}Needi\u0026lt;n-1 $$\nDeadlock Detection \u0026amp; Recovery   如果放任resource使用較無限制，雖然Utilization高，但是System有可能進入死結而不自知。因為需要有一個死結偵測演算法，及萬一偵測出有死結，如何破除這個死結(recovery)的作法。\n  Recovery做法：\n   Kill Process in the deadlock\n 方法一：Kill All Processes in the deadlock寸草不生，眼不見為淨\n缺點：成本太高，先前的工作成果全部作廢。\n方法二：Kill processes one by one，Kill一個之後，須再跑偵測Algo，若死結仍存在，再Repeat上述步驟\n缺點：成本太高，Loop次數*偵測成本\n   Resource Preemption\n 步驟一：選擇\u0026quot;Victim\u0026quot; process(假設此Process擁有資源A,B,C)\n步驟二：剝奪他們身上的資源(剝奪B，保留A,B，這是最基本的情況)\n步驟三：回復此Victim process當初未取得此剝奪資源的狀態(這一步非常困難，成本極高，也不一定做得好，此外也可能有Starvation的問題)\n      Deadlock Detection Algorithm(考比較多的是Banker,Detection稍微知道就好)   Data Structures used\nn：process數\nm：resource種類\n Allocation：n*m matrix Availavle：[1\u0026hellip;m] of int 目前可用資源數量 Work: [1\u0026hellip;m] of int Finish：[1\u0026hellip;n] of Boolean Request：n*m matrix，各process目前提出之各式資源申請量  Note：\n Avoidance(Banker\u0026rsquo;s Algo)含有未來(Future)info(MAX,Need) Detection：只有現在(Current)info    Procedures\n步驟一：初值設定\nWork=Available\nFinish[i]= True: if Allocation ==0\n​\tFalse: **if Allocation ≠0 **\n步驟二：看可否找到Pi滿足：\n Finish[i]為False Requesti ≦ Work  若找到，則進入步驟三，否則進入步驟四\n步驟三：設定Finish[i]=True，且Work=Work+Allocationi, then 回到步驟二，找不到則回到第四步\n步驟四：Check Finish Array，若皆為True，因此目前無死結，否則則有死結，且Finish[i]= False者，即為陷入死結中\n  Time：O(n^2 *m) \u0026ndash;\u0026gt; 死結偵測一次，cost很高，再加上乘以偵測頻率\n  範例1：\n Allocation      A B C     P0 0 1 0   P1 2 0 0   P2 3 0 3   P3 2 1 1   P4 0 0 2     Request      A B C     P0 0 0 0   P1 2 0 2   P2 0 0 0   P3 1 0 0   P4 0 0 2     Available     A B C     0 0 0    偵測目前有哪些死結?\n若有，那些process in the Deadlock\nAns.\n  Work = Available = (0,0,0)\nFinish\n   0 1 2 3 4     F F F F F    因為Allocation皆≠(0,0,0)\n  ∵可以找到P0滿足Finish[0]為F，且Request≤work ∴到第三步驟\n  設定Finish[0]為True，且Work=(0,0,0)+(0,1,0)=(0,1,0)，回到第二步驟\n  ∵可以找到P2滿足Finish[2]為F，且Request2 ≤ Work，∴到第三步驟\n  設定Finsh[2]為True，且Work=(0,1,0)+(3,0,3)=(3,1,3)，回到第三步驟\n  在步驟二與步驟三之間抽插，往復循環，P1, P3, P4皆可Finished\n  Check Finish Array ∵皆為True，∴目前無死結\n  若每一類型資源資源皆為Single-instance，則有較簡化的Detection作法-使用Wait-For Graph  定義：令G=\u0026lt;V,E\u0026gt;有向圖，代表Wait-For Graph，其中   Vertex：只有Process Only，沒有Resource頂點 Edge：Pi 等待\u0026mdash;\u0026gt;Pj，稱之為wait edge    是從RAG簡化而得，即若RAG中存在：\n1 2  graph LR; Pi --申請--\u0026gt; R --配置--\u0026gt; Pj   則在Wait-For Graph 以\n1 2  graph LR; Pi --等待--\u0026gt; Pj   呈現\n  偵測作法：在Wait-For Graph中，若有Cycle，則目前有死結，否則目前無死結\n  例：RAG如下\n    化成Wait-For Graph\n  目前有無死結\nAns.∵有Cycle，∴目前有死結\n  Chapter 6 Process Synchronization Process Communication,Inter Processes Communication; IPC\nProcess的關係就兩種\n Independent Cooperating(有資訊交換的需求)  何謂同步(Synchronization)？Process在執行的過程當中，因為某件事情的發生或沒有發生，導致它必須停下來，等對方完成，才可以接著往下做，符合這些事情的就是同步。\n   Process Communication兩大方式\n  Shared Memory\n  Message Passing\n    Race Condition Problem\n  解決Race Condition之兩大策略\n Disable interrupt Critical section design    C.S.Design 必須滿足的3個Criteria(Mutual Exclustion, Progress, Bounded Waiting)\n  C.S Design 方法(架構)\n SoftWare Solutions HardWare Instructions Support(Test-and-Set, SWAP) semaphore☆☆☆☆☆(號誌) Monitor 解決著名的同步問題  Producer-Consumer Problem Reader/Writer Problem  First Second   The Sleeping Barber problem The Dining-Philosophers Problem      Message Passing 溝通方式(較少考)\n   Process communication之兩大方式 Shared Memory(本篇重點) 定義：Processes透過共享變數(shared Variable)之存(Write)取(Read)達到溝通(Info exchange)之目的\n分析：\n 適用於大量Data(message)傳輸之狀況 傳輸速度較快(因為不須kernel介入干預/支持，Shared memory是Programmer的責任，Programmer要負責去處理互斥的問題) 不適合用於Distributed System Kernel不需提供額外的支援(頂多供應Shared memory space) 是Programmer的負擔，必須寫額外的程式碼防止Race Condition的發生  Message Passing 定義：Process雙方要溝通必須遵循下列Steps\n 建立Communication Link 訊息可雙向傳輸 傳輸完畢，必須Release  分析：\n  適用於少量Data(message)傳輸之情況\n  傳輸速度較慢(因為需要kernel支持)\n  適合用於Distribute System\n  Kernel必須提供額外的支援\n例：send/recevice system call, Communication Link管理，Message lost之偵測、例外狀況之處理\n  Programmer沒有什麼負擔，只要會用send/receive的System Call就好\n  Race Condition problem in shared memory Communication\n定義：In shared memory Communication, 若未對共享變數存取提供任何互斥存取控制之Synchronization機制，則會造成\u0026quot;共享變數的最終結果值會因為Process之間的執行順序不同而有不同的結果值\u0026quot;，此種Data inconsistency情況，稱之為Race Condition\n例子：Ｃ是共享變數，初值=5，此時有2個Process\n   Pi Pj     \u0026hellip; \u0026hellip;   C=C+1 C=C-1   \u0026hellip; \u0026hellip;   \u0026hellip; \u0026hellip;    Pi，Pj各執行一次，則C的最終值可能是5 or 4 or 6 ，這種稱之為Race Condition\n  結果為5，執行順序可能為\nT1= Pi = C =C+1\nT2= Pj = C =C -1\nor\nT1 = Pj = C = C - 1\nT2 = Pi = C = C + 1\n  結果為4，執行順序可能為\nT1：Pi執行C+1，得到6，但尚未Assign給C，只是先放在一個佔存器\nT2：Pj執行C-1，得到4，尚未Assign回C\nT3：Pi 6 assign回C\nT4：Pj 4 assign回C\nC的結果為4\n  結果為6，執行順序可能為\nT1：Pi執行C+1，得到6，但尚未Assign給C，只是先放在一個佔存器\nT2：Pj執行C-1，得到4，尚未Assign回C\nT3：Pj 4 assign回C\nT4：Pi 6 assign回C\n結果為6\n  範例1\nx, y 是共享變數，初值x=5, y=7\n   Pi Pj     x= x+y y=x*y    Pi,Pj各作一次，求(x,y)之可能值\nAns.\n(x,y) = (12,84)\n(x,y) = (40,35)\n(x,y) = (12,35)\n範例2\nx=0是共享變數，i 是區域變數\n   Pi Pj     for(i=1;i\u0026lt;=3;i++)x=x+1 for(i=1;i\u0026lt;=3;i++)x=x+1    Pi,Pj各作一次，求(x)之可能值\n提示\n    Pi Pj     第一次 x=x+1 x=x+1   第二次 x=x+1 x=x+1   第三次 x=x+1 x=x+1    Ans.(3,4,5,6)\n範例3\nx=0是共享變數，i 是區域變數\n   Pi Pj     for(i=1;i\u0026lt;=3;i++)x=x+1 for(i=1;i\u0026lt;=3;i++)x=x-1    Pi,Pj各作一次，求(x)之可能值\n(-3,-2,-1,0,1,2,3)\n解決Race Condition之兩大策略 Disable Interrupt 對CPU下手\n定義：Process在對共享變數存取之前，先Disable Interrupt，等到完成共享變數的存取後再才Enable Interrupt。如此一來可以保證Process在存取共享變數的期間CPU不會被Preempted，即此一存取是Atomically Executed\n例\n   Pi Pj     \u0026hellip;Disable interrupt \u0026hellip; Disable Interrupt   C=C+1 C=C-1   Enable Interrupt \u0026hellip; Enable Interrupt \u0026hellip;    優點：\n Simple, Easy implementation 適用於Uniprocessor System(單一CPU)  缺點：\n 不適合用於Multiprocessor的系統當中，只Disable 單一CPU的Interrupt，是無法防止Race Condition(因為其他CPUs上執行的Process仍可存取共享變數)，必須要Disable掉全部的CPU\u0026rsquo;s Interrupt才可防止Race Condition，但這樣會大幅降低Performance(因為無法平行執行) 風險很高，因為必須信任user process在Disable interrupt後，在很短的時間可以在Enable Interrupt，否則CPU never come back to kernel。注意，通常Disable Interrupt做法是不會開放給user Process的，它通常只存在於kernel的製作中(只有OS Developers可以用，因為開發者也要避免kernel內部的Race Condition)  Critical section(臨界區間) Design 對共享Data下手\n恐龍誤用Spinlock, Busy-waiting\n是一個概念\n定義：對共享變數之存取進行管制，當Pi取得共享變數存取權利，在它尚未完成的期間，即使別的Process取得CPU，任何其他Process也無法存取共享變數。\n  Critiacal Section：Process中對共享變數進行存、取的敘述之集合\n  Remainder Section(RS)：Process中除了Critical Section以外的區間，統稱為Remainder Section\n  Process內容：\n每個CS的前後，Programmer須設計/加入額外的控制碼，叫Entity Section，即Exit Section\n  而CS Design不是在設計臨界區間，因為臨界區間是個概念，CS Design是在設計Entry Sec及Exit Sec的Code\n  一個process可以擁有不只一個CS 只是範例都是只畫一個而已，要注意,進入C=C+1後，CPU可以被Pj搶走，但Pj想要對C操作時，Pj的Enrty Section就會把它擋下來。  C.S Design 與 Disable Interrupt相比(spinlock, Busy waiting)\n優點：適用於Multiprocessors system\n缺點：\n 設計較為複雜 較不適合用在uniprocessor    Busy-Waiting Skill(or Spinlock)  定義：透過使用looping相關敘述(eg. for, while, repeat \u0026hellip; util)，達到讓process暫時等待之效果  例：\n1 2 3  while(條件式){ //不做事，只是讓它跑 }   當條件式為True時，process就被卡在while中，無法離開while，如此達到Process暫停的效果，直到條件式變為False，process才會離開while，往下執行。\nNote：\n  [恐]誤用：因為在C.S Design Entry section中經常是使用Busy waiting的技巧(或叫Spinlock)，因此恐龍會把spinlock \u0026amp; busy waiting 視作C.S Design，來去跟Disable Interrupt比較    分析：\n缺點：等待中的Process，會跟其他的Processes競爭CPU，將搶到的CPU time浪費掉，用於做無實質進展的迴圈測試上。因此，若此Process要等很長的時間才能exit迴圈，則此舉非常浪費CPU time\n優點：若Process卡在Loop的時間很短(i.e 小於Context Switcing time)，則Spinlock十分有利，因為Loop的時間很短，浪費的時間也不會太短。\n  另一種Non-Busy-waiting Skill\n定義：當Process因為同步事件被卡住，且如要卡很久的時間，則可以使用Block(p)的System call，將p暫停，即讓p進入Blocked的狀態，如此一來，P就不會與其他Processes競爭CPU，直到同步事件發生了，才wakeup(p) system call，將P從blocked變成ready state。\n優點：等待當中的Process不會與別人競爭CPU，不會浪費CPU Time\n缺點：額外付出Context Switch的事件幹 這真的算缺點嗎\n  C.S Design應該滿足的3個性質  Mutual exclusion Progress Bounded waiting  分述如下\nMutual exclusion(相互排斥) 定義：最重要的一點，如果沒這點的話談個屁的C.S Design，Race Condition都處理不了了。在任何時間點，最多只允許一個Process進入它自己的CS，不可有多個Process分別進入\u0026quot;各自\u0026quot;的CS\nProgress(進展)  定義：須滿足以下兩點才算Progress  不想進入C.S的Process(亦即在Ramaid Section活動)，不可以阻礙其他Process進入C.S(或不參與進入C.S之決策)不想進去的process不會阻礙別人進入 從那些想進入C.S的Processes中，決定誰可以進入C.S的決策時間是有限的(不可以無窮，也就是No Deadlock likes waitgin forever 大家都無法進入CS)    Bounded waiting(有限的等待)  定義：以個別process的角度來看，自某progress提出申請到核准進入C.S的等待時間是有限的，即若有n個Process想進入CS，則任一Process至多等(n-1)次後，即可進入CS，即No Startvation，須公平對待  C.S Design的方法(架構圖)重要      關注的焦點 補充     高階 Monitor定義、應用、種類、製作方式 同步問題之解決(應用)    中階 Semaphore(號誌)定義、應用、種類、製作方式 C.S Degign正確與否，同步問題之解決    基礎 Software solutions, Hardware Insturctions support C.S Degign正確與否 同位階的還有Disable Interrupt    Software Solutions    特色\n  2個Processes(Pi,Pj)(P0,P1)\n Algo1 x\nAlgo2 x\nAlgo3 o = Peterson\u0026rsquo;s solution\n   n個Processes\n Peterson\u0026rsquo;s Solution(n個Processes)[不太會考了，因為真的很爛]\nBankery\u0026rsquo;s Algo[麵包店取號碼牌的演算法，恐龍移掉了，但真的很重要，要學]\n     2個Processes之C.S Design(Pi,Pj,i≠j) Algo1   共享變數宣告如下\n1 2  turn: int 值為i或為j 意義：權杖，turn值為i，就是只能讓Pi進入(只有Pi有資格進入)，反之亦然     程式\n       CS Design要滿足的條件 滿足與否 解析     Mutual Exclusion O 因為turn值不會同時為i且為j，只會為i或j的其中一個，因此只有Pi或Pj其中一個可以進入CS，不會兩個同時進入C.S   Progress X 假設目前Pi在RS(Pi不想進入CS)，且Turn值為i，若此時Pj想進入CS卻無法進入，被Pi阻礙，因為唯有仰賴Pi才能將Turn的值改為j，Pj才能進入CS，但此時Pi並不會去做此設定   Bounded Waiting O 假設目前turn為i，且Pi已先於Pj進入CS，而Pj等待中，當Pi離開CS後，又立刻想再進入CS，但因Pi會在離開CS後，將turn的值設為j，使得Pi無法先於Pj進入CS，所以Pj至多等一次後即可進入CS    Algo2   共享變數宣告如下\n1 2 3 4 5 6  flag[i..j] of boolean; 初值皆為False 意義：flag[i] ={ True:Pi有意進C.S False:Pi無意進C.S }     程式：\n  分析\n     CS Design要滿足的條件 滿足與否 解析     Mutual Exclusion O 兩個人確實都不會同時進去，但有可能會兩個都想進去，卡住彼此，參照下面   Progress X 第二點不符合，會形成Deadlock，Pi,Pj可能接無法進入C.S解析在下面   Bounded Waiting O 兩個都進不去，是deadlock，不是stravation    解析：Algo3 Peterson's solution\n混合Algo1,Algo2做撒尿牛丸\nalgo1只考慮誰有資格，沒考慮意願。algo2只考量意願，但會造成死結。因此結合百家之長，不只考量資格也考量意願\n  共享變數宣告如下\n Flag[i\u0026hellip;j] of Boolean初值皆為False 表意願 Turn：值為i或j only 表資格    程式\n  分析\n   CS Design要滿足的條件 滿足與否 解析     Mutual Exclusion O 相互排斥，不會有兩個process同時進入C.S：若Pi，Pj皆想進入C.S，代表flag[i]跟flag[j]結為True， 當雙方皆做到while測試的時候(也就是交錯)，表示雙方已分別執行過Turn=i, Trun=j之設定，差別只是先後順序不同而已。若Pi執行比較快，把Turn改成J，接著Pj因為執行比較慢，又把Turn改成i，所以Turn的值只會為i(或j其中一個)，不會同時為兩者，所以只有Pi或Pj一個Process得以進入CS，因此符合Mutual Exclustion   Progress O 因為progress有兩個情況，因此分別討論之。\n1.不想進去的process不會阻礙別人進入： 假設turn值為i，且Pi不想進入C.S，代表Flag[i]為False，若此時Pj想進去則Pj必可離開while(因為Flag[i]==False)，而進入CS，因為Pi不會阻礙Pj進CS\n2.不產生Deadlock：若Pi,Pj皆想進入C.S，則在有限的時間內必可決定出Turn值為i或為j，讓Pi or Pj進入，兩者不會waiting forever   Bounded Waiting O 先進去的process出來後，不會立刻再進去，亦即不會有Starvation的情形：假設turn為i，Pi已先於Pj進入CS，而Pj等待進入中，Flag[i]==[j]==True，若Pi離開CS之後，又立刻想進入CS，則Pi必定會做一件事情，就是**~~把Flag[i]自己設為False~~，把Turn設成=j**，一定是Pj進入CS，因為Pj至多等一次後即可進入CS。      N個Processes C.S Design Bankery\u0026rsquo;s Algo(麵包店取號碼牌) 解決Race Condition\n  觀念：\n 客人(Process)要先取得號碼牌，才可入店內(CS) 店內(CS)一次只容一人(Process)進入 號碼最小的客人或同為最小號碼之多個客人中ID最小的(PID)，得以優先進入店(CS)    共享變數宣告如下：\n  Choosing[0\u0026hellip;n-1] of Boolean 初值皆為False。\n意義：choosing[i]=\n True：Pi正在取得號碼牌，尚未確定號碼 False：  Pi取得號碼牌 初值      Number [0\u0026hellip;n-1] of int 代表號碼牌\n意義：代表P0~Pn-1，n個Process之號碼牌值，初值皆為0。\nnumber[i]：\n 0：表Pi無意願進入CS .\u0026gt;0：表Pi有意願進入CS    數學函數used\n MAX(\u0026hellip;)：取最大值(用來決定號碼牌的值) (a,b)\u0026lt;(c,d)若要成立，則必須滿足下列兩個條件之其中一個  a\u0026lt;c a==c and b\u0026lt;d      Pi之程式如下：\n  1 2 3 4 5 6 7 8 9 10 11 12 13  repeat chosing[i]= True; //表明正在取得號碼牌 Number[i] = MAX(Number[0]...[n-1])+1; //決定號碼牌是幾號 choosing[i]= False; //表示已取得號碼牌  for(j=0;j\u0026lt;n;j++){ // 此for-loop去檢測所有process  while (choosing[j]){do noting} //若別人pj正在取號碼牌中，則稍等一下，若都沒有被卡住，可以順利跑完，則進入CS  while(number[j]\u0026gt;0 and (number[j],j)\u0026lt;(number[i],i)){do noting} //i代表自己，j代表別人。Pj有意願進入CS，並取Pj號碼小於我或跟我同好，Pj Id j \u0026lt;Pi ID i，則我等待。 } C.S Number[i]=0; R.S untill False     經典問題 為何會有很多個Processes取得相同的Number值？ Ans. 假設MAX(Number [0]~[n-1]值為k，Pi,Pj(i≠j) 2個Processes之交錯執行順序如下：\n正確性證明？ Ans.\n  Mutual Exclusion：OK\nCase1. 假設Number值皆不同(\u0026gt;0)，則具有最小的Number值之Process，得以優先進入CS，其餘Process wait而最小值必唯一\nCase2. 有多個Processes具最小Number值，則以Processes之PID最小者得以進入CS，而ProcessID具備Unique性質，因為最小值必定唯一。\n藉由Case1, Case2知道唯一性確定，互斥確保\n  Progress：OK\nCase1. 假設Pj不想進入CS，代表Number[j]為0，若此時Pi想進入CS則Pi檢查到Pj，Pi必定不會被Pj所阻礙，可以exits for中第二個While(因為while(number[j]\u0026gt;0 )，這個條件判斷不成立)\nCase2. 若P0~Pn1-1，n個Processes皆想進入CS，則在有限的時間內，必有一個Proess(其Number最小或同號中ProcessID最小)，可以順利跑完for loop進入CS，因為No Deadlock\n  Bouned waiting：OK\nCase1. 假設P0~Pn-1 n個Processes皆想進入CS，另Pi具有最大的，number值為=K(number[i]=K)，因此Pi會是最後進去的，其他(n-1)個Processes:Pj(j≠i)，必定皆先於Pi進入CS。若Pj離開C.S後，又立刻想再進入C.S，則Pj取得的號碼牌之值Number[j]必定大於K，所以Pj不會再度先於Pi進入CS，因此Pi頂多等(n-1)次後即可進入CS\n  設計問題 1 2 3 4 5 6 7 8  for(j=0;j\u0026lt;n;j++){ while(choosing[j]){ // do noting  } while(number[i]\u0026gt;0 and number[j],j\u0026lt;(number[i],i)){ //問題，既然這邊都會把不符合的Process攔下來，娜何還需要上面的choosing[j]來卡住呢?是不是可以把choosing[j]刪掉，這樣的邏輯對嗎?會出現什麼問題嗎  // do noting  } }   解釋：\n違反了互斥。\n例：令　目前Number[0,n-1]都還沒領到號碼牌值皆為0，Pi，Pj2個Processes(i≠j)想進入CS，且假設ProcessID是i\u0026lt;j\n​\t就好比一個阿婆跟一個年輕妹妹一起去麵包店，年輕人先取完號碼牌，老太婆還沒取完。這時候妹妹領完後，老太婆還沒領，原本的設計下，妹妹會等阿婆領完才執行下一步，但這種情況下，即使阿婆還沒取，妹妹也會直接進入麵包店裡。接著阿婆取完號碼牌，發現跟妹妹同號(Race Condition)，此時他也想進入CS，這時候阿婆的身分證號碼(UID)比妹妹小，所以阿婆也可以進入CS，這種情況下，有兩個Process同時進入CS裡，違反了互斥(Mutual Exclustion)\nHardware Solution - CPU Instructions Support 若CPU有提供下列指令之一\n  Test-and-Set (Lock) SWAP(a,b)   則Programmer可以運用在CS Design\nTest-and-Set(Lock) 指令 定義：此CPU Instruction之功能為，傳出Lock參數值Lock的資料型別為boolean且將Lock參數設為True(1)，且CPU保證此指令是☆☆☆\u0026quot;Atomically Executed\u0026quot;☆☆☆，\n範例：以Ｃ語言說明此指令功能：\n1 2 3 4 5  int Test-and-Set(int *Lock){ int temp = *Lock; *Lock = 1; return temp; }   用在C.S Design上\n[Algo1]：Ｘ不可以用   共享變數如下：\nLock：boolean = False\n  Pi程式如下：\n1 2 3 4 5 6 7 8 9  repeat{ while(Test-and-Set(Lock)){ // do nothing  } C.S區塊; Lock = False; R.S; Utill False; }     分析：\n  Mutual Exclustion：OK\n  Progress：OK\n 不想進去的人就待在RS裡面，不會去搶 避免死結，總有一個人會搶到Test-and-Set(Lock)    Bounded Waiting：違反\n假設Pi已先於Pj進入CS，且Pj等待中，當Pi離開CS後，若想在立刻進去CS，則Pi是有機會在優先進去搶到Test-and-set之執行，因此Pj 有可能Starvation\n    [Algo2] ：穩的，可以用   共享變數如下：\n Lock：boolean = False; Test and Set會用到的變數 waiting[0 ..n-1] of boolean初值皆為False，若為True則代表有意進入區間，若為False則代表初值，或準備進入C.S  意義：\nwaiting[i]有兩種，若為\nTrue：表Pi有意進入CS，且正在等待中\nFalse：代表初值，或是表示Pi不需要再等了，可以進入CS\n  Pi之程式如下： [034 17 02 CH6 P 6 71時24分02秒 17:57]\n區域變數\n  Key：boolean;\n  j: int\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  repeat waiting[i] =True; //Pi有意，且等待中...  key= True; while(waiting[i]\u0026amp;\u0026amp; key) { key = Test-and-set(Lock); } //--------------------分隔線-------------- //在還沒離開while前，waiting[i]的值不可能為False，Process i 個人而言不可能把waiting[i]值改成False進入CS。因此只剩Key可以動了 // 又因TestAndSet(Lock)方法會返回Lock的Boolean值，並將Lock設為True，也因此，惟有第一個搶到CPU的Process，才會有False的Key值 waiting[i]= False; //☆☆☆☆☆表明Pi不用等了，可以進入CS了☆☆☆☆☆  C.S; j= (i+1) % n; //n是陣列長度, j 是指i的下一個element of array  while(j≠i \u0026amp;\u0026amp; not waiting[j]){ //若j=i，則表示已經繞了一圈。waiting表意願，True代表想，False代表不想  j=(j+1)%n; //找出下一個想進入C.S之Pj  } if(j==i) { //搭配下面的case2，代表都沒人想進入CS，並且因為 Test-and-Set(Lock)會將Lock設為True(可參照上面)  Lock =False; //因為都沒人想進去，因此就把鎖打開  } else{ waiting[j]= False; //Pj不用等了，換你進CS  } R.S; utill False;   Case1.\nCase2：當Pi執行完後，發現外面都沒任何人想進來，只好再把Lock設回False，一切重新ReSet\n  Q1：證明正確性\nAns．\n[1] Mutual Exclusion：OK\npf： Pi可進入C.S之條件有兩種可能\ncase1. Key值為False\n代表Pi是第一個搶到Test-and-Set(Lock)執行者，如此才能將Key改為False，==因此唯一性確立==\ncase2. waiting[i]為False\n代表Pi在離開while之前，是不會將waiting[i]改為False,==只會將它設為True，只有在CS的Proces當它離開CS後，才能改變其他processes中之一個process的waiting值變False，在CS中的Process只有一個，出來CS後也只改變一個Process之waiting值為False，因此唯一性也確立。換言之，一個process不會自己把自己的waitiing值設成False，一定都是別的process來設的，因此唯一性確立==\n因此由case1及2得知，互斥成立\n[2] Progress：OK\npf：==若Pi不想進入C.S，其waiting[i]為False，而且Pi不會跟其他Process競爭Test-and-Set(Lock)的執行，且從CS離開之Process，也不會改變Pi之waiting值，因此Pi不會參與進行CS之決策。==\n若n個Process都想進入CS，則在有限的時間內必定會決定出第一個搶到Tetst-and-Set()執行，並進入CS。它從CS離開後，也會在有限的時間內讓下一個想進入CS之Process進入CS或Lock設False。\n==不會有Deadlock==\n[3]Bounded Waiting：OK\npf：假設P0~Pn-1等n個Processes皆想進入C.S表示waiting[0]~[n-1]皆為True\n令Pi是第一個搶到Test-and-Set執行之Process，率先進入CS當Pi離開CS後，會將P(n+1)%n之waiting值改為False，讓P(n+1)%n進入cs，依此類推，Process會依Pi,P(i+1)%n,P(i+2)%n\u0026hellip;P(i-1)%nFIFO 順序依據進入CS，故不會有Starvation\nSWAP(a,b)指令  定義：此CPU指令是將a,b兩值互換，且CPU保證它是==Atomically executed==  若以C語言描述，功能如下：\n1 2 3 4 5  void swap(int *a, int *b){ int temp = *a; *a = *b; *b = temp; }    用在C.S design上  [algo1]：Ｘ\n共享變數如下\nLock：boolean=False;\n區域變數如下：\nkey：boolean\n1 2 3 4 5 6 7 8 9  repeat; key=True; {repeat; swap(Lock,key); utill(key==False)} ; //成立才離開 C.S Lock=False; R.S until False;   分析：\n[Algo1]同Test-and-Set\nMutual Exclustion= ok\nprogress= ok\nBounded waiting= No，只有設成Fales而已，還是無法避免無限等待\n[Algo2] 正確的\n將Test-and-set的[algo2]中\n1 2 3 4 5 6 7 8  ... while(...){ // key=test-and-set(Lock); swap(Lock,key); //改成這樣即可 } ...   綜合練習\n在Test-and-set[Algo2]中\n1 2 3 4 5  while(waiting[i] and key){ key = Test-and-Set(Lock); } waiting[i] = False; //Pi不用等了，可進入CS CS   若把waiting[i] = False; 這行刪掉，此行removed是否正確?explain in details\nAns.\n違反Progress，不想進入的progress參與決策，並且會發生死結，兩件事情都會發生\nSemaphore(號誌) 製作Semaphore的目的就是為了確保 ，號誌的值不會Race Condition\n學習地圖\n 定義\n應用\n CS Design (臨界區間設計)\nsynchronization problem solution(解決同步問題)\n 種類\n Binary semaphore vs counting semaphore\nspinlock semaphore vs non-busy waiting semaphore\n    定義：令Ｓ為Semaphore type變數，架構在integer type針對S，提供兩個Atomica operations\n wait(S)或P(S) 因為是荷蘭人，所以用荷蘭命名 signal(S)或V(S) 因為是荷蘭人，所以用荷蘭命名  定義如下\n  wait(S)： ==若S為0則卡住，若S不為0則通過==\n1 2 3  while(S≦０){do no-op;} //若semaphore的值為0，則卡在這邊 S=S-1; //退出後semaphore值-1   signal(S)： 1  S=S+1;   note：因為Atomical, 所以S不會有race condition\n 應用：主要用在CS Design，及同步問題之解決  CS Design使用如下   共享變數宣告如下\nmutex常見的變數名稱，代表mutual exclustion的意思：semaphore= 1; //初值為1\n  Pi程式如下：\n1 2 3 4 5 6  repeat : wait(mutex); C.S signal(mutex); RS untill False;      Pi Pj     T1：wait(mutex);\n因為mutex = 1\n所以Pi可以離開while，then,mutex值在減1變0，then Pi進入CS T2：wait(mutex)，因為此時mutex=0，這時候Pj會卡住。符合Mutual exclustion\nProgress也符合\nBounded waiting也符合      解決簡單的Synchronization problem ​\t何謂Synchronization? Process因為某些事件發生(or未發生)而被迫等待，無法往下執行，直到其他Processes do something才得以往下\n範例1：\n   Pi Pj     \u0026hellip; \u0026hellip;   A; B;   \u0026hellip; \u0026hellip;    規定：A必須在B之前執行，試用Semaphore達到此需求\nAns. 宣告一共享變數\nS= Semaphore=0;    Pi Pj     \u0026hellip; \u0026hellip;   A;\nsignal(S); wait(S);\nB;   \u0026hellip; \u0026hellip;    ==Note：semaphore的初值是具有某些意義的，並且初值不一定要是０或１，其實都可以，只是都用０跟１做舉例==\n 初值為1：用作互斥控制 初值為0：用作強迫等待  例2：\nS1：Semaphore= 0;\nS2：Semaphore= 0;\n規定執行順序為A -\u0026gt; C -\u0026gt; B 該如何完成?\nAns：\n   Pi Pj Pk      wait(s2) wait(s1)   A B; C;   signal(s1)  signal(s2)    Ex2：希望達成 A,B,C,A,B,C,A,B,C repeatly execuction\n承上性質，S1,S2 semaphore=0;S3 semaphore=1\n   Pi Pj Pk     wait(s3) wait(s1) wait(s2)   A; B; C;   signal(s1) signal(s2) signal(s3)    Ex3：C是共享變數，初值為3，請寫出最後C的值為多少\n 第一小題     Pi Pj     C=C*2 C=C+1    7或8或4或6\n 第二小題  s= semaphore=1\n   Pi Pj     wait(s) wait(s)   c=c*2 c=c+1   signal(s) singal(s)    7或8\n 第三小題  s= semaphore = 0\n   Pi Pj      wait(s)   c=c*2 c=c+1   signal(s)     7\nEX4\nS1：Semaphore = 1;\nS2：Semaphore = 0;\n求ABC可能執行順序\n   Pi Pj Pk     wait(s1) wait(s2) wait(s1)   A; B; C;   signal(s2) signal(s1) signal(s1)    Ans：把不可能的刪除就好\nABC,\nACB,\nBAC,\nBCA,\nCAB,\nCBA\nsemaphore之誤用所造成之問題 違反互斥、形成死結\n例1\ns= Semaphore=1\n   Pi     singal(s)   CS   Wait(s)    \u0026mdash;\u0026gt; 違反mutual exclusion\n例2\ns= semaphore = 2\n   Pi     wait(s)   cs   wait(s)   rs    \u0026mdash;\u0026gt; 形成死結\n例3\nS1,S2 = Semaphore = 1;\n   Pi Pj     T1:wait(s1) T2:wait(s2)   T3:wait(s2) T4:wait(s1)   \u0026hellip; \u0026hellip;   signal(s1) signal(s2)   signal(s2) signal(s1)    可能形成deadlock，如果Pi，Pj依照T1~T4之順序交錯執行\n著名的Synchronization Problem之解決 想看看何時會停下來\nProducer-Consumer Problem(生產者消費者問題) Producer：此process專門產生資訊供別人使用\nConsumer：此process專門消耗別人產生的成果\n在sharrd memory溝通方式底下，會準備一個buffer\n細分為兩個類型的問題\n  Bounded Buffer Producer-Consumer(Buffer有限)\n有兩個情況會被迫等待\n 當Buffer滿了，Producer被迫等待 當Buffer空了，Consumer被迫等待    Unbounded Buffer Producer-Consumer(Buffer無限)\n  algo1 共享變數宣告如下\n  Buffer: [0..n-1] of items;\n  in,out: int = 0;\n  Producer 程式：\n1 2 3 4 5 6  repeat: produce an item in nextp; while((in+1)%n==out) {do noting}; //當buffer滿的話，就卡在while中 Buffer[in] =nextp; in = (in+1)%n; until false;   Consumer程式：\n1 2 3 4 5 6 7  repeat while(in == out ){ do nothing} //buffer為空 nextc= Buffer[out]; out=(out+1) % n; ... consumes the item in nextc; until false;   此時producer 無法在加item，因為(in+1)%n == out, 即buffer已經滿了，因此最多利用(n-1)格\nalgo2 共享變數宣告如下\n  Buffer: [0..n-1] of items;\n  in,out: int = 0;\n  ==count:int =0==\n  這個count值有可能導致race condition，因此不完全正確\nProducer 程式：\n1 2 3 4 5 6 7  repeat: produce an item in nextp; while(count==n) {do noting}; //當buffer滿的話，就卡在while中 Buffer[in] =nextp; in = (in+1)%n; count = count +1; until false;   Consumer程式：\n1 2 3 4 5 6 7 8  repeat while(count ==0 ){ do nothing} //buffer為空 nextc= Buffer[out]; out=(out+1) % n; count = count -1; ... consumes the item in nextc; until false;   用semaphore解producer-consumer problem 共享變數宣告如下：\n empty : semaphore = n . 代表buffer內空格數，若空格數變為0，代表滿了 full : semaphore=0. 代表buffer區中，填入item之格數，若為0，表buffer為空 mutex：semaphore=1; 對buffer, in , out , count做互斥控制，防止race condition  semaphore的設計哲學   滿足同步條件之號誌變數empty, full 互斥控制防止race condition之號誌 mutex 先測同步在測互斥，不然會造成死結 ==共享變數取存之前都需要經過互斥的處理==   producer\n1 2 3 4 5 6 7  repeat produce on item in nextp; wait(empty) ; //若無空格則P被迫等待 wait(mutex); add nextp into Bufffer; //濃縮很多程式在這行裡面喔 signal(mutex); signal(full); //填入item之格數加1，maybe拯救Consumer   consumer\n1 2 3 4 5 6  repeat wait(full); wait(mutex); remove item from Buffer in nextc signal(mutex); singal(empty)   Read/write Problem 基本的同步條件\n Reader write要互斥 writer,writer也要互斥  此外，這問題再細分成兩類\n  First read/writer problem\n-\u0026gt; 對Reader有利，對writer不利，因此writer可能starvation\n  Second read/writer problem\n-\u0026gt; 對writer有利，對reader不利，因此reader可能startvation\n  First Reader/Writer Problem 何謂「對Reader有利，Writer不利」?\n只要有源源不絕的Reader，則W1可能Starvation\n共享變數宣告如下：\n  wrt：semaphore =1\n 提供R/W 及 W/W互斥控制，並兼差對Writer不利的控制\n   readcnt：int = 0;\n 統計Reader個數，直到沒有Reader，才可以放writer進去\nReader到-\u0026gt;Readcnt +1\nReader走 -\u0026gt;Readcnt -1\n   mutex：semaphore=1\n 由於readcnt是一共享變數，會有Race Condition之問題，故需額外宣告一變數Mutex做互斥控制\n   程式：\n   writer reader     \u0026hellip;\nwait(wrt)\n執行寫入作業\nsignal(wrt)\n\u0026hellip; \u0026hellip;\nwait(mutex) ;\nreadcnt = readcnt +1\nif(readcnt==1)代表你是第一個Reader then wait(wrt)要去偵測是否有writer存在。若有則卡住，若無則通過，也順便卡住writer\nsignal(mutex);\n執行reading工作 wait(mutex);\nreadcnt = readcnt -1 //reader走，reader-1\nif(readcnt=.=0) then signal(wrt) //No reader，放writer進去\nsingal(mutex)    練習：\n若目前W1已在寫入中\n R1到，則R1會卡在wrt 裡，此時readcnt=1 R2又到，則R2會卡在mutex，此時readcnt=1 R3到，則R3會卡在mutex，此時readcnt=1  Second Reader/ writer problem 何謂對Writer 有利，對Reader不利\nT6：w1離開，優先放W2近來(並非R1)\nT7：w2離開，優先放W2近來(並非R1)\n\u0026hellip;(以此類推)\n只要Writer離開，發現尚有waiting writer在，那就會優先放writer近來，所以R1有可能Startvation\n共享變數之宣告\n  readcnt：int=0 ：統計reader個數\n  wrtcnd：int=0：統計writer個數\n  x：semaphore：１　//用來對readcnt做互斥控制，防止race condition\n  y：semaphore：１ //用來對wrtcnd做互斥控制，防止race condition\n  z：semaphore：１　//有的版本會有，有的版本不會有。作為對reader之入口控制(讓它卡多一些關卡，讓reader slower)\n  rsem：semaphore=1　//作為對reader不利之控制\n  wsem：semephore=1 //提供R/W及W/W互斥控制\n  程式：\n   writer reaeder(以First reader程式為主，再加入控制)     wait(y)\nwrtcnt = wrtcnt+1;\nif(wrtcnt==1) then(wait(rsem)) //第一個writer ，要負責築起對reader不利之控制\nsignal(y);\nwait(wsem) //\n執行writing工作\nwait(y)\nwrtcnt = wrtcnt-1\nif(wrtcnt==0) then signal(resm) //解除對reader不利之控制\nsignal(wsem) //解除 R/W W/W互斥\nsignal(y) wait(z)\nwait(rsem) //通過對reader不利之控制?\nwait(x)\nreadcnt = readcnt +1;\nif(readcnt ==1) then wait(wsem) //R/W互斥\nsignal(x)\nsignal(rsem)\nsignal(z)\n(執行reading工作)\nwait(x);\nreadcnt = readcnt -1\nif(readcnt ==0) then signal(wsem) //解除R/W互斥\nsignal(x)    The Sleeping Barbers Problem 描述：有一個barber，一張BarberChair，n張waitingChair。並且有客人。\n客人的行為如下\n waiting chairs 坐滿(n個等待客人)：不入店\nwaiting chairs 尚未坐滿：入店內，坐在waitingChair，通知(喚醒)barber\n客人睡覺(wait) if barber is busy now\u0026hellip; 直到Barber叫他起床剪髮，剪完髮Exit\n 理髮師的行為如下\n 睡覺 if no 客人\n直到有客人喚醒(通知)他\n叫醒客人剪髮\n剪完髮後如果還有客人，則叫醒客人剪髮\n剪完髮後如果沒有客人，則繼續睡，繼續水時間\n 共享變數宣告： ==共享變數取存之前都需要經過互斥的處理==\n Customer：semaphore=0 ：用來卡住理髮師 if no 客人 Barber：semaphore=0：用來卡住客人的 if Barber is busy waiting：int=0 // 坐在等待椅上的客人數目。何時+1?何時-1?客人入店，坐上椅子。Barber叫客人起來剪髮，會有race condition的問題 mutex：semaphore=1 //防止waiting值race condition  程式：\n   Barber Customer     repeat\nwait((Customer))\nwait(mutex)\nwaiting = waiting -1;\nsignal(Barber)\nsignal(mutex)\n剪客人頭髮();\nuntil False wait(mutex);\nif(waitng\u0026lt;n){waiting=waiting+1;\nsignal(Customer) //叫醒、通知barber\nsignal(mutex);\nwait(barber);\n被理髮()\n}else{ signal(mutex)}    客人是沒有repear \u0026hellip; until false        The Dining-Philosophers Problems 描述\n注意：1. 吃中餐：奇數、偶數哲學家皆可\n2. 吃西餐：偶數位才可以（刀叉一副\n共享變數之宣告\nchopstick：[0,1,2,3,4] of semaphore；初值皆為1，對5根筷子做互斥控制。\ni號哲學家(i=0~4)哲學家Pi之狀況(這程式是有問題的)\n1 2 3 4 5 6 7 8  repeat... hugry now; wait(chopstick[i]); wait(chopstick[(i+1)%5]) eating now; signal(chopstick[i]); signal(chopstick[(i+1)%5]); think now;   此Solution有問題，可能會形成Deadlock!!\n若每位哲學家都拿起自己左邊的筷子，則每位哲學家都卡住，皆無法取得右筷，形成circular waiting\n解法一\n一次最多讓4位哲學家上桌\nm=5根,Maxi=2\n  1≦Maxi≦m成立\n  $$ \\sum_{i=1}^nMaxi \u0026lt; n+m,因此2n\u0026lt;n+5, n\u0026lt;5。最多4位 $$\n  保證DeadLock Free-\u0026gt; 可額外加入另一個號誌 No:semaphore=4，做入口控制\n1 2 3 4 5 6 7 8 9  repeat... wait(No); hugry now; wait(chopstick[i]); wait(chopstick[(i+1)%5]) eating now; signal(chopstick[i]); signal(chopstick[(i+1)%5]); think now;   解法二\n除非哲學家可同時取得左右兩邊筷子，才准許持有筷子，否則不得持有任何筷子。否則不得持有任何筷子\n破除Hold\u0026amp;wait 條件\n解法三\n相鄰哲學家之取筷順序不同，創造Asymmetric mode，例如：\n   奇數號 偶數號     先取左，再取右 先取右，再取左    破除Circular waiting條件\nNote：等同於西餐，大家規定：先取刀再取叉\ncigarette smokers problem 很少考，從50年前就沒考過了。Pass\nSemaphore之種類 分類一：號誌值域做區分 Binary(二元) Semaphore Vs Counting(計數) semaphore\n Binary Semaphore  定義：Semaphore之值只有0,與1兩種(C.S Design正常使用下)不可為負值，無法統計有多少個Process卡在wait中\nS：Binary-Semaphore=1;\n1 2 3 4  Wait(S)： While)(S≦0) {do no-op} S=S-1   1 2 3  Signal(S){ S=S+1; }   Counting Semaphore  定義：Semaphore值不限於0,1 可以為負值，且若值為-N，可知道(統計出)有N個processes卡在wait中\n範例1.\n請用Binary Semaphore定義出Counting Semaphore。\n共享變數宣告如下\n C：int //代表 Counting Semaphore號誌值 S1：Binary-Semaphore=1 對C作互斥控制，防止C值race Condition S2：Binary-Semaphore=0 ，當C值\u0026lt;0，強迫Process暫停之用  程式：\n1 2 3 4 5 6 7 8  wait(C)： wait(S1); C=C-1; if(c\u0026lt;0) then { signal(S1); wait(S2); //process自己卡住  }else signal(S1)   1 2 3 4 5  Signal(C)： wait(S1); C=C+1; if(c≦0) then Singal(S2); //救process \tsignal(s1)   Demo如下\n1 2 3 4 5  C：Counting semaphore= 1 wait(C); C.S // 臨界區間 Singal(C) R.S   分類二：是否採用Busy-waiting(Spinlock)技巧來定義Semaphore Spinlock Vs Non-Busy-waiting Semaphore\nSpinlock\n定義：令Ｓ為Semaphore變數，而\n  wait(S)：\n定義：\n1 2  while(S≦0){do no-op} //採用Busy-waiting Skill S=S-1     Signal(S)：\n定義：\n1  Ｓ=S+1;     優缺點：參閱前述Busy-waiting內容\nNon-Busy waiting semaphore\n定義：Semaphore type定義如下\n1 2 3 4  Struct semaphore{ int value; //號誌值  Queue Q ; // FIFO Queue }   令S為Semaphore變數，則\n1 2 3 4 5 6  Wait(S)： S.value = S.value-1; if(S.value \u0026lt;0 ) then{ add process P into S.Q; Block(P); // P之狀態改為block state  }   1 2 3 4 5 6  Signal(S)： S.value = S.value+1; if(S.value ≦０)then{ remove a process form S.Q wakeup(P) //將P改為ready state  }   Note：此號誌也是一個Counting Semaphore\n製作Semaphore using\n Disable interrupt Software solution or Hardware instructions support  何謂製作Semaphore?\n即是如何保證Semaphore值不會Race Condition(or 如何確保wait與singal是Atomic operation?)\n製作Semaphore的目的就是為了確保 ，號誌的值不會Race Condition\n   製作方式|號誌定義 Non-Busy waiting Semaphore Spinlock Semaphore     Disable Interrupt [Algo1] [Algo3]   C.S Design(基礎)\nsoftware Solution\n硬體指令 [Algo2] [Algo4]    Algo1 1 2 3 4 5 6 7 8 9  wait(s)： Disable interrupt; S.value = S.value -1; if(S.value\u0026lt;0) then{ Enable Interrupt(); //在這邊打開中斷，而不是在if之外，避免Block(p)之後，因為Disable Interrupt而無法釋放CPU  add process P into S.Q; block(p); }   Algo2 將[Algo1]中的Disable Interrupt 換成 Enter Section，Enable Interrupt改成Exit Section。\nEnter Section與Exit Section之控制碼找個地方寫出來。取決於題目教你用Software Solution(Bakery\u0026rsquo;Algo) or Hardware Instrution(Test-and-set or Swap的Algo[2]或Algo[1]時間不夠就寫這個，但這好像不符合什麼Bound wait還是什麼鬼的)\nAlgo3 1 2 3 4 5 6  wait(s)：while(S≦０){ Enable Interrupt; no-op; Disble Interrupt } S=S-1   1  Signal(S)：S=S+1   Algo4 將[Algo3]中的Disable Interrupt 換成 Enter Section，Enable Interrupt改成Exit Section。\nEnter Section與Exit Section之控制碼找個地方寫出來。取決於題目教你用Software Solution(Bakery\u0026rsquo;Algo) or Hardware Instrution(Test-and-set or Swap的Algo[2]或Algo[1]時間不夠就寫這個，但這好像不符合什麼Bound wait還是什麼鬼的)\nBusy-waiting是否可以完全避免之(avoid altogether) Ans. No, 無法完全避免，以Semaphore為例\nMonitor  定義、組成\n特性(優點)\nCondition 變數使用\n解同步問題\nConditional Monitor\n種類(3種)\n用semaphore Monitor\n 定義：Ｍonitor是一個用來解決同步問題的高階結構class，是一種ADT(abstract data type)，Monitor之定義，主要有3個\n組成：\n 共享變數宣告區 一組local function(or procedures) Initialization area(初始區)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public Class MonitorName{ //共享變數宣告  procedure entry function1(參數){ begin Body; end } procedure entry functionX(參數){ begin; Body; end; } begin; 初始區 end; }   特性(優點)：\nMonitor本身已保證互斥(Mutual excluesive)即任何時間點最多只允許，1個Process在Monitor內活動(Active)，也就是說：在任何時間點，最多只允許一個1個Process呼叫(calling)monitor的某個function(或procedure)執行中，不可以有多個processes同時呼叫monitor的functions\n 此一互斥性質帶來何種好處？\n 因為共享變數區之共享變數只能被monitor的local function直接存取，外界不能直接存取，外界(process)只能透過呼叫Monitor的Local Function來存取共享變數，而Monitor保障互斥，因此保障了共享變數不會發生Race Condition，所以Programmer毋須煩惱Race Condition problem (不用撰寫額外的Code，或是使用Mutex semaphore)，只需專心處理同步問題即可。此點優於Semaphore\nQuestion：Semaphore 比 Monitor容易使用 when solving synchronization problem\nAns：False，參照如上。並且semaphore一多，容易產生Deadloc\nCondition Type 定義：Condition 型別是用Monitor中，提供給Programmer解決同步問題之用，令x是Condition Type變數，在X上提供兩個operations：\nx.wait 及 x.signal\n x.wait：執行此運作的process會被Blocked且置入Monitor內x所屬的waiting queue中(預設是FIFO) x.signal：如果先前有Processes卡在x的waiting queue中，則此運作會自此waiting queue中移走一個process且恢復(resume)其執行，否則無任何作用  使用Monitor解決 The dining-philosophers Problem 先定義所需的Monitor ADT Type\nDining-philosophers = Monitor\nVar\n State[0..4] of {thinking, hungry, eating} self[0..4] of condition;  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  procedure entry pickup(i : 0...4){ //拿起筷子  begin: state[i] = hungry; test(i); if(state[i]≠eating) then self[i].wait; // Pi自己卡住 } procedure test(k:0...4){ //測試  begin: if(state[(k+4)%5]≠eating and state[k]==hungry and state[(k+1)%5]≠eating) then{ state[k]= eating; self[k].signal } } procedure entry putdown(i: 0..4){ // 吃飽了放下筷子  begin state[i]= thinking; test((i+4)%5); test((i+1)%5); end begin for(i=0;i ≦4 ; i++){ state[i]= thinking; } end }    使用方式  共享變數宣告：\n1  dp`變數名稱`：Dining-ph`Monitor type`   Pi (i號哲學家)\n1 2 3 4 5 6 7  repeat hungry now; dp.pickup(i); //在Monitor中 \teating; //不在Mnitor中 \tdp.putdown(i); //在Monitor中 \tthinking; untill False;   Conditional Monitor   緣由：condition變數，eg. X所附屬的waiting Queue, 一般皆是FIFO Queue (甚至Monitor的Entry Quene 也是FIFO,In general)，可是我們有時需要Priority Queue，優先移除高優先權的Process，恢復執行或讓已進入Monitor內active，此種monitor稱之\n  語法改變：\n1 2  x.wait(c); // c代表此process的priority info      使用Conditional Monitor解決問題  範例一  使用Monitor解決互斥資源的配置問題\n規定：process最小者，優先權高，優先取得資源\n解決問題之哲學\n 「非」優先權之需求-\u0026gt;寫入Monitor之定義\n優先權之需求-\u0026gt;只要告知老師說你用的是Priority Queue的Monitor即可\n Ans.\n 先定義Monitor  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  type ResourceAllocator = Monitor var Busy : Boolean //代表資源配置出去與否  var X：Condition; //代表資源到底可用不可用  procdure entry Apply(processId:int) begin if(Busy) then x.wait(pid); Busy = True; procedure entry Release() begin Busy= False; X.signal; end; Begin; Busy= False; end;   使用方式：\n共享變數宣告如下：\n​\tRA：Resource Allocator;\n​\tPi(i代表processId)：\n程式如下：\nRA.Apply(i);\n使用資源;\nRA.Release();\n此Monitor的X Condition變數之waiting Queue及Monior的entry Queue是Priority Queue且processId小者，優先權高，優先移出\n 範例二 ==(最常考)==  有一個File可被多個Processes使用，每一個Process有Unique priority No，並且存取File須滿足以下限制\n 所有正在存取file的process之priority No之加總須\u0026lt;n，超過就無法存取 process priority No小的，優先度高  試設計Monitor\nAns.\neg n =10\n  先定義Monitor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  type FileAccess = Monitor; var sum:int; var x:condition; procedure entry Access(i:priority No){ begin; while((sum+i)≧n){ do x.wait(i) } sum = sum + i ; end ; } procedure entry Leave(i:priorityNo){ begin; sum = sum -i; x.signal; end; begin; sum=0; end; }     使用方式：\n共享變數宣告：\n  FA：FileAccess;\n  Pi(i：process Priority No)程式：\n​\tFA.Access(i);\n​\t使用File;\n​\tFA.Leave(i);\n     範例三  有3部printer 被processes使用(三個互斥資源)，且規定Process Id 小，優先權高。\nAns.\n先定義Monitor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  var p [0..2] of Boolean; x:condition; int Acquire (i:processId){ if(p[0] and p[1] and p[2]){ x.wait(i) } if(not p[0]){ y=0; } else if (not p[1]){ y =1; } else{ y=2; } p[x]= true; return y; } void Release(y: printerNo){ p[y] = False; x.signal }   使用方式：\n  共享變數宣告：\nPA: Allocator\n  Pi(i=processId)\n  程式如下\n1 2 3 4 5 6 7  pNo: printerNo; pNo=PA.Acquire(i); //使用pno號之列表機  PA.Realse(pno);   範例四 使用Monitor定義Semaphore\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  type semaphore = Monitor; var value : int; //號誌值 var x : condition; procedure entry wait(){ begin value = value -1; if (value \u0026lt;0) then x.wait; end } procedure entry Signal(){ begin value = value+1; x.signal; end }   Monitor的種類(3種)   區分角度(緣由)\n假設Process A目前卡在 x condition 變數之 waiting Queue(因為 Q 先前執行了 X.wait目前，**Process P is active in the **)\n  幹他媽的，這邊也拖太久了，我受不了，我想先去看記憶體管理 2023/3/23 Chapter 7 Memory Management 本章的考試重點是圖，有圖的都很重要\n Binding 及其時機點\nDynamic Binding\nDynamic Loading, Dynamic Linking\nContiguous Memory Allocation(Firstt/Best/Worst Fit)☆☆\nExternal Fragmentation, Internal Fragmentation☆☆☆☆☆\n解決外部碎裂方法\n Compaction☆☆\nPage\n Page Memory Management☆☆☆☆☆\n Schema\nPage Table 製作(3個)\n相關計算\nPage Table Size 太大之解決(3個)\n Segment Memory Management☆☆\nPaged Segment Memory Management [恐龍本已移除]\n Binding 定義：決定程式/process執行的起始位址，此一動作稱之為Binding\n時機點：\n   Compiling Time：由Compiler作Binding\n  Loading Time 或 Linking Loading Time：由Linking Loader 或 Linkage Editor作\n\u0026laquo;以上兩者都叫Static Binding\u0026raquo;\n  Execution Time：由OS動態決定，也叫Dynamic Binding\n     Compiler作Binding\n  產生之Object Code叫做Absolute object code(絕對式目的碼)\neg:\n  後面的Loader叫作Absolute Loader主要是作Allocation與Loading only\n  缺點：Process若要改變起始位址，則必須re-compiling非常不便\n  Note：通常用於.COM(命令檔)\n    Loading Time由 Linking Loader 作Binding\n  Compiler所產生出的Object Code叫作Relocatable Object Code(可重定位之目的碼)\n    何謂Relocation修正？\n 當成是執行起始位址改變，某些Object code內容必須隨之修正，將來才能正確執行。\n例：採用直接定址(Direct Addressing Mode)指令，假設今天起始位址為0000，變數儲存於2000的位址。今起始位址改為1000後，變數儲存的位址需要有相應的改動，這個改動值就是寫在Relocation修正資訊\n   何謂Linking修正？\n   解決External Symbol reference(外部符號參考)之修正\n例：外部符號：副程式名稱\n外部變數(extern)、Library, etc\n Linking Loader主要4個工作\n Allocation：依照目的碼之大小，向OS要求分配起始位址 Loading：obj code 載入到Memory Linking：依Compiler所交辦之Linking修正資訊，執行Linking修正，將Jump ????改為 Jump 8000 Relocation：作重定位修正  優點：程式起始位址若要改變，則只需重新Relocation, Linking即可，無須re-compiling\n缺點：\n  程式重新執行，若Modules數多，則re-linking(外部符號參考修正)很花時間。\n  Process執行期間，不可更改起始位址\nNote：凡是Static Binding皆無法更改\n  Linkage Editor的主要工作\n  Dynamic Binding 定義：決定Process起始位址之工作，推遲至執行時期(Execution Time)才動態執行，即Process在執行期間，可任意變更起始位址，且Process仍能正確執行。\n需要Hardware額外支持\n  Logical Address：generated by CPU logical代表以使用者觀點來看\n  Physical Address：實際去physical memory(ie. RAM存取之位址)physical代表以硬體觀點來看 \n   logical address = physical address = \u0026gt; static binding\nlogical address ≠ Physical address = \u0026gt; Dynamic binding, Page, segment, Paged segment。會有「logical address轉成physical address之運作」，且此運作交由Hardware負責\n   優點：\n Process之起始位址可於execution time 任意更動且能正確執行，有助於OS Memory Management之彈性度。eg. Compaction實施、process swapout後再swap in，不一定要相同起始位址\\  缺點：\n 需要Hardware額外支持 Process執行時間較久、效益較差  Dynamic Loading 定義：也叫Load-on-Call，在execution time，若module真正被呼叫到且不在memory中，此時loader才將它載入到memory中。當一個程序只有當它真正被呼叫時才載入到記憶體之中。\n目的：節省Memory space\n優點：不須要OS之額外支持\n缺點：Process執行時間較久\nNote：早期使用overlay的技巧，是programmer的責任，OS沒啥責任。近代則是OS提供Virtual Memory來處理\nDynamic Linking 定義：在Execution Time，若Module被呼叫到，才將之載入，並且與其他Modules進行Linking修正(外部符號參考之解決)，適用在Library Linking eg Dynamic Linking Library(DLL)\n目的：節省不必要之Linking Time，需要OS額外支持\nContiguous (連續性) Memory Allocation 也叫Dynamic Variable Partitions Memoy Management 動態變動分區記憶體管理。\nOS必須配置Process一個連續的Free Memory Space\nPartition：Process所占用的Memory Space\nPartition數目＝Process數目＝Multiprogramming Degree，由於不同時期，系統內Process數目不固定\n因此Parition數目不固定(Dynamic)\n由於各Process Size不盡相同，因此各Partition大小也就不一定相同(Variable)\nMemory中會有一些Free Memory Space(or Block)，叫做Hole，通常OS會用LinkedList的概念，來管理這些Holes，叫做AV-List(Available List 可用空間串列)\n配置方法\n  First-Fit Best-Fit Worst-Fit    First-Fit  定義：從AV-List頭開始找起，直到找到第一個Hole，其hole size ≧　process size為止，即可配置或找完整條串列，或找完整條串列，無依夠大符合為止\nBest-Fit  定義：必須檢查AV-List中所有Holes找出一個hole，其hole size≧process size，且hole size減去process size後差值最小的hole，予以配置\nBest-Fit  定義：必須檢查AV-List中所有Holes找出一個hole，其hole size≧process size，且hole size減去process size後差值最大的hole，予以配置\n例題一\n若Process大小=90K\n則\n First-Fit會配置\u0026quot;A\u0026quot;Block之90K給Process，剩下\u0026quot;210\u0026quot;K之Hole Best-Fit會配置\u0026quot;B\u0026quot;Block之90K給Process，剩下\u0026quot;10\u0026quot;K之Hole Worst-Fit會配置\u0026quot;C\u0026quot;Block之90K給Process，剩下410K之Hole  例題二\nFirst, Best,Worst Fit，哪個最好 in memory Utilization?\nFirst-Fit\n最後會剩420K的無法配置\nBest-Fit\n皆可配置\n比較表     時間效率 空間利用度     First-Fit(勝) 最佳 佳   Best-Fit 差 最佳   Worst-Fit 差 差    上述Contiguous Memory Allocation方法均遭遇一個共通問題\u0026quot;External Fragmentation\u0026quot; External Fragmentation\n定義：在Contiguous Allocation要求，目前AV-List中任何一個hole Size均小於process size，但這些holes size 加總卻≧process size，然而，因為這些holes 並不連續，因此仍無法配置給此process，造成空間閒置不用，memory utilization低之問題\n範例：\n若Process大小為220K，而這些hole size加總=250K\u0026gt;220K，但這些hole不連續，仍無法配置，[恐]一般而言，每配置N大小，平均會有0.5N的外碎，所以外碎的比例為=1/3，是個嚴重的問題\n另一個名詞Internal Fragmentation(內部碎裂) 定義：配置給Process之space超過process size，兩者之差值空間，此process使用不到且其他processes亦無法使用，此一浪費空間，稱之為內部碎裂\n解決External Fragmentation 方法一：使用**Compaction(聚集)**技術\n作法：移動執行中的process，使得原本非連續的holes，得以聚集形成一個夠大的連續的Free Memory Space\n例子：　困難處：\n  不易制定最佳的Compaction策略\n  Processes必須是Dynamic Binding才可於execution time移動\n  方法二：使用Page Memory Management\n方法三：Multiple Base/Limit Register方法\n這個方法其實不行解決，只能降低。將Process拆成Code Section與Data Section兩部分，分開配置連續的hole，以降低外部碎裂發生的機率。因此，每個Process需要2套 Base/Limit Registers，分別記Code Sec及Data Sec 的起始位址及大小\nPage(分頁) memory Management   Physical Memory (i,e RAM)視為一組Frame(頁框)之集合，且各Frame Size相同，Note：Frame Size是HW決定，OS只是配合，Paging是採Physical ViewPoint。\n  Logical Memory (即User Process大小)視為一組Page(頁面)之集合，且Page Size=Frame Size\n  RAM=400KB=40個Frames\nFrames=10KB\n配置方式：OS採非連續性配置原則，即若Process大小=n個Pages，則OS只需在Physical memory 找出n個Free Frames(不一定要連續)，即可配給此process\nOS會替每個Process建立一個Page Table(分頁表)，紀錄各個Page置於哪個Frame 之Frame No\nNote：Page Table is stoted in PCB\n若Process大小=n個Pages，則它的Page Table就有n個entry(格子)\n圖示：\nLogical Address 轉 Physical Address 過程By MMU(Hardware) Steps [例：假設Page size=10]\n LogicalAddress初始是單一量，自動拆解成：  ​\t其中p代表PageNo，d代表Page offset(偏移量)\n$$ 單一量位址 \\div PageSize = 商數(p)\u0026hellip;餘數(d) $$\n 依P查詢Page Table, 取得該Page的FrameNo(頁框號碼)，令為f\n  f與d合成即為Physical Address\n或 f * PageSize + d = Physical Address\neg.\n   p d     3 2    依P=3查表，它的Frame No= F7, 因此\n   f d     7 2    =Physical Address\n=7*10+2=72\n  優缺點比較 優點：  沒有外部碎裂 可支援Memory Sharing及Memory Protection之實施 可支持Dynamic Loading, Dynamic Linking及Virtual Memory之實現  Memory Sharing(共享)\n若多個Processes彼此具有共通的Read-only Code/Data Pages，則我們可以藉由process各自的Page Table，將共通Pages映射到同一個頁框，如此可以節省memory space\nMemory Protection(保護)\n在Page Table中多加一個欄位：\nProtection Bit 值為\n R：表此Page只能Read-Only\nW：表此Page Read/write都可以\n 缺點：   有Internal Fragmentation，因為Process大小不見得是PageSize之整數倍數。eg. PageSize=10KB，Process大小=32KB，因此需配置4個Frames，因此內碎=4*10-32=8KB\nNote：若PageSize愈大，則內碎越嚴重\n  需要額外Hardware支援，例：Page Table之製作、Logical Address轉physical address By MMU\n  effective memory access time 較長因為有Logical Address轉physical address 的時間，這邊的較長是相對於Contiguous來看\n  Page Table之製作(保存) [方法一] 使用Register保存，Page Table中每個Entry內容(frame No)\n優點：存取page table 時，無須memory access，因為速度最快\n缺點：Register數量有限，不適用大型的Page Table(或大型Process)\n[方法二] 使用Memory保存分頁表，且用一個Register:PTBR(Page Table Base Register)紀錄它在memory中之位址，及PTLR(Page Table Length Register)紀錄Table大小\n優點：適用於大型Page Table\n缺點：須額外多一次Memory Access來存取Page Table，因此速度很慢\n[方法三] 最普遍的方法，使用TLB(Translation-Lookaside Buffer) Register(或叫Associative Registers)保存Page Table中經常被存取之Page No及FrameNo，且完整的age Table存於memory中\n使用TLB之effective Memory Access Time =\n$$ effective Memory Access Time=P \\times (TLB time+ Memory Access Time)+ (1-P) * (TLB Time +2*Memory Access Time) \\\nwhere P is TLB Hit Ration $$\n Translation Lookaside Buffer (TLB) 是一種硬體快取，用於加速虛擬記憶體的地址轉換過程。當程式存取一個虛擬記憶體頁面時，處理器需要將虛擬地址轉換成實體地址，才能夠從記憶體中取得資料。這個轉換過程需要查詢一個由作業系統維護的稱為頁表的資料結構，以獲取虛擬地址和實體地址的對應關係。但是，這個查詢過程需要訪問主記憶體，因此非常耗時。為了加速這個過程，處理器使用 TLB 快取了最近的地址轉換資料，以便在下一次存取相同虛擬頁面時可以直接從快取中取得資料，而不必再次查詢頁表。\nTLB 是一種關鍵的虛擬記憶體子系統，因為地址轉換是虛擬記憶體系統中最常見、最複雜和最耗時的操作之一。TLB 的效能直接影響了系統的整體效能，因此設計高效的 TLB 是非常重要的。\n 範例：\nRegister access Time : 0 ns(ignored)\nMemory Access Time：200ns\nTLB Time：100ns\nTLB Hit Ration：90%\n求Effective Memory Access Time if Page Table is Stored using\n Register Memory TLB  Ans.\n 200ns(只訪問一次記憶體) 2*200 =400 ns 0.9 * (100+200) + 0.1 * (100+2*200) = 100+200+0.1*200=320ns  Paging相關計算 [型一] 使用TLB之effective Memory Access Time [型二] Logical Address 與 Physical Address Bit 數目計算 例一：\n  pageSize=1kb;\n  Process最大有8個Pages\n  Physical Memory 有32個Frames\n  求\n Logical Address length physical Address length  Ans.\n  Logical address\n   p d     13 10    因為pageSize=1kb= 2 10Bytes ，所以d佔10bits。又因為process最多8個process最多8(23\u0026gt;)個Pages。所以P佔3bits，因此3+10 = 13bits\n  physical address\n   f d     15bits     因為physical memory有32(25)個Frames，所以f佔5bits，所以5+10= 15bits\n  [型三] PageTable size相關計算 1bit = 0 or 1\n1 KB = 1024 bytes\n1 byte= 8 bits\n1MB = 1024 KB\n例一\n Page size=8KB Process 大小 = 2MB Page Table entry 佔4bytes  求此process的pageTable size?\nans\nprocess大小= 2MB/8KB = 221/213=28個Pages，這麼大\n因此 Page Table 有2 8 entry，因此size = 28*4bytes = 1KB\n例二\n logical address = 32 bits page size = 16kb page table entry 佔 4 bytes  求MAX page table size?\nans\n因為Page size = 16kb = 2 14 bytes，所以d佔14bites，所以p佔32-14= 18bits\nprocess 最大可以有218Pages，所以MAX. page Table size = 2 18 個entry * 4bytes= 1MB\nEx. 承上 若Logical Adress = 48 bits呢?\nAns:\np 佔 48-14 = 34 bits\n因此MAX page table size = 234 * 4 bytes = 64GB\nNote：page table size 太大是個議題！！\n例三\n Page Size = 16 KB Page Table entry 佔 4 bytes MAX Page Table Size 恰為one Page 求 Logical Address length  因為Page size = 16KB = 2 14 bytes，所以d佔14 bits，因為MAX Page Table Size = One Page = 16KB。因為MAX Page Table = 16KB/ 4 bytes = 212entry，因此P佔12bits，因此12+14= 26 bits\n[型四] Page Table Size 太大之解法的相關計算 (考試必考) Page Table Size 太大 之解決方案   ☆☆☆☆☆MultiLevel Paging(Hierarchical Paging)(Paging the Page Table)(Forward Mapping)\n  Hashing Page Table\n  ☆☆☆☆☆Inverted Page Table\n  Multilevels Paging 考的頻率較高\n定義：並不是把分頁表縮小，而是縮減抓進來的分頁表的內容，只抓有需要的區間，不需要將整個Page Table 載入進memory中，而是載入部分需要的內容就好，因此提出多層次的Paging的做法，例：以2-level paging 為例，當然你想要分3, 4 ,5 層都可以，你爽就好\n Level 1 Page Table ：有2x個entry，每個entry 紀錄某個Level-2 Page Table Level 2 Page Table ：有2y個entry，每個entry紀錄Frame No.   Process在執行時只須1個Level 1- Page Table以及某1個 Level 2 - Page Table在memory中即可，因此可大幅降低Pable Table占用之Memory Space  缺點：effective Memory Access Time更久，因為須多次Memory Access存取Page Table\n例如\nTwo-Level Paging -\u0026gt; 整個過程須三次MA\nThree-Level Paging - \u0026gt; 整個過程須四次MA\n相關計算：\n例一：\n TLB Time：100ns TLB Hit Ratio：80% Memory Access(MA) Time ：200ns Two-Level Paging 採用  求有效Memory Access Time\nAns.\n0.8 * (100ns + 200ms) +0.2 * (100ns+3*200ns)\n例二：\n Logical Address= 32 bits Page Size = 4KB Page Table Entry 佔 4 bytes  在以下幾種情下，求Max. Page Table Size\n Single-level-paging Two-level paging 且Level-1 Paging與Level 2 Paging Bit數相等  Ans.\n    因為Level-1及Level-2 Paging 各佔 20/2 = 10bits，所以\n1個level-1 Page Table MAX Size = 210*4bytes = 4 KB,\n1個Level-2 Page Table MAX Size = 210*4bytes=4KB\n因此頂多4KB+4KB= 8KB in the memory\n  例三：\n Logical Address = 65 bits Page Size = 16kb Page Table entry 佔 4 bytes; 任一 Level Paging之MAX Page Table Size頂多為One Page  則至少分幾層 ?-level Paging\nAns.\n因為任一level之MAX Page table Size = One Page = 16KB，\n所以任一Level之Page Table 最多有 16KB / 4 bytes =span 212個Entry\n所以任意Level Paging Bits數 ≦ 12bits\n50 / 12 = 5 Level\nHashing Page Table 考的機會較少\n定義：利用Hashing 技巧，將Page Table 視為Hash Table，具有相同的Hasing Address的Page No及他的Frame No資訊，會置入於同一個Entry(Bucket)中，且已Link List(Chain)串接，圖示如下：\n缺點：使用Linear Search 在Link List中找符合的Page No，較為耗時\n例題：\n H(x)= X % 53 Page Table Entry 佔 4 bytes 求Hashing Page Table Size  Ans：有53個entry ，所以53 * 4 = 212 bytes\nInverted Page Table 反轉分頁表，考的頻率較高\n定義：大部分的解決方案都是以Process為對象，這個方法改為以記憶體為對象。是以Physical Memory為記錄對象，並非以Process為對象，即若有N個Frames，則此表就有n個entry，每個entry紀錄 \u0026lt;Process Id, Page No\u0026gt;，配對資訊，代表此Frame存放的是哪個Process的哪個Page，如此一來，整個系統只有一份表格\n圖示：\n缺點：\n  必須使用\u0026lt;Process Id, Page No\u0026gt; 資訊，一一比對查詢，此舉甚為耗時\n  喪失了Memory Sharaing之好處，即無法支持其實現，因為Process Id不一樣\n  例題：\n Page Size = 8 KB Physical Memory = 16 GB Page Table entry 佔 4 bytes 求Inverted Page Table 之 size?  Ans.\nphysical memory 有 16 GB/ 8 KB= 234 / 213 = 2 21個frames，所以Inverted page table 有221個entry，所以size = 221 4 bytes= 8MB*\nSegment Memory Management   Physical Memory 視為一個夠大的連續可用空間\n  Logical memory(process)視為一組Segment(段)之集合，且各段大小不一定相同，段的觀點是採用Logical viewpoint，與user對memory之看法一致\n例：code segment, Data segment, stack segment etc\u0026hellip;\n  配置原則：\n  段與段之間可以是非連續性配置\n  但對每一個段而言，必須占用連續的(Sapce)空間\n    Os會替每個Process建立Segment Table分段表，紀錄每個段的Limit(大小)即Base(起始位址)\n  圖示：\n  Logical Address轉physical Address\n  Logical Address initially是兩個量，[ s | d ]其中s是段編號，d是段的offset\n  依S查分段表，取得它的limit及Base\n  **Check d \u0026lt; limit ?**若成立，代表合法，所以physical address = Base + d，若不成立，則代表非法存取\n    例題：\n分段表如下，求下列Logical Addresss,d 之physical Address?\n    Limit Base     0 100 4200   1 500 80   2 830 7300   3 940 1000     (0,90) (1,380) (2,900) (3,940)  Ans.\n  因為90\u0026lt;100，所以合法。4200+90 = 4290\n  因為380\u0026lt; 500，所以合法。80+380 = 460\n  因為900 \u0026gt; 830，不合法。非法存取\n  因為940 不小於940，不合法。非法存取\n  優點\n  沒有內部碎裂\n  可支持Memory Sharing及Memory protection，且比Page容易實施(因為段是採用Logical viewpoint)\neg. 以Protection為例\n  可支持Dynamic Loading , Linking 及 Vitual Memory 實施\n    缺點\n 有外部碎裂 必須要有額外硬體支持，例如分段表的保存、logical address轉physical address Effective memory access time 更久    Page與Segment比較表    Page Segment     各Page Size相同 各段大小不一定相同   用physical viewpoint logical viewpoint   無外部碎裂 有外部碎裂   有內部碎裂 無內部碎裂   Memory protection及Sharing較難實施 較容易實施   無須Check page offset \u0026lt; page size 須 check 段 offset \u0026lt; 段大小   Logical address initially 單一量 兩個量\u0026lt;s,d\u0026gt;   Page Table紀錄Frame No 分段表紀錄段的Limit 及Base    Paged Segment Memory Management [恐]現已移除，當作補充\n觀念：process \u0026mdash;\u0026gt; 段組成 \u0026mdash;\u0026gt; Page 組成。段在分頁(Process由一堆段構成，段再由頁面構成)\n動機：希望保有分段採logical viewpoint的好處，且又要解決外部碎裂，所以段再分頁\n圖示：\n小結 四大記憶體管理方式，\n    Contiguous Allocation Page(主角，考最多) Segment Paged Segment     外部碎裂 有 無 有 無   內部碎裂 無 有 無 有    047\nChapter 8 Virtula Memory (虛擬記憶體)  [基本]主要目的(優點)以及附帶好處\n[基本]Demand Paging技術\n☆☆☆Page fault 即其處理步驟\n☆☆☆☆☆Effective Memory Access time計算 in virtual memory\n影響Page fault ration之因素\n☆☆☆☆☆Page replacement 及其法則、計算題、及相關名詞(Modification Bit, Belady Anomaly, stack property)\n☆Frame數分配多寡之影響\n☆☆☆☆☆Thrashing現象及其解法\n☆☆Page Size 大小之影響\n☆☆☆Program structure 之影響\n☆☆☆☆Copy-on-write之技術 (3種Fork())\n☆TLB Reach\n 主要目的(優點)以及附帶好處 優點：允許Process size 在超過physical memory 可用空間大小情況下，process仍能進行，是OS的責任(負擔)，programmerr沒什麼負擔\n附帶好處：\n Memory Utilization較高 盡可能地的提升Multiprogramming Degree，增高CPU Utilization，Note：Thrasing除外 I/O Transfer(傳輸) Time較小 Note：I/O次數、Total Time增加 programmer只須專心寫好程式即可，毋須煩惱程式過大無法執行之問題，這是OS的責任，所以Programmer也不須要，過時的overlay技術  實現Virtual Memory的技術之一　Demand Paging(需求分頁) 是架構在Page Memory Management 基礎上。差別在於採用Lazy Swapper觀念，即Process在執行之初，毋須事先載入全部的Page，而是指載入部分的Pages(甚至不載入任何Page，Pure demand paging)，Process即可執行。\n 若Process執行時，它所需要的Pages皆在Memory中，則Process本身一切無誤地執行 若Process執行時，企圖存取不在memory中的Pages，則稱為發生Page Fault，OS必須處理，將Process所需的lost Page(missed page)載入到Memory 中 from disk，process才可執行  在Page Table中須引進一個欄位：Valid/ Invalid Bit ，用以區分此page是否在memory當中\nV：表在memory\nI：表不在memory\nNote：此Bit是由OS set and modify。MMU reference\n圖示：\nPage fault 之處理 Steps  MMU會發出一個Address error interrupt 通知OS OS收到中斷後，必須要暫停目前Process之執行且保存其Status info OS檢查Process之存取位址是否合法。  若非法，則終止此Process 若合法，則SO判定是由Page Fault所引起   OS先去Memory中檢查有無Free的Frame  若沒有，則OS必須執行Page Replacement工作，以空出一個Free Frame 有的話就把頁面抓近來   OS再到Disk中找出Lost Page所在位置，啟動I/O運作，將Lost Page 載入到Free Frame中 然後，OS修改Page Table紀錄此Page的Frame No，以及將Invailaid 值改為Valid值 OS 恢復中斷之前Process的執行  No.\n p8-5簡單一點 p8-7 更多一些stpes  Effective Memory Access Time計算 in Virtual Memory 公式：\n$$ (1-p) \\times \\begin{matrix}\\text{memory} \\ \\text{Access} \\\\text{Time}\\end{matrix} + P \\times \\begin{matrix}\\text{Page Fault} \\ \\text{Process Time} \\\\end{matrix} $$\nProcess Fault Process Time的時間超級久！\nwhere P is Page Fault Ration\n範例1.\n Memory Access Time: 200ns Page Fault process time: 5ms   若Page Fault ration = 10 %，求effective memory access time  ans. (1-0.1) * 200ns + 0.1 *5ms = 180ns + 0.1 * 5 % 10 6ns = 500180ns\n           m milli 毫 10-3   u micro 微 10-6   n nano 奈 10-9    範例2. `\n若希望effective memory access time不超過2 ms，則Page fault ration應為?\nAns.\n(1-p) * 200ms + p * 5ms ≦ 2ms \n= p ≒ 2/5\n小結 欲降低effective memory Access Time提升VM效益，關鍵做法在於降低Page Fault Ration\n[049]\n影響Page Fault ration因素   Page Replacement 法則之選擇 Frame 數目分配多寡之影響 Page Size 影響 Program Structure 之影響   Page Replacement(頁面替換) 定義：當Page Fault發生且Memory中無Free frame時，OS必須執行此工作，即選一個Victim Page (or the replaced page)將它Swap out到Disk保存，以空出一個Free Frame\n圖示：\n會額外多出一個Disk I/O運作，所以Page falut process time更久\n如何降低Swap out此一額外I/O次數？\n作法：在Page Table 再引進一個欄位，Modification Bit 或 Dirty Bit，用以表示Page上次載入後，到現在，內容是否被修改過\n 0：沒有\n１：有\n 引進這件事情後，OS可檢查Victim page的modification Bit值，若為0，則無需Swap it out，因此可降低I/O次數，反之，則需Swap it out \nNote：此Bit由MMU set(0\u0026mdash;\u0026gt;1)，OS Reference 及 Reset (1 \u0026mdash;\u0026gt; 0)\n例題：\n Page Fault process time：8ms  ​\tif 有可用頁框，或 the replaced page is not modified\n Page fault process tiem if victim page is modified : 20ms memory access time：100ns victim page is modified 之機率 ：70%  求Page fault ration ≦ ? if effective memory access time ≦ 200ns\nAns.\n(1-p) * 100ns + p * page fault process time(0.3 * 8ms + 0.7 * 20ms)=16.4ms\n= (1-p * 100ns + p * 16.4 ms ≦ 200ns )\n= 100 - 100p + P* 16.4 * 10 6 ≦　200 p ≦ 1/ 163999\n例題：\n  1次 I/O time ：10 ms\n  page Fault Ration：10 %\n  Victim page modified ration：60%\n  memory access time：200ns\n  求Effective memory access time\nAns .\n0.9 * 200ns + 0.1 *(page fault process time)(0.4 * 10 ms + 0.6 * 10ms *2 兩次I/O)\nreplacement policy 有兩種\n Local replacement policy Global replacement policy    Local：OS只能從發生Page Fault 的process 之Pages中，去挑victim page ，不可以從其他processes之pages(in memory)挑victim page\n缺點：\n Memory utilization較差  優點：\n 可限縮Thrashing 的範圍    Global：OS可從其他processes挑victim page(目前都是採此方案) 缺點：\n 不能限縮Thrasing的範圍  優點：\n Memory Utilization較佳    Page replacement法則介紹  FIFO OPT LRU LRUU近似  Additional Reference Bitws Usage Second chance Enhanced Second Chance   LFU與MFU Page Buffering algo (偏向機制)  FIFO 法則 定義：最早載入(Loading Time最小)的Page，作為Victim page\n[049 00:45:00]\n範例：給予3個Frames, Initially, they are all empty(或 pure demand paging)有下列的Page Reference String ，求Page Fault次數\n頁面編號：7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1\n或　Page Size = 100，下列存取位址：731, 008, 117, 258, 039 , 331, 047 \u0026hellip;\n或　Logical address= 12 bits, Page No佔3 bits，存取位址如下：7AF, 8BD, 259, 047, EAF, D72\nAns.\n分析：\n  Simple , easy, implementation\n  效能不是很好，Page Fault ration相當高\nNote：Page replacement法則中，只有最佳，沒有最差\n  可能有Belady Anormaly(異常現象)\n  Belady Anormaly 定義：process 分配到的頁框數增加，其Page Fault ration卻不降反升之異常現象\n例子：\n頁面編號：1,2,3,4,1,2,5,1,2,3,4,5\n 3個頁框  ​\t 4個頁框\n  Stack Property 定義：：ｎ個Frames所包含的Page Set保證是(n+1)個Frames \u0026hellip; 之子集合(subset)，此性質稱之\n性質：若具有 stack property，保證不會有Belady Anormaly，只有OPT與LRU法則，具有stack property，所以他們不會發生belady anomaly\nOPT (Optional 最佳)法則 定義：選擇將來(未來)長期不會用到的Page為Victim Page\n範例：\n分析：\n  Page Fault ration最低，因此最佳\n  不會有Belady AnomalyS\n  無法被實作(因為 needs the future knowledge)，通常做為理論上研究比較對象之用\n  LRU(Least Recently Used)法則 定義：選擇過去不常使用的Page作為Victim Page，即相當於是OPT reverse (依歷史info 做決定的OPT)即挑選the last reference time 最小的page\n分析：\n Page fault ration可以接受 不會發生Belady Anomaly LRU的製作，須要大量Hardware支持，因此Cost很高，因此才有LRU近  LRU的製作方法 方法一：Counter法 步驟\n 每發生memory Acess，Counter值++ Copy Counter值到Access Page的\u0026quot;the last reference time\u0026quot;欄位，將來OS要選LRU Page時，就挑the last reference time最小的Page   方法二：Stack 法　 此為Stack property之由來\n定義：\n 最後一次存取之Page 必置於Stack Top端 Stack 之 Botton(底端)，即為LRU Page Stack大小=Frame數目  釋例：\nLRU近似法則 主要是以Reference Bit(參考位元)為基礎，此作法較為簡單\n0：此Page不曾被參考過\n1：此Page曾被參考過\n[050]\nAdditional Reference Bits usage 作法：每個Page 有一個欄位(or Register) ，例如：8 bits\n當發生Memory Access，該被Access Page之Ref Bit 會 Set為1\n系統每隔一段時間會將各page的register值右移一位(空出最高位元，最右位元捨去)並將各Page之Ref Bit值Copy到Register之最高位元，且Reset 各Page 之ref bit 為0，將來要排victim page時，就挑Register最小之Page，若多個Page具相同值，則以FIFO為準\n圖示：\n犧牲頁面會挑Page2，因為暫存器的值最小\nSecond Chance 二次機會法則\n定義：以FIFO為基礎，搭配Reference Bit使用，挑victim page之Steps如下\n  先以FIFO order 挑出一個Page\n  檢查此page的Reference Bit值\nCase 1：若為0，則它即Victim Page\nCase 2：若為1，則給它機會，不讓它當犧牲頁面。但Reset its Reference Bit值為0。並將它的Loading Time(載入時間)更改為現在，因此FIFO指針往下指。接回Step1\n  例：\n挑犧牲頁面\n例：3個Frames\n頁面參考：1,2,3,4,2,5,2,6,1,2，求Second Change\nNote：當所有Pages之Reference Bit皆相同，則退化成FIFO。也叫Clock Algorithm\nEnhanced Second Chance 加強型二次機會\n定義：以\u0026lt;Reference Bit, Modification Bit\u0026gt;配對值，作為挑選Victim Page之依據，值最小之Page，作為Victim。若有多個Pages具相同值，則以FIFO為準\n   值 \u0026lt;R bit, M bit\u0026gt;     第一小 \u0026lt;0,0\u0026gt;   第二小 \u0026lt;0,1\u0026gt;   第三小 \u0026lt;1,0\u0026gt;   第四小 \u0026lt;1,1\u0026gt;    LFU與MFU法則 定義：以Page的累積參考總次數作為挑Victim Page之依據，分為兩種：\n  LFU(Least Frequently Used)\n次數最小的Page為Victim\n  MFU(Most Frequently Used)\n次數最大的page 為Vimtim\n  若多個Pages具相同值，也是FIFO為準\n分析：計算題FIFO,OPT,LRU最常考。\n Page Fault Ration相當高　 有Belady Anomoaly 製作需大量Hardware支持，因此Cost很高  \n例：\n   Page Loading　TIme The Last reference Time R bit M Bit 參考次數     Page1 493 800 0 0 410   Page2 172 700 1 1 235   Page3 333 430 0 1 147   Page4 584 621 1 0 875   Page5 256 564 0 1 432    在下列情況中，victim page為\n  FIFO：Page2\n  LRU：Page3\n  Second Chance：Page5\n  Enhanced Second Chance：Page1\n  LFU：Page3\n  MFU：Page4\n  Page Buffering機制 緣由：當挑出Victim Page之後，且它被Modified過，步驟如下\n1. 則把Victim PageSwap Out 到 Disk\n2. 載入Lost Page\n3. Process resume execution\n\u0026ndash;\u0026gt; IO太多，Process恢復執行的時間點拖太久，想要改善\n方法一 OS 會 Keeps一個 Free Frames Pool(OS的私房錢，不是配置給Process的)\n圖示：\n流程：\nOS挑完犧牲頁面(Modified)\n步驟更改如下\n1. OS從Free Frame pool中，取出一個Free Frame，供Lost Page使用，讓它先載入\n2. 載入完後，Process恢復執行\n3. Process Resume execution\nOS可稍後將Victim Page 寫回Disk，空出Frame再還給OS，加入Free Frame Pool中\n方法二 OS會Keep一條Modification List，記錄所有被Modified過的Page info(即Modification Bit值=1之Pages)，OS會等Paging I/O Device有空時，將此List中某些Pages寫回Disk，同時自此List中，移走這些Pages，Reset their Modification Bit值為0。如此可增加Victim pages是unmodified 之機率，這樣直接把Lost Page抓進來就好，這樣Process有較高機會快速resume exec\n[051 00:00:00 ~00:40:00]\n方法三 希望連一次I/O都不要有。是以方法一為基礎，差別在於針對Free Frames Pool(私房錢)中的每個Frame，紀錄放的是哪個Process的哪個Page(\u0026lt;process ID, Page No\u0026gt;)，這些Page內容必定是最新的\n流程：\n OS選完Victim Page(modified) OS去Free Frames Pool中尋找有無Lost Page存在。若存在，代表其內容為最新的，則將此Free Frame加入Resident Frames Pool中，Process即可Resume exec，連一次I/O都不用！，OS寫回Victim Page後，再加入(還給)Free Frames Pool，若不存在，則依方法一步驟處理  . .\n.\n這邊看不太懂，先Pass\n.\n.\n.\nFrame 數目分配多寡之影響  一般而言Process分配到的頁框數增加，其Page Fault Ration理應下降 OS在分配Process頁框數時，必須滿足最少及最多數目之限制，這兩個限制均由Hardware決定的，非OS  最多數目限制即是Physical Memory Size(頁框總數)\n最少數目限制即是CPU完成機器指令執行過程中，最多的可能Memory存取次數，否則機器指令可能永遠無法完成\n例：\n[051] 01:10:00 看不太懂，需要計組知識\n 假設指令不跨頁面 運算元(memory變數)是採用Direct Addressing   則最多可能需要3次Memory Access(M.A.)，因此os至少要分給process ≧3個Frames\nThrashing現象 ☆☆☆☆☆ Thrashing meaning 徒勞無功\n定義：若Process分配到的頁框數不足時，則此Process會經常Page Fault，且OS要做Page Replacement，若OS採用Global replacement policy，所以OS可能挑其他Process之Page，而這也會造成其他Process Page Fault，它們也會去搶奪別的Process之Frame來用，如此一來，幾乎所有的Processes皆Page Fault，大家皆在等待Paging I/O Device 之I/O 運作(swap out/in)完成，CPU Utilization下降，系統會企圖調高Multiprogramming degree，引入更多Process進入執行，但是Memory本來就不夠，Process也立刻Page Fault，系統又調高Multiprogramming Degree，如此循環下去，此時系統呈現\n CPU Utilization急速下降 Paging I/O Device 異常忙碌 Processes花在Page Fault Processing Time(就是閒置時間啦)遠大於正常執行時間，此一現象稱為Thrashing  解決/預防 Thrashing 方法一 減少 Multiprogramming Degree \n例如挑選一些lower-priority 或完成度低 Process swap-out\n方法二 利用Page Fault Frequency Control 機制，來防止/預防Thrashimg發生\n作法：OS會去制定process Page Fault Ration之合理的上限與下限值\nOS若發現Process的Page Fault ration\n 高於上限，則OS應增加額外Frame數目給此Process，降低其Ratio，回到合理區間 低於下限，則OS自此Process取走多餘的Frame，分給其他有需要之Processes  若OS能夠控制所有processes之Page Fault ratio 在合理區間，則理當不會有Thrashing\n方法三\n運用Working Set Model技術預估Process在不同執行時期所需之頁框數，並依此分配各Process足夠的Frame數目，以防止Thrashing\nWorking Set Model 技術 是架在\u0026quot;Locality Mode\u0026quot;之理論基礎上\n定義：Process執行時，對於所存取的Memory Area，並非是均勻的，而是具有某種局部/集中區域存取之特性，一般分為兩種Locality\n Temporal時間 Locality Spatial空間 Locality  Temporal Locality 目前所存取的區域，過不久又會再度被存取(或此區域經常被存取)\n例：For Loop (while, for , repeat \u0026hellip;), Subroutine副程式(function, pure code), Counter, Stack\nSpatial Locality 定義：目前所存取之區域，其鄰近的區域，也即有可能被存取\n例：Array, Sequential Code Execution, Common Data area, Linear Search, Vector operat\n[052]\n只要Program中用到的指令, Data Structures, algo 符合 Locality Model 則為Good(所以 Page Fault Ratio 度會下降) 若違反，則為Bad\n例：BAD Samples\nAns：Hashing(分散在各個記憶體頁面，不符空間局部性), Binary Search(跳來跳去), LinkedList(散落在不同頁面), goto Jump指令(跳來跳去), Indirect Addressing mode(間接定址模式)\nWorking Set Model相關術語解析：\n Working Set window：記為△表示以△次　Pages reference 作為統計Working Set之依據 Working Set:  在△次Page參考中，所參考到的不同Pages之集合 Working Set Size(WSS)：working Set之 元素(Page)個數，代表Process 此時所需之頁框數  [052] 00:13:00\n例題：到時候再來補\nPage Size 之影響 若Page Size越小，則\n  Page Fault ratio：上升 Page Table Size ：變數 I/O次數(total Time)：增加 內部碎裂：輕微 I/O Transfer Time：變小 Locality：越佳   趨勢：朝Page size大的更新，因為我們只關心Page Fault ration\nProgram Structures 之影響   若Profram中使用的指令Data Structure, Algo 符合 \u0026ldquo;Locality Model\u0026rdquo;，則為GOOD(有助於降低Page Fault Ratio)，反之，若違反，則為BAD\n  程式中對於Arrray元素的處理順序最好與Array元素在Memory中的儲存方式(Row-Major或Column-mahor)對應，有助於降低Page Fault ratio\n例：A：Array[1..128,1..128] of int;\n每個int 佔 1 bytes\nA以Row-major(第一列放完再放第二列在放第三列...)方式存於Memory\nPage Size= 128 byte\n給3個Frames，且程式已在Memory中\n採FIFO Replacemenrt policy\n求下列Code之Page Fault次數\n1 2 3  for i = 1 to 128 do for j = 1 to 128 do A[i,j]=0   1 2 3  for j=1 to 128 do for i to 128 do A[i,j] = 0    Row-Major 的排列方式 Column-Major  例2：A：Array[1..100,1..100] of int;\n每個int 佔 1 bytes\nA以Row-major(第一列放完再放第二列在放第三列...)方式存於Memory\nPage Size= 200 byte\n給3個Frames，且程式已在Memory中\n採LRU Replacemenrt policy\n求下列Code之Page Fault次數\n1 2 3  for i = 1 to 100 do for j = 1 to 100 do A[i,j]=0   1 2 3  for j=1 to 100 do for i to 100 do A[i,j] = 0         Copy-On-Write技術 (此處主要是討論3種Fork())\n  傳統的Fork() ch4\n(fork () without \u0026ldquo;copy-on-write\u0026rdquo;)\n定義：Parent process fork() 建立出Child process，OS會配置New Frames給Child Process(即Child 與 Parent 占用不同的Memory Space)，同時OS也要複製(Copy)Parent Process內容(code Sec 及 Data Sec)給Child Process initially\n此舉會導致兩個缺失\n Memory(Frames)需求量大增 Slower Child Process Creation  而且上述做法在Child 生出後，立刻執行execlp()作其他Task時，更加顯得無用 unnecessary(不適合，因為沒有共通的東西，卻要Copy不用的東西給child)\n  Fork() with copy-on-write\n定義：當Parent Process 生出child process 之初，OS會讓child共享parent process之memory(frames)空間，如此，無須配置給Child process New Frames 且也不用Copy Parent 內容給Child，因此可降低頁框需求量及加速Speed Up process Creation。\n但是，任何一方改變了某Page內容，則另一方會受到影響(此為risk)，所以引入Copy-on-write技術，即eg. 若Child Process 想要更改某Page內容(eg. Stack內容)，則OS會配置一個New Frame給Child，且Copy Page內容到new Frame中，且修改Child的page Table 指向 New Frame，供Child 使用/修改，如此，則不會影響Parent\n因此那些有Modified可能的Pages，須標示Copy-on-write，而有些不會Modified 的Page(eg: read-only code/data)則不須標示，則可共享\n  Vfork() (virtual memory fork())\n定義：Parent 生出Child 之初，也是讓Child共享parent相同的frames，但是，它並未提供Copy-on-weite技術，所以，任何一方改變了某Page內容，則另一方會受到影響，故務必小心使用。這個東西特別適合用在：當生出Child 後，Child立刻執行execlp()去作其他task時，Vfork()非常有效率。例如：Command Interpreter製作(eg：Unix shell)\n  TLB Reach 定義：經由TLB Mapping 所能存取到的Memory Area大小，即TLB Reach = TLB Entry數目 * Page Size\neg. TLB有8個Entry，且Page Szie= 16 KB，所以TLB reach = 8 * 16kb = 128 kb\nNote：希望 TLB Reach 越大越好\nQ：如何加大TLB Reach?\n方法一 提高TLB Entry數目\n優點：\n TLB Reach 變大 連帶TLB Hit Ratio也較高   TLB (Translation Lookaside Buffer) Hit Ratio 是計算虛擬記憶體管理中 TLB 命中率的一個指標。TLB 是處理器中一種硬體快取，用於加速虛擬記憶體的地址轉換過程。當程式存取一個虛擬記憶體頁面時，處理器會先在 TLB 中查找是否已經有該頁面的轉換資料。如果有，就可以直接進行地址轉換，稱為 TLB 命中。如果沒有，則需要從主記憶體中讀取轉換資料，並且更新 TLB 中的內容，稱為 TLB 錯誤。\nTLB Hit Ratio 就是 TLB 命中率，即在虛擬記憶體管理中，TLB 命中的次數與總存取次數之比。這個指標反映了 TLB 的效率，也可以用來評估虛擬記憶體子系統的效能。一般來說，高的 TLB Hit Ratio 表示處理器能夠更快速地完成地址轉換，因為有更多的轉換資料被快取在 TLB 中。\n 缺點：\n 成本貴(高) 有時TLB Entry數仍不足以涵蓋Process   方法二 加大Page Size\n優點：\n 加大TLB Reach Cost可接受  缺點：\n  內部碎裂會很嚴重\n  解決方法：現代很多硬體均提供一些不同大小的Page(Multiple Page Size)\n  eg . 提供乙組Page Size (4 KB, 2 MB)\n  因此TLB 紀錄項目多增加一個Page(Frame) Size\n     Page No Frame No Page(Frame) Size      此外，TLB管理以前是Hardware管理，現在委由OS管理，這樣帶來的好處遠大於效能下降的壞處\n    [053 1:29:23]\nChapter 9 Disk Management  Disk System 組成即大小計算 ☆☆\nDisk Access Time 組成 計算 ☆☆☆☆\nDisk Free Space Management(4種) 很少考\nFile Allocatation Method(3種) ☆☆☆☆☆\nDisk Scheduling Algo (6種) ☆☆☆☆☆\n其他名詞 考個一兩次吧\n Formatting ☆\nRaw-I/O x\nBootstrap loader, Boot Disk ☆☆\nBad Sectors 處理方法(3種) ☆☆☆\nSwap Space Mangement (2方法) ☆\nRAID 介紹 ☆☆☆☆\n  ​\nDisk System組成 定義：Disk System 由多片Disks組成，\n 每片Disk通常雙面(Double-side)，可存Data 每一面(surface)劃分為多個同心圓軌道，叫做磁軌(Track) 每條Track由多個Sector(磁區)所組成 不同面之相同Track No組成之Track 集合，叫做Cylinder(磁柱)  圖示：\n例：Disk System有10片Disk\n 每片皆雙面可存 每面有2048條Tracks 每條Track有4096個Sectors 每個Sector可存16KB Data  求Disk System Size?\nAns.\n10 * 2 * 2048 * 4096 * 16KB = 20 * 211 * 2 12 * 2 14 Bytes\n= 10 * 238 bytes = 2.5 * 2 40 bytes = 2.5 TB\nDisk Access Time 定義：Disk Access Time 由下列3個時間加總而得\n Seek Time Latency Time (or Rotation旋轉 Time) Transfer Time  分述如下：\n Seek Time：將Head(磁頭)移到欲存取之Track上方所花的時間 Latency Time：將欲存取之Sector 轉到Head 下方所花的時間 Transfer Time：Data在Disk 與 Memory 之間的傳輸時間，與傳輸量成正比  此外上述3者通常以 Seek time 佔比較大\n計算：\n例1：\nDisk 轉速 7200 rpm，求Avg Latency (rotation) Time?\nAns.\n7200 rpm = 一分鐘轉7200次 = 一秒鐘120次 = 轉一圈1/120 秒\n平均Rotation Time = 1/2 * 1/120 = 1/240 秒\n例2：\nDisk System 有3片Disks，雙面可存\n 每面有1024條Tracks 每條Track有40%個Sectors 每個Sector可存32KB 轉速6000 rpm  求Transfer Rate(即每秒可傳輸多大量Data)\nAns.\n6000 Rpm = 1秒可轉 6000/60 = 100圈\n每轉一圈可傳輸一個Cylinder容量(多面時)\n因為一條Track容量 = 4096 * 32 Kb\n一條Cylinder容量 = 6條Track * 4096 * 32KB\n= 6 * 128 MB\nTransfer Rate = 100 * 6 * 128 MB/sec \n= 600 * 128 Mb/Sec\n例3：\n承上，若Disk平均Seek Time = 10 ms，今有一個File大小=2MB，欲read this file，要花多少I/O TIme?\nAns.\nSeekTime + Latency time + Transfer Time = 10 ms +(1/2 * 1/100)秒 + 2MB / 500 * 128MB\n= 10 ms + ms + 10 / 3*128 ms\nDisk Free Space Management 有四種方法\n Bit Vector(或Bit Map) Link List Grouping Counting  Bit Vector(Bit Map) (位元向量/地圖)\n定義：每一個Block皆用一個Bit表示Free與否\n0：表Free\n1：表Allocated\nDisk有n個Block，則Bit Vector大小= n Bit\n例\n   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15     0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0    優點：\n 簡單易實施 容易找到連續的Free Block(即連續的0)  缺點：\n 小型Disk適用，但大型Disk不適用，因為Block數目龐大，造成Block Vector Size很大，很佔Memory Space甚至被迫置於Disk  Link List 定義：OS直接在Disk上，將這些Free Blocks以Linking方式串接，進行管理\n優點：\n1. 大型Disk適用\n2. 插入/刪除 Free Block方便\n缺點：\n1. 不夠迅速去找大量的可用區塊，因為Disk上讀取Link Info耗時(I/O)\nNote：用Grouping法改善\n2. 不容易找到連續的Free Blocks\nNote：用Counting法改善\nGrouping 定義：是Link List法之變形，在Free Block內除了紀錄 Link Info之外，另額外紀錄其他Free Block之No(Address)\n例：(Assume one Block 可記5個欄位)\n優點：可迅速找到大量的Free Blocks\nCounting 定義：利用連續性配置及連續性歸還之特性，稍加改變Link List記錄方式，Free Block 內除了紀錄Linking info以外，另外紀錄在此Free Block之後的連續Free Block之個數\n例：\n優點：\n適用於連續性配置，方便找到連續性的Free Block，且若連續的Free Block很多，Link List長度也可大幅縮短\n[054]\nFile Allocation Methods ☆☆☆☆☆ 主要有三大方法\n Contiguous Allocation(連續性) Linked Allocation(鏈結式)  有一個變形叫做 FAT metohd   Index Allocation(索引式)  例：UNIX的I-Node Structure    Contiguous Allocation 定義：若File大小=n個Blocks，則OS必須在Disk中找到n個連續性的Free Blocks才能配置給它，此外OS在Physical Directory，會記錄下列資訊\n   File Name Strat Block No Size(區塊數)           例：\n若File1大小=3個Blocks，則OS配置6,7,8號Block給它，且Physical Directory紀錄如下\n   File Name State No Size     File1 6 3    優點：\n 平均SeekTime較小(因為Blocks大都落在同一條Track或鄰近Track上) 可支持Ramdom(Direct) Access及Sequential Access 可靠度較高(than Linked Allocation) 循序存取速度較快(than LinkedList)  缺點：\n 會有External Fragmentation(外部碎裂)(Note：Disk用Repack(磁碟重組)方式解決，類似Memory的Compaction)(Note：所有File配置方法皆有內部碎裂)   eg. Block Size = 10KB, File大小=44 KB, 配5個Blocks，內碎=5*16-44 = 6KB  File大小不易動態擴充 建檔之前須要事先宣告大小  Linked Allocation 定義：若File大小=n個 Blocks，則OS只須在Disk中找到n個Free Blocks(不須連續)，即可配置且Allocated Blocks之間以Link方式串連，另OS在Physical Directory紀錄下列Info\n   File Name Start Block No End Block No     File2 3 4    例：\n優缺點與Contiguous相反\n優點：\n 沒有外部碎裂 File大小容易動態擴充 建File前無需事先宣告大小  缺點：\n Seek Time較長(因為不連續的block可能散落在許多不同的Track上) 不支援Random Access 可靠度較差(因為萬一Link斷裂，Data Lost) 循序存取速度慢(因為要在Disk上讀取Link資訊，才知下一個Block為何)  \n若File2大小=3個Blocks，則OS可配置 3, 1, 4 號\n[055]\nFAT(File Allocation Table) 定義：是LinkedAllocation之變形，主要差異如下\nAllocated Block之間的Linked Info存於OS Memory Area中的一個表格，叫FAT，而非存於Disk中\n例：\nFile Directory\n   File Name FAT Entry     File 2 3    優點：\n 想要加速Random Access In the Linked Allocation(因為可以在memory中的FAT找到第i個區塊的號碼，相比於在Disk中找更快。找完後再去Disk Access i th Block)，不用在Disk 中Traverse LinkedList  Index Allocation 定義：若File大小=n個Blocks，則OS除了配置n個Blocks(無須連續)存放Data之外，另須額外配置Index Block，儲存所有Data Block 之No(address) ，且OS在Physical Directory\n紀錄：\n   File Name Index Block No          例：File3大小=3個Blocks，則OS可配置11,0,14號Block給它存放Data，另外配置15號Block作為Index Block 而Index Block內容為\n   File Name Index Block No     File3 15    想要融合連續性配置與鏈結式配置部分的好處\n優點：\n 不會有外部碎裂 支援Ramdom Access及Sequential Access File大小容易動態擴充 建File之前無須事先宣告大小，  缺點：\n Index Block 占用額外空間 Linking Space浪費(OverHead)比Linked Allocation 若File很大，則單一個Index Block可能無法容納(保存)File的所有Data Block No，此問題須被解決  解決單一Index Block 不夠存放所有Data Block No之問題 方法一 使用多個Index Blocks，且彼此以Link方式串連\n例：\nAssume一個index Block可存5個No\n缺點：\nRandom Access of i th Block之平均I/O次數大幅增長(線性成長)\n方法二 使用階層式Index Structure \n例：\nTwo-Level Index Structure\n優點：\n Random Access of i th Block之I/O次數是固定值 eg 2層-\u0026gt; 3次I/O 適合大型檔案  缺點：\n 對小型檔案極不合適，因為Index Blocks太佔空間，甚至多於Data Block 數目(目錄20頁，內文2頁)  方法三☆☆☆☆☆ 混合法，即UNIX的I-Node結構，一定要會，狠狠地記下來\n例：I-Node有15格(entry)\n第1~第12格：直接用來記錄Data Block No\n第13格：pointer to Single-Level Index\n第14格：pointer To Two-Level Index\n第15格：pointer To Three-Level Index\n\u0026hellip; 以此類推\nMAX.FILE size = (12+n2+n3+\u0026hellip; ) 個Data Blocks\n優點：\n小型、大型File皆適合\n[055 1:20:00]\n例題1：\nI-Node之定義同上所述(15個Entry)\n Block-Size = 16Kb Block No(Address) 佔4Bytes  求MAX File Size多大?\nAns\n一個Index Block可以存 16KB/4Byte = 212Data Block No\n因此MAX File SIZE\n=12+212+(212)2+(212)3\n=(12+212+224+36) * 16kb\n= 250 byte\n≒ 1PB\n例題2：\n承上，若File大小 = 8000個Blocks，假設I-Node已在Memory中，則要存取此File的第6000個Data Block，需要?次I/O\nAns.\n前12個：6000-12 = 5988\n第13個：5988-4096= 1892\n第14個：大概就在這\n共3次的I/O\n例題3：\n循序存取前面6000個Data Blocks，則要?次I/O\nAns.\n6000+3= 6003次 I/O\n[055 1:39:00]\nDisk Scheduling Algo 目的在於降低軌道移動總數\n FCFS SSTF SCAN C-SCAN (C:Cirular) Look C-Look  FCFS(First-Come-First-Service) 定義：最早到達的Track request，優先服務\n例子：\nDisk有200軌，編號0~199，Head目前停在第53軌，剛剛服務完第40軌，現在Disk Queue中有下列Track request依序為\n98, 183, 37, 122, 14, 124, 65, 67\n求Track移動總數\nAns\n(183-53)+(183-37)+(122-37)+(122-14)+(124-14)+(124-65)+(67-65) = 640軌\n分析：\n 排班效果並不是很好，Track移動數較多，Seek Time 較長  Note：Disk Scheduling法則，既無最佳，也無最差\n公平，No Starvation  SSTF(Shortest Seek-Time Track First) 定義：距離Head目前位置最近的Track request，優先服務\n例：\n98, 183, 37, 122, 14, 124, 65, 67\nans\n53-\u0026gt;65-\u0026gt;67-\u0026gt;37-\u0026gt;14-\u0026gt;98-\u0026gt;122-\u0026gt;124-\u0026gt;183\n= 236軌\n分析：\n 排班效果不錯，Track移動數較少，Seek Time小，但並非是Optimal 不公平，有可能Starvation  SCAN法則 SCAN is Suck Do not Use\n定義：Head來回雙向移動掃描，遇有Track request，即行服務，Head遇到Track開端或盡頭時，才會折返提供服務\n示意圖：\n分析：\n 排班效能可接受適用於大量負載之情況(因為在Track Request有較均勻一致之等待時間)  Note：Look也是\n在某些時刻對某些Track Request，似乎不盡公平  ​\tNote：用C-SCAN解\nHead需要遇到Track 開端或盡頭才折返，此舉耗費不必要的Seek Time  ​\tNote：用Look解決\n[056]\nC-SCAN 定義：C Stand for circuler，是SCAN變形\n差別：只提供單項服務，折返回程不提供服務\n示意：\n爭議在計算上，折返的Track移動數要列入還是不列入計算?\nLook 定義：是SCAN之變形\n差別：Head服務完該方向最後一個Track Request後，即可折返提供回程服務\n示意圖：\nC-LOOK 定義：Look之變形\n差別：只提供單向服務，折返的Track列入計算\n補充    [恐] [Modern]其他版     SCAN x   C-SCAN x   Look SCAN   C-Look C-SCAN    其他名詞項 Formatting (格式化) 分為兩種\n  Physical format\n又稱low-level format\n  工廠生產Disk System時執行\n  主要是劃分出Disk Controller可以存取的Sector\n  偵測有無不良Sector\n    Logical formatting\n user在使用Disk之前，必須做兩件事情  Partition：切割分區，即Logical drive，ec: C,D,E磁碟機 Logical Format：OS製作(寫入) File Management System 所需之資料結構  Free Space管理(eg. Bit Vector) FAT, I-Node (配置方法) 空的Physical Directory        Row原始的-I/O (基本上沒考過) 定義：將Disk視為大型Array在使用，一個Sector好比是Array的一格，無File System之資源，這樣的優點是檔案存取速度快速，缺點是User不易使用，通常在DBMS底層使用\n[057]\nBootstrap Loader ☆☆☆☆☆ 主要目的：開機時，用以從Disk載入 OS Object Code 到Memory(RAM) 的特殊Loader\n早期的作法 缺點：\n  Bootstrap Loader無法任意變更\n  ROM Size有限，BootStrap Loader 無法很大\n  現代的做法 BAD Sectors 之處理方法 Sector會壞的原因\n 工廠生產時已Bad 正常使用一段時間後，Bad  處理方法：\n[方法一] Mark(標示) Bad Sectors，以後不用\n例：IDE Disk Controller\n[方法二] Spare(備品) Sectors方法\n例：SCSI Disk Controller採用\n作法：\n一旦有BAD Sector(eg 87號 Sector BAD)，則Disk Controller 會從 Spare Sectors選擇一個Spare Sector (eg. 333號 Sector) 來替代BAD Sector。將來OS在存取87號Sector時，SCSI Controller會將它轉向成對333號之存取(但OS不知道這件事情)\n缺點：\n此一Sector轉向存取之動作，可能會破壞掉OS Disk Scheduling之最適效益，破壞磁碟排班效能\n例：\n改善作法：\n將Spare Sectors 分散到每條Track (or cylinder)上，不要集中存放\n若Sector BAD，則用相同軌道或鄰近的Track 上的Spare Sector作替代\n舉例來說：維修中心如果都在台東，那運送時間會拖很長，要讓時間降低的做法就是讓全省各地都有維修中心，降低運送時間\n[方法三] Sector Sliping 法\n例：\nSwap Space Management [交大成大有考過一次，至此之後滅跡]\n在Virtual Memory, Medium-term Scheduler，會將Disk作為Swap out的page或process image之暫存處\nSwap Space空間大小，宜超估，比較安全\n如果留太小的示意圖：\nSwap Space Management方式\n(用什麼方式保存Swap out page/process image?)\n方法一\n用File Sy(stem，仍然以File型式保存(.temp)\n優點：\n Easy implementation  缺點：\n 有外部碎裂(因為大都採Contiguous Allocatation) 效能比較差  方法二\n使用一個獨立的Partition來保存(使用者看不到)\n優點：\n 效能佳，因為採用Row-I/O，無File System 支持  缺點：\n 內部碎裂(但老實說，超估比低估安全) 若Partition一開始切不夠大，導致不夠用，則需要重新re-partition  提升Disk Data Access Performance(效能)之技術-Data(Disk) Striping(Interleaving) 技術 定義：把多部Physical Disks，組成單一的Logical Disk，運用平行存取技巧來提升效能，一班分為兩種\n Bit-Level Striping Block-Level Stirping  示意圖：　提升Disk Reliability(可靠度)之技術 當Block壞了，Data Lost，如何作Data Recovery?\n兩種\n Mirror(或Shadow)技術 Parity-check技術  Mirror 定義：每一部正常的Disk，均配備有對應的Mirror Disk，資料必須同時存入正常Disk及its Mirror Disk，將來，若正常Disk is Bad，則用its Mirror Disk替代\n優點：\n 可靠度最高 Data Recovery 速度最快  缺點：\n 成本高(貴)  Parity-Check 技術 定義：多準備一部Disk作為儲存Parity-Check Block之用，資料寫入時，需要額外算出Pariry-check Block內容\n將來，若某一個Block BAD，只要用其他Block及Pariry Block作偶同位，即可Recovery Data\n優點：\n 成本比Mirror便宜許多  缺點：\n 可靠度低，因為如果同時有多個Block壞掉，則無法復原 資料恢復速度慢於Mirror 資料寫入速度也慢  RAID 規格 (Redundant Array Of Independent Disks)\n磁碟冗餘陣列\n RAID 0~6 RAID-0與RAID-1組合  範例：\n皆以4部正常使用的Disk為例，\nRAID-0 只提供Block-Level Striping(Interleaving)而已，未提供任何可靠度技術(eg. mirror, parity-Check，用在強調存取效能要求高，但可靠度不重要之場合\neg. VOD(Video Of Demand) Server\nRAID-1 就是Mirror\nRAID-2 採用Memory的ECC技術來改善可靠度，希望降低Mirror成本，但是成本降低有限(只比Mirror少一部Disk而以)\n例\nDisk數=2n-1\n此外，與RAID-3相比，可靠度一樣，但成本高於RAID-3，因此RAID-2無實際產品，跟RAID-6一樣，跟RAID-2一樣沒實際產品，口訣2266\nRAID-3 採用Bit-Level Striping 及 Parity-Check技術\nDisK數=n+1\nRAID-4 採用Block-Level及Pariry-Check技術\nRAID-5 採用Block-Level Striping及Parity-Check技術，與RAID-3,RAID-4之主要差別在，將parity Block分散存於不同Disk，並非集中在一部Disk\nRAID-6 不用Parity-Check技術，改用類似Reed-Solomon技術，可以做到2部Disk Block同時出錯，\n還能Recovery，但Cost太高(≧ Mirror成本)，因此也無實際產品\nRAID-0 \u0026amp; RAID-1 之組合 用在高效能以及高可度要求之場合，雖然很高，但不計任何代價\n組合方式有：\n RAID0+1 RAID1+0[優秀]  這邊考畫圖\nRAID0+1 先Striping，再整體Mirror\n一部Disk BAD，整組的Disk都要換成Mirror的，不可以只換一個Disk\nRAID1+0 先Mirror，再Striping\nChapter10 FileManagement  File Open \u0026amp; Close 動作\nConsistency semantic\nFile Protection\n [058]\nFile Open \u0026amp; Close動作 緣由： OS 對 File 進行任何運作之前，都必須要Disk之Physical Directory 找出File的配置資訊，此舉會導致2個Problems\n 搜尋的時間很長(因為File數目太龐大) Disk I/O Time(次數)很多，非常耗時  為了改善此問題，才有File Open及Close動作\nFile Open運作 定義：當File第一次被使用時，OS必須要Disk之Physical Directory找出File的配置資訊，Then，將此資訊Copy到OS Memory Area中的一個Table，叫做 「Open File Table」，將來對此File進行任何運作之前，OS只需到此，搜尋取得File的配置資訊即可，由於Open File Table中的File數目少(eg. 20個)，搜尋時間可大幅降低，又此表格在Memory中，所以省下可觀的I/O Time(次數)\n由於File可被多個Processes共用之故，每個Process讀取到的位置可能不一樣，有的可能在第八行，有個可能在第八百航，所以Open File Table可進一步分成兩種\n System-Open File Table：保存File的共通配置資訊(File名稱、配置區塊、大小)，不因Process不同而有所不同。 Process-open File Table：Process存取File時，會有不同的資訊要保存eg. File當前指標位置、File Access權利  File Close運作 定義：當File不再使用時，OS會將Open File Table中此File的配置資訊更新回Disk之Physical Directory，且自Table中刪除此File的配置資訊\nConsistency Semantic (一致性語言，翻成白話文就是。檔案可以被多個Process/user共享，而共享的模式(model)有哪幾種?)\n分為三種\n UNIX Semantic：例如：訂票系統的座次表  需要互斥存取 大家看到的File內容是一致的 某個Process對File作的任何改變，其他Processes會知道   Session Semantic：例如：空白報名表File 供人下載填字  不須互斥存取，大家都在各自的Copy上read/write存取不受限制 大家看到的內容不一定一致   Immutable Sematic：例如：總經理公告文件第005號.pdf  Read-Only，不可更改內容 檔名不得重複    File Protection Physical Protection：防止因為Disk BAD所造成的File Data Lost，方法：Backup only\nLogical Protection：防止非法使用者對FIle之不當存取\n方法如下\n  Name Protection\n  Passwork Protection\n  Access List\n  Access Group☆☆☆\n以UNIX為例\n 將User 分為三類  Owner Group(Member) Other(Universal)   File存取權利  R：Read W：Write Ｘ：eXecute      \n\n\n\n\n\n\n\n","date":"2022-10-08T03:02:43+08:00","image":"https://i.imgur.com/HJLk11O.png","permalink":"https://hoxtonhsu.com/p/%E4%BD%9C%E6%A5%AD%E7%B3%BB%E7%B5%B1%E7%AD%86%E8%A8%98/","title":"作業系統筆記"},{"content":"[ToC]\n學習路線 Ch1Algorithm, Recursion and Performance Analysis(space + Time) Ch3 Stack \u0026amp; Queue Ch5 Tree And Binary Tree Ch9 Advanced Trees Ch7 Search and Sorting CH8 Hasing Ch6 Graph Ch2/Ch4 Array\u0026amp;Linked List Ch1 Algorith, Recursion and Performance Analysis  Algo定義(5個Criteria)\nRecursion(遞迴)☆☆☆☆☆\n 定義\n種類\n與 Non-Recursion比較考型及來源\n 效能分析\n Space(較少考)\nTime(較常考)☆☆☆☆☆\n  Algorithm(演算法)  定義：為了解決特定問題之有限個敘述／步驟／指令所構成之集合，且必須滿足下列５個Criteria：   Input：輸入的資料量\u0026gt;=0個即可 Output：至少要有\u0026gt;=1個輸出量 Definiteness(明確性)：每個敘述／步驟／指令必須是Clear且unambiauous(不可混淆不清)。3之要求在於Algo之寫作格式無一致標準之規範  Finiteness(有限性)：必須在執行／追蹤有限個步驟後，必能夠終止 Effectiveness(有效性)：人可以用紙和筆追蹤／執行每一個步驟，即每一個Step is baisc enough to be carried。當log完成，你如何確定它是正確的  Recurtion(遞迴)   定義：(以Direct Recursion為例)，Algo/program中含有==self-calling(自我呼叫)==敘述存在者，稱之遞迴\n  種類：\n Direct：直接遞迴 Indirect：間接遞迴 Tail：尾端遞迴    分述如下\n  直接遞迴：方法中直接呼叫自己\n1 2 3 4 5 6 7  function A(){ // do something  if(...) then A(); //重複自己  else{ // do something  } }     間接遞迴：多個Module之間彼此形成Calling Cycle，\n1 2 3 4 5 6 7 8 9 10 11  function A(){ //something  Call B(); //相互呼叫  //something } function B(){ //something  Call A(); //相互呼叫  //something }     尾端遞迴：是Direct Recustion 之一種，recursive call發生在程式即將結束之前一行\n1 2 3 4  function A(){ //do something  if(xxx){} then A() //程式的最後一行 優點是Complier或工程師方便改寫成非遞迴的形式(降低時間複雜度 }       任何problem之解決，必定存在兩種形式之Algo\n 遞迴 非遞迴(Interation)  eq. 求n! 求費氏數列\n比較圖如下\n   Recursion Non-Recursion     程式碼較為精簡 冗長   較少，或沒有使用區域變數 使用到區域變數來保存中間值，Loop控制等等   程式碼占的儲存空間比較少 程式碼占用的儲存空間較多   表達力較強(powerful) 表達力較弱(weak)   ==執行的時間較久，較沒效率== 執行時間較短，較有效率   ==需要額外的stack space支持== 不需要這東西     補充  在complier或程式語言的課程裡面，會討論如何處理recursion?\n  當遇到Recursive call的時候，\n 必須先保存當時執行狀況，push這些東西    參數值 區域/占存 變數值 返回位址(return address)   到System stack\nJump to 程式開端執行    若遇到程式結束(END)敘述時遞迴條件不符合，繼續往下執行，遇到程式的END，要判斷是某一次的遞迴結束，還是整個都結束了。判斷的依據是查看Stack區是否為空，若為空則代表只是一次的遞迴結束，若Stack為空，則代表整個程式結束\n1 2 3 4 5  if (stack is empty) then 整個結束 else{ pop stack; //取出當時保存的參數或區域變數以及返回位置(return address) then go to \u0026#34;return address\u0026#34;執行  //所謂的return address(返回位址，就是指遞迴結束完後，下一個會執行的程式碼)  }   例：\n1 2 3 4 5 6 7 8 9 10  function A(int a){ int x = 0; int y=0; a++; if(xxx) then A(a); //recursive call  else{ //do something  } x=x+1; (這就是返回位址 (1:) }     考型及來源 考型：\n  給一個Probleam，寫下Recursive algo/code 給Recursive algo/code，要我們追蹤結果 etc\u0026hellip;   來源：\n  數學類：階層 往後章節(二元樹的追蹤、圖形的追蹤、排序的追蹤\u0026hellip;) 其他    Tower fo Hanoi permutation printing    數學類  寫下一個非遞迴的求階層方法  1 2 3 4 5 6 7 8 9 10 11 12  int fac(int n){ if(n==0){ return 1; }else // n\u0026gt;0{  int S=1; int i ; for(i=1;i\u0026lt;=n;i++){ S=S*i; return S; } } }    寫下一個用遞迴處理的求階程式\n==關鍵點：記下數學遞迴定義式==\n1 2 3 4 5 6 7  int fac(int n){ if(n==0){ return 1; }else{ return n * fac(n-1) ; } }     以2的Code為題目\n  求Fac(3)\n  共呼叫Fac函數?次，含Fac(3)這次這影響到了時間複雜度，以及會調用幾次pop\n4次，Fac(n)共呼叫幾次=n+1次\n    write a recursive algo for sum(n)= 1+2+\u0026hellip;+n, and sum(0)=0;\n1 2 3 4 5 6 7  int sum(int n){ if(n==0){ return 0; }else{ return n+sum(n-1); } }     Fibonacci Number(費氏數列)\n   n 0 1 2 3 4 5 6 7 8 9 10 11 12 13     Fn 0 1 1 2 3 5 8 13 21 34 55 89 144 233    Q：F98 = ? + ? = ? - ? = ? - ?\n F97+F96; F99-F97; F100-F99;  Q：不超過500之費氏數列\n​\tA. F14 = 377\n  Write a recursive algo/code for Fibonacci\n 遞迴解法  1 2 3 4 5  int Fib(int n){ if(n==0){ return 0;} if(n==1){return 1;} return Fib(n-1)+Fib(n-2); }   非遞迴解法  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  int Fib(int n){ if (n==0){ return 0 }else if(n==1){ return 1 }else{ int a =0; int b =1; int c ; int i ; for(i=2;i\u0026lt;n;i++){ c= a + b; a =b ; b = c ; } return c; } }      Fo F1 F2 F3 \u0026hellip;     a=0 b=1 c=a+b\na=b\nb=c c=a+b\na=b\nb=c \u0026hellip;      依(1)之code，(i)求出Fib(5)之值(ii)呼叫次數?次(iii)Fib(10)的呼叫次數呢?\n1 2 3 4 5  int Fib(int n){ if(n==0){ return 0;} if(n==1){return 1;} return Fib(n-1)+Fib(n-2); }   ans .\n(i) 5\n(ii)(iii) 令T(n)代表求Fin(n)時之呼叫次數，即T(0)=T(1)=1次，(i)寫出T(n)之Recursive definition(ii)Based on (i)，求出T(10)之值\nans . (i) T(n) = T(n-1)+T(n-2)+1 且 T(0) =T(1) = 1;\n​\t(ii)\n   0 1 2 3 4 5 6 7 8 9 10     1 1 3 5 9 15 25 41 67 109 177      求Fib(5)時，則Fib(0),Fib(1),Fib(2),Fib(3),Fib(4),Fib(5),分別被呼叫?次\n   Fib(n) 0 1 2 3 4 5     呼叫幾次 3 5 3 2 1 1    5只會自己生自己，4只會由5產生，3會由4跟5產生(1+1)，2則是由3跟4產生(2+1)，1會由2跟3產生(3+5)，但0只會由2產生，不會由0產生。\n  接續上題，那Fib(10)呢?\n   Fin(n) 0 1 2 3 4 5 6 7 8 9 10     呼叫幾次 34 55 34 21 13 8 5 3 2 1 1      令T(n)代表求Fib(n)時之加法次數\n(i)求出T(n)之recursive definition\n(ii)求T(5)之值 based on(i)\nans\n(i) T(n)=T(n-1)+T(n-2)+1，且T(0)=0,T(1)=0\n   Fib(n) 0 1 2 3 4 5 6 7 8     呼叫幾次 0 0 1 2 4 7 12 20 33      code如下，求F(5)之值\n1 2 3 4  int Fib(int n){ if(n==0 || n==1){return 1} return F(n-1)+F(n-2) }      Fib(n) 0 1 2 3 4 5     值 1 1 2 3 5 8      code如下\n1 2 3 4 5  int Fib(int n){ if(n\u0026lt;1){return 0} if(n\u0026lt;3){return 1} return Fib(n-1)+Fin(n-2) }   (i)求Fib(5)之值\n   Fib(n) 0 1 2 3 4 5     值 0 1 1 2 3 5    (ii)呼叫Fib函數?次(含Fib(5))\n  Binomical coe(二項式係數)\n  ​\n$$ {C_m}^n =(\\underset{m}{\\overset{n}{{}}})=\\frac{n!}{m!(n-m)!} $$\n  ​\n$$ (i)write a recursive algo / code 求 (\\underset{m}{\\overset{n}{{}}})之值 $$\nans. 關鍵，==必背==\n$$ (\\underset{m}{\\overset{n}{{}}})=\n\\begin{cases} \u0026amp; 1, \\text{ if } (n = m \\text{ or } m = 0) \\\n\u0026amp; (\\underset{m}{\\overset{n-1}{{}}})+(\\underset{m-1}{\\overset{n-1}{{}}}) \\end{cases} $$\n1 2 3 4 5 6  int Bin(int n , int m){ if(n==m || m==0){return 1} else{ return Bin(n-1,m)+Bin(n-1,m-1) } }   (ii) based on (i) code 求Bin(5,3)之值及呼叫次數\nans 10 ,19次\nNote ：計算時有些撇步\n$$ (\\underset{3}{\\overset{5}{{}}}) = \\frac{5\\times4\\times3}{1\\times2\\times3}=10 $$\n$$ (\\underset{4}{\\overset{8}{{}}}) = \\frac{8\\times7\\times6\\times5}{1\\times2\\times3\\times4}=70 $$\nGCD(A,B) 求A,B兩數之最大公因數，寫出recursive algo/code  ==☆☆☆☆☆☆☆☆☆要背☆☆☆☆☆☆☆☆☆☆☆☆==\n$$ GCD(A,B)=\\ \\begin{cases} \u0026amp; B, \\text{ if } (A modsB)=0 \\\n\u0026amp;GCD(B,AmodsB), other wise \\end{cases} $$\n1 2 3 4  int GCD(int A,int B){ if (A%B==0) {return B} else return GCD(B,A%B) }   依上述code，試求(1)求GCD(18,33)之值(2)呼叫GCD?次\nAckerman\u0026rsquo;s Function 一坨大便，幹破你娘  $$ A(m,n) = \\begin{cases} n+1, \u0026amp; \\text{if } m=0\\\nA(m-1,1), \u0026amp; \\text{if } n=0\\\nA(m-1,A(m,n-1)), \u0026amp; \\text{otherwise} \\end{cases} $$\n(i) A(2,2)=?\nans.\nA(2, 2) =7\n(ii) A(10,10) ans.\nA(10, 10) = A(9, A(10, 9)) = A(9, A(9, A(10, 8))) = A(9, A(9, A(9, A(10, 7)))) = A(9, A(9, A(9, A(9, A(10, 6))))) = A(9, A(9, A(9, A(9, A(9, A(10, 5)))))) = A(9, A(9, A(9, A(9, A(9, A(9, A(10, 4))))))) = A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(10, 3)))))))) = A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(10, 2))))))))) = A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(10, 1)))))))))) = A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(9, A(9, 1)))))))))) ≈ 2.1216 x 10^19728\n(iii)A(1,3)\nA(1, 3) = A(0, A(1, 2)) = A(0, A(0, A(1, 1))) = A(0, A(0, A(0, A(1, 0)))) = A(0, A(0, A(0, A(0, 1)))) = A(0, A(0, A(0, 1))) = A(0, A(0, 2)) = A(0, 3) = 4\n常考排行\nA(2,2) = 7\nA(2,1) = 5\nA(1,2) = 4\nA(2,3)= 9\n求xn，其中x,n是integer，且n ≧ 0 , write a recursive algo/ code  ans\n$$ x^n= \\begin{cases} 1\u0026amp;\\text {if}(n==0) \\ x \\times x^{n-1}\u0026amp;\\text {if} (n\u0026gt;0) \\end{cases} $$\n1 2 3 4 5 6  int exp(int x,int n){ if (n==0){return 1} else{ return Exp(x,n-1)*x } }     1 2 3 4 5 6 7 8 9 10 11  int foo(int x, int n){ if(n%2==0){ f=1; }else{ f=x } if(n\u0026lt;2){ return f; } return f*foo(x*x, n/2); }   (i) 求foo(2,5)值\n​\t(ii)求foo(x,n)之功能\n​\t求xn\n(iii)求foo(x,n)之Time Complexity\n​\tO(logn)\n河內塔(Towers of Hanai) 程式如下：\nHanoi(n,x,y,z);\nn：盤數\nx：來源\ny：占存地\nz：目的地\nStep1 Hanoi(n-1,A,C,B);\nStep2 Hanoi(1,A,B,C);\nStep3 Hanoi(n-1,B,A,C);\n1 2 3 4 5 6 7 8 9 10  void Hanoi(int n,char A,Char B, Char C){ if(n==1){ printf(\u0026#34;move disk %d from %c to %c \\n\u0026#34;,n,A,C); }else //n\u0026gt;1{  Hanoi(n-1,A,C,B); printf(\u0026#34;move disk %d from %c \\n\u0026#34;,n,A,C); Hanoi(n-1,B,A,C); } }   Permutation列印 將[a,b,c]以不同的排列組合印出來\n如\nabc\nacb\nbac\nbca\ncba\ncab\n有3!=6種寫法\n以遞迴的概念來理解\n原始碼的部分\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  void perm(char list[], int i, int n){ //產生list[i]~list[n]之排列組合  //i≦n  if(i==n){ //代表遞迴中止  for(j=1;j\u0026lt;=n;j++){ printf(list[j]); // for each完後印出當時list的內容  } }else{ for(j=i;j\u0026lt;=n;j++){ swap(list[i],list[j]); // list[j]做頭  perm(list,i+1,n); //接(i+1)~(n)之perm  swap(list[i],list[j]) // 還原成原本List的內容  } } }   實際演練\n1 2 3 4  void main(){ char list[3] = {a,b,c}; Perm(list,1,3); }   Performance Analysis(效能分析) Algo/code之效能分析，主要分析兩點\n Space Time  Space(空間)需求分析 定義：令SP(P)代表Algo/Code P 之空間需求，則SP(P)= Fixed Space requirement + Variable Space Requirement\n固定(Fixed)空間需求= Instruction (or Code) Space 意即你寫了幾行的程式+變數+常數空間 =C(mean Constant)\n變動(Varialbe)空間需求=\n主要有兩個來源\n 若參數為結構型態(Array, Struct)且採用Call-By-Value參數傳遞方式(若是用Call-By-Address則也不是變動空間，因為只收一個Address的起始位址而已) 遞迴(recursion)所需之stack space (堆疊空間)  因此主要的分析是在變動空間需求這邊\nSP(P)= C + SP(i)\n範例\n求SP(i)=?\n1 2 3 4 5 6 7 8  rsum(floot list[], int n){ if(n!=0){ return rsum(list,n-1)+list[n-1] } return list[0] } // 此外，假設 floot 佔4 bytes, int佔2bytes pointr(address)佔2bytes, List[]採用Call-by-address傳遞    Ans.SP(i)= Stack Space for recursion\n如何計算?\n  每發生一次遞迴的呼叫(recusive call)，我們需要將\n  參數值 list[] 佔2byte,因為是call by address。n 佔2bytes\n  區域變數值無\n  Return Address一定有，題目說是2Byte\nPush 6 byte per recursive call\n又共發生n次recursive call(不含rsum(list,n))\n    因此Sp(i)= 6n bytes\nTime(時間)需求分析 定義：令T(P)代表Algo,code P之時間需求，則T(P)=Development time(開發時間) + Execution Time\n只注重/討論 Execution Time分析in DS/Algo課程\nExecution Time之評量有兩個方法\n Measurement(實際量度) Analysis(分析、預估)\\  本課程是採用Analysis方式，Analysis是以Algo/Code的指令執行總次數，作為分析Time之基礎\n範例1. 不考慮指令之難易度\neq. 整數除法 a/b，浮點數除法 a/b視為一樣\n原始code如下：\n1 2 3 4  for(i=1i≦n;i++){ a = a + b; } return a;   Then, 宣告一個Global變數，Count=0，在適當處加入Count++之敘述\n1 2 3 4 5 6 7 8  for(i=1i≦n;i++){ count++; //用來統計for做幾次  a = a + b; count++ //統計 a=a+b做幾次 } count ++;// for最後失敗的那一次，跳出for迴圈，實際上還是有做，因此要補上 conut++; //用來統計下面的return return a;   T(P)= 指令執行次數之統計= 2n+1+1(每行被執行了幾次)=2n+2次\n範例2. 考慮指令之難易程度\n   Source Code S/E Frequency Total     for(i=1;i≦n;i++) 4 n+1 4n+4   {a=a+b} 2 n 2n   return a 1 1 1      6n+5    利用S/E (Steps per Execution每執行一次要花幾步，開心要怎麼定就怎麼定)區別指令難易程度 S/E高，代表較難\n研究所的Time分析考型   計算某行指令執行次數\n  Asymptotic漸進式 Notations符號定義、大小、定理\n(O,Ω,θ,o,w)\n  Recursive time function遞迴時間函數計算/求解 (eq. Honai Tower:T(n)+2*T(n-1)+1)\n  給一遞迴演算法Recursive algo/code寫出Time Function求解\n  [006]\n[複習] 數學公式   等差數列\n公式：(首項＋尾項) * 項數 / 2\n  等比數列\n公式：((最高項)exp+1- (最低項))/公比-1\n範例：r0+r1+r2+\u0026hellip;+rn = (rn+1-1) / r-1 = (rn+1 -r0)/(r-1)\n  平方和公式：\n公式：(n(n+1)(2n+1))/6\n範例：12+22+32+\u0026hellip;+n2\n  Σ id 約莫是 nd+1的多項式，d ≧之 int\n  Σ 1/i = log n (底數為2) (調和數列)\n  排列組合 C幾取幾之計算\n  n!之相關式子\n n! = 1* 2 * \u0026hellip; n ≦ n * n * n =nn n! ≧ (n/2) n/2 (離散) Striling\u0026rsquo;s 公式 n ! ≒ n n+(1/2) * e-n, e 為自然對數之底    Σ i x 2 i 解法為\n令S= Σ i x 2 i，因此S= 1x2 +2x2 2 + 3x33+\u0026hellip;nx2n，兩邊同x2，為\n2S = 1x22 +2x2 3 + 3x34+\u0026hellip;nx2n+1\n然後兩邊相減，得出 S = -21-22-23-\u0026hellip;-2n + n* 2 n+1=經過很多推導之後=n*2n+1-2n+1+2\nNote：其他相似型也是如此求法\n  對數系列(底數預設為2)\n  給Code，求某行指令執行次數或Big-Oh 例１\n1 2 3 4 5 6  for i = 1 to n do for j = 1 to n do x++; 求x ++ 執行次數 ans :　ｎ＊ｎ次   例２\n1 2 3 4 5 6 7  for i = 1 to n do for j = 1 to i do x++; 求x ++ 執行次數 ans :　(1+n)*n/2次   針對i++, i\u0026ndash;之 Loop，可用級數求解\n1 2 3 4 5 6  for i = 1 to n do for j = i to n do x++; 求x ++ 執行次數 ans :　n+(n-1)+(n-2)...+1 = (n+1)n/2   ​\n太基本，直接跳過\n[007]\n例題一\n1 2 3 4 5  for i = 1 to n do for j = 1 to n*n if(j%i ==0) then for k = 1 to j do x++      i=1 i=2 i=3     j=1 to 1 j=1 to 4 j= 1 to 9   j % i ==0 when j=1 j % i == 0 when j = 2 and 4 j % i ==0 when j = 3 ,6 and 9   1次 2+4次 3+6+9次    若i=4時，x會加 4+8+12+16次，也就是4(1+2+3+4)，若i是n時，x會加\nn(1+2+..+n)次 = n((1+n)*n)/2\nAsymptotic Notations 漸進式符號\n目的：表示時間函數之成長速率(Growth rate)之等級\n符號種類：\n Big-Oh：O Omega：Ω Theta：θ Little-Oh：o Little-Omega：ω  Big-Oh 小於等於\n定義：F(n)= O(g(n)) iff(若且為若) exitst two postitive constatnts C and N0 such that f(n)≦ C* g(n)，對所有n≧N0\nNote：Big-Oh代表理論之上限值(upper-Bound)\n例：f(n)=5n2+8n-3，則f(n) = O(n2)\nproof：可找到兩個正常數，C=6,N0=8，使得5n2+8n-3≦C*n2，所以f(n) = O(n2)\n解法如下，通常會先取最大次項的項數，將他+1\n例：f(n) = 3n2+8，則f(n)=O(n)是錯的\n例：log(n!) = O (nLogn) ☆☆☆☆\nans\n例\n例：\n1 2 3  for (i=1;i\u0026lt;=n;i++) for(j=1; j\u0026lt;=i; j*=2) x++;   求此Code之Time=O(?)\n比較Growth rate等級之大小 例１：基本型 Growth rate：小 \u0026mdash;\u0026gt; 大\n例2：複雜型，請參閱課本 [007 1:24:00]\n[008]\n例題：\n例題：\n例三\nOmega Ω 大於等於\n定義：f(n)=Ω(g(n) iff exists two positive constants C and no. such that f(n)≧ c.g(n)，對所有大於N0的n而言\nNote：Ω視為理論之下限值(low-bound)\n例題：\n例題\nTheta θ 定義：f(n)= θ (g(n)) iff exists three positive constrants C1, C2, and N0, such that，C1*g(n) ≦ f(n) ≦C2*g(n)，對所有大於n0的n而言。\nNote：\n θ is more precise than O and Ω f(n) = θ (n) f(n) = O(g(n)) and f(n) = Ω(g(n))  例：\n例：\nLittle-Oh：o  哲學意義在於絕對小於\n o 就像小於\n定義：f(n) = o (g(n)) iff 對於所有的C，存在n0，且C為正常數，使得f(n) ≦ C*g(n)，對於所有的n0皆大於n\n大部分都考是非題\n例：\nLittle-Omega：ω  哲學意義在於絕對大於\n w 就像大於\n定義：f(n) = ω (g(n)) iff 對於所有的C，存在n0，且C為正常數，使得f(n) \u0026gt; C*g(n)，對於所有的n0皆大於n\n相關性質/關係   反身性(Reflexive)：自己與自己之間的關係\n f(n)=O(f(n))。f(n)≦1*f(n), ∀ n≧n0 f(n)=Ω(f(n))。 f(n)=θ(f(n))。  這三者皆滿足反身性\n f(n)=o(f(n)) 不成立，自己絕對不小於自己 f(n)=ω(f(n)) 不成立，自己也不大於自己  這兩者不滿足反身性\n  遞移性(Transitive)：若a R b, b R c, 則 a R c 也成立\nO, Ω. θ ,o, ω皆滿足遞移性\n f(n)=O(g(n))且g(n)=O(h(n))，則f(n)=O(h(n))    對稱性(Symmetric)：若aＲb成立，則bＲa也成立\n 只有θ滿足這個性質(==)，其他均不滿足。 即f(n)=θ(g(n))成立，則g(n)=θ(f(n))也會成立    反對稱性(Asymmetric)：\n  若f(n)=O(g(n))，則g(n)=Ω(f(n))為True\n f(n)≦c*g(n) =\u0026gt; g(n)≧1/c*f(n)\n   若f(n)=o(g(n))，則g(n)=ω(f(n))為True\n    綜合練習 [009 00:40:00]\n例題一：\n例題二：下列哪些是polynomial-Bounded(≦多項式時間等級)?\n例題３\n[010]\nRecursive Time Function求解  展開代入法 Master Theory Extended Master Theory Recursive Tree [離散]特徵方程組 猜測、近似法則  展開代入法  做苦工，通常沒問題，但缺點就是麻煩\n 例一：Tower Of Hanoi\n1 2  T(n)= 2*T(n-1)+1, T(1)=1 求T(n)=? O=?   Ans ：\n例題二\n例題三\n例題四\n例題五\n例題六：陷阱題\n　例題七：好難，不懂\n例題八\n[010 1:30:00]\nMaster Theory   若T(n)=a*T(n/b)+f(n),其中a≧1之constant，b是\u0026gt;1之constant，f(n)是positive-growth function，則可以使用此定理求出T(n)=θ(?)\n  使用方式\n  先求出   與f(n)比較growth rate大小\n    Case1 Case2 Case3 例一：　例二：\n例三：\n綜合練習：\nMaster Theory 之例外狀況 若遇到這種情況，則用Extended Master Theory\n[011] 00:30:00\nExtended Master Theory 以上面那一題為例，重新再解一次\n例題一\n例題二\n綜合練習\n更特殊之例外 [011 01:30:00]\nRecursive Tree(遞迴樹)求解 就是結構化的展開帶入法啦\n太抽象了。之後再來看\n[012]\n特徵方程 太抽象了。之後再來看\n近似值 太抽象了。之後再來看\n[013]\nCh3 Stack 與 Queue  Stack Def 、應用、製作\nStack Permutations\nInfix, Postfix, Perfix 轉換與計算 ☆☆☆☆☆\nComplier Parsing Using stack例子 ☆☆☆\nQueue 定義、應用、\u0026ldquo;製作\u0026rdquo;、種類\nStack與Queue相互製作 ☆☆☆\n Stack (堆疊) 定義：Stack 具有LIFO之性質，其Insert元素動作叫做PUSH，DELETE元素之動作叫做POP，且PUSH、POP動作發生在同一端，稱為TOP(頂端)\n就像品客洋芋片罐一樣\n例：對空Stack執行\nPushA\nPushB\nPushC\nPOP\nPushD\nPOP\nPOP\nPushE\n後，Stack內容為何?\nAE\n應用  re-entrant routine  ​\t= pure code\n​\t= 可重複進入執行之程式\n​\t= 用在Utility program\n  走迷宮\n  Palindrome(迴文)\n= 由左而右 Reading 等於由右而左\n= 若將一文字依序Push到Stack，再一一Pop輸出，等於加到Queue再一一刪除輸出，這一字串有什麼特性？Palindrome\n  Stack之製作 一個Stack之ADT(abstract data type)應提供下列Operations供外界呼叫/使用\nCreate,push,pop,isEmpty,isFull，有時候還會多一個TOP(只傳回TOP元素，但不刪除)\n  利用Arrray製作Stack\n宣告\n  S : Array [1..n] of items 或 [0 .. (n-1)]\n  Top：Int = 0 ; 也有可能是-1 取決於你的Index怎麼訂\n1 2 3 4 5 6 7 8 9  push (S, Item){ if(top==n)then return \u0026#34;S is Full\u0026#34;; else { top = top+1; S[top] = item; } }   1 2 3 4 5 6 7 8 9 10  pop(s){ if(top==0)then{ return \u0026#34;s is empty\u0026#34; } else { item = s[top]; top = top-1; return item; } }       利用Link List製作Stack\n宣告\n  Note Structure如下\n若以C語言來看\n1 2 3 4  struct Node{ int Data; Struct Node *Next; }     top : pointer = null;\n1 2 3 4 5 6  Push(S,Item){ new(t); //向系統要求配置一個Node空間，讓t指標指向它 t -\u0026gt; Data = item; t -\u0026gt; Next = Top; Top = t; }   1 2 3 4 5 6 7 8 9 10 11 12  Pop(s){ if(top ==null){ return \u0026#34;S is empty\u0026#34; } else { t = top; item = top - \u0026gt; Data; Top = Top -\u0026gt; Next ; release(t); //回收T所指的Node Space return item; } }       Stack Permutation 定義：給予N個Data，規定須依序push入Stack，但在過程中，可執行任意合法的POP輸出資料，則所有Data之輸出排列組合，稱之\nn個Data之Stack permutation數目 =\n與下列問題同義：\n n個node可形成的不同Binary Tree結構(ch5) n個\u0026quot;(\u0026ldquo;與n個\u0026rdquo;)\u0026ldquo;的合法配對數目 (n+1)個Matrix相乘之可能乘法配對順序數目 軌道問題  [014]\nInfix,Postfix,Prefix 之轉換 (本章最常考) 先介紹這3個式子\n  Infix中序置式\n格式：Operand1 Operator Operand2 運算元 運算子 運算元\neg. a+b, a*b, (a-b)/c\n缺點：對Compiler 處理Infix計算十分不方便，因為必須考慮Operator之間的優先權及結合性，故可能導致來回多次的掃描式子，才可求出結果，用白話文來講就是先乘除後加減的特性導致Compiler不方便\neg: a+b*c^d \u0026hellip;.\n  Postfix(後序式)\n格式：Operand1 operand 2 Operator\nag ab+, ab*, ab\u0026gt;\n優點：Compilter處理Postfix計算，只須由左而右Scan一次\n  Perfix(前序式)\n格式：格式：OperatorOperand1 operand 2\neg. +ab, *ab, /ab\n優點：同Postfix，但由右而左Scan\n缺點：中序轉前序須兩個Stack支持，但中序轉後序須1個Stack即可\n  Infix轉Postfix/Prefix計算題型 作法：使用括號法\n以Infix轉PostFix為例\nSteps\n 對Infix加上完整的括號配對 Operator取代最近的右括號 刪左括號，其他由左而右寫出即得Postfix  一般而言，Operator之優先權等參考下表\n   Operator 優先權 結合性 Binary 或 unary     括號() 高 Na Na   負號 - . Na unary   冪次方 ^ . 右結合 Binary   *,/ 乘除 . 左結合 Binary   +,- . 左結合 Binary   \u0026gt;,\u0026lt;,==,\u0026gt;=,\u0026lt;=,!= . 左結合 Binary   Not(否定),~ . Na Unary   AND,OR . 左結合 Binary   Assign = := 低 右結合 Binary    題目若有規定，則以題目為主\n例一：Infix轉Postfix\n  a+b*c-d/e*f\nAns. a+(b*c)-((d/e)*f))\nabc*+de/f*-\n  a*(b-c/d)^e*(f/g+h)\nAns：abcd/-e\u0026amp;*fg\u0026amp;/f+*\n  (a+(b-c))^d^e*((f-g)/h)\nAns: abc-+de^^fg-h/*\n  ~A and (B\u0026gt;C or D\u0026lt;E) or(~F)\nAns: A~BC\u0026gt;DE\u0026lt;or And F~ or\n  例二：Infix 轉 Prefix\n  a*((b/c)-d)+e*f/g\nAns: +*a-/bcd/*efg\n  a*(b-(c+d))/(e*f)^g\nAns：/*a-b+cd^*efg\n  a+((b-c)/d)-e*f\nAns：-+a/-bcd*ef\n  A or ((~B and C\u0026gt;D) and E\u0026gt;F)\nAns. Or A and and ~ B \u0026gt; CD \u0026gt; EF\n  規定：優先權：括號＞＋＞÷＞－＞╳。＋，÷，－為右結合。×為左結合\n (a*b)-c/d/e+f+g (a/b/c)+d+(e*f*g)  Ans. (a*b)-c/d/e+f+g\nAns. +/a/bc+d**efg\n例三：Postfix轉Infix\n 找出Postfix 樣板  op1 op2 operator\n 改為Infix (op1 operator op2) 刪除不必要之括號    AB+C*DE-FG+^-\nAns. (A+B)*C-(D-E)^(F+G)\n  ab/c-de*+ac*-\nAns. ((()))\n  [014 50:00:00]\n先跳過，太複雜了，之後來看\n[015]\n先跳過，太複雜了，之後來看\n[016]\nQueue(佇列)☆☆☆ 定義：具有FIFO(First-In-First-Out)先進先出。性質之有序串列\n Insert(enqueue)元素在rear(尾端) Delete(dequeue)元素在front(前端)  所以是發生在不同端\n例：針對Empty Queue實施\nenqueue(a)\nenqueue(b)\nenqueue(c)\ndequeue\ndequeue\nenqueue(d)\nenqueue(e)\ndequeue\n後，Queue內容為何?\nAns\nd,e\n應用：\n 作業系統裡頭各式各樣的Queue eg: ready queue, waiting queue, i/o-device queue etc Buffer(緩衝區)也採FIFO Queue  佇列理論：Simulation(模擬) System Performnace 評估 圖形的BFS(Breadth First Seatch) Binary Tree的Level-order Traversal 日常生活的排隊行為  Queue 的製作   Queue 此一ADT必須提供下列運作供外界使用以及呼叫\nCreate, Enqueue, Dequeue,InFull, Isempty \n   利用Array製作  Linear Array Circular Array(最多可利用(n-1)格 Space) Circular Array(最多可利用n格space)      Linear Array 缺點：若Rear ==n成立，並不一定代表Queue真的滿，若此時Front\u0026gt;0，代表仍有Front 個Space可用，但卻無法加入東西，代表有空間閒置、浪費\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class LinearStack { Integer[] array = new Integer[]{10}; /** * 佇列前端 */ int front = 0; /** * 佇列尾端 */ int rear = 0; public void Enqueue(Integer[] array, Integer item) { if (rear == 10) { //問題點  System.out.println(\u0026#34;Queue已滿\u0026#34;); } else { rear = rear + 1; array[rear] = item; } } public Integer Dequeue(Integer[] array) { if (rear == front) { System.out.println(\u0026#34;Queue為空\u0026#34;); return null; } else { front = front + 1; Integer integer = array[front]; array[front] = 0; return integer; } } }   分析：\n 解法一：一個直覺的做法當Rear==n，且front\u0026gt;0時，表示有front個空格所以可將[front+1]~[rear]這些元素往左移Front格，並設Rear=Rear-Front,Front=0; then 再作Enqueue。但缺點：導致Enqueue 平均Time從O(1)變成O(n) 解法二：利用Circular Array來作Queue  Circular Array(n-1) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class CircularLinearStack { int queueSize = 10; Integer[] array = new Integer[]{queueSize}; /** * 佇列前端 */ int front = 0; /** * 佇列尾端 */ int rear = 0; public void Enqueue(Integer[] array, Integer item) { rear = (rear + 1) % queueSize; if (front == rear) { System.out.println(\u0026#34;Queue已滿\u0026#34;); rear = (rear - 1) % queueSize; } else { array[rear] = item; } } public Integer Dequeue(Integer[] array) { if (front == rear) { System.out.println(\u0026#34;Queue為空\u0026#34;); return null; } else { front = (front + 1) % queueSize; Integer integer = array[front]; array[front] = 0; return integer; } } }   分析：\n  最多只能利用(n-1)格Space即front 所指之格不用\n  若硬用此格(Front)，則當front==rear成立時，無法區分Queue為空或Queue為滿。eg. 明明滿了，但卻無法刪除\n  判斷Queue空，及Queue滿之條件式一樣\n  Enqueue 及 Dequeue 之 Time為O(1)\n  Circular Array (n) 宣告：多加一個tag:boolean 變數，初值為false\n目的：協助rear, front判斷Queue空orQueue滿，當rear==front成立時\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  class CircularLinearStackBetter { int queueSize = 10; Integer[] array = new Integer[]{queueSize}; /** * 佇列前端 */ int front = 0; /** * 佇列尾端 */ int rear = 0; /** * */ boolean tag = false; public void Enqueue(Integer[] array, Integer item) { if (front == rear \u0026amp; tag == true) { System.out.println(\u0026#34;Queue已滿\u0026#34;); } else { rear = (rear + 1) % queueSize; array[rear] = item; if (front == rear) { tag = true; } } } public Integer Dequeue(Integer[] array) { if (front == rear \u0026amp; tag == false) { System.out.println(\u0026#34;Queue為空\u0026#34;); return null; } else { front = (front + 1) % queueSize; Integer integer = array[front]; array[front] = 0; if (front == rear) { tag = false; } return integer; } } }   分析：\n 最多可利用n格space Enqueue及Dequeue之Time皆為O(1); 與法二相比，此法Enqueue及Dequeue之時間會變長，因為每個運作中皆多了一條if額外測試，看tag值是否要改變  LinkedList作Queue 使用Single Link List 單向鏈結串列\n[017 00:55:00]\n跟Pointer有關，先跳過\nQueue的種類   FIFO Queue （標準、內定、預設）\n  Priority Ｑueue(優先權佇列)\nDef: 不見得是FIFO order 而是刪除時是Delete-MAX或Delete-Min value元素\neg. OS中運用頗多(CPU Schedule)\n製作Priority Queue 合適之Data structure- Heap\n  Double-ended Queue(雙邊佇列)\nDef: 此佇列之兩端(front, rear)皆可插入及刪除\n  Double-ended Priority Queue(雙邊優先權佇列)\nDef: 此Queue支持3個主要運作\n Insert Delete-Min Delete-MAx  製作此Queue之最合適Data Structure有\n Min-Max Heap Deop SMMH  高等樹會碰到\n  練習題：用Circular Array(法二)製作Queue，如何球出Queue中元素個數，使用Rear, front, n?\nAns. (Rear-Front+n)%n\nStack與Queue之相互製作   利用stack製作(模擬)Queue兩個Stack✩✩✩✩✩\n1 2 3 4  Enqueue(queue,item){ if(isFull(stack1)) then return \u0026#34;Queue已滿\u0026#34; else push(stack1,item) }   1 2 3 4 5 6 7 8 9 10 11 12  Dequeue(queue){ //由於Stack無法讓你Dequeue最底下的element出去，因此要借助第二個Stack來實現這件事情 if(IsEmpty(stack2))then if(IsEmpty(stack1)) then return \u0026#34;Queue空\u0026#34; else{ while(!IsEmpty(stack1))do{ x= pop(stack1); push(stack2,x);\t} } item = pop(stack2) return item; }   Time分析：\n 大部分case(T!=空) -\u0026gt; Time: O(1) 少部分case(S!=空,T=空) -\u0026gt; Time:O(n)  \u0026mdash;\u0026gt; amortized cose:O(1)\n  利用Queue製作Stack(假設是用Circular Array(法二)作的)\n1 2 3 4  Push(stack, item){ if(isFull(queue)) then return \u0026#34;Stack滿\u0026#34; else Enqueue(queue) }   1 2 3 4 5 6 7 8 9 10 11 12 13  Pop(stack){ if (isEmpty(queue)) then return \u0026#34;Stack為空\u0026#34; else{ n = (rear-front+n) %n //求出元素個數 for(i=1 to (n-1)) do { x= dequeue(queue) enqueue(queue,x) } item = dequeue(queue) return item } }     Ch5 Tree And Binary Tree  Tree Def 相關術語\nTree的表示方法(4種)\nBinary Tree之Def，與Tree不同比較\n \n\n\n\n\n\n​\n","date":"2022-10-08T03:02:43+08:00","image":"https://i.imgur.com/NiqSvey.png","permalink":"https://hoxtonhsu.com/p/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"資料結構筆記"},{"content":"最近領到薪水後買了TYPORA後，想找如何上傳圖片的教學，發現網路上的教學蠻少的，台灣好像只有一篇，還是For mac的教學，剩下的都是中國的教學，但他們用的圖床，台灣也很多不能用，後來研究了幾天終於搞懂，所以決定寫一篇看看\n圖片空間有Github跟imgur，就看你想要用哪個就用哪個吧，其實沒差太多，但imgur會稍微簡單一點點點點點點，以下是步驟\n開始  先去安裝node.js，因為會需要裡面的npm  https://nodejs.org/en/download/\n安裝好可以用系統管理員身分打開cmd，並輸入\n1  node    如果有成功安裝的話應該會顯示  接著安裝picGo-core\n1  npm install picgo -g   說出現錯誤，要我們執行\n1  npm audit fix -force   執行完之後就安裝好了，接著輸入\n1  picgo   來確認是否有安裝成功，有時候可能會出現\n1  檔案未經數位簽署這個指令碼將不會在系統上執行   之類之類的句子，這時候可以輸入\n1  Set-ExecutionPolicy RemoteSigned   來允許執行，這時候在輸入picgo應該就可以看到這樣子的畫面了\n到這一步本地端的設定已經完成80%了，接下來就是要選擇要使用哪種圖片空間\nGithub  首先先到Github創建一個公開的Repository，名字隨意就好   接著把這個Repository的URL複製下來  1  https://github.com/Hoxton019030/Typora    右上角個人頭像點開，選擇Settings   左側選項最下面有一個Developer settings   選擇Personal access tokens   選擇 Generate new token   輸入這個token的名稱，隨便取就好，Expiration看個人喜好，我很懶，所以我選擇永久，下面的select scopes勾選repo   接著會產生一組ghp開頭的token，這組序號只會在這裡以明碼出現一次，接下來永遠都不會再以明碼的方式呈現所以請好好記起來 然後到Typora的偏好設定裡打開開啟設定檔，通常會是用一個文本編輯器打開，通常都是vscode啦   接著把這串東西複製貼上去  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  { \u0026#34;picBed\u0026#34;: { \u0026#34;current\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;uploader\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;github\u0026#34;: { \u0026#34;repo\u0026#34;: \u0026#34;Hoxton019030/Typora\u0026#34;, //這串對應的是使用者名稱+Repo名稱，改成自己的 \u0026#34;token\u0026#34;: \u0026#34;ghp_xxxxxxxxxxxxxxxxxxxx\u0026#34;, //這邊把剛剛產生的token貼上去 \u0026#34;path\u0026#34;: \u0026#34;data/\u0026#34;, //圖片要上傳到哪個資料夾，可以先不用設定， \u0026#34;customUrl\u0026#34;: \u0026#34;https://raw.githubusercontent.com/Hoxton019030/Typora/main\u0026#34;, //把Hoxton019030/Typora改成你自己的repo \u0026#34;branch\u0026#34;: \u0026#34;main\u0026#34; //應該也不用動 } }, \u0026#34;picgoPlugins\u0026#34;: {} }    完成之後應該長這個樣子，接著按存檔   接著回到設定，試著按看看測試圖片上傳  如果成功的話就會出現這樣的畫面\n就代表你成功了！\n 如果你在按一次測試圖片上傳，由於上傳的圖片檔名一模一樣，會報錯，這樣是正常現象，請不要驚慌\n imgur  首先先辦帳號 https://api.imgur.com/oauth2/addclient 點擊這個網址 老樣子，名字隨意取就好，然後Authorization type選擇第二個   接著會跳出畫面，會告訴你你的Client ID是什麼，請複製下來   接著到偏好設定裡面打開開啟設定檔，通常會用vscode開啟   接著把這段複製貼上上去  1 2 3 4 5 6 7 8 9 10 11  { \u0026#34;picBed\u0026#34;: { \u0026#34;current\u0026#34;: \u0026#34;imgur\u0026#34;, \u0026#34;uploader\u0026#34;: \u0026#34;imgur\u0026#34;, \u0026#34;imgur\u0026#34;:{ \u0026#34;clientId\u0026#34;: \u0026#34;XXXXXXXXXXX\u0026#34; } }, \u0026#34;picgoPlugins\u0026#34;: {} }   貼上去之後應該會長這個樣子\n 然後存檔之後，回到偏好設定，按「測試圖片上傳」  跳出這個就代表成功上傳了！\n小結 這樣子只要在typora裡面貼上圖片，typora就會自動幫我們上傳圖片到圖片空間了。\n","date":"2022-10-08T01:02:04+08:00","image":"https://i.imgur.com/W6FAkN1.png","permalink":"https://hoxtonhsu.com/p/typora-%E5%A6%82%E4%BD%95%E4%B8%8A%E5%82%B3%E5%9C%96%E7%89%87%E6%95%99%E5%AD%B8-%E4%BD%BF%E7%94%A8github-imagur%E4%BD%9C%E7%82%BA%E5%9C%96%E7%89%87%E7%A9%BA%E9%96%93/","title":"TYPORA 如何上傳圖片(教學 使用Github , imagur作為圖片空間)"},{"content":"​\t到底要不要進事務所？\n我想一開始就給出解答\n如果不知道做什麼就進事務所吧！\n​\t如果是會計系的學生，在大學期間一定有想過自己到底要不要進入所謂的四大（勤業、資誠、安侯、安永），我在大學的時候對於這個問題倒是沒太多想法，只覺得進入四大事務所好像很威風，出入信義區，西裝革履的樣子，名稱也是國際上有名公司，怎麼想都覺得很穩，能出什麼問題？\n當然實際進去之後我就後悔了，發現這樣的生活根本不是自己想要的，索性的待到一月，把年終獎金還有到職獎金，以及政府的青年就業補助的錢領一領之後，就趕緊跑回高雄準備轉換跑道，做什麼都行，但這輩子絕對不會在做會計了。\n但離職過後也快一年，轉換工作也算成功，但持續的一直有在Follow會計這個圈子，所以想說來分享一下自己的一些想法，希望可以幫助到一些會計系的學生。\n 一份工作一定是有好有壞的，事務所的工作則是將好與壞的那非常極端，這篇文章先來講「我」覺得事務所好的地方，下一篇文章再來講我為什麼離職。\n  事務所的名聲   事務所的名聲是我在離職之後最直接的感受，在自我介紹或是之後轉換跑道的面試，第一個被問的問題都是\n「你之前在資誠耶，很好的一間公司？怎麼會想要離職轉換跑道呢？」\n誠然四大在會計系學生的眼中已經是臭到不能再臭的公司，但出了事務所之後，只要待的公司不是太鳥的那種，基本上四大的經歷即使不到亮眼，但也絕對不會是一個看不上眼的經歷。\n 事務所是一家很大的公司   在離職之後第二個很深的感受是，四大確實是一間很大的公司，在信義區的精華地段裡有很多層樓的辦公室，有包場的尾牙，會請藝人來唱歌，還有很完善的公司分工制度。我現在的公司就是一家在中山區普通商辦大樓裡面的辦公室，員工數大概也就十來人左右，也沒什麼完整的分工制度，有時候感覺一個人要身兼多職。\n而且我相信很多人離職之後，第二家公司的規模都不會再有四大那樣的規模，所以我覺得可以來四大體驗看看一家員工數破千的公司感覺是怎麼樣的。\n 事務所的工作強度   這點其實很諷刺，我之前在的組別是最近很夯的資誠A11 AKA 獨立所疊字組。說實話當時也沒覺得什麼地不地獄的，當你看同事在加班，組長在加班，經理們也在加班，其實當下也會覺得沒什麼，反正大家就一起加班，有時候晚上六點多，同事們相約訂餐的畫面總讓我想起國小在讀安親班的感覺。\n我在事務所的上班的大概就是9月入職然後到1月初離職，唯一接觸到的忙季大概就是十月，那時候星期一到五大概都是9點10點那邊回家，差不多有三天是待到11點才走（11點就可以走是因為資誠是在國貿大樓，國貿大樓11點就要關門，所以才有機會回家Q_Q），星期六大概是10點11點進所內，然後可能晚上8、9點離開，至於星期天我是沒進過所內，快樂的小確幸～\n在這樣中強度的加班強度下，我離職之後，不管待哪家公司我都覺得好爽，這可能也是事務所很諷刺的一個好處吧，畢竟從四大出來的，每個都是見過地獄的人，到哪裡都像是天堂一樣。\n 哈哈，可能真的太久沒寫文章了，感覺原本腦中有很多想法，突然要寫就寫不出什麼東西來，自己寫完再回頭來看自己列的這幾點，發現真的是蠻無聊的幾個點，也不構成什麼吸引力，但要問我後悔進入事務所嗎？其實還蠻慶幸我有進入事務所的，因為世界上真的找不太到比那更爛的工作了，我也是在那段期間真的很想離職，有這樣的念頭之後才知道自己到底想做的是什麼，這可能就是所謂的「在極大的痛苦中感覺精神甦醒吧」，總之我想說的是，不管你是台政北或是私科會計，不知道做啥就是選事務所，進去之後就會知道原來有這麼爛的工作，就會強迫自己去想自己到底要做什麼，如果做得下去那也很好，事務所的履歷還是有一點點用的（但我都建議最好是待到組長會比較有用一點）。\n接下來下一篇文章會聊聊我為什麼從事務所離職，應該蠻多可以談的～\n","date":"2022-10-08T00:36:13+08:00","image":"https://i.imgur.com/aHMlhAm.png","permalink":"https://hoxtonhsu.com/p/%E5%BE%9E%E5%85%A5%E8%81%B7%E5%88%B0%E9%9B%A2%E8%81%B7%E4%BA%8B%E5%8B%99%E6%89%80%E7%9A%84%E6%97%A5%E5%AD%90%E4%B9%8B%E8%A9%B2%E9%80%B2%E4%BA%8B%E5%8B%99%E6%89%80%E5%97%8E/","title":"從入職到離職，事務所的日子之《該進事務所嗎？》"},{"content":"目錄  Filter(過濾器)Interceptor(攔截器)AOP(剖面導向程式設計)之差異  Filter  Interceptor AspectJ    AspectJ 1 2  graph TD; AOP ---\u0026gt; SpringAop \u0026amp; AspectJ   AOP (概念) 面向切面編程，利用AOP可以對業務邏輯的各個部分進行隔離，使得業務邏輯各部分之間的耦合度降低，提高程式的可重用性，同時提高開發的效率\n不修改原始碼，從而擴充新功能\nFilter(過濾器)Interceptor(攔截器)AspectJ(AOP)之差異 1 2 3 4 5 6 7 8 9 10 11  flowchart LR; 1((使用者))--發送請求 --\u0026gt;Filter\\n+統一設置編碼\\n+過濾敏感字\\n+登入驗證\\n+URL級別的訪問權限控制\\n+數據壓縮 --\u0026gt;dispatcher --\u0026gt;Interceptor\\n+權限驗證\\n+登入驗證\\n+性能檢測 --\u0026gt;AOP\\n+日誌紀錄 --\u0026gt;2(Controller) -1[粗糙]--能處理request的精細程度----\u0026gt;-2[細緻]   Filter 1 2 3 4 5 6  flowchart LR; 1[瀏覽器]---\u0026gt;2{過濾器}---\u0026gt;3[Web資源] 3[Web資源]--\u0026gt;2{過濾器}--\u0026gt;1[瀏覽器]   在HttpServletRequest到達Servlet之前，過濾、處理一些資訊，本身依賴Sevlet容器，不能獲取SpringBean的一些資訊，它是javax.servlet.FilterChain的項目，不是Springboot\n可以做什麼\n 修改Request, Response 防止xss(Cross-Site-SCripting跨網站指令碼)攻擊 包裝二進制流  自定義Filter  以註解方式製作Filter  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  /** * 網路上教學蠻多都是implenments filter，但我建議extend GenericFilterBean * 會比較方便一點，省去implenments init(), distory()的麻煩 */ @Slf4j @Component @WebFilter(filterName = \u0026#34;f1\u0026#34;,urlPatterns = {\u0026#34;*.html\u0026#34;,\u0026#34;*.jsp\u0026#34;,\u0026#34;/\u0026#34;}) //filterName就只是一個名稱可以，隨意就好，urlPattern是用來指定哪些url要經過這個過濾器 public class HiFilter extends GenericFilterBean { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { log.info(\u0026#34;Hello Hoxton\u0026#34;); chain.doFilter(request,response); //代表這個Filter已經作用完畢，可以把request,response交給下一個Filter了  } }   結果如上\n 以Java配置方式製作Filter  1 2 3 4 5 6 7 8 9 10 11 12 13 14  @Slf4j /** * 網路上教學蠻多都是implenments filter，但我建議extend GenericFilterBean * 會比較方便一點，省去implenments init(), distory()的麻煩 */ public class HiFilter extends GenericFilterBean { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { log.info(\u0026#34;Hello Hoxton\u0026#34;); chain.doFilter(request,response); //代表這個Filter已經作用完畢，可以把request,response交給下一個Filter了  } }   1 2 3 4 5 6 7 8 9  @Configuration public class FilterConfig { @Bean public FilterRegistrationBean heFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(new HiFilter()); registration.addUrlPatterns(\u0026#34;/*\u0026#34;); //配置相關的路徑  return registration; } }    一些其他的config設置，僅供參考，與上面釋例無關\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  @Configuration public class FilterConfig { //test @Bean public FilterRegistrationBean\u0026lt;Filter\u0026gt; logProcessTimeFilter() { FilterRegistrationBean\u0026lt;Filter\u0026gt; bean = new FilterRegistrationBean\u0026lt;\u0026gt;(); bean.setFilter(new LogProcessTimeFilter()); //設定想要使用哪一個Filter  bean.addUrlPatterns(\u0026#34;/*\u0026#34;); //設置哪些url會觸發Filter，設置成/* 就代表全部都會吃到，/user/*就代表/user開頭的都會吃到  bean.setName(\u0026#34;logProcessTimeFilter\u0026#34;); //設置要叫什麼名字  bean.setOrder(0); //設定過濾器的執行順序  return bean; } @Bean public FilterRegistrationBean\u0026lt;Filter\u0026gt; logApiFilter() { FilterRegistrationBean\u0026lt;Filter\u0026gt; bean = new FilterRegistrationBean\u0026lt;\u0026gt;(); bean.setFilter(new LogApiFilter()); //設定想要使用哪一個Filter  bean.addUrlPatterns(\u0026#34;/*\u0026#34;); //設置哪些url會觸發Filter，設置成/* 就代表全部都會吃到，/user/*就代表/user開頭的都會吃到  bean.setName(\u0026#34;logApiFilter\u0026#34;); //設置要叫什麼名字  bean.setOrder(1); //設定過濾器的執行順序  return bean; } @Bean public FilterRegistrationBean\u0026lt;Filter\u0026gt; printResponseRequestFilter() { FilterRegistrationBean\u0026lt;Filter\u0026gt; bean = new FilterRegistrationBean\u0026lt;\u0026gt;(); bean.setFilter(new PrintResponseRequest()); //設定想要使用哪一個Filter  bean.addUrlPatterns(\u0026#34;/*\u0026#34;); //設置哪些url會觸發Filter，設置成/* 就代表全部都會吃到，/user/*就代表/user開頭的都會吃到  bean.setName(\u0026#34;printResponseRequestFilter\u0026#34;); //設置要叫什麼名字  bean.setOrder(2); //設定過濾器的執行順序  return bean; } }    SpringBoot本身也提供了許多不同的Filter供使用，參考如下\n常用的有以下幾個\n CharacterEncodingFilter(用於處理編碼問題) HiddenHttpMethodFilter(隱藏Http函數) HttpPutFormContentFilter(form表單處理) RequesrtContextFilter(請求上下文)  其他資訊可以詳閱Spring MVC中各个filter的用法\n其中以OncePerRequestFilter最常被使用，這個Filter會去過濾每一個Request請求，且不會重複執行，且這個Filter有一個doFilterInternal()的方法，供我們撰寫Filter邏輯因doFilter()的方法已在OncePerRequestFilter裡面實現了，可以用來做Jwtoken的登入驗證，程式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  @Component public class JwtAuthenticationFilter extends OncePerRequestFilter { @Autowired private JwtService jwtService; @Autowired private UserDetailsService userDetailsService; //注入JwtService UserDetailsService，分別用來解析Token與查詢使用者詳情  @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String authHeader = request.getHeader(HttpHeaders.AUTHORIZATION); if (authHeader != null) { String accessToken = authHeader.replace(\u0026#34;Bearer \u0026#34;, \u0026#34;\u0026#34;); //從請求標頭中取得Authorization欄位中的值  Map\u0026lt;String, Object\u0026gt; claims = jwtService.parseToken(accessToken); //擷取出後面的JWT字串，接著解析它  String username = (String) claims.get(\u0026#34;username\u0026#34;); //從claims物件中取得username欄位的值  UserDetails userDetails = userDetailsService.loadUserByUsername(username); //並透過userDetailService查詢使用者詳情。這也代表JWT的內容(payload)必須包含username這個欄位  //在filter中查詢使用者的目的，是為了將該次請求所代表的驗證後資料(Authentication)帶進security中的Context。  //Context是一種較抽象的概念，可以想像成該次請求的身分狀態  Authentication authentication = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); //為了將這個請求的使用者身分告訴伺服器，我們建立UsernamePasswordAuthenticationToken的物件，其中第三個參數放GrantedAuthority的List， 作為API的授權檢查  //第一個參數(principal)傳入使用者詳請(UserDetails)。  // 而第二個參數是credential，通常是密碼，但不傳入也無訪  //經由傳入principal，我們得以在業務邏輯中從Context輕易獲取使用者身分的資料  SecurityContextHolder.getContext().setAuthentication(authentication); } filterChain.doFilter(request, response); } }   配置完後再將這個Filter加入Security的過濾鍊\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private UserDetailsService userDetailsService; @Autowired private JwtAuthenticationFilter jwtAuthenticationFilter; /** * 協助帳號密碼認證的東西 * @return */ @Override @Bean public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } //加入Security的過濾鍊  protected void configure(HttpSecurity http) throws Exception { http.authorizeHttpRequests() .antMatchers(HttpMethod.GET, \u0026#34;/users/**\u0026#34;).hasAuthority(MemberAuthority.SYSTEM_ADMIN.name()) // .antMatchers(HttpMethod.GET,\u0026#34;/h2/**\u0026#34;).hasAuthority(MemberAuthority.SYSTEM_ADMIN.name())  .antMatchers(HttpMethod.GET,\u0026#34;/login/**\u0026#34;).permitAll() // .antMatchers(HttpMethod.POST,\u0026#34;login\u0026#34;).permitAll() // .antMatchers(HttpMethod.POST, \u0026#34;/users\u0026#34;).permitAll()  .anyRequest().permitAll() .and() .addFilterBefore(jwtAuthenticationFilter, UsernamePasswordAuthenticationFilter.class) //於UsernamePasswordAuthenticationFilter進行認證  .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .csrf().disable() .formLogin(); http.headers().frameOptions().disable(); //讓spring Security可以和h2建立連線  } /** * * @param auth 配置全局驗證資訊，如Authentication Provider,UserDetailService等等資訊， * authenticationManager會接收到UsernamePasswordAuthenticationToken傳入的資料後 * 調用SecurityConfig中所配置的userDetailsService,passwordEncoder來協助驗證 * * @throws Exception */ protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService).passwordEncoder(new BCryptPasswordEncoder()); } }   一些Code的示範\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class LogProcessTimeFilter extends OncePerRequestFilter { /** * @param request 請求 * @param response 回應 * @param filterChain 過濾鏈 會將現有的filter給串聯起來，當請求進入後端，需要依序經過它們才會達到Controller，相對的，當回應離開Controller，則是按照相反的方向經過那些Filter * @throws ServletException * @throws IOException */ @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { long startTime = System.currentTimeMillis(); filterChain.doFilter(request, response); //doFilter:相當於將請求送至Controller。  long endTime = System.currentTimeMillis(); long processTime = endTime - startTime; System.out.println(\u0026#34;processTime = \u0026#34; + processTime); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  /** * Controller收到的請求主體(RequestBody)和回應主體(ResponseBody) * 分別由HttpServletRequest與HttpServletResponse的InputStream、OutputStream轉化而來， * 但資料流只能讀取一次，如果在Filter層就被讀掉，可能會導致後面都收不到資料 * 為了保留主體中的資料，我們將請求主體與回應主體包裝成ContentCachingResponseWrapper ContentCachingRequestWrapper * 再如同往常傳入FilterChain * * 這兩個Wrapper的特色是會在內部備份一個ByteArrayOutputStream，我們只要呼叫這兩個Wrapper的 * getContentAsByteArray就可以無限制地取得主體內容 */ public class PrintResponseRequest extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { ContentCachingRequestWrapper requestWrapper = new ContentCachingRequestWrapper(request); ContentCachingResponseWrapper responseWrapper = new ContentCachingResponseWrapper(response); filterChain.doFilter(requestWrapper, responseWrapper); // logApi(request, response);  logBody(requestWrapper,responseWrapper); responseWrapper.copyBodyToResponse(); } private void logApi(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { int httpStatus = response.getStatus(); //200,403,404之類的  String httpMethod = request.getMethod(); String uri = request.getRequestURI(); String params = request.getQueryString(); if (params != null) { uri += \u0026#34;?\u0026#34; + params; } System.out.println(String.join(\u0026#34; \u0026#34;, String.valueOf(httpStatus), httpMethod, uri)); } private void logBody(ContentCachingRequestWrapper request, ContentCachingResponseWrapper response) { String requestBody = getContent(request.getContentAsByteArray()); System.out.println(\u0026#34;Request: \u0026#34; + requestBody); String responseBody = getContent(response.getContentAsByteArray()); System.out.println(\u0026#34;Response: \u0026#34; + responseBody); } /** * @param content * @return 返回JSON字串 */ private String getContent(byte [] content){ String body = new String(content); return body.replaceAll(\u0026#34;[\\n\\t]\u0026#34;, \u0026#34;\u0026#34;); //去除換行\\n與定位符號\\t  } }   Interceptor 本身是AOP的一種應用，其實攔截器跟過濾器是可以互相替換的，功能其實差不多，只是攔截器可以在請求到達Controller或是回應回傳出Contrller時進行攔截，攔截成功時可以實做一些自定義的業務邏輯進行修改，且Interceptor是Springboot下的一個功能org.springframework.web.servlet.HandlerInterceptor\n可以用來\n 性能監控：紀錄請求的處理時間，比如說請求處理太久（超過500毫秒） 登入檢測   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  graph LR; request--\u0026gt;id1 id1--\u0026gt;id2--\u0026gt;id4--\u0026gt;id3--\u0026gt;id6--\u0026gt;id5 subgraph 攔截器1 direction TB id1[\u0026#34;preHandle()\u0026#34;] id3[\u0026#34;postHandler()\u0026#34;] id5[\u0026#34;afterCompletion()\u0026#34;] end subgraph 攔截器2 direction TB id2[\u0026#34;preHandle()\u0026#34;] id4[\u0026#34;postHandler()\u0026#34;] id6[\u0026#34;afterCompletion()\u0026#34;] end   要實現interceptor有兩種方式\n 實作HandlerInterceptor 繼承HandlerInterceptorAdapter  釋例\n 自定義攔截器  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class LogInterceptor extends HandlerInterceptorAdapter { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { long startTime = System.currentTimeMillis(); System.out.println(\u0026#34;\\n-------- LogInterception.preHandle --- \u0026#34;); System.out.println(\u0026#34;Request URL: \u0026#34; + request.getRequestURL()); System.out.println(\u0026#34;Start Time: \u0026#34; + System.currentTimeMillis()); request.setAttribute(\u0026#34;startTime\u0026#34;, startTime); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\u0026#34;\\n-------- LogInterception.postHandle --- \u0026#34;); System.out.println(\u0026#34;Request URL: \u0026#34; + request.getRequestURL()); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\u0026#34;\\n-------- LogInterception.afterCompletion --- \u0026#34;); long startTime = (Long) request.getAttribute(\u0026#34;startTime\u0026#34;); long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;Request URL: \u0026#34; + request.getRequestURL()); System.out.println(\u0026#34;End Time: \u0026#34; + endTime); System.out.println(\u0026#34;Time Taken: \u0026#34; + (endTime - startTime)); } }    註冊攔截器  1 2 3 4 5 6 7 8 9 10 11 12  @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new LogInterceptor()); registry.addInterceptor(new OldLoginInterceptor()).addPathPatterns(\u0026#34;/admin/oldLogin\u0026#34;); registry.addInterceptor(new AdminInterceptor()).addPathPatterns(\u0026#34;/admin/*\u0026#34;).excludePathPatterns(\u0026#34;/admin/oldLogin\u0026#34;); } }   AspectJ 屬於一種AOP框架\n 動態代理(Spring5本身已經封裝了)  有兩種情況的動態代理   有介面(JDK動態代理)\n1 2 3  interface UserDao{ public void login(); }   1 2 3 4  class UserDaoImpl implements　UserDao{ public void login(){ } }   創建UserDao介面實現類的代理對象，代理對象會有被代理對象的所有方法，並且增強\n  無介面(CGLIB動態代理)\n1 2 3 4 5  class User{ public void add (){ } }   1 2 3 4 5  class Person extends User{ public void add(){ super.add(); } }         AOP(JDK動態代理) 使用JDK的動態代理，要使用Proxy類裡面的方法來創建出代理對象 newProxyInstance(類加載器,增強方法所在的類，這個類實現的介面,實現這個接口(InvocationHandler)\n編寫JDK動態代碼\n1 2 3 4 5 6  public interface UserDao { public int add (int a,int b); public String update(String id); }   1 2 3 4 5 6 7 8 9 10 11 12 13  public class UserDaoImpl implements UserDao{ @Override public int add(int a, int b) { System.out.println(\u0026#34;add方法執行了\u0026#34;); return a+b; } @Override public String update(String id) { return id; } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  package com.example.aop; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.util.Arrays; /** * @author Hoxton * @version 1.1.0 */ public class JDKProxy { public static void main(String[] args) { Class[] interfaces = {UserDao.class}; UserDaoImpl userDao = new UserDaoImpl(); UserDao dao = (UserDao) Proxy.newProxyInstance(JDKProxy.class.getClassLoader(), interfaces, new UserDaoProxy(userDao)); //此dao已經不是原本的dao，而是新的代理類dao了  int result = dao.add(1, 2); System.out.println(\u0026#34;result = \u0026#34; + result); } } //創建代理對象的代碼 class UserDaoProxy implements InvocationHandler { //1. 把創建的是誰的代理對象，把誰傳遞進來  // 有參建構子  private Object obj; public UserDaoProxy(Object obj) { this.obj = obj; } //增強的邏輯  @Override public Object invoke(Object proxy, Method method, Object[] methodArgs) throws Throwable { //方法之前  System.out.println(\u0026#34;方法之前執行...\u0026#34; + method.getName() + \u0026#34;傳遞的參數...\u0026#34; + Arrays.toString(methodArgs)); //被增強的方法執行  Object res = method.invoke(obj, methodArgs); //方法之後  System.out.println(\u0026#34;方法之後執行...\u0026#34; + obj); return res; } }   AOP專業術語   連接點\n一個類裡面中，能被增強的方法就叫連接點，下面這個類就有四個連接點\n1 2 3 4 5 6  class User{ add(); update(); select(); delete(); }     切入點\n實際被增強的方法，就叫切入點\n  通知(增強)\n  實際增強的邏輯部分稱為通知(增強)\n  通知有多種類型\n  前置通知\n在切入點前執行\n  後置通知\n在切入點後執行\n  環繞通知\n在切入點前後執行\n  異常通知\n出現異常時執行\n  最終通知\n執行到try\u0026hellip;catch的final時執行\n      切面\n是一個動作\n 把通知應用到切入點的過程，就叫切面    AOP(準備)   Spring 框架一般都是基於AspectJ實現的AOP操作\n  什麼是AspectJ\n AspectJ不是Spring的組成部分，是一個獨立的AOP框架， 一般把AspectJ和Spring框架一起使用，進行AOP操作    基於Aspect實現AOP操作\n xml配置文件實現 基於註解方法實現(主要使用)    再專案裡面引入AOP依賴\n  切入點表達式\n  切入點表達式的作用: 知道對哪個類的哪個方法進行增強\n  語法結構:\nexecution( [權限修飾符] [返回類型] [類全路徑] [方法名稱] ( [參數列表] ) )\n  權限修飾符: public, private, *(代表不論是public, private 都選)\n  返回類型: String, int\n  類全路徑: com.hoxton\u0026hellip;\u0026hellip;.\n  方法名稱: 就方法名稱\n  參數列表: 有哪些參數\n舉例\n  對com.hoxton.dao.BookDao類裡面的add方法進行增強\n  1  execution(* com.hoxton.dao.BookDao.add(..) )       對com.hoxton.dao.BookDao類的所有方法進行增強\n  1  execution(* com.hoxton.dao.BookDao.*(..))       對com.hoxton.dao包裡的所有類，類裡面的髓有方法進行增強\n  1  excution(* com.hoxton.dao.*.*(..))         within([package名].* )或( [package名]..*)\n舉例\n          AOP操作(Aspect J 註解)  創建類，在類裡面定義方法  1 2 3 4 5 6  public class User { public void add(){ System.out.println(\u0026#34;add\u0026#34;); } }    創建增強類(編寫增強邏輯)\n  在增強類的裡面，創建方法，讓不同方法代表不同通知類型\n1 2 3 4 5  public class UserProxy { public void before(){ System.out.println(\u0026#34;before\u0026#34;); } }       進行通知的配置\n 在Spring    Log4j 2 1 2 3 4  flowchart TD; 8[\u0026#34;ALL(全輸出不留情)\u0026#34;]---\u0026gt;7[\u0026#34;Trace(更細的除錯資訊，通常用來追蹤城市流程的日誌)\u0026#34;]---\u0026gt;6[\u0026#34;DEBUG(除錯資訊的日志)推薦★\u0026#34;]---\u0026gt;5[\u0026#34;INFO(一般資訊的日志)推薦★\u0026#34;]---\u0026gt;4[\u0026#34;WARN(可能導致錯誤的日志)\u0026#34;]---\u0026gt;3[\u0026#34;ERROR(造成應用錯誤停止的日志)\u0026#34;]---\u0026gt;2[\u0026#34;FETAL(造成應用程式停止的日志)\u0026#34;]---\u0026gt;1[\u0026#34;OFF(不輸出任何日志)\u0026#34;]   參考 https://www.cnblogs.com/itlihao/p/14329905.html\nhttps://blog.csdn.net/fly910905/article/details/86537648\nSpringBoot攔截器(Interceptor)詳解\nSpring Boot使用過濾器和攔截器分別實現REST介面簡易安全認證\n  ","date":"2022-10-07T22:41:52+08:00","image":"https://i.imgur.com/B7GhSw1.png","permalink":"https://hoxtonhsu.com/p/%E5%9F%BA%E7%A4%8Eaop%E4%BB%8B%E7%B4%B9-filter-interceptor-aspectj/","title":"基礎AOP介紹-Filter Interceptor AspectJ"},{"content":"SpringBoot-Scheduling 用來做定期任務的東西，有兩種\n Spring schedule：只適合處理簡單的計畫任務，不能處理分散式的任務，當任務太多時，可能出現阻塞、崩潰、延遲啟動等問題 Quartz：更強大的一個排程器，能夠配置上百甚至上千的事務。  Spring Schedule 步驟  在啟動類上加上@EnableScheduling  1 2 3 4 5 6 7  @SpringBootApplication() @EnableScheduling public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } }   在方法上加上@Scheduled  1 2 3 4 5 6 7  @Component public class Task { @Scheduled(fixedDelay = 10 * 100) public void printLocalTime() { System.out.println(LocalTime.now().toString()); } }   1 2 3 4  @Scheduled(cron = \u0026#34;1 * * * * ?\u0026#34;,zone = \u0026#34;Asia/Taipei\u0026#34;) public void printPer5second(){ log.info(\u0026#34;cron\u0026#34;); }   1 2 3 4  @Scheduled(cron = \u0026#34;0/1 * * * * ?\u0026#34;,zone = \u0026#34;Asia/Taipei\u0026#34;) public void printPer5second(){ log.info(\u0026#34;cron\u0026#34;); }   Cron表達式(七子表達式) 表達式生成工具\nCron語源來自Chronos，是希臘神話中掌管時間的神柯羅諾斯(Chronos)。\n   秒 分 時 日 月 周 年(可選)     1 * * * * ? ?     秒：0-59 分：0-59 時 ：0-23 日：1-31 月：0-11或\u0026quot;JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, DEC\u0026quot; 周：1-7或SUN, MON, TUE, WED, THU, FRI,SAT 年  想像一個時鐘\u0026hellip;\n   當每次秒針指向一秒時 1 * * * * ?     當每次時針指向12時 * * 12 * * ?   每個月 1 號中午 12 點 0 0 12 1 * ?   1 月每天中午 12 點，每 5 秒 0/5 0 12 * 1 ?       字元 意義     * 表達任意值，所有值都可以匹配   ? 只用在 日 跟 周 的值域，有點表達 don’t care 的概念，無所謂，不關心到底是什麼值   - 指定範圍，前後接數字: 10-12   , 指定離散的選項: 1,5,6,8，或者的概念   / 指定增量，表達 每 的概念: 0/5 意旨從 0 開始每 5 單位   L 用在 月 跟 周 的值域。在月的話表達最後一天，在周的話前面可以加上數字 3L 表示該月最後一個星期二   W 用在日的值域表示距離最近的該月工作日: 15W，距離 15 號最近的工作日，可能往前也可能往後   LW 用在日的值域，表示最後一周的工作日   # 用在周的值域，指定特定周的特定日: “4#2” 表示第二周的星期三   C 用在日跟周的值域，指某特定個日期的後一天: 在日中寫 3C 指該月 3 號的後一天，在周中寫 2C 指該周星期一的後一天    Quartz 是一個開源的任務排程器，幾乎可以整合到任何Java應用程式中。\n它可以用來\n 安排每個晚上把資料庫內容轉存到檔案 提供定時提醒服務 族繁不及備載\u0026hellip;  底層數據結構- 堆 介紹 堆是一種特殊的樹，滿足下面兩個條件，就是一個堆\n 堆是一顆完全二元樹完整二元樹：除了最後一層以外，其他層的節點數需要達到最大(1,2,4,8. ..)  每個節點所儲存的值，必須要大於小頂堆或小於大頂堆父節點的值   小頂堆\n 完整二元樹的一些特性：快速定位父節點\n在排程器的框架中，每一個節點就是一個Job，越頻繁的Job會被放置在越上層的節點\n如何插入元素 尾插法，在尾部插入一個新的元素，然後上浮，浮到符合定義\n 除了最後一層以外，其他層的節點數需要達到最大(1,2,4,8. ..)，且最後一層節點都靠左排列 每個節點所儲存的值，必須要大於小頂堆或小於大頂堆父節點的值  如何刪除元素 將尾部(最後一個節點)放置到堆頂，然後下沉\n時間輪算法(Time Wheel) 再刪除元素的時候都需要下沉，當節點數很多時會造成性能延宕\nround 型的時間輪 任務上記錄一個round，遍歷到了就將round減一，為0時取出來執行\n分層時間輪 Cron表達式以及其他排程器所採用的底層架構，分成秒輪、分輪、小時輪、日輪、周輪、月輪、年輪\u0026hellip;，月輪迭代到了，就將任務取出放到天輪中執行\u0026hellip;，以此類推\nCron表達式(七子表達式) 表達式生成工具\nCron語源來自Chronos，是希臘神話中掌管時間的神柯羅諾斯(Chronos)。\n   秒 分 時 日 月 周 年(可選)     1 * * * * ? ?     秒：0-59 分：0-59 時 ：0-23 日：1-31 月：0-11或\u0026quot;JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, DEC\u0026quot; 周：1-7或SUN, MON, TUE, WED, THU, FRI,SAT 年  想像一個時鐘\u0026hellip;\n   當每次秒針指向一秒時 1 * * * * ?     當每次時針指向12時 * * 12 * * ?   每個月 1 號中午 12 點 0 0 12 1 * ?   1 月每天中午 12 點，每 5 秒 0/5 0 12 * 1 ?       字元 意義     * 表達任意值，所有值都可以匹配   ? 只用在 日 跟 周 的值域，有點表達 don’t care 的概念，無所謂，不關心到底是什麼值   - 指定範圍，前後接數字: 10-12   , 指定離散的選項: 1,5,6,8，或者的概念   / 指定增量，表達 每 的概念: 0/5 意旨從 0 開始每 5 單位   L 用在 月 跟 周 的值域。在月的話表達最後一天，在周的話前面可以加上數字 3L 表示該月最後一個星期二   W 用在日的值域表示距離最近的該月工作日: 15W，距離 15 號最近的工作日，可能往前也可能往後   LW 用在日的值域，表示最後一周的工作日   # 用在周的值域，指定特定周的特定日: “4#2” 表示第二周的星期三   C 用在日跟周的值域，指某特定個日期的後一天: 在日中寫 3C 指該月 3 號的後一天，在周中寫 2C 指該周星期一的後一天    ​\n重要API及概念  記得Job類一定要是public class，不然Scheduler會讀不到\n 釋例一：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class Quartz { public static void main(String[] args) { MyJob myJob = new MyJob(); JobDetail jobDetail = JobBuilder.newJob(MyJob.class) .withIdentity(\u0026#34;job1\u0026#34;, \u0026#34;group1\u0026#34;) .build(); Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(\u0026#34;trigger1\u0026#34;, \u0026#34;trigger1\u0026#34;) .startNow() .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(1).repeatForever()) .build(); try { Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); scheduler.scheduleJob(jobDetail,trigger); scheduler.start(); } catch (SchedulerException e) { throw new RuntimeException(e); } ; } }   1 2 3 4 5 6  public class MyJob implements Job { @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException { System.out.println(\u0026#34;MyJob execute:\u0026#34; + new Date()); } }   釋例二\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class HelloJob { public static void main(String[] args) { try { Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); scheduler.start(); JobDetail jobDetail = JobBuilder.newJob(SayHello.class) .withIdentity(\u0026#34;job1\u0026#34;, \u0026#34;group1\u0026#34;) //Job1是名字，具有唯一性，group1是這個Job屬於哪一組，同一組的Job可以共享相同的邏輯來處理Job。需要name與Job才可以組成一個JobKey  .usingJobData(\u0026#34;username\u0026#34;, \u0026#34;Hoxton\u0026#34;) .usingJobData(\u0026#34;age\u0026#34;, \u0026#34;20\u0026#34;) .withDescription(\u0026#34;desc-demo\u0026#34;) .build(); SimpleTrigger trigger = TriggerBuilder.newTrigger() .withIdentity(\u0026#34;trigger1\u0026#34;, \u0026#34;group1\u0026#34;) .startNow() .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(1).repeatForever()) .build(); scheduler.scheduleJob(jobDetail,trigger); scheduler.start(); // scheduler.shutdown();  } catch (SchedulerException e) { throw new RuntimeException(e); } } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  @Slf4j @NoArgsConstructor public class SayHello implements Job { @Override public void execute(JobExecutionContext context) throws JobExecutionException { JobDetail jobDetail = context.getJobDetail();//從context中獲取屬性  JobKey key = jobDetail.getKey(); Class\u0026lt;? extends Job\u0026gt; jobClass = jobDetail.getJobClass(); String description = jobDetail.getDescription(); JobDataMap jobDataMap = jobDetail.getJobDataMap(); String username = jobDataMap.getString(\u0026#34;username\u0026#34;); int age = jobDataMap.getIntValue(\u0026#34;age\u0026#34;); log.info(\u0026#34;\\nJobKey : {},\\n JobClass : {},\\n JobDesc : {},\\n username : {},\\n age : {}\u0026#34;, key, jobClass.getName(), description, username, age); } }   Scheduler 生命週期由ScheduleFactory建立開始，呼叫shutdown方法結束。\n當Schduler建立，任何關於Schduling相關的事情，都由它控制\n 新增 刪除 列出所有Job 暫停觸發器  在Start之前不會做任何事情\nJob 你希望被排程器排程的任務元件介面，定義如何執行，是正在執行的作業例項，一個Job可以建立多個JobDetail，擁有不同的JobDataMap。本身implement了Job類\n1 2 3  graph TD; Job ---\u0026gt; JodDetail1 \u0026amp; JodDetail2 \u0026amp; JodDetail3 \u0026amp; JodDetail...   1 2 3 4 5 6  public class SendEmail implements Job { @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException { System.out.println(\u0026#34;SendEmail\u0026#34;); } }    當Job的觸發器觸發時，排程程式的工作執行將呼叫excute()方法 該方法接收一個JobExcutionContext物件，為Job提供了豐富的執行時環境，比如schduler,trigger,jobDataMap,job,calender,time   何謂Context(上下文)\n可以理解為環境、容器的意思會比上下文更具體一點，它提供了一個程式中全域性的資訊。\n JobDetail 用於定義Job的各種屬性、各種任務，還可以用來為Job儲存狀態資訊的JobDataMap，是將Job加入scheduler時，所需要創建的一個物件，它包含了各種屬性設置，以及用於存取job實例狀態訊息的JobDataMap，在創建JobDetail時，需要將欲執行的類名傳遞給JobDetail，這樣schedule就知道要執行何種類型的job。\n1  JobDetail jobDetail=JobBulider.newJob(Job.class).bulid();   JobDataMap 實作Map介面，因此具有Key-Value，儲存可序列化資料，供Job在執行時使用。也可以使用usingJobData(key,value)在建構JobDetail的時候傳入資料，使用JobDetail.getDataMap()獲取Map。可以再透過jobDataMap取出裡面的數據\n1 2 3 4 5  JobDetail job = JobBuilder.newJob(HelloJob.class) .withIdentity(\u0026#34;helloJob\u0026#34;, \u0026#34;hello\u0026#34;)//給job命名並分組  .usingJobData(\u0026#34;jobdd\u0026#34;, \u0026#34;hello job\u0026#34;)//通過JobBuilder的usingJobData方法給JobDataMap中塞入數據  .build();   1 2 3 4 5 6 7 8 9 10  public class HelloJob implements Job { @Override public void execute(JobExecutionContext context) throws JobExecutionException { System.err.println(context.getJobDetail().getKey());// JobDetail的key又他的name和group組成 \tSystem.err.println(context.getTrigger().getKey());// Trigger的key又他的name和group組成 \tSystem.err.println(context.getJobDetail().getJobDataMap().get(\u0026#34;jobdd\u0026#34;)); System.err.println(\u0026#34;hello,quartz\u0026#34;); } }   會輸出\n`hello.helloJob\nhello.helloTrigger\nhello job\nhello, quartz\nTrigger 觸發任務執行，觸發器可能具有與Job有關的JobDataMap，以便將觸發器觸發的引數傳遞給Job，Quartz本身提供了幾種觸發器SimpleTrigger和CronTrigger是最常用到的。\nSimpleTriger 用於一次性執行作業或需要在給定的時間觸發一個作業並重複執行N次，且兩次執行時間有Delay。用在具體的時間點，並已指定的間隔時間重複執行若干次，它包含了幾種屬性：\n 開始時間 結束時間 重複次數 重複間隔  釋例一：立刻觸發一次，然後停止\n1 2 3 4 5  Date date = new Date(); Trigger trigger1 = TriggerBuilder.newTrigger() .withIdentity(\u0026#34;trigger1\u0026#34;, \u0026#34;group1\u0026#34;) .startAt(date) .build();   釋例二：指定時間觸發，每隔十秒執行一次，重複10次\n1 2 3 4 5 6 7 8  trigger = newTrigger() .withIdentity(\u0026#34;trigger3\u0026#34;, \u0026#34;group1\u0026#34;) .startAt(myTimeToStartFiring) // if a start time is not given (if this line were omitted), \u0026#34;now\u0026#34; is implied  .withSchedule(simpleSchedule() .withIntervalInSeconds(10) .withRepeatCount(10)) // note that 10 repeats will give a total of 11 firings  .forJob(myJob) // identify job with handle to its JobDetail itself  .build();   釋例三：5分鐘以後開始觸發，僅執行一次\n1 2 3 4 5  trigger = (SimpleTrigger) newTrigger() .withIdentity(\u0026#34;trigger5\u0026#34;, \u0026#34;group1\u0026#34;) .startAt(futureDate(5, IntervalUnit.MINUTE)) // use DateBuilder to create a date in the future  .forJob(myJobKey) // identify job with its JobKey  .build();   釋例四：立即觸發，每個5分鐘執行一次，直到22:00：\n1 2 3 4 5 6 7  trigger = newTrigger() .withIdentity(\u0026#34;trigger7\u0026#34;, \u0026#34;group1\u0026#34;) .withSchedule(simpleSchedule() .withIntervalInMinutes(5) .repeatForever()) .endAt(dateOf(22, 0, 0)) .build();   釋例五：在下一小時整點觸發，每個2小時執行一次，一直重複：\n1 2 3 4 5 6 7 8 9 10 11  trigger = newTrigger() .withIdentity(\u0026#34;trigger8\u0026#34;) // because group is not specified, \u0026#34;trigger8\u0026#34; will be in the default group  .startAt(evenHourDate(null)) // get the next even-hour (minutes and seconds zero (\u0026#34;00:00\u0026#34;))  .withSchedule(simpleSchedule() .withIntervalInHours(2) .repeatForever()) // note that in this example, \u0026#39;forJob(..)\u0026#39; is not called which is valid  // if the trigger is passed to the scheduler along with the job  .build(); scheduler.scheduleJob(trigger, job);   CronTrigger 希望以日期作為觸發任務的板機，就用CronTriger，實務上比較常用這個\n1 2 3 4  CronTrigger trigger2 = TriggerBuilder.newTrigger() .withIdentity(\u0026#34;trigger3\u0026#34;, \u0026#34;group1\u0026#34;) .withSchedule(CronScheduleBuilder.cronSchedule(\u0026#34;0/2 * * * * ?\u0026#34;)) .build();   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  package com.how2java; import static org.quartz.CronScheduleBuilder.cronSchedule; import static org.quartz.JobBuilder.newJob; import static org.quartz.TriggerBuilder.newTrigger; import static org.quartz.SimpleScheduleBuilder.simpleSchedule; import java.util.Date; import org.quartz.CronTrigger; import org.quartz.DateBuilder; import org.quartz.JobDetail; import org.quartz.Scheduler; import org.quartz.SimpleTrigger; import org.quartz.impl.StdSchedulerFactory; public class TestQuartz { public static void main(String[] args) throws Exception{ Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); Date startTime = DateBuilder.nextGivenSecondDate(null, 8); JobDetail job = newJob(MailJob.class).withIdentity(\u0026#34;mailJob\u0026#34;, \u0026#34;mailGroup\u0026#34;).build(); CronTrigger trigger = newTrigger().withIdentity(\u0026#34;trigger1\u0026#34;, \u0026#34;group1\u0026#34;).withSchedule(cronSchedule(\u0026#34;0/2 * * * * ?\u0026#34;)) .build(); // schedule it to run!  Date ft = scheduler.scheduleJob(job, trigger); System.out.println(\u0026#34;使用的Cron表达式是：\u0026#34;+trigger.getCronExpression()); // System.out.printf(\u0026#34;%s 这个任务会在 %s 准时开始运行，累计运行%d次，间隔时间是%d毫秒%n\u0026#34;, job.getKey(), ft.toLocaleString(), trigger.getRepeatCount()+1, trigger.getRepeatInterval());  scheduler.start(); //等待200秒，让前面的任务都执行完了之后，再关闭调度器  Thread.sleep(200000); scheduler.shutdown(true); } }   JobBulider 用來建立JobDetail\n1 2 3 4 5 6 7 8  JobDetail jobDetail = JobBuilder.newJob(某個繼承了Job的類)... JobDetail jobDetail = JobBuilder.newJob(SayHello.class) .withIdentity(\u0026#34;job1\u0026#34;, \u0026#34;group1\u0026#34;) .usingJobData(\u0026#34;username\u0026#34;, \u0026#34;Hoxton\u0026#34;) .usingJobData(\u0026#34;age\u0026#34;, \u0026#34;20\u0026#34;) .withDescription(\u0026#34;desc-demo\u0026#34;) .build();   TriggerBulider\n用於建立Trigger\nIdentity 當Job和Trgger在Quartz排程程式中註冊時，會獲得標示鍵，JobKey和TriggerKey置入group中，易於組織管理，其中name與group必須唯一\n為何要將Job和Trigger分開來?  While developing Quartz, we decided that it made sense to create a separation between the schedule and the work to be performed on that schedule. This has (in our opinion) many benefits.\nFor example, Jobs can be created and stored in the job scheduler independent of a trigger, and many triggers can be associated with the same job. Another benefit of this loose-coupling is the ability to configure jobs that remain in the scheduler after their associated triggers have expired, so that that it can be rescheduled later, without having to re-define it. It also allows you to modify or replace a trigger without having to re-define its associated job.\n Job與JobDetail的一些說明  Job是正在執行的作業，JobDetail則是作業的定義 一個Job可以創建多個JobDetail，擁有不同的JobDataMap  舉例來說，今天寫了一個定時寄送信件的Job，叫做SendEmailJob，我們希望這個Job可以寄給客戶，然後在cc給你的主管，所以需要創建兩個不同的JobDetail，比如說SendEmailToClient、SendEmailToAdministor，並透過JobDataMap綁定參數傳遞至JobDetail中，這兩個JobDetail擁有各自獨立的JobDataMap，實現起來會更靈活。\n參考 官方文檔\n任務排程框架Quartz快速入門\nQuartz教學基礎\n觸發器詳細定義\n","date":"2022-10-06T23:14:21+08:00","image":"https://i.imgur.com/9or5BzU.png","permalink":"https://hoxtonhsu.com/p/java%E5%85%A7%E7%9A%84%E6%8E%92%E7%A8%8B%E5%99%A8%E4%BB%8B%E7%B4%B9/","title":"Java內的排程器介紹"}]